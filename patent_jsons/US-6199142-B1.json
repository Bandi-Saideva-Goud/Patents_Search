{"patent_number": "US-6199142-B1", "publication_id": 72580763, "family_id": 24709688, "publication_date": "2001-03-06", "titles": [{"lang": "EN", "text": "Processor/memory device with integrated CPU, main memory, and full width cache and associated method"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72521185\"><p>An integrated processor/memory device comprising a main memory, a CPU, and a full width cache. The main memory comprises main memory banks. Each of the main memory banks stores rows of words. The rows are a predetermined number of words wide. The cache comprises cache banks. Each of the cache banks stores one or more cache lines of words. Each of the cache lines has a corresponding row in the corresponding main memory bank. The cache lines are the predetermined number of words wide. When the CPU issues an address in the address space of the corresponding main memory bank, the cache bank determines from the address and the tags of the cache lines whether a cache bank hit or a cache miss has occurred in the cache bank. When a cache bank miss occurs, the cache bank replaces a victim cache line of the cache lines with a new cache line that comprises the corresponding row of the corresponding memory bank specified by the issued address.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00001\" num=\"1\"><claim-text>1. An integrated processor/memory device comprising:</claim-text><claim-text>a CPU to issue an address; </claim-text><claim-text>a cache bank; </claim-text><claim-text>a main memory bank with rows of memory cells and sense amplifiers, the main memory bank being configured to simultaneously read out with the sense amplifiers all bits stored in the memory cells of an addressed row of the rows as a new cache line when a cache miss in the cache bank occurs for the issued address, the issued address specifying the addressed row; and </claim-text><claim-text>the cache bank comprising one or more buffers with each of the buffers comprising latches, the cache bank being configured to simultaneously store in the latches of a selected buffer of the one or more buffers all of the bits of the new cache line when the cache miss occurs; </claim-text><claim-text>wherein the CPU, the main memory bank, and the cache bank are all integrated together on a chip; and </claim-text><claim-text>further wherein the number of the memory cells in each of the rows, the number of the sense amplifiers, the number of the bits of the new cache line, and the number of latches of each of the one or more buffers are all the same number. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00002\" num=\"2\"><claim-text>2. The integrated processor/memory device of claim <b>1</b> wherein:</claim-text><claim-text>the cache bank is further configured to, when a cache miss occurs for the issued address and the latches of the selected buffer store bits of a dirty cache line, simultaneously route all of the bits of the dirty cache line to the main memory bank prior to storing the bits of the new cache line; </claim-text><claim-text>the main memory bank is further configured to, when a cache miss occurs for the issued address and the latches of the selected buffer store bits of a dirty cache line, simultaneously write with the sense amplifiers all of the bits of the dirty cache line into the memory cells of a tagged row of the rows prior to reading out the bits of the new cache line; and </claim-text><claim-text>the number of bits of the dirty cache line is the same number as well. </claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00003\" num=\"3\"><claim-text>3. The integrated processor/memory device of claim <b>2</b> wherein the same number is 4096.</claim-text></claim>"}, {"num": 4, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00004\" num=\"4\"><claim-text>4. An integrated processor/memory device comprising:</claim-text><claim-text>a CPU to issue an address; </claim-text><claim-text>a cache comprising cache banks, </claim-text><claim-text>a main memory comprising main memory banks where there is a corresponding one of the cache banks for each of the main memory banks, each of the main memory banks comprising rows of memory cells and sense amplifiers, each of the main memory banks being configured to simultaneously read out with the main memory bank's sense amplifiers all bits stored in the memory cells of an addressed row of the main memory bank's rows as a new cache line when a cache miss in the corresponding cache bank occurs for the issued address, the issued address specifying the addressed row; and </claim-text><claim-text>each of the cache banks comprises one or more buffers with each of the buffers comprising latches, each of the cache banks being configured to simultaneously store in the latches of a selected buffer of the cache bank's one or more buffers all of the bits of the new cache line from the corresponding main memory bank when a cache miss in the cache bank occurs for the issued address; </claim-text><claim-text>wherein the CPU, the main memory, and the cache are all integrated together on a single chip; and </claim-text><claim-text>further wherein the number of the memory cells in each of the rows of each of the main memory banks, the number of the sense amplifiers of each of the main memory banks, the number of the bits of a new cache line from each of the main memory banks, and the number of latches in each of the one or more buffers of each of the cache banks are all the same number. </claim-text></claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00005\" num=\"5\"><claim-text>5. The integrated processor/memory device of claim <b>4</b> wherein:</claim-text><claim-text>each of the cache banks is further configured to, when a cache miss in the cache bank occurs for the issued address and the cache bank's latches store bits of a victim cache line that is dirty, simultaneously route all of the bits of the victim cache line to the corresponding main memory bank prior to storing the bits of the new cache line; </claim-text><claim-text>each of the main memory banks being further configured to, when a cache miss in the corresponding cache bank occurs for the issued address and the corresponding cache bank's latches store bits of a victim cache line that is dirty, simultaneously write with the main memory bank's sense amplifiers the bits of the victim cache line from the corresponding cache bank into the memory cells of a tagged row of the memory bank's rows prior to reading out the bits of the new cache line; and </claim-text><claim-text>the number of bits of the victim cache line is the same number as well. </claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00006\" num=\"6\"><claim-text>6. The integrated processor/memory device of claim <b>5</b> wherein:</claim-text><claim-text>each of the cache banks is further configured to, when a cache miss in another one of the cache banks occurs for the issued address and the cache bank's latches store bits of a dirty cache line, simultaneously route all of the bits of the dirty cache line to the corresponding main memory bank; </claim-text><claim-text>each of the main memory banks being further configured to, when a cache miss in one of the cache banks that is not the corresponding cache bank occurs for the issued address and the corresponding cache bank's latches store bits of a dirty cache line, simultaneously write with the main memory bank's sense amplifiers the bits of the dirty cache line from the corresponding cache bank into the memory cells of a tagged row of the memory bank's rows; </claim-text><claim-text>the number of bits of the dirty cache line is the same number as well. </claim-text></claim>"}, {"num": 7, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00007\" num=\"7\"><claim-text>7. The integrated processor/memory device of claim <b>5</b> wherein the same number is 4096.</claim-text></claim>"}, {"num": 8, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00008\" num=\"8\"><claim-text>8. A method of operating an integrated processor/memory device comprising a CPU, a main memory bank, and a cache bank integrated together on a single chip, the method comprising the steps of:</claim-text><claim-text>issuing an address with the CPU; </claim-text><claim-text>simultaneously reading out with sense amplifiers of the main memory bank all bits stored in memory cells of an addressed row of the main memory bank's rows as a new cache line when a cache miss in the cache bank occurs for the issued address, the issued address specifying the addressed row; </claim-text><claim-text>simultaneously storing in latches of a selected buffer of the cache bank's one or more buffers all of the bits of the new cache line when the cache miss occurs; </claim-text><claim-text>wherein the number of the memory cells in each of the main memory bank's rows, the number of the sense amplifiers, the number of the bits of the new cache line, the number of bits of the dirty cache line, and the number of latches of each of the cache bank's one or more buffers are all the same number. </claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00009\" num=\"9\"><claim-text>9. The method of claim <b>8</b> wherein the same number is 4096.</claim-text></claim>"}, {"num": 10, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00010\" num=\"10\"><claim-text>10. The method of claim <b>8</b> further comprising the steps of:</claim-text><claim-text>simultaneously routing all of the bits of the dirty cache line to the main memory bank prior to the storing step when the cache miss occurs and the latches of the selected buffer store bits of a dirty cache line; and </claim-text><claim-text>simultaneously writing with the sense amplifiers all of the bits of the dirty cache line into the memory cells of a tagged row of the main memory bank prior to the reading out step when the cache miss occurs and the latches of the selected buffer store the bits of the dirty cache line; </claim-text><claim-text>wherein the number of bits of the dirty cache line is the same number as well. </claim-text></claim>"}, {"num": 11, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00011\" num=\"11\"><claim-text>11. A method of operating an integrated processor/memory device comprising a CPU, a main memory, and a cache integrated together on a single chip, the main memory comprising main memory banks and the cache comprising cache banks so that there is a corresponding one of the cache banks for each of the memory banks, the method comprising the steps of:</claim-text><claim-text>issuing an address with the CPU; </claim-text><claim-text>in each of the main memory banks, simultaneously reading out with sense amplifiers of the main memory bank all bits stored in memory cells of an addressed row of the main memory bank as a new cache line when a cache miss in the corresponding cache bank occurs for the issued address, the issued address specifying the addressed row; and </claim-text><claim-text>in each of the cache banks, simultaneously storing in latches of a selected buffer of the cache bank's one or more buffers all of the bits of the new cache line when a cache miss in the cache bank occurs for the issued address; </claim-text><claim-text>wherein the number of the memory cells in each of the rows of each of the main memory banks, the number of the sense amplifiers of each of the main memory banks, the number of the bits of the new cache line, the number of bits of the dirty cache line, and the number of latches of each of the one or more buffers of each of the cache banks are all the same number. </claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00012\" num=\"12\"><claim-text>12. The device of claim <b>11</b> wherein the same number is 4096.</claim-text></claim>"}, {"num": 13, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00013\" num=\"13\"><claim-text>13. The method of claim <b>11</b> further comprising the steps of:</claim-text><claim-text>in each of the cache banks, when a cache miss in the cache bank occurs for the issued address and the cache bank's latches store bits of a victim cache line that is dirty, simultaneously routing all of the bits of the victim cache line to the corresponding main memory bank prior to storing the bits of the new cache line; </claim-text><claim-text>in each of the main memory banks, when a cache miss in the corresponding cache bank occurs for the issued address and the corresponding cache bank's latches store bits of a victim cache line that is dirty simultaneously writing with the main memory bank's sense amplifiers the bits of the victim cache line from the corresponding cache bank into the memory cells of a tagged row of the memory bank's rows prior to reading out the bits of the new cache line; and </claim-text><claim-text>the number of bits of the victim cache line is the same number as well. </claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6199142-B1-CLM-00014\" num=\"14\"><claim-text>14. The method of claim <b>13</b> further comprising the steps of:</claim-text><claim-text>in each of the cache banks, when a cache miss in another one of the cache banks occurs for the issued address and the cache bank's latches store bits of a dirty cache line, simultaneously routing all of the bits of the dirty cache line to the corresponding main memory bank; </claim-text><claim-text>in each of the main memory banks, when a cache miss in one of the cache banks that is not the corresponding cache bank occurs for the issued address and the corresponding cache bank's latches store bits of a dirty cache line, simultaneously writing with the main memory bank's sense amplifiers the bits of the dirty cache line from the corresponding cache bank into the memory cells of a tagged row of the memory bank's rows; </claim-text><claim-text>the number of bits of the dirty cache line is the same number as well.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54506469\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><p>The present invention relates generally to integrated processor/memory (P/M) devices with an on-chip cache and an on-chip main memory. In particular, it pertains to a P/M device with an on-chip cache that is as wide as the on-chip main memory (i.e., is full width).</p><h4>BACKGROUND OF THE INVENTION</h4><p>Traditionally, the development of processor and memory devices has proceeded independently. Advances in process technology, circuit design, and integrated chip (IC) architecture have led to a near exponential increase in processor speed and memory capacity. However, memory device latencies have not improved as dramatically and access times are increasingly becoming the limiter of processor performance. This is a problem known as the Memory Wall and is more fully described in <i>Hitting the Memory Wall: Implication of the Obvious, </i>by William A. Wulf and Sally A. McKee, ACM Computer Architecture News, Vol. 23, No. 1, March 1995, which is hereby explicitly incorporated by reference.</p><p>Current high performance processors, which use complex superscalar central processing units (CPUs) that interface to external off-chip main memory through a hierarchy of caches, are particularly affected by the Memory Wall problem. In fact, this CPU-centric design approach requires a large amount of power and chip area to bridge the gap between CPU and memory speeds.</p><p>The Memory Wall problem is commonly addressed by adding several levels of cache to the memory system so that small, high speed, static random access memory (SRAM) devices feed the CPU at low latencies. Combined with latency hiding techniques, such as prefetching and proper code scheduling, it is possible to run a high performance processor at reasonable efficiencies for applications with enough locality for the caches. However, while achieving impressive performance on applications that fit nicely into their caches, these processors have become increasingly application sensitive. For example, large applications such as CAD programs, data base applications, or scientific applications often fail to meet CPU based speed expectations by a wide margin.</p><p>Moreover, the CPU-centric design approach has lead to very complex superscalar processors with deep pipelines. Much of this complexity, such as out-of-order execution and register scoreboarding, is devoted to hiding memory system latency. In addition, these processors demand a large amount of support logic in terms of caches, controllers and data paths to talk to the external main memory. This adds considerable cost, power dissipation, and design complexity.</p><p>To fully utilize a superscalar processor, a large memory system is required. The effect of this is to create a bottleneck that increases the distance between the CPU and main memory. Specifically, it adds interfaces and chip boundaries which reduce the available memory bandwidth due to packaging and connection constraints.</p><p>However, integrating the processor with the memory device avoids most of the problems of the CPU-centric design approach. And, doing so offers a number of advantages that effectively compensate for the technological limitations of a single chip design.</p><p>Specifically, in CPU-centric processor designs, the instruction and data cache lines have a width that is significantly less than the width of the main memory. This is primarily due to the fact that the time to fill these cache lines from the off-chip main memory would introduce severe second order contention effects at the memory interface of the processor. As a result, such less than full width caches are unable to take advantage of the often high spatial locality of instruction and data streams.</p><p>Thus, there is a need for full width instruction and data caches that take advantage of the high spatial locality of instruction and data streams in many applications. Moreover, the corresponding U.S. Pat. No. 5,900,011, issued May 4, 1999, and hereby explicitly incorporated by reference, describes and claims the use of a victim data cache to further improve the miss rate of such a full width data cache.</p><h4>SUMMARY OF THE INVENTION</h4><p>In summary, the present invention is an integrated processor/memory device. It comprises a main memory, a CPU, and a full width cache.</p><p>The main memory has a predefined address space and comprises main memory banks. Each of the main memory banks occupies a corresponding portion of the address space and stores rows of words at memory locations with addresses in the corresponding portion of the address space. The rows are a predetermined number of words wide.</p><p>The cache comprises cache banks. Each of the cache banks is coupled to a corresponding main memory bank of the main memory banks and the CPU. Each of the cache banks comprises a cache bank line storage, a cache bank tag storage, and cache bank logic. The cache bank line storage is coupled to the corresponding main memory bank and stores one or more cache lines of words. Each of the cache lines has a corresponding row in the corresponding main memory bank. The cache lines are the predetermined number of words wide. The cache bank tag storage stores a corresponding tag for each of the cache lines. Each of the tags identifies the row in the corresponding memory bank of the corresponding cache line. The cache bank logic is coupled to the CPU, the corresponding memory bank, and the cache storage. When the CPU issues an address in the address space of the corresponding main memory bank, the cache bank logic determines from the address and the tags of the cache lines whether a cache bank hit or a cache miss has occurred in the cache bank line storage. When a cache bank miss occurs, the cache bank logic replaces a victim cache line of the cache lines with a new cache line that comprises the corresponding row of the corresponding memory bank specified by the issued address.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>Additional objects and features of the invention will be more readily apparent from the following detailed description and appended claims when taken in conjunction with the drawings, in which:</p><p>FIG. 1 is a block diagram of an integrated processor/memory (P/M) device in accordance with the present invention.</p><p>FIG. 2 is a block diagram of the main memory bank, the primary data cache bank, and instruction cache bank of each memory block of the P/M device.</p><p>FIG. 3 is a block diagram of the instruction cache bank logic of each instruction cache bank.</p><p>FIG. 4 is a state diagram of the states of the instruction cache bank logic of each instruction cache bank.</p><p>FIG. 5 is a block diagram of the primary data cache bank logic of each primary data cache bank.</p><p>FIG. 6 is a state diagram of the states of the primary data cache bank logic of each primary data cache bank.</p><p>FIG. 7 is a block diagram of the victim cache of the P/M device.</p><p>FIG. 8 is a block diagram of the victim cache logic of the victim cache.</p><p>FIG. 9 is a state diagram of the states of the victim cache logic.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE INVENTION</h4><p>Referring to FIG. 1, there is shown an exemplary embodiment of an integrated P/M device <b>100</b> in accordance with the present invention. The integrated components of the P/M device include a CPU <b>102</b>, an on-chip memory system <b>103</b>, a 64 bit data bus <b>108</b>, a 25 bit data address bus <b>110</b>, a 32 bit instruction bus <b>112</b>, a 25 bit instruction address bus <b>114</b>, and a control bus <b>116</b>. The memory system includes 16 memory blocks <b>104</b> and a victim cache <b>106</b>.</p><p>Each memory block <b>104</b> includes a corresponding main memory bank <b>118</b>, a corresponding instruction cache bank <b>120</b>, and a corresponding data cache bank <b>122</b>. As will be evident from the following discussion, the 16 main memory banks together form the main memory of the P/M device. And, the 16 instruction cache banks together form a direct-mapped instruction cache while the 16 data cache banks together form a two-way set-associative data cache. In addition, the victim cache is a 16-way fully-associative cache.</p><h4>Main Memory</h4><p>Referring to FIG. 2, the main memory bank <b>118</b> of each memory block <b>104</b> comprises a 16M bit DRAM that has 4096 (4K) rows of memory cells <b>123</b>. Each row has 4096 memory cells. The main memory bank also includes a row decoder <b>124</b> that decodes 12 address bits to locate the row addressed (i.e., identified) by the 12 address bits. And, the main memory bank includes 4096 sense amplifiers <b>126</b> that collectively read or write an addressed row of 4096 bits at a time to or from the memory cells of the addressed row. Since in the exemplary embodiment the main memory bank comprises a DRAM, access time to the main memory bank is 6 cycles (e.g., 30 ns).</p><p>Since the rows of each main memory bank <b>118</b> are 4096 bits or 512 bytes wide, each main memory bank contains 2M bytes and the 16 main memory banks together form a main memory that contains 32M bytes. Thus, each main memory bank occupies a 2M byte portion of the 32M byte main memory address space. Moreover, each byte is addressable with a 25 bit address A<b>24</b>-A<b>0</b> where the 4 most significant address bits A<b>24</b>-A<b>21</b> identify the main memory bank, the next 12 address bits A<b>20</b>-A<b>9</b> identify the row of the main memory bank, and the 9 least significant address bits A<b>0</b>-A<b>8</b> identify the byte in the row.</p><h4>Instruction Cache</h4><p>Still referring to FIG. 2, the instruction cache bank <b>120</b> of each memory block <b>104</b> includes an instruction cache bank line storage <b>128</b>. The instruction cache bank line storage comprises a single long buffer <b>130</b> with 4096 latches. The latches of the buffer collectively store a single long instruction cache line (or block) that, like each row of the main memory bank <b>118</b> of the memory block, is 4096 bits or 512 bytes wide. And, since the instruction cache line is as wide as each row of the main memory bank, it is considered full-width. In the exemplary embodiment, each instruction word is 32 bits or 4 bytes long. As a result, the instruction cache line is 128 instruction words wide and so is each row of the main memory bank that stores instruction words.</p><p>Moreover, in each memory block <b>104</b>, each row of the main memory bank <b>118</b> is indexed (i.e., mapped) to the single instruction cache line of the instruction cache bank line storage <b>128</b>. Thus, all 25 bit instruction addresses A<b>24</b>-A<b>0</b> that specify a row in the main memory bank will include the same index to the instruction cache bank line storage. This index is the 4 most significant bits A<b>24</b>-A<b>21</b> of these addresses and also identifies the main memory bank.</p><p>The instruction cache bank <b>120</b> of each memory block <b>104</b> also includes an instruction cache bank tag storage <b>132</b>. The instruction cache bank tag storage stores a 12 bit instruction cache line tag that identifies the row in the corresponding main memory bank <b>118</b> normally occupied by the instruction cache line currently stored (i.e., cached) by the instruction cache bank line storage <b>128</b>. This tag, as will be explained shortly, is compared by the instruction cache bank logic <b>134</b> with the 12 address bits A<b>20</b>-A<b>9</b> of each 25 bit instruction address A<b>24</b>-A<b>0</b> that is issued and is in the corresponding main memory bank's portion of the main memory address space.</p><p>The operation of the instruction cache bank <b>120</b> of each memory block <b>104</b> is controlled by the instruction cache bank logic <b>134</b>. Turning now to FIG. 3, the instruction cache bank logic of each instruction cache bank includes an instruction cache bank control state machine <b>136</b>, an instruction cache bank address/tag comparison circuit <b>138</b>, and an instruction cache bank select circuit <b>140</b>. FIG. 4 shows the states of operation of the instruction cache bank logic control state machine.</p><p>Referring to FIGS. 2-4, when the CPU wishes to fetch a new instruction word for the instruction pipeline of the CPU, it issues a 25 bit instruction address A<b>24</b>-A<b>0</b> on the instruction address bus <b>114</b> for fetching the instruction word. The issued instruction address specifies the memory location of the instruction word in the address space of the main memory.</p><p>In each instruction cache bank <b>120</b>, the instruction cache bank select circuit <b>140</b> of the instruction cache bank logic <b>134</b> receives the 4 most significant bits A<b>24</b>-A<b>21</b> of the issued instruction address from the instruction address bus <b>114</b>. In response, it decodes these 4 address bits to determine whether they identify the corresponding main memory bank <b>118</b> (i.e., wether the issued address is in the corresponding main memory's portion of the main memory address space). If they do identify the corresponding main memory bank, then the instruction cache bank select circuit sends a bank select signal to the instruction cache bank control state machine <b>136</b> and the instruction cache bank address/tag comparison circuit <b>138</b> indicating that the corresponding main memory bank has been selected. Otherwise, the bank select signal indicates that the corresponding main memory bank has not been selected and the instruction cache bank control state machine remains in an idle state (state <b>137</b> of FIG. <b>4</b>).</p><p>In each instruction cache bank <b>120</b>, when the bank select signal indicates that the corresponding main memory bank <b>118</b> has been selected, then the instruction cache bank address/tag comparison circuit <b>138</b> compares the instruction cache line tag currently stored in the instruction cache bank tag storage <b>132</b> with the 12 address bits A<b>20</b>-A<b>9</b> of the issued instruction address on the instruction address bus <b>114</b>. As alluded to earlier, these 12 address bits identify the memory location of the row in the corresponding main memory bank where the instruction word is stored.</p><p>If there is a match, then the instruction cache bank address/tag comparison circuit <b>138</b> issues an instruction cache bank hit/miss signal that together with the bank select signal indicates that an instruction cache bank hit has occurred. This means that the memory location specified by the issued instruction address is currently accessible at the instruction cache line currently stored by the instruction cache bank line storage <b>128</b>.</p><p>The instruction cache bank hit/miss signal and the bank select signal from each instruction cache bank <b>120</b> are provided to the CPU <b>102</b> via the control bus <b>116</b>. When the instruction cache bank hit/miss and bank select signals from an instruction cache bank indicate that an instruction cache bank hit has occurred in the instruction cache bank, this lets the CPU know that the instruction word will be fetched directly from the instruction cache bank <b>120</b>. As a result, the CPU does not need to stall the instruction pipeline in order to wait for the instruction to be read from the main memory bank into the instruction cache bank and then be fetched, as would have been the case had an instruction cache bank miss occurred.</p><p>In each instruction cache bank <b>120</b>, the instruction cache bank hit/miss signal is also provided to the instruction cache bank control state machine <b>136</b>. The instruction cache bank control state machine additionally receives from the instruction address bus <b>114</b> the 7 address bits A<b>8</b>-A<b>2</b> of the issued instruction address and the instruction cache line currently stored by the instruction cache bank line storage <b>128</b>.</p><p>When the instruction cache bank hit/miss and bank select signals from an instruction cache bank <b>120</b> indicate that an instruction cache bank hit has occurred in the instruction cache bank, the instruction cache bank control state machine <b>136</b> of the instruction cache bank leaves its idle state (state <b>137</b> of FIG. 4) and decodes the received 7 address bits to determine the accessible memory location in the instruction cache line specified by the issued instruction address. It then fetches the instruction word from this location and provides it to the CPU <b>102</b> (state <b>139</b> of FIG. <b>4</b>). This is done by routing (i.e., multiplexing) the instruction word onto the instruction bus <b>112</b> so that it is received by the CPU <b>102</b>. As a result, the fetch of the instruction word is completed. In the exemplary embodiment, this is done in a single cycle (e.g., 5 ns).</p><p>However, in each instruction cache bank <b>120</b>, when the instruction cache bank address/tag comparison circuit <b>138</b> determines that there is no match between the compared instruction cache line tag and the 12 address bits A<b>20</b>-A<b>9</b> of the issued instruction address, then it issues an instruction cache bank hit/miss signal that together with the bank select signal indicates that an instruction cache bank miss has occurred. This means that the location specified by the issued instruction address is not currently accessible at the instruction cache line currently stored by the instruction cache bank line storage <b>128</b>.</p><p>Thus, when the instruction cache bank hit/miss and bank select signals received by the CPU <b>102</b> from an instruction cache bank <b>120</b> indicate that an instruction cache bank miss has occurred, it stalls so that a new instruction cache line at the memory location specified by the issued instruction address can be read by the instruction cache bank control state machine from the corresponding main memory bank <b>118</b> into the instruction cache bank (state <b>141</b> of FIG. <b>4</b>). In this case, when the instruction cache bank control state machine <b>136</b> receives this instruction cache bank hit/miss and bank select signals, it issues to the main memory bank <b>118</b> a W/R control signal indicating that a read is to occur and the 12 address bits A<b>20</b>-A<b>9</b> received from the instruction address bus <b>114</b>. In response to the 12 address bits, the row decoder locates the row of the main memory bank identified by the 12 address bits. And, in response to the W/R control signal, the sense amplifiers <b>126</b> read out this row as the new instruction cache line. While this is occurring, the instruction cache bank control state machine <b>136</b> issues buffer control signals to the buffer <b>130</b> of the instruction cache bank line storage <b>128</b>. In response, the buffer latches the new instruction cache line received from the sense amplifiers <b>126</b> and in doing so replaces the previous instruction cache line that was latched by the buffer. In the exemplary embodiment this requires 6 cycles to perform including 1 cycle to determine that an instruction cache bank miss occurred, 4 cycles of pre-charging the sense amplifiers and address bit decoding by the row decoder, and 1 cycle to latch into the buffer the new instruction cache line read out by the sense amplifiers.</p><p>In each instruction cache bank, once a new instruction cache line has been stored in the instruction cache bank line storage <b>128</b>, the instruction cache bank control state machine <b>136</b> decodes the 7 address bits A<b>8</b>-A<b>2</b> of the issued instruction address to locate the instruction word in the new instruction cache line. It then fetches the located instruction word from the instruction cache line and routes it to the CPU <b>102</b> in the manner described earlier (state <b>139</b> of FIG. <b>4</b>). As indicated previously, in the exemplary embodiment, this is done in a single cycle. After this is accomplished, it returns to an idle state (state <b>137</b> of FIG. 4) and waits for the next issued instruction address.</p><p>In view of the foregoing, it is clear that the 16 instruction cache banks <b>120</b> together form a direct-mapped on-chip instruction cache memory that contains 8K bytes. Since the instruction cache line stored by each instruction cache bank is full-width, the cache miss rate is greatly reduced over conventional processors with instruction cache lines that are less than full-width. This low cache miss rate is due to the prefetching effect of the long instruction cache line and the usually high spatial locality found in instruction streams.</p><p>Moreover, conventional processors with off-chip main memory and on-chip instruction caches are unable to reap the benefit of a full-width instruction cache line. This is due to the severe second order contention effects that would be introduced at the memory interface in reading such a full-width cache line from the main memory to the instruction cache. However, in the present invention, these contention effects are eliminated because both the instruction cache and main memory banks <b>118</b> and <b>120</b> are on-chip. Thus, in the exemplary embodiment, an entire full-width instruction cache line can be read in a single cycle from a main memory bank into the corresponding instruction cache bank in 6 cycles.</p><h4>Data Cache and Victim Data Cache</h4><p>Referring again to FIG. 2, the primary data cache bank <b>122</b> of each memory block <b>104</b> includes a primary data cache bank line storage <b>144</b> that comprises two buffers <b>146</b>. Like the buffer <b>130</b> of each instruction cache bank line storage <b>128</b>, each buffer of the primary data cache bank line storage includes 4096 latches that together store a primary data cache line that is 4096 bits or 512 bytes wide. Moreover, in the exemplary embodiment, each primary data cache line is 64 data words wide with each data word being 64 bits or 8 bytes long.</p><p>In each memory block <b>104</b>, each row of the main memory bank <b>118</b> is indexed to both of the primary data cache lines of the primary data cache bank line storage <b>144</b>, as well as being indexed to the instruction cache line of the instruction cache bank line storage <b>128</b>. Thus, all 25 bit data addresses A<b>24</b>-A<b>0</b> that specify a row in the main memory bank will include the same index to the primary data cache bank line storage. Similar to the instruction addresses, this index is the 4 most significant bits A<b>24</b>-A<b>21</b> of the data addresses and also identifies the main memory bank.</p><p>The primary data cache bank <b>122</b> of each memory block <b>104</b> also includes a primary data cache bank tag/flag storage <b>148</b>. The primary data cache bank tag/flag storage stores a corresponding 12 bit primary data cache line tag and a corresponding dirty flag for each of the two primary data cache lines currently stored by the primary data cache bank line storage <b>144</b>. Each tag identifies the row in the corresponding main memory bank <b>118</b> normally occupied by the corresponding primary data cache line. These tags are compared by the primary data cache bank logic <b>150</b> with the 12 address bits A<b>20</b>-A<b>9</b> of each 25 bit data address A<b>24</b>-A<b>0</b> that is issued and is in the corresponding main memory bank's portion of the main memory address space. Each dirty flag identifies whether the corresponding primary data cache line is dirty (i.e., contains one or more data words that have been written into the primary data cache line but not yet to the main memory bank). Additionally, the primary data cache bank tag/flag storage stores a least recently used flag (LRU) flag that identifies which of the primary data cache lines was least recently used (i.e., accessed).</p><p>The operation of the primary data cache bank <b>120</b> of each memory block <b>104</b> is controlled by the primary data cache bank logic <b>150</b>. As shown in FIG. 5, the primary data cache bank logic of each primary data cache bank includes a primary data cache bank control state machine <b>152</b>, a primary data cache bank address/tag comparison circuit <b>154</b>, and a primary data cache bank select circuit <b>156</b>. FIG. 6 shows the states of operation of the primary data cache bank logic control state machine.</p><p>Referring to FIG. 7, and as will be explained in greater detail later, the victim data cache is used to store victim data cache sub-lines (or sub-blocks) of primary data cache lines that were recently replaced (i.e., were replacement victims) with new primary data cache lines in the primary data cache banks <b>122</b>. The victim data cache includes a victim data cache line storage <b>160</b> that comprises 16 buffers <b>162</b>. Each buffer of the victim data cache line storage includes 256 latches that together store a victim data cache sub-line that is 256 bits or 32 bytes wide. Thus, in the exemplary embodiment, each victim data cache sub-line is 4 data words wide.</p><p>The victim data cache <b>106</b> also includes a victim data cache tag/flag storage <b>164</b>. The victim data cache tag/flag storage stores a corresponding 22 bit tag for each of the 16 victim data cache sub-lines currently stored by the victim data cache line storage <b>160</b>. Each tag identifies the corresponding victim data cache sub-line and indicates the memory location it normally occupies in the main memory. These tags are compared by the victim data cache logic <b>166</b> with the 19 address bits A<b>24</b>-A<b>6</b> of each 25 bit data address A<b>24</b>-A<b>0</b> that is issued. Additionally, the victim data cache tag/flag storage stores a flush flag that identifies which of the victim data cache sub-lines is to be flushed the next time a new victim data cache sub-line is written into the victim data cache.</p><p>The operation of the victim data cache <b>106</b> is controlled by the victim data cache logic <b>166</b>. As shown in FIG. 8, the victim data cache logic includes a victim data cache control state machine <b>168</b> and a victim data cache address/tag comparison circuit <b>170</b>. FIG. 9 shows the states of operation of the victim data cache logic control state machine.</p><p>Referring to FIG. 1, the CPU issues a 25 bit data address A<b>24</b>-A<b>0</b> on the data address bus <b>110</b> when it wishes to read or write a data word from or to the main memory. The issued data address specifies the memory location in the address space of the main memory at which the data word is to be read or written. The CPU also issues a write/read (W/R) signal on the control bus <b>116</b> that indicates whether a read or write is occurring.</p><p>Turning now to FIGS. 7-9, each time a data address is issued by the CPU <b>102</b>, the victim data cache address/tag comparison circuit <b>170</b> of the victim data cache <b>106</b> compares the tags currently stored in the victim data cache tag/flag storage <b>164</b> with the 19 address bits A<b>24</b>-A<b>6</b> of the issued data address on the data address bus <b>110</b>. If there is a match, then the victim data cache address/tag comparison circuit issues a victim data cache hit/miss signal that indicates that a victim data cache hit has occurred. This means that the memory location addressed by the issued data address is currently accessible at one of the victim data cache sub-lines stored in the victim data cache line storage <b>160</b>. The victim data cache hit/miss signal also identifies the victim data cache sub-line in which the victim data cache hit occurred. But, if there is no match, then this means that the memory location addressed by the issued data address is not currently accessible at one of the victim data cache sub-lines stored in the victim data cache line storage and the victim data cache address/tag comparison circuit issues a victim data cache hit/miss signal that indicates that a victim data cache miss has occurred.</p><p>Unlike conventional victim data caches, the victim data cache <b>106</b> in the exemplary embodiment is not used to write back victim data cache sub-lines to the primary data cache banks <b>122</b>. In other words, the victim data cache cannot write a data word into a victim data cache sub-line and then write back the dirty victim data cache sub-line to the corresponding primary data cache bank. This, is due to the timing and architectural constraints discussed later.</p><p>The victim data cache control state machine <b>168</b> receives the W/R signal from the CPU <b>102</b> on the control bus, the victim data cache hit/miss signal from the victim data cache address/tag comparison circuit <b>170</b>, the 6 address bits A<b>8</b>-A<b>3</b> of the issued data address on the data address bus <b>110</b>, and the victim data cache sub-lines currently stored by the victim data cache line storage <b>160</b>. When the W/R signal indicates that a read is occurring and the victim data cache hit/miss signal indicates that a victim data cache hit has occurred, then the victim data cache control state machine leaves its idle state (state <b>171</b> of FIG. 9) and decodes the received 6 address bits to determine the accessible memory location of the data word in the identified victim data cache sub-line at which the data word is to be read. The victim data cache control state machine then reads the data word from the identified victim data cache sub-line and provides it to the CPU <b>102</b> (state <b>173</b> of FIG. <b>9</b>). This is done by routing the data word in the identified victim data cache sub-line onto the data bus <b>108</b> so that it is received by the CPU. In the exemplary embodiment, only a single cycle is required to access the victim data cache and read a victim data cache sub-line to the CPU.</p><p>However, when the W/R signal received from the CPU <b>102</b> indicates that a write is occurring or when a victim data cache hit/miss signal is issued indicating that a victim data cache miss has occurred, then the victim data cache control state machine <b>168</b> remains in an idle state (state <b>171</b> of FIG. <b>9</b>). In this case, the data word that is to be written or read at the memory location specified by the issued data address must be written to or read from the primary data cache bank <b>122</b> in the memory block <b>104</b> with the corresponding main memory bank <b>118</b> that has the memory location specified by the issued data address.</p><p>The CPU <b>102</b> also receives the victim data cache hit/miss signal. Thus, when the CPU receives a victim data cache hit/miss signal indicating that a victim data cache hit has occurred during a read, it waits for the data word at the memory location specified by the issued data address to be provided to it by the victim data cache <b>106</b> via the data bus <b>108</b>. However, when the CPU receives a victim data cache hit/miss signal that indicates that a victim data cache hit has occurred during a write or receives a victim data cache hit signal indicating that a victim data cache miss has occurred, it determines whether a primary data cache bank hit or miss signal has been issued by the primary data cache bank <b>122</b> corresponding to the main memory bank <b>118</b> with the memory location specified by the issued data address.</p><p>Referring to FIGS. 2, <b>5</b>, and <b>6</b>, in each primary data cache bank <b>122</b>, the primary data cache bank select circuit <b>156</b> of the primary data cache bank logic <b>150</b> operates in the same way as the instruction cache bank select circuit <b>140</b> of the instruction cache bank logic <b>134</b> of each instruction cache bank <b>120</b>. Thus, it receives the 4 most significant bits A<b>24</b>-A<b>21</b> of the issued data address from the data address bus <b>110</b>. In response, it decodes these 4 address bits to determine whether they identify the corresponding main memory bank <b>118</b>. If they do identify the corresponding main memory bank, then the primary data cache bank select circuit sends a bank select signal to the primary data cache bank control state machine <b>152</b> and the primary data cache bank address/tag comparison circuit <b>154</b> indicating that the corresponding main memory bank has been selected. Otherwise, the bank select signal indicates that the corresponding main memory bank has not been selected and the primary data cache bank control state machine remains in an idle state (state <b>157</b> of FIG. <b>6</b>).</p><p>In each primary data cache bank <b>122</b>, when the bank select signal indicates that the corresponding main memory bank <b>118</b> has been selected, then the primary data cache bank address/tag comparison circuit <b>154</b> compares the primary data cache line tags currently stored in the primary data cache bank tag/flag storage <b>148</b> with the 12 address bits A<b>20</b>-A<b>9</b> of the issued data address on the data address bus <b>110</b>. These 12 address bits identify the memory location of the row in the corresponding main memory bank where the data word is currently stored for a read or is to be stored for a write.</p><p>If there is a match, then the primary data cache bank address/tag comparison circuit <b>154</b> issues a primary data cache bank hit/miss signal that together with the bank select signal indicates that a primary data cache bank hit has occurred. This means that the memory location addressed by the issued data address is currently accessible at one of the primary data cache lines stored in the primary data cache bank line storage <b>144</b>. The primary data cache bank hit/miss signal also identifies this primary data cache line. On the other hand, if there is no match, then this means that the memory location addressed by the issued data address is not currently accessible at one of the primary data cache lines stored in the primary data cache bank line storage <b>144</b> and the primary data cache bank address/tag comparison circuit issues a primary data cache bank hit/miss signal that together with the bank select signal indicates that a primary data cache bank miss has occurred.</p><p>In each primary data cache bank <b>122</b>, the primary data cache bank hit/miss signal is provided to the primary data cache bank control state machine <b>152</b>. The victim data cache hit/miss signal from the victim data cache <b>106</b> is also provided to the primary data cache bank control state machine on the control bus <b>116</b> along with the W/R signal from the CPU.</p><p>As indicated earlier, when a victim data cache hit/miss signal indicating a victim data cache hit is issued during a read, then the victim data cache <b>106</b> provides the CPU with the data word at the memory location addressed by the issued data address. Thus, in each primary data cache bank <b>122</b>, when the primary data cache bank control state machine <b>152</b> receives a victim data cache hit/miss signal indicating a victim data cache hit and a W/R signal indicating a read, then it remains in an idle state (state <b>157</b> of FIG. <b>6</b>). This is true even when the primary data cache bank hit/miss signal it receives from the primary data cache bank address/tag comparison circuit <b>154</b> indicates that a primary data cache bank hit has occurred.</p><p>However, when a victim data cache hit/miss signal indicating a victim data cache hit is issued during a write or when a victim data cache hit/miss signal indicating a victim data cache miss is issued, then the victim data cache <b>106</b> is not used to access the location addressed by the issued data address. Thus, in each primary data cache bank <b>122</b>, in either of the two conditions just described, the primary data cache bank control state machine <b>152</b> controls the reading and writing of a data word at the memory location specified by the issued data address in either case where the primary data cache bank hit/miss and bank select signals indicate a primary data cache bank hit or miss has occurred.</p><p>The primary data cache bank hit/miss and bank select signals from each primary data cache bank <b>122</b> are also provided to the CPU <b>102</b> via the control bus <b>116</b>. When these signals from a primary data cache bank indicate that a primary data cache bank hit has occurred and either a victim data cache hit/miss signal that indicates that a victim data cache hit has occurred is received during a write or a victim data cache hit/miss signal indicating that a victim data cache miss has occurred is received, the CPU knows that the data word to be read or written can be done so directly from or to the primary data cache bank <b>122</b>. The CPU then does not stall the instruction pipeline in order to wait for a primary data cache line with an accessible memory location specified by the issued data address is read from the main memory bank into the primary data cache bank, as would have been the case had a primary data cache bank miss occurred.</p><p>In each primary data cache bank <b>122</b>, in addition to the primary data cache bank hit/miss, bank select, and W/R signals, the primary data cache bank control state machine <b>152</b> receives from the data address bus <b>110</b> the 6 address bits A<b>8</b>-A<b>3</b> of the issued data address and the primary data cache lines currently stored by the primary data cache bank line storage <b>144</b>. When the primary data cache bank hit/miss and bank select signals indicate that a primary data cache bank hit has occurred, the primary data cache bank control state machine <b>152</b> decodes the received 6 address bits to determine the accessible memory location specified by the issued data address in the primary data cache line identified by the primary data cache bank hit/miss signal as being the primary data cache line in which the primary data cache bank hit occurred. If the W/R signal indicates a read, then the primary data cache bank control state machine reads the data word from the determined location in the identified data cache line and provides it to the CPU <b>102</b> (state <b>159</b> of FIG. <b>6</b>). This is done by routing the data word in the identified data cache line onto the data bus <b>108</b> so that it is received by the CPU. In the exemplary embodiment, only a single cycle is required to access the primary data cache bank and read the data word to the CPU. Once the read is completed, the primary data cache bank control state machine returns to an idle state (state <b>157</b> of FIG. <b>6</b>).</p><p>But, if the W/R signal indicates a write, the primary data cache bank control state machine <b>152</b> writes a data word from the CPU to the determined location in the identified data cache line. This is done by routing the data word from the data bus <b>108</b> to the buffer <b>146</b> in the primary data cache bank line storage <b>144</b> that stores the identified primary data cache line and issuing buffer control signals that cause the buffer to latch the data word (state <b>159</b> of FIG. <b>6</b>). Then, if the corresponding dirty flag for the identified primary data cache line does not already indicate that the primary data cache line is dirty, then the primary data cache bank control state machine updates it to indicate that it is now dirty (sub-state <b>161</b> of FIG. <b>6</b>). This is done by providing the updated dirty flag to the primary data cache bank tag/flag storage <b>148</b> and issuing storage control signals that cause the primary data cache bank tag/flag storage to store the updated dirty flag. Once the write is completed, the primary data cache bank control state machine returns to an idle state (state <b>157</b> of FIG. <b>6</b>).</p><p>However, when the CPU receives primary data cache bank hit/miss and bank select signals from a primary data cache bank <b>122</b> that indicate that a primary data cache bank miss has occurred and either receives during a write a victim data cache hit/miss signal that indicates that a victim data cache hit has occurred or receives a victim data cache hit signal indicating that a victim data cache miss has occurred, it stalls while a new primary data cache line with the memory location specified by the issued data address is read from the corresponding main memory bank <b>118</b> into the primary data cache bank. This also requires writing to the main memory bank the victim primary data cache line being replaced by the new primary data cache line if the corresponding dirty flag for the victim primary data cache line indicates that it is dirty. In this case, the CPU will be additionally stalled.</p><p>In each primary data cache bank <b>122</b>, the primary data cache bank control state machine <b>152</b> also receives from the primary data cache bank tag/flag storage <b>148</b> the dirty flags for the primary data cache lines stored by the primary data cache bank line storage <b>144</b> in order to determine whether they are dirty. As described earlier, each dirty flag is updated to indicate that the corresponding primary data cache line is dirty whenever a data word is written to the corresponding primary data cache line and the dirty flag does not yet indicate that the primary data cache line is dirty.</p><p>The primary data cache bank control state machine <b>152</b> of each primary data cache bank <b>122</b> also receives the LRU flag from the primary data cache bank tag/flag storage <b>148</b> of the primary data cache bank. As mentioned previously, the LRU flag identifies the primary data cache line that was least recently used. The LRU flag is updated by the primary data cache bank control state machine each time that a different primary data cache line is accessed for a read or a write. The updated LRU flag is then provided to the primary data cache bank tag/flag storage and stored in it with storage control signals issued by the primary data cache bank control state machine.</p><p>In each primary data cache bank <b>122</b>, when the primary data cache bank control state machine <b>152</b> of the primary data cache bank receives primary data cache bank hit/miss and bank select signals indicating that a primary data cache bank miss has occurred and either receives a victim data cache hit/miss signal indicating that a victim data cache hit has occurred and a W/R signal indicating that a write is occurring or receives a victim data cache hit signal indicating that a victim data cache miss has occurred, then this means that a new primary data cache line with the memory location specified by the issued data address must be read from the corresponding main memory bank <b>118</b>. However, prior to doing so, the primary data cache bank control state machine determines from the LRU flag which of the currently stored primary data cache lines is the least recently used one and therefore will be the victim primary data cache line that will be replaced by the new primary data cache line.</p><p>However, in each primary data cache bank <b>122</b>, prior to replacing the victim data cache line with a new data cache line, the primary data cache bank control state machine <b>152</b> writes back to the corresponding main memory bank <b>118</b> the victim primary data cache line if it is dirty (state <b>163</b> of FIG. <b>6</b>). The primary data cache bank control state machine does so by first determining from the corresponding dirty flag provided by the primary data cache bank tag/flag storage <b>148</b> whether the victim primary data cache line is dirty. If it is dirty, then the primary data cache bank control state machine issues on the control bus <b>116</b> a dirty cache line write signal indicating that it needs to write back a dirty victim primary data cache line. This signal is received by the CPU <b>102</b> and in response the CPU stalls to allow the dirty victim primary data cache line to be written back to the corresponding main memory bank and the new primary data cache line to be read into the primary data cache bank.</p><p>The primary data cache bank control state machine <b>152</b> writes back the dirty victim primary data cache line by issuing to the corresponding main memory bank <b>118</b> a W/R control signal indicating that a write is to occur and the 12 address bits A<b>20</b>-A<b>9</b> received from the corresponding tag for the dirty victim primary data cache line provided by the primary data cache bank tag/flag storage <b>148</b>. Moreover, the primary data cache bank control state machine issues buffer control signals to the buffer <b>146</b> that stores the dirty victim primary data cache line being written back so that the dirty victim primary data cache line is routed to the sense amplifiers <b>126</b> of the corresponding main memory bank. In response to the 12 address bits, the row decoder <b>124</b> locates the row of the corresponding main memory bank that is identified by the 12 address bits. And, in response to the W/R control signal, the sense amplifiers <b>126</b> write the provided dirty victim primary data cache line into the identified row of the corresponding main memory bank. In the exemplary embodiment, 6 cycles are required to write back a dirty victim primary data cache line including 1 cycle to determine that a primary data cache bank miss occurred and to identify a dirty victim primary data cache line, 4 cycles of pre-charging the sense amplifiers and address bit decoding by the row decoder, and 1 cycle to write the dirty victim primary data cache line into the main memory bank.</p><p>Moreover, since the CPU is stalled while a dirty victim primary data cache line is being written back, the other primary data cache banks <b>122</b> each write back a dirty primary data cache line to the corresponding main memory bank <b>118</b> if it stores at least one dirty primary data cache line (state <b>163</b> of FIG. <b>6</b>). In each of these other primary data cache banks, this is done when the dirty cache line write signal on the control bus <b>116</b> indicates that a dirty victim primary data cache line is being written back and the bank select signal indicates that the corresponding main memory bank has not been selected. This write back is controlled by the primary data cache bank control state machine <b>152</b> of each of these other primary data cache banks in a similar manner to that just described. However, if there is only one dirty primary data cache line stored by a primary data cache bank, then it is written back. But, if there are two dirty primary data cache lines, then the dirty primary data cache line identified by the LRU flag as being the LRU primary data cache line is the one that is written back. Once this write back is completed, then the primary data cache bank control state machine returns to an idle state (state <b>157</b> of FIG. <b>6</b>).</p><p>In each primary data cache bank <b>122</b>, once a dirty victim primary data cache line has been written back to the corresponding main memory bank <b>118</b> or when the corresponding dirty flag for the victim primary data cache line indicates that it is not dirty, then the primary data cache bank control state machine <b>152</b> reads the new primary data cache line with the location specified by the issued data address from the corresponding main memory bank <b>118</b> into the primary data cache bank (state <b>163</b> of FIG. <b>6</b>). This is done by issuing to the corresponding main memory bank <b>118</b> a W/R control signal indicating that a write is to occur and the 12 address bits A<b>20</b>-A<b>9</b> of the issued data address on the data address bus <b>110</b>. In response to the 12 address bits, the row decoder <b>124</b> locates the row of the corresponding main memory bank that is identified by the 12 address bits. And, in response to the W/R control signal, the sense amplifiers <b>126</b> read out the new primary data cache line from the identified row of the corresponding main memory bank. Moreover, the primary data cache bank control state machine issues buffer control signals to the buffer <b>146</b> that stores the victim primary data cache line being replaced so that the new primary data cache line is latched by the buffer and replaces the victim primary data cache line. In the exemplary embodiment, this requires 5 cycles including 4 cycles of pre-charging the sense amplifiers and address bit decoding by the row decoder and 1 cycle to latch the new primary data cache line read out by the sense amplifiers into the main memory bank.</p><p>But, since accessing the main memory bank <b>118</b> to read out the new primary data cache line requires time for address bit decoding by the row decoder <b>124</b> and pre-charging of the sense amplifiers <b>126</b>, this time can be efficiently used to write the most recently used (MRU) primary data cache sub-line of the victim primary data cache line to the victim data cache <b>106</b> prior to the new primary data cache line being latched in the buffer <b>146</b>. In order to determine which primary data cache sub-line in a victim primary data cache line is the MRU sub-line, the primary data cache bank tag/flag storage <b>148</b> of each primary data cache bank <b>122</b> stores an MRU flag that identifies the MRU victim data cache sub-line in each primary data cache line stored by the primary data cache bank line storage <b>144</b>. In addition, since the data bus <b>108</b> is not being used during this time, it can be efficiently used to write the MRU victim data cache sub-line to the victim data cache.</p><p>Therefore, during the time the sense amplifiers are being pre-charged and the row decoder is decoding address bits, the primary data cache bank control state machine <b>152</b> identifies the MRU victim data cache sub-line from the corresponding MRU flag received from the primary data cache bank tag/flag storage <b>148</b>. It then routes the MRU victim data cache sub-line to the victim data cache <b>106</b> (sub-state <b>165</b> of FIG. 6) using the data bus <b>108</b>. In the exemplary embodiment, this is done in four cycles since the data bus is 64 bits wide or 1 data word wide and the MRU victim data cache sub-line is 256 bits or 4 data words wide. Thus, the primary data cache bank control state machine routes a block of 64 bits or 1 data word of the MRU victim data cache sub-line each cycle onto the data bus during this time period.</p><p>Referring again to FIGS. 7-9, the victim data cache control state machine <b>168</b> receives from the control bus <b>116</b> the primary data cache bank hit/miss and bank select signals from each primary data cache bank <b>122</b> and also the dirty cache line write signal. When the primary data cache bank hit/miss and bank select signals from a primary data cache bank indicate that a primary data cache bank miss has occurred and the dirty cache line write signal indicates that a dirty victim primary data cache line is not being written back, then the victim data cache control state machine writes the MRU victim data cache sub-line provided by the primary data cache bank on the data bus <b>108</b> into victim data cache line storage <b>160</b> (state <b>175</b> of FIG. <b>9</b>).</p><p>The victim data cache control state machine <b>168</b> does this by first determining which of the victim data cache sub-lines is to be replaced by the MRU victim data cache sub-line. In the case where there is a victim data cache hit during a read, the victim data cache control state machine <b>168</b> replaces the victim data cache subline in which the hit occurred with the MRU victim data cache sub-line. This is done because a primary data cache bank miss occurred in the primary data cache bank <b>122</b> that provides the MRU victim data cache sub-line and the primary data cache line that is being read in response from the corresponding main memory bank into the primary data cache bank includes the victim data cache sub-line being replaced. This is indicated by the fact that a victim data cache hit occurred in the victim data cache sub-line being replaced.</p><p>However, in the case where there was a victim data cache miss, the victim data cache control state machine <b>168</b> replaces the LRU victim data cache sub-line with the MRU victim data cache sub-line. The LRU victim data cache sub-line is identified by the LRU flag stored by the victim data cache tag/flag storage <b>164</b>. The LRU flag is updated by the victim data cache control state machine each time that a victim data cache sub-line is accessed for a read. The updated LRU flag is then provided to the victim data cache tag/flag storage and stored in it with storage control signals issued by the victim data cache control state machine.</p><p>The victim data cache control state machine <b>168</b> stores the MRU victim data cache sub-line in the buffer <b>162</b> that currently stores the victim data cache sub-line being replaced. This is done by routing to the corresponding latches of the buffer the 64 bit blocks received on the data bus during the 4 cycles required to transfer the MRU victim data cache sub-line. At the same time, buffer control signals are issued to the corresponding latches during the 4 cycles so as to latch the 64 bit blocks in the buffer.</p><p>Turning again to FIGS. 2, <b>5</b>, and <b>6</b>, in each primary data cache bank <b>122</b>, after a new primary data cache line has been read into the primary data cache bank and an MRU victim data cache sub-line has been read into the victim data cache <b>106</b>, then a data word is read from or written to the new primary data cache line as described earlier (states <b>159</b> and <b>161</b> of FIG. <b>6</b>).</p><p>Thus, from the foregoing, the 16 primary data cache banks <b>122</b> together form a two-way set-associative data cache that contains 16K bytes and the victim data cache <b>106</b> is a 16-way fully-associative victim data cache. Moreover, collectively, they form the data cache system of the P/M device <b>100</b>. Since the primary data cache lines stored by each data cache bank are full-width and on-chip, the cache miss rate is greatly reduced over conventional data caches that store data cache lines that are less than full-width. As in the instruction cache formed by the instruction cache banks <b>120</b>, this low cache miss rate is due to the benefit of prefetching the long data cache lines for accesses with high spatial locality. Moreover, this miss rate is even further reduced by the utilization of the on-chip victim data cache which absorbs accesses with poor spatial locality. Additionally, because of severe second order contention effects of the kind described earlier for off-chip main memory and on-chip instruction caches, conventional processors with off-chip main memory and on-chip data caches are unable to take advantage of the benefit of a full-width data cache line.</p><p>As those skilled in the art will recognize numerous alternative embodiments to the exemplary embodiment of FIGS. 1-9 exist. For example, the rows in the main memory banks <b>118</b> and the buffers <b>130</b> and <b>146</b> in the data and instruction cache bank line storages may have a different width than the exemplary width of 4096 bits, but would still preferably have equal size widths. And, each instruction cache bank and each data cache bank could include one or more buffers. Furthermore, a victim data cache, like the victim data cache used for the primary data cache banks, could be used for the instruction cache banks. Finally, rather than using the LRU policy for determining victim data cache lines and the MRU policy for determining a victim data cache sub-line to be written to the victim data cache, other policies could be used instead.</p><p>While the present invention has been described with reference to a few specific embodiments, the description is illustrative of the invention and is not to be construed as limiting the invention. Various modifications may occur to those skilled in the art without departing from the true spirit and scope of the invention as defined by the appended claims.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Ashley", "last_name": "Saulsbury", "name": ""}, {"first_name": "Andreas", "last_name": "Nowatzyk", "name": ""}, {"first_name": "Fong", "last_name": "Pong", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "SUN MICROSYSTEMS, INC."}, {"first_name": "", "last_name": "Oracle America, Inc.", "name": ""}, {"first_name": "", "last_name": "SUN MICROSYSTEMS, INC.", "name": ""}, {"first_name": "", "last_name": "SUN MICROSYSTEMS, INC.", "name": ""}, {"first_name": "", "last_name": "SUN MICROSYSTEMS, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  13/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/06        20060101AFI20060310RMJP"}, {"label": "G06F  12/08        20060101A I20051008RMEP"}, {"label": "G06F  15/78        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711118"}, {"primary": false, "label": "711105"}, {"primary": false, "label": "711144"}, {"primary": false, "label": "711123"}, {"primary": false, "label": "711133"}, {"primary": false, "label": "711005"}, {"primary": false, "label": "711E12041"}, {"primary": false, "label": "711168"}], "ecla_classes": [{"label": "G06F  12/08B22"}, {"label": "G06F  15/78P1N"}], "cpc_classes": [{"label": "G06F  12/0893"}, {"label": "G06F  15/7821"}, {"label": "G06F  12/00"}, {"label": "G06F  12/0893"}, {"label": "G06F  15/7821"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1996-07-01", "application_date": "1996-07-01", "family_members": [{"ucid": "EP-0817066-A3", "titles": [{"lang": "FR", "text": "Dispositif de processeur et de m\u00e9moire int\u00e9gr\u00e9 avec ant\u00e9m\u00e9moire \u00e0 pleine largeur"}, {"lang": "EN", "text": "Integrated processor/memory device with full width cache"}, {"lang": "DE", "text": "Integrierte Prozessor/Speichervorrichtung mit Cachespeicher ganzer Breite"}]}, {"ucid": "KR-100454441-B1", "titles": [{"lang": "EN", "text": "INTEGRATED PROCESSOR/MEMORY DEVICE WITH FULL WIDTH CACHE"}, {"lang": "KO", "text": "\uc804\ud3ed\uce90\uc26c\ub97c\uac00\uc9c4\uc9d1\uc801\ud504\ub85c\uc138\uc11c/\uba54\ubaa8\ub9ac\uc7a5\uce58"}]}, {"ucid": "KR-980010781-A", "titles": [{"lang": "KO", "text": "\uc804\ud3ed \uce90\uc26c\ub97c \uac00\uc9c4 \uc9d1\uc801 \ud504\ub85c\uc138\uc11c/\uba54\ubaa8\ub9ac \uc7a5\uce58"}, {"lang": "EN", "text": "Integrated processor / memory device with full cache"}]}, {"ucid": "US-6199142-B1", "titles": [{"lang": "EN", "text": "Processor/memory device with integrated CPU, main memory, and full width cache and associated method"}]}, {"ucid": "JP-H10177519-A", "titles": [{"lang": "JA", "text": "\u7d71\u5408\u3055\u308c\u305f\u30d7\u30ed\u30bb\u30c3\u30b5\u30fb\u30e1\u30e2\u30ea\u88c5\u7f6e"}, {"lang": "EN", "text": "INTEGRATED PROCESSOR MEMORY DEVICE"}]}, {"ucid": "EP-0817066-A2", "titles": [{"lang": "FR", "text": "Dispositif de processeur et de m\u00e9moire int\u00e9gr\u00e9 avec ant\u00e9m\u00e9moire \u00e0 pleine largeur"}, {"lang": "EN", "text": "Integrated processor/memory device with full width cache"}, {"lang": "DE", "text": "Integrierte Prozessor/Speichervorrichtung mit Cachespeicher ganzer Breite"}]}]}