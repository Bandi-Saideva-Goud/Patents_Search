{"patent_number": "US-6202125-B1", "publication_id": 72607533, "family_id": 25049881, "publication_date": "2001-03-13", "titles": [{"lang": "EN", "text": "Processor-cache protocol using simple commands to implement a range of cache configurations"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11156904\" source=\"national office\"><p>A computer system having a processor-cache protocol supporting multiple cache configurations is described. The computer system has a processor having a cache control circuit to control multiple cache memory circuits. The processor including its cache control circuit is coupled to a cache bus. A second level cache memory is also coupled to the cache bus. The cache control circuit controls the second level cache by issuing commands that are executed by the second level cache.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72525165\"><p>A computer system having a processor-cache protocol supporting multiple cache configurations is described. The computer system has a processor having a cache control circuit to control multiple cache memory circuits. The processor including its cache control circuit is coupled to a cache bus. A second level cache memory is also coupled to the cache bus. The cache control circuit controls the second level cache by issuing commands that are executed by the second level cache.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00001\" num=\"1\"><claim-text>1. A system comprising:</claim-text><claim-text>a processor having a cache control circuit, the cache control circuit to control multiple types of cache memories, the processor having a first level cache coupled with the cache control circuit; </claim-text><claim-text>a cache bus coupled to the processor; and </claim-text><claim-text>a second level cache coupled with the cache control circuit via the cache bus; </claim-text><claim-text>wherein the cache control circuit controls the first level cache and the second level cache by issuing one or more micro-operations from a set of micro-operations that are decoded and executed by the first level cache and the second level cache, respectively. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00002\" num=\"2\"><claim-text>2. The system of claim <b>1</b>, wherein the set of micro-operations include a data read with least recently used update (RLU) micro-operation that causes the second level cache to update a least recently used (LRU) field associated with a requested cache line, send the requested cache line to the processor, send a cache way from which the requested cache line was read to the processor, and send a state of the requested cache line to the processor.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00003\" num=\"3\"><claim-text>3. The system of claim <b>1</b>, wherein the set of micro-operations include a data half read with least recently used update (RHU) micro-operation that causes the second level cache to update a least recently used (LRU) field associated with a requested half cache line, send the requested half cache line to the processor, send a cache way from which the requested half cache line was read to the processor, and send a state of the requested half cache line to the processor.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00004\" num=\"4\"><claim-text>4. The system of claim <b>1</b>, wherein the micro-operations include a tag read with line read (TRR) micro-operation that causes the second level cache to send a requested cache line, a tag and a state associated with the requested cache line to the processor.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00005\" num=\"5\"><claim-text>5. The system of claim <b>1</b>, wherein the micro-operations include a tag write with line read (TWR) micro-operation that causes the second level cache to send a requested cache line to the processor and update a state associated with the requested cache line.</claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00006\" num=\"6\"><claim-text>6. The system of claim <b>1</b>, wherein the micro-operations include a tag write with data write (TWW) micro-operation that causes the second level cache to store a cache line sent by the processor and a tag and a state associated with the cache line.</claim-text></claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00007\" num=\"7\"><claim-text>7. The system of claim <b>1</b>, wherein the micro-operations include a tag write with half data write (TWH) micro-operation that causes the second level cache to store a cache half line sent by the processor, a tag, and a state associated with the cache half line.</claim-text></claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00008\" num=\"8\"><claim-text>8. The system of claim <b>1</b>, wherein the micro-operations include a tag write with chunk data write (TWC) micro-operation that causes the second level cache to store a chunk of data sent by the processor, a tag, and a state associated with the chunk of data.</claim-text></claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00009\" num=\"9\"><claim-text>9. The system of claim <b>1</b>, wherein the micro-operations include a tag write (TW) micro-operation that causes the second level cache to update a tag and a state associated with a specified cache line.</claim-text></claim>"}, {"num": 10, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00010\" num=\"10\"><claim-text>10. The system of claim <b>1</b>, wherein the micro-operations includes a tag inquire (TI) micro-operation that causes the second level cache to lookup a tag associated with a specified cache line and return results from the lookup to the processor.</claim-text></claim>"}, {"num": 11, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00011\" num=\"11\"><claim-text>11. The system of claim <b>1</b>, wherein the micro-operations include a configuration register read (CR) micro-operation that causes the second level cache to send a data value associated with a specified device register to the processor.</claim-text></claim>"}, {"num": 12, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00012\" num=\"12\"><claim-text>12. The system of claim <b>1</b>, wherein the micro-operations includes a configuration register write (CW) micro-operation that causes the second level cache to write a data value sent from the processor to a register associated with a specified device.</claim-text></claim>"}, {"num": 13, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00013\" num=\"13\"><claim-text>13. A processor comprising:</claim-text><claim-text>a first level cache memory; and </claim-text><claim-text>a cache control circuit to control multiple types of cache memory circuits, the cache control circuit having </claim-text><claim-text>a first level cache interface coupled to the first level cache, wherein the cache control circuit communicates one or more micro-operations from a set of micro-operations that are decoded and executed by the first level cache, and </claim-text><claim-text>a second level cache interface to communicate one or more micro-operations to a second level cache that decodes and executes the micro-operations, if the second level cache is communicatively coupled to the second level cache interface. </claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00014\" num=\"14\"><claim-text>14. The processor of claim <b>13</b>, wherein the set of micro-operations include a data read with least recently used update (RLU) micro-operation that causes the second level cache to update a least recently used (LRU) field associated with a requested cache line, send the requested cache line to the processor, send a cache way from which the requested cache line was read to the processor, and send a state of the requested cache line to the processor.</claim-text></claim>"}, {"num": 15, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00015\" num=\"15\"><claim-text>15. The processor of claim <b>13</b>, wherein the set of micro-operations include a data half read with least recently used update (RHU) micro-operation that causes the second level cache to update a least recently used (LRU) field associated with a requested half cache line, send the requested half cache line to the processor, send a cache way from which the requested half cache line was read to the processor, and send a state of the requested half cache line to the processor.</claim-text></claim>"}, {"num": 16, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00016\" num=\"16\"><claim-text>16. The processor of claim <b>13</b>, wherein the micro-operations include a tag read with line read (TRR) micro-operation that causes the second level cache to send a requested cache line, a tag and a state associated with the requested cache line to the processor.</claim-text></claim>"}, {"num": 17, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00017\" num=\"17\"><claim-text>17. The processor of claim <b>13</b>, wherein the micro-operations include a tag write with line read (TWR) micro-operation that causes the second level cache to send a requested cache line to the processor and update a state associated with the requested cache line.</claim-text></claim>"}, {"num": 18, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00018\" num=\"18\"><claim-text>18. The processor of claim <b>13</b>, wherein the micro-operations include a tag write with data write (TWW) micro-operation that causes the second level cache to store a cache line sent by the processor and a tag and a state associated with the cache line.</claim-text></claim>"}, {"num": 19, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00019\" num=\"19\"><claim-text>19. The processor of claim <b>13</b>, wherein the micro-operations include a tag write with half data write (TWH) micro-operation that causes the second level cache to store a cache half line sent by the processor, a tag, and a state associated with the cache half line.</claim-text></claim>"}, {"num": 20, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00020\" num=\"20\"><claim-text>20. The processor of claim <b>13</b>, wherein the micro-operations include a tag write with chunk data write (TWC) micro-operation that causes the second level cache to store a chunk of data sent by the processor, a tag, and a state associated with the chunk of data.</claim-text></claim>"}, {"num": 21, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00021\" num=\"21\"><claim-text>21. The processor of claim <b>13</b>, wherein the micro-operations include a tag write (TW) micro-operation that causes the second level cache to update a tag and a state associated with a specified cache line.</claim-text></claim>"}, {"num": 22, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00022\" num=\"22\"><claim-text>22. The processor of claim <b>13</b>, wherein the micro-operations includes a tag inquire (TI) micro-operation that causes the second level cache to lookup a tag associated with a specified cache line and return results from the lookup to the processor.</claim-text></claim>"}, {"num": 23, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00023\" num=\"23\"><claim-text>23. The processor of claim <b>13</b>, wherein the micro-operations include a configuration register read (CR) micro-operation that causes the second level cache to send a data value associated with a specified device register to the processor.</claim-text></claim>"}, {"num": 24, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00024\" num=\"24\"><claim-text>24. The processor of claim <b>13</b>, wherein the micro-operations includes a configuration register write (CW) micro-operation that causes the second level cache to write a data value sent from the processor to a register associated with a specified device.</claim-text></claim>"}, {"num": 25, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00025\" num=\"25\"><claim-text>25. A method comprising:</claim-text><claim-text>sending, selectively, a micro-operation from a set of micro-operations to control multiple types of cache memories, from a processor located on a first die to a cache memory circuit located on the first die or to a cache memory circuit located on a second die via a cache bus; </claim-text><claim-text>decoding the micro-operation by the cache memory receiving the micro-operation; </claim-text><claim-text>executing the micro-operation by the cache memory receiving the micro-operation; and </claim-text><claim-text>sending results, if indicated by the micro-operation, to the processor. </claim-text></claim>"}, {"num": 26, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00026\" num=\"26\"><claim-text>26. The method of claim <b>25</b>, wherein the set of micro-operations include a data read with least recently used update (RLU) micro-operation that causes the second level cache to update a least recently used (LRU) field associated with a requested cache line, send the requested cache line to the processor, send a cache way from which the requested cache line was read to the processor, and send a state of the requested cache line to the processor.</claim-text></claim>"}, {"num": 27, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00027\" num=\"27\"><claim-text>27. The method of claim <b>25</b>, wherein the set of micro-operations include a data half read with least recently used update (RHU) micro-operation that causes the second level cache to update a least recently used (LRU) field associated with a requested half cache line, send the requested half cache line to the processor, send a cache way from which the requested half cache line was read to the processor, and send a state of the requested half cache line to the processor.</claim-text></claim>"}, {"num": 28, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00028\" num=\"28\"><claim-text>28. The method of claim <b>25</b>, wherein the micro-operations include a tag read with line read (TRR) micro-operation that causes the second level cache to send a requested cache line, a tag and a state associated with the requested cache line to the processor.</claim-text></claim>"}, {"num": 29, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00029\" num=\"29\"><claim-text>29. The method of claim <b>25</b>, wherein the micro-operations include a tag write with line read (TWR) micro-operation that causes the second level cache to send a requested cache line to the processor and update a state associated with the requested cache line.</claim-text></claim>"}, {"num": 30, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00030\" num=\"30\"><claim-text>30. The method of claim <b>25</b>, wherein the micro-operations include a tag write with data write (TWW) micro-operation that causes the second level cache to store a cache line sent by the processor and a tag and a state associated with the cache line.</claim-text></claim>"}, {"num": 31, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00031\" num=\"31\"><claim-text>31. The method of claim <b>25</b>, wherein the micro-operations include a tag write with half data write (TWH) micro-operation that causes the second level cache to store a cache half line sent by the processor, a tag, and a state associated with the cache half line.</claim-text></claim>"}, {"num": 32, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00032\" num=\"32\"><claim-text>32. The method of claim <b>25</b>, wherein the micro-operations include a tag write with chunk data write (TWC) micro-operation that causes the second level cache to store a chunk of data sent by the processor, a tag, and a state associated with the chunk of data.</claim-text></claim>"}, {"num": 33, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00033\" num=\"33\"><claim-text>33. The method of claim <b>25</b>, wherein the micro-operations include a tag write (TW) micro-operation that causes the second level cache to update a tag and a state associated with a specified cache line.</claim-text></claim>"}, {"num": 34, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00034\" num=\"34\"><claim-text>34. The method of claim <b>25</b>, wherein the micro-operations includes a tag inquire (TI) micro-operation that causes the second level cache to lookup a tag associated with a specified cache line and return results from the lookup to the processor.</claim-text></claim>"}, {"num": 35, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00035\" num=\"35\"><claim-text>35. The method of claim <b>25</b>, wherein the micro-operations include a configuration register read (CR) micro-operation that causes the second level cache to send a data value associated with a specified device register to the processor.</claim-text></claim>"}, {"num": 36, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6202125-B1-CLM-00036\" num=\"36\"><claim-text>36. The method of claim <b>25</b>, wherein the micro-operations includes a configuration register write (CW) micro-operation that causes the second level cache to write a data value sent from the processor to a register associated with a specified device.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54510785\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><p>This is a continuation-in-part of application Ser. No. 08/757,959 filed Nov. 25, 1996, now U.S. Pat. No. 5,678,020.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>FIELD OF THE INVENTION</h4><p>The present invention relates to the field of computer systems; more particularly, the present invention relates to the field of cache memory arrangements in which a cache controller controls multiple cache memories at the same time and is compatible with multiple types of cache memories.</p><h4>BACKGROUND</h4><p>Cache controllers require very complicated logic and most computer systems contain two such controllers, one to control the first level (L<b>1</b>) cache within the processor and the other to control the second level (L<b>2</b>) cache in the system. The design of these two controllers is a compromise between performance and complexity of state that must be shared between them. A system of hierarchical caches would provide a higher overall performance if the cache controllers had access to information about accesses to all cache memories, along with information regarding the processor state and external bus accesses. This is clearly not possible when the cache controller for the L<b>2</b> cache memory is separate from the L<b>1</b> cache controller.</p><p>Also, in the prior art, processors communicate with cache controllers and L<b>2</b> cache memory by asserting and deasserting signals at specific pins. For example, a read is requested by asserting the read pin while sending the requested address to the L<b>2</b> cache memory. Thus, access to the cache memory begins when the signals are asserted or deasserted. In other words, prior art L<b>2</b> cache memories do not receive commands to be decoded and executed.</p><p>Furthermore, prior art L<b>2</b> caches are not designed to support more than one cache-processor architecture.</p><p>That is, prior art cache configurations are designed for specific processors or processor families. Different cache configurations typically are made having different balances between performance and cost. Because a cache configuration is designed for use with a specific processor family, the cost/performance balance of a computer system sought by the user may not be available. In fact, because of this dependence on a particular type of processor, the cache memory configuration cannot be upgraded with advances in technology independently of upgrading the processor. Thus, it is desirable to have a processor that is compatible with multiple types of cache organizations, including the option of operating without a cache memory (if so desired). Therefore, as the different organizations are upgraded, the microprocessor may not have to undergo any changes itself.</p><h4>SUMMARY OF THE INVENTION</h4><p>A computer system having a processor-cache protocol supporting multiple cache configurations is described. The computer system includes a processor having a cache control circuit to control multiple cache memory circuits. The processor is coupled to a cache bus. A second level cache memory is also coupled to the cache bus. The cache control circuit controls the second level cache by issuing commands from a set of commands that are decoded and executed by the second level cache memory.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1 is a block diagram of one embodiment of a cache memory system with a dedicated cache bus according to the present invention.</p><p>FIG. 2 is a block diagram of one embodiment of a memory subsystem of a computer system implemented according to the present invention.</p><p>FIG. 3 is a diagram of one embodiment of the computer system of the present invention.</p><p>FIG. 4A is a flow diagram of one embodiment of an Instruction/Data Fetch sequence according to the present invention.</p><p>FIG. 4B is a flow diagram of one embodiment of an Instruction/Data Fetch Return From Main Memory sequence according to the present invention.</p><p>FIG. 4C is a flow diagram of one embodiment of a Data Cache Read For Ownership Return from Main Memory sequence according to the present invention.</p><p>FIG. 4D is a flow diagram of one embodiment of a Data Cache Writeback sequence according to the present invention.</p><p>FIG. 4E is a flow diagram of one embodiment of an L<b>2</b> Line Flush sequence according to the present invention.</p><p>FIG. 4F is a flow diagram of one embodiment of an L<b>2</b> Line Invalidation sequence according to the present invention.</p><p>FIG. 4G is a flow diagram of one embodiment of a Snoop Probe sequence according to the present invention.</p><p>FIG. 4H is a flow diagram of one embodiment of a Snoop Confirm sequence according to the present invention.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION</h4><p>A cache memory subsystem for use in a computer system is described. In the following detailed description numerous specific details are set forth, such as specific numbers of bits, command and signal names, etc., in order to provide a thorough understanding of the invention. However, it will be understood by one skilled in the art that the present invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the invention.</p><p>The present invention provides a protocol and interface to allow a single integrated circuit (IC) die to control multiple IC dice containing cache memory. According to one embodiment, the dice that are controlled are located in separate packages. Alternatively, multiple dice may be contained within a single integrated circuit package, such that the single die controls the operations of the dice within the package, including its own control. The single die is able to provide control for other dice due to the partitioning of functionality between the dice. The control function of the dice is partitioned, such that the control necessary to monitor and start operations on other dice is placed on a single die, while the control needed to perform a specific function on a die remains on the die that performs the specific function. In this manner, a single die is able to control what the other dice are doing, while the other dice are performing the functions themselves.</p><p>The interface and protocol comprises a set of simple commands, referred to as micro-operations, that allow implementation of a range of cache configurations. Micro-operations are issued to cache memory from cache control logic on a microprocessor die. By implementing a predefined interface between the processor and cache dice with defined commands, the present invention allows for upgrading of cache memory by replacing the cache memory. Also, because micro-operations are decoded and executed by the cache memory, the microprocessor may process other non-cache instructions while the cache memory processes cache operations.</p><p>FIG. 1 is a block diagram of one embodiment of a processor and L<b>2</b> cache memory arrangement of the present invention. Processor <b>101</b> is coupled to L<b>2</b> cache memory <b>102</b> by dedicated cache bus <b>103</b>. Processor <b>101</b> is also coupled to system bus <b>104</b>. Processor <b>101</b> and L<b>2</b> cache memory <b>102</b> may be contained in separate packages or processor <b>101</b> and L<b>2</b> cache memory <b>102</b> may be contained in a dual cavity integrated circuit package. In the present invention, processor <b>101</b> contains cache control circuit <b>112</b>, which provides the functionality for controlling both an L<b>1</b> cache <b>110</b> contained in processor <b>101</b> and L<b>2</b> cache memory <b>102</b>.</p><p>In one embodiment, L<b>2</b> cache memory <b>102</b> comprises L<b>2</b> cache decode unit <b>120</b>. L<b>2</b> cache decode unit <b>120</b> decodes commands (also referred to as micro-operations) to control L<b>2</b> cache memory <b>102</b> according to the commands issued by processor <b>101</b>. As a result of decoding, the L<b>2</b> cache decode unit <b>120</b> generates one or more signals to access information stored in the L<b>2</b> cache memory <b>102</b>. In one embodiment, the information may include data. The information may also include tag information, cache coherency state information, instruction information, etc. Thus, subsequent to decoding, L<b>2</b> cache memory <b>102</b> executes commands by using generated access signals to access information stored in L<b>2</b> cache memory <b>102</b>. The generated access signals may be coupled between the L<b>2</b> cache decode unit <b>120</b> and a storage area such as a tag RAM, data RAM, register, storage area or other memory element in L<b>2</b> cache memory <b>102</b> which stores the information. These have not been shown to avoid obscuring the present invention. L<b>2</b> cache decode unit <b>120</b> also returns results generated by execution of the commands to processor <b>101</b> via dedicated cache bus <b>103</b>. By sending commands to the L<b>2</b> cache to be decoded and executed, the processor may process additional instructions from a program, which increases overall system performance. L<b>2</b> cache memory <b>102</b> may optionally include a static random access memory (SRAM) that stores data, a cache directory and cache management logic; however, other types of memory may be used. The data is stored in a data storage array in the SRAM. The cache directory may include a tag array, tag status and least recently used (LRU) bits. The cache management logic includes the logic to perform tag matching, a replacement algorithm and data routing.</p><p>In one embodiment, the L<b>2</b> cache memory <b>102</b> communicates with processor <b>101</b> using dedicated cache bus <b>103</b>. In one embodiment, dedicated cache bus <b>103</b> includes a bi-directional address bus for sending addresses between processor <b>101</b> and L<b>2</b> cache memory <b>102</b>, a bi-directional data bus, a command bus for sending commands from processor <b>101</b> to L<b>2</b> cache memory <b>102</b> and a response bus. However, other bus configurations may also be used, such as a shared bus or any bus coupling a processor to a cache that allows for commands to be transferred from the processor to the cache memory to control the cache memory.</p><p>FIG. 2 is a block diagram of a memory subsystem of the computer system of the present invention. Boundary lines are shown to define the portion of the memory subsystem that is contained within the processor and that portion which is external to the processor. Referring to FIG. 2, L<b>2</b> cache memory <b>301</b> is coupled to dedicated cache bus <b>103</b>. Dedicated cache bus <b>103</b> is also coupled to dedicated cache bus logic (BBL) <b>303</b>. BBL <b>303</b> is coupled to external bus logic <b>304</b>, instruction fetch unit (IFU) <b>305</b> and the data cache unit (DCU) <b>306</b>. External bus logic <b>304</b> is coupled to IFU <b>305</b>, DCU <b>306</b> and processor system bus <b>307</b>. System memory <b>308</b> is coupled to processor system bus <b>307</b>.</p><p>IFU <b>305</b> includes instruction fetch logic as well as the instruction cache and fetches instructions for execution in the processor. When the instruction cache of IFU <b>305</b> desires to fetch more instructions, it sends a request on request lines <b>310</b> to external bus logic <b>304</b>. External bus logic <b>304</b> sends the request on request lines <b>315</b> to BBL <b>303</b>, which forwards the request to L<b>2</b> cache memory <b>301</b>. In response, L<b>2</b> cache memory <b>301</b> performs a read operation. If there is a hit in L<b>2</b> cache memory <b>301</b>, the instructions are returned to IFU <b>305</b> on the data return signal lines <b>311</b> from BBL <b>303</b> and dedicated cache bus <b>103</b>.</p><p>DCU <b>306</b> holds temporary copies of data for use by the processor in executing instructions. In one embodiment, DCU <b>306</b> comprises an L<b>1</b> cache memory. Note that the present invention may be applied to an instruction cache or a cache that stores both instructions and data at the same time.</p><p>In executing instructions, if the data is not in DCU <b>306</b> (i.e., the L<b>1</b> cache), a request is made on request lines <b>312</b> to external bus logic <b>304</b>. External bus logic <b>304</b> sends a request on request lines <b>315</b> to BBL <b>303</b> which forwards the request onto L<b>2</b> cache memory <b>301</b>. If the data is in L<b>2</b> cache memory <b>301</b> (if L<b>2</b> cache memory <b>301</b> hits), then the data is forwarded and returned to DCU <b>306</b> on data return lines <b>313</b>. When data is written back from DCU <b>306</b>, data is sent out on data writeback path <b>314</b> to dedicated cache bus <b>103</b> via BBL <b>303</b> to L<b>2</b> cache memory <b>301</b>.</p><p>If data from L<b>2</b> cache memory <b>301</b> is to be written back to system memory <b>308</b>, a request is made to external bus logic <b>304</b> via request lines <b>316</b> from BBL <b>303</b>. The data is written from dedicated cache bus <b>103</b> through BBL <b>303</b> to external bus logic <b>304</b> via data path <b>327</b>. External bus logic <b>304</b> controls the data by writing the data on bus <b>104</b> to system memory <b>308</b> via processor system bus <b>307</b>. When there is a miss to L<b>2</b> cache memory <b>301</b>, external bus logic <b>304</b> sends the request to system memory <b>308</b> using bus <b>104</b> and processor system bus <b>307</b>. The data returned is received by external bus logic <b>304</b> and sent to BBL <b>303</b> via data path <b>327</b> for storage in L<b>2</b> cache memory <b>301</b>. The data is also written to DCU <b>306</b> via data return lines <b>313</b> and to L<b>2</b> cache memory <b>301</b> via dedicated cache bus <b>103</b>. Note that in another embodiment L<b>2</b> cache <b>301</b> may also be coupled to processor system bus <b>307</b> and commands sent from the processor, which are decoded and executed by L<b>2</b> cache memory <b>301</b>, cause L<b>2</b> cache memory <b>301</b> to write data directly to processor system bus <b>307</b>. Note that for reasons discussed below, such an additional coupling may not be entirely desirable.</p><p>Processor accesses from IFU <b>305</b> are always fetch operations that do not modify the data. Similarly, read operations from the data cache <b>306</b> that are generated by the processor executing a read operation are always data fetch operations. These requests are forwarded to processor system bus <b>307</b>, if they miss L<b>2</b> cache memory <b>301</b>, as read operations from the memory. When the data is returned by system memory <b>308</b>, a signal on processor system bus <b>307</b> indicates if copies of this data also exist in other cache memories in a multiple processor system. If they do, then the data is placed in L<b>2</b> cache memory <b>301</b> and DCU <b>306</b> and marked with a state of Shared (S). On the other hand, if no other cache memory has a copy of the data as indicated on processor system bus <b>307</b>, the data can be placed in L<b>2</b> cache memory <b>301</b> and DCU <b>306</b> and marked Exclusive (E).</p><p>When the processor modifies data, it issues a request to DCU <b>306</b> to obtain a copy of the data with complete ownership. If the data is not present in DCU <b>306</b>, a similar request is sent to L<b>2</b> cache memory <b>301</b>. If the request also misses L<b>2</b> cache memory <b>301</b>, it is then forwarded to processor system bus <b>307</b> as a data read request with a command modifier indicating to all other processors on processor system bus <b>307</b> that they must relinquish ownership of this cache line of data and invalidate all copies of the line in their cache memories. The data is then returned to the requesting processor granting it exclusive ownership and is placed in L<b>2</b> cache memory <b>301</b> and DCU <b>306</b> in the Modified (M) state. The processor is then free to update any portion of the cache line it chooses. This results in a write command being issued to DCU <b>306</b> with the modified data and DCU <b>306</b> updates its copy of the cache line to reflect the change.</p><p>By integrating the control for L<b>2</b> cache memory <b>301</b> into the processor, the present invention is able to better coordinate the activities and transactions that occur in the computer system as a function of the type of cache memory connected to the processor. The single control of the processor is functionally positioned with respect to DCU <b>306</b>, L<b>2</b> cache memory <b>301</b> and the processor system bus <b>307</b> to allow the controller to obtain information and respond, if necessary, to any transaction on the three ports (DCU <b>306</b>, L<b>2</b> cache memory <b>301</b> and the processor system bus <b>307</b>) that is currently in progress. The controller of the present invention can optimize the transactions sourced from one or more of DCU <b>306</b>, L<b>2</b> cache memory <b>301</b> and processor system bus <b>307</b> to improve performance.</p><h4>Controlling the L<b>2</b> Cache Memory</h4><p>The processor of the present invention controls the functionality of the L<b>2</b> cache memory, such that the L<b>2</b> cache memory is a slave on the dedicated cache bus. That is, the control of the L<b>2</b> cache memory is partitioned between the processor and the L<b>2</b> cache memory in such a way that the processor of the present invention controls what the L<b>2</b> cache memory is doing (e.g., whether the L<b>2</b> cache memory is transferring data). In one embodiment, the processor uses the same control logic to control both the L<b>1</b> and the L<b>2</b> caches. By using the same control logic, cost and complexity of the system is reduced and better overall performance is obtained. In the present invention, the processor controls the L<b>2</b> cache memory using micro-operations sent by the processor to the L<b>2</b> cache memory.</p><p>The processor controls the L<b>2</b> cache memory behavior through micro-operations which provide the functionality needed for all processor requests to L<b>2</b> cache memory. These micro-operations function within the confines of the interface provided between the processor and the L<b>2</b> cache memory in order to implement single die control in a multi-chip system. A brief description of one embodiment of micro-operations performed by the L<b>2</b> cache memory is given below.</p><p>Data Line Read with LRU Update (RLU): This command is used by the processor to lookup a line in the L<b>2</b> cache memory, and upon an L<b>2</b> hit, read the data from the L<b>2</b> cache memory. This command also updates the LRU field in the L<b>2</b> cache memory.</p><p>Data Half Line Read with LRU (RHU): This command operates in the same manner as the RLU command except that half of a cache line is returned to the processor.</p><p>Tag Read with Line Read (TRR): This command is used to read the entire content of a line in cache memory. The processor provides the set and way address to cache memory and cache memory returns the tag, state and data of the requested line.</p><p>Tag Write with Line Read (TWR): This command is used to update the state of a specific line while reading its data content for the purpose of returning it out to the system bus. The processor provides the set and way address and the new state to cache memory and cache memory returns the data at the requested location.</p><p>Tag Write with Data Write (TWW): The processor uses this command to write the entire content of a cache line and its tag into cache memory. The processor provides the set, tag, chunk and way addresses along with the state and data to cache memory. Cache memory stores the information at the address requested. Other than a possible error message, no information is returned by the L<b>2</b> cache.</p><p>Tag Write With Half Data Write (TWH): This command operates in the same manner as the TWW command except half of a cache line is stored in cache memory.</p><p>Tag Write with Chunk Data Write (TWC): This command operates in the same manner as the TWW command except a chunk (8 bytes) of data is stored in cache memory.</p><p>Tag Write (TW): The processor uses this command to update the tag and state of a cache line. The processor provides the set, tag and way addresses along with the new state to cache memory. Cache memory stores the new tag and state information at the addressed location and does not return any information other than a possible error indication.</p><p>Tag Inquire (TI): The processor uses this command to determine if cache memory contains data at a particular location. The processor provides the set and tag address to cache memory, which returns a hit/miss indication. If a hit occurs, cache memory also returns the state and way information.</p><p>Configuration Register Read (CR): The processor provides a device and register address to cache memory, which returns the data value in the register over the bi-directional address bus.</p><p>Configuration Register Write (CW): The processor provides the device and register address along with a data value on the bi-directional address bus that cache memory writes into the addressed register. Cache memory may return an error message.</p><p>Due to the partitioning of control in the present invention, multiple types of cache memory organizations may be utilized with the processor of the present invention. The cache memory is only be able to satisfy the memory request from the processor according to its organization. This allows the L<b>2</b> cache memory to be upgraded to a different organization in the future. In the present invention, the directory and data of the L<b>2</b> cache memory operate independently. Because of this, the L<b>2</b> cache memory can be upgraded independently.</p><p>Also, because the processor handles all L<b>2</b> cache memory look-ups, a miss to the L<b>2</b> cache memory does not stall accesses on the system bus. For example, if the processor sends memory requests for addresses A, B and C to the L<b>2</b> cache memory, a miss to address A in the prior art would tie up the bus even though data corresponding to addresses B and C are in the L<b>2</b> cache memory. Thus, if data of address A is not in cache memory, the data at addresses B and C in the cache memory could not be obtained until the memory request to address A was satisfied. In the present invention, because the processor contains all the control logic, when a miss occurs, the processor can send the request out on the system bus while continuing to send requests to the L<b>2</b> cache memory for data corresponding to addresses B and C.</p><p>The processor and the L<b>2</b> cache memory in the present invention may be integrated in a computer system such as that in FIG. <b>3</b>. Referring to FIG. 3, an overview of a computer system of the present invention is shown in block diagram form. It will be understood that while FIG. 3 is useful for providing an overall description of the computer system of the present invention, a number of details of the system are not shown.</p><p>The computer system of FIG. 3, as may be utilized by the preferred embodiment of the present invention, generally comprises of processor-system bus <b>401</b> and processor <b>402</b> coupled to processor-system bus <b>401</b> for processing information. In the present invention, processor-system bus <b>401</b> includes address, data and control buses. In the currently preferred embodiment, processor <b>402</b> includes an internal L<b>1</b> cache memory, that temporarily stores data and instructions on-chip. L<b>2</b> cache memory <b>404</b> is coupled to processor <b>402</b> via dedicated cache bus <b>103</b> for temporarily storing data and instructions for use by processor <b>402</b>.</p><p>Also coupled to processor-system bus <b>401</b> is processor <b>403</b> for processing information in conjunction with processor <b>402</b>. Processor <b>403</b> may comprise a parallel processor, such as a processor similar to or the same as processor <b>402</b>. A level three (L<b>3</b>) cache memory <b>411</b> for temporarily storing data and instructions for use by other devices in the computer system (e.g., processor <b>402</b>, processor <b>403</b>, etc.) and a L<b>3</b> cache controller <b>410</b> for controlling access to L<b>3</b> cache memory <b>411</b> may also be coupled to processor-system bus <b>401</b>. The L<b>3</b> cache controller <b>410</b> is also coupled to memory-system bus <b>415</b>.</p><p>Memory controller <b>422</b> is coupled to memory-system bus <b>415</b> for controlling access to a random access memory (RAM) <b>421</b>. Mass data storage device <b>425</b>, such as a magnetic disk and disk drive and display device <b>423</b> may be coupled to memory-system bus <b>415</b>.</p><p>I/O bridge <b>424</b> is coupled to memory-system bus <b>415</b> and system bus <b>431</b> to provide a communication path or gateway for devices on either memory-system bus <b>415</b> or system bus <b>431</b> to access or transfer data between devices on the other bus. Specifically, I/O bridge <b>424</b> transfers the data from system bus <b>431</b> to memory-system bus <b>415</b>.</p><p>System bus <b>431</b> communicates information between devices in the computer system. Devices that may be coupled to system bus <b>431</b> include display device <b>432</b>, an alphanumeric input device <b>433</b> and a cursor control device <b>434</b>. Moreover, a hard copy device <b>435</b> and mass storage device <b>436</b> may also be coupled to system bus <b>431</b>.</p><p>Of course, certain implementations and uses of the present invention may not require nor include all of the above components. For example, in certain implementations, the L<b>3</b> cache controller and L<b>3</b> cache memory may not be required. In such implementations processors (<b>402</b>) and (<b>403</b>) will reside directly on memory-system bus <b>415</b>.</p><p>FIG. 4A is a flow diagram of one embodiment of an Instruction/Data Fetch operation according to the present invention. From the perspective of the sequence of L<b>2</b> micro-operations that appear on the dedicated cache bus, the Instruction Fetch and the Data Fetch instructions, shown in process block <b>800</b>, are the same. The first micro-operation issued by BBL <b>303</b> is an RLU micro-operation, shown in process block <b>801</b>. If the lookup results in a hit in process block <b>802</b>, the sequence is complete, shown by process block <b>806</b>. If a miss occurs, and a clean victim is selected in process block <b>803</b>, the sequence is complete. If the selected victim is modified, it is read out with a TRR micro-operation in process block <b>804</b>. Then the victim is invalidated with a TW micro-operation in process block <b>805</b>. The sequence is then complete, as shown by process block <b>806</b>.</p><p>FIG. 4B is a flow diagram of one embodiment of an Instruction/data fetch return from main memory operation according to the present invention. When a cache line has been returned from main memory via the system bus and is ready to be placed in the L<b>2</b> cache, as shown by process block <b>810</b>, BBL <b>303</b> issues a TWW micro-operation shown in process block <b>811</b>. The data that comprise the cache line are then written into the L<b>2</b> data array as shown by process block <b>812</b>. The sequence is then complete as shown by process block <b>813</b>.</p><p>FIG. 4C is a flow diagram of one embodiment of a Data Cache Read For Ownership Return from Main Memory operation according to the present invention. This sequence differs slightly from the sequence shown in FIG. 4B in that the data does not have to be written into the L<b>2</b> cache because it is written into the L<b>1</b> cache instead. Thus, in response to a Data Cache Read for Ownership Return from Main Memory operation, shown in process block <b>820</b>, BBL <b>303</b> issues a TW micro-operation to allocate the line into the L<b>2</b> cache shown in process block <b>821</b>. The sequence is then complete, as shown by process block <b>822</b>.</p><p>FIG. 4D is a flow diagram of one embodiment of a Data Cache Writeback operation according to the present invention. When a modified cache line is evicted from the L<b>1</b> cache, it is written to the L<b>2</b> cache. Because inclusion is not guaranteed in the cache hierarchy, the line may not be present in the L<b>2</b> cache. Thus, when a Data Cache Writeback operation, as shown in process block <b>830</b>, is performed, BBL <b>303</b> issues a TI micro-operation, shown in process block <b>831</b>, to determine whether the line is present in the L<b>2</b> cache, shown in process block <b>832</b>. If the line is not present in the L<b>2</b> cache, the sequence is complete, as shown by process block <b>835</b>. Otherwise, a TWW micro-operation is issued, as shown in process block <b>833</b>. Subsequently, the data that comprise the cache line are written to the data array of the L<b>2</b> cache, as shown in process block <b>834</b>. The sequence then completes in process block <b>835</b>.</p><p>FIG. 4E is a flow diagram of one embodiment of an L<b>2</b> Line Flush operation according to the present invention. When the L<b>2</b> cache is to be flushed, the sequence of FIG. 4E is performed for each line in the L<b>2</b> cache. The sequence begins with an L<b>2</b> Line Flush operation, shown by process block <b>840</b>. In response, BBL <b>303</b> issues a TRR micro-operation in process block <b>841</b>. If the line read out is invalid, the sequence is completed in process block <b>844</b>. If the line read out is valid, BBL <b>303</b> issues a TW micro-operation in process block <b>843</b> to invalidate the line. The sequence is then completed in process block <b>844</b>.</p><p>FIG. 4F is a flow diagram of one embodiment of an L<b>2</b> Line Invalidation operation according to the present invention. When the L<b>2</b> cache is to be invalidated the sequence of FIG. 4F is performed for each line in the L<b>2</b> cache. In response to an L<b>2</b> Line Invalidation operation shown in process block <b>850</b>, BBL <b>303</b> issues a TW micro-operation in process block <b>851</b> to invalidate a cache line. The sequence is then complete in process block <b>852</b> and repeated for subsequent lines, if necessary.</p><p>FIG. 4G is a flow diagram of one embodiment of a Snoop Probe operation according to the present invention. In response to a Snoop Probe operation, shown in process block <b>860</b>, BBL <b>303</b> issues a TI micro-operation, shown in process block <b>861</b>. If the TI results in a miss or a hit to a modified line, in process block <b>862</b>, the sequence is completed in process block <b>866</b>. In the case of a modified line, a Snoop Confirm operation is used to complete the snoop process. If the line is marked as exclusive, as determined in process block <b>863</b>, a TW micro-operation is issued in process block <b>865</b> to change the state to Shared (S) or Invalid (I). If the line is a shared line, as determined in process block <b>863</b>, and the target state is also Shared (S), then the process is complete. Otherwise, a TW micro-operation is issued in process block <b>865</b> to change the line to Invalid (I).</p><p>FIG. 4H is a flow diagram of one embodiment of a Snoop Confirm operation according to the present invention. A Snoop Confirm operation is performed if a Snoop Probe operation hits a modified line, which requires a state update to be performed and may require data to be returned; however, the most up to date copy of the data may not be present in the L<b>2</b> cache (i.e., more modified data may exist in the L<b>1</b> cache). In this case, the data will be obtained from the L<b>1</b> cache and only the state in the L<b>2</b> cache needs to be updated. The Snoop Confirm, in process block <b>870</b>, indicates that a state update is necessary, and whether data is required. If the Snoop Confirm requires data, as determined in process block <b>871</b>, BBL <b>303</b> issues a TWR micro-operation in process block <b>872</b>. Otherwise, BBL <b>303</b> issues a TW micro-operation in process block <b>873</b>. The sequence is then complete in process block <b>874</b>.</p><h4>Cache Interface Signals</h4><p>In one embodiment, the interface between the processor and cache is composed of five groups of signals. These groups are:</p><p>1. Transaction Request Signals.</p><p>2. Transaction Response Signals.</p><p>3. Data Signals.</p><p>4. RAM Control Signals (in one embodiment, these are BSRAM control signals).</p><p>5. General Signals.</p><p>In other embodiments, some of these signals are not included.</p><p>For L<b>2</b> cache configurations that make use of tag RAM(s) and BSRAMs, an additional group of signals, the BSRAM Address Signals, are used as an interface between these components. In one embodiment, this interface only exists between the tag SRAM(s) and the BSRAMs.</p><p>One embodiment of the signals in the groups are described below.</p><h4>Transaction Request Signals</h4><p>This group of signals connects the processor to either the cache RAM(s) or tag SRAM(s). The signals in this group are:</p><h4>Cache Address (CA)</h4><p>In one embodiment, the CA bus is 33 bit wide bus that carries the address from the processor to the cache. The address is driven on to this bus and held stable for a minimum of one cache clock cycle. The bus is bi-directional and also carries the victim cache line address from the tag, SRAM(s) or cache RAM to the processor, in response to a request for this information. The width of this bus can be limited, as necessary, to accommodate processors and caches that do not require the entire 36 bits of address. Other CA bus widths may also be used that may be include a greater or fewer number of address bits.</p><h4>Cache Address Parity (CAP)</h4><p>This bus carries the two parity bits covering the Cache Address bus described above. In one embodiment, the lower order parity bit, CAP[0] covers the lower 16 bits, CA[20:5], of the bus wile the upper parity bit CAP[1] is computed across the upper bits, CA[35:21]. In case the address bus width is less than 36 bits, the coverage provided by CAP[1] is adjusted accordingly assuming that the higher order bits are zero. The CAP bits carry valid parity along with the CA bus signals. This bus is bi-directional and valid one cache clock phase after the address when the bus is operating at full speed, and one cache clock cycle after the address otherwise. Of course, different CA bus widths may result in a different number of CAP bits.</p><h4>Cache Command (CCMD)</h4><p>This bus carries commands (referred to above as a micro-operation) from the processor to the cache. The commands on this bus control the tag SRAM or the SRAMs of the cache via the cache control circuit. The commands supported by the interface are shown in Table 1. This bus is unidirectional and valid for a period no less than one cache clock cycle.</p><h4>Cache Way (CWY)</h4><p>In a four-way set-associative cache embodiment, the two bits on this bus carry the way information from the processor to the cache whenever the processor has to address a specific way in a set. These bus signals are unidirectional and are valid for a period no less than one cache clock cycle and driven out at the same time as the Cache Command. Commands that use the way information are shown in Table 1. Of course, alternative cache configurations may result in a different number of way signals.</p><h4>Command Address Strobe (CADS)</h4><p>In one embodiment, this signal is driven by the processor to initiate every cache transaction on the bus. It is a unidirectional signal and is active for one cache clock phase when the bus is operating at the full frequency of the processor. It is active for one cache clock cycle when the bus is operating at a fraction of the processor frequency.</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217PT\"></colspec><thead valign=\"bottom\"><row><entry morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\">TABLE 1</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\">Command Encoding</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"5\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"OFFSET\" colwidth=\"14PT\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"56PT\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"56PT\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"42PT\"></colspec><colspec align=\"center\" colname=\"4\" colwidth=\"49PT\"></colspec><tbody valign=\"top\"><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Transaction</entry><entry morerows=\"0\" valign=\"top\">CCMD[4:2]</entry><entry morerows=\"0\" valign=\"top\">CCMD[1:0]</entry><entry morerows=\"0\" valign=\"top\">CWY[1:0]</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"4\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Data Line Read</entry><entry morerows=\"0\" valign=\"top\">011</entry><entry morerows=\"0\" valign=\"top\">00</entry><entry morerows=\"0\" valign=\"top\">XX</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">w/ LRU update</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">(RLU)</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Read Half Line</entry><entry morerows=\"0\" valign=\"top\">011</entry><entry morerows=\"0\" valign=\"top\">01</entry><entry morerows=\"0\" valign=\"top\">XX</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">w/ LRU Update</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">(RHU)*</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Read w/ Data</entry><entry morerows=\"0\" valign=\"top\">011</entry><entry morerows=\"0\" valign=\"top\">10</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Read (TRR)</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Write w/</entry><entry morerows=\"0\" valign=\"top\">010</entry><entry morerows=\"0\" valign=\"top\">State</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Line Read (TWR)</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Write w/</entry><entry morerows=\"0\" valign=\"top\">111</entry><entry morerows=\"0\" valign=\"top\">State</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Data Write</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">(TWW)</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Write w/</entry><entry morerows=\"0\" valign=\"top\">110</entry><entry morerows=\"0\" valign=\"top\">State</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Half Line Write</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">(TWH)*</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Write w/</entry><entry morerows=\"0\" valign=\"top\">101</entry><entry morerows=\"0\" valign=\"top\">State</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Chunk Write</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">(TWC)*</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Write (TW)</entry><entry morerows=\"0\" valign=\"top\">100</entry><entry morerows=\"0\" valign=\"top\">State</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Inquire (TI)</entry><entry morerows=\"0\" valign=\"top\">011</entry><entry morerows=\"0\" valign=\"top\">11</entry><entry morerows=\"0\" valign=\"top\">XX</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Configuration</entry><entry morerows=\"0\" valign=\"top\">000</entry><entry morerows=\"0\" valign=\"top\">10</entry><entry morerows=\"0\" valign=\"top\">XX</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Register Read</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">(CR)</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Configuration</entry><entry morerows=\"0\" valign=\"top\">000</entry><entry morerows=\"0\" valign=\"top\">11</entry><entry morerows=\"0\" valign=\"top\">XX</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Register Write</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">(CW)</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Reserved</entry><entry morerows=\"0\" valign=\"top\">000</entry><entry morerows=\"0\" valign=\"top\">0X</entry><entry morerows=\"0\" valign=\"top\">XX</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Reserved</entry><entry morerows=\"0\" valign=\"top\">001</entry><entry morerows=\"0\" valign=\"top\">XX</entry><entry morerows=\"0\" valign=\"top\">XX</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"4\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"left\" morerows=\"0\" nameend=\"4\" namest=\"OFFSET\" valign=\"top\">*In one embodiment, these commands are optional and need not be implemented in every processor/cache combination. </entry></row></tbody></tgroup></table></tables></p><h4>Command Parity (CCP)</h4><p>In one embodiment, this signal is the parity bit that covers the cache command (CCMD[4:0]) and way (CWY[1:0]) signals. The signal is valid one cache clock phase after the signals it covers when the bus is operating at full speed, and one cache clock cycle after those signals otherwise. It is a unidirectional signal and driven by the processor for a period no less than one cache clock cycle.</p><h4>Transaction Response Signals</h4><p>In one embodiment, certain cache transactions initiated by the processor over the Transaction Request group of signals produce a response from the cache that is carried over this group of signals. These signals are:</p><h4>Cache Return (CRTN)</h4><p>According to one embodiment, five signals carry the status of cache tag from the tag SRAM or cache SRAMs to the processor. The encoding of these signals is shown in Table 2. These signals are unidirectional and valid for a period no less than one cache clock cycle and are held on the bus through \u201ckeepers\u201d until a new value is driven out.</p><p><tables id=\"TABLE-US-00002\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217PT\"></colspec><thead valign=\"bottom\"><row><entry morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\">TABLE 2</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\">Response Return Encoding</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"5\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"OFFSET\" colwidth=\"14PT\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"56PT\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"42PT\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"42PT\"></colspec><colspec align=\"center\" colname=\"4\" colwidth=\"63PT\"></colspec><tbody valign=\"top\"><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Transaction</entry><entry morerows=\"0\" valign=\"top\">RTN[4]</entry><entry morerows=\"0\" valign=\"top\">RTN[3:2]</entry><entry morerows=\"0\" valign=\"top\">RTN[1:0]</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"4\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Data Read w/</entry><entry morerows=\"0\" valign=\"top\">Hit</entry><entry morerows=\"0\" valign=\"top\">State</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LRU HIT</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Data Read w/</entry><entry morerows=\"0\" valign=\"top\">Miss</entry><entry morerows=\"0\" valign=\"top\">Victim State</entry><entry morerows=\"0\" valign=\"top\">Victim Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LRU MISS</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Read w/ Data</entry><entry morerows=\"0\" valign=\"top\">X</entry><entry morerows=\"0\" valign=\"top\">Victim State</entry><entry morerows=\"0\" valign=\"top\">X</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Read</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Tag Inquire HIT</entry><entry morerows=\"0\" valign=\"top\">Hit</entry><entry morerows=\"0\" valign=\"top\">State</entry><entry morerows=\"0\" valign=\"top\">Way</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"4\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row></tbody></tgroup></table></tables></p><h4>Cache Synchronous Error (CSER)</h4><p>In one embodiment, this signal is issued by the tag SRAM or cache SRAM to indicate the error status of the cache in response to the command it has just received from the processor. The error is signaled in the same cycle as the response from the cache. This signal is unidirectional and is active for no less than one cache clock cycle.</p><h4>Cache Return Parity (CRP)</h4><p>In one embodiment, this parity signal covers the cache return one cache clock phase after the signals it covers when the bus is operating at full speed, and one cache clock cycle after those signals otherwise. It is a unidirectional signal given by the tag SRAM or cache SRAM to the processor. It is active for a period of no less than one cache clock cycle. Of course, alternative parity schemes may cover the cache return signals.</p><h4>Cache Return Strobe (CSTB)</h4><p>In one embodiment, this strobe signal is issued to clock the response signals into the processor when source-synchronous mode is used for operation at high frequencies. It is driven by the cache for a period of a cache clock phase with a fixed timing relationship to the rest of the signals in this group. This signal is optional on the processor. It need only be used if the processor cannot guarantee correct sampling at the frequency of operation. In alternative non-source-synchronous embodiments, the CSTB may be replaced with a clock signal.</p><h4>Data Signals</h4><p>According to one embodiment, this group of signals runs between the processor and the data port of the cache SRAMs or the BSRAMs. In one embodiment, the signals in this group are:</p><h4>Data Bus (BD)</h4><p>In one embodiment, the BD is a 64 bit wide bus that carries the data between the cache and processor. It connects to either the data port of the cache SRAM(s) or the BSRAMs. It is a bi-directional bus that is driven once every phase of the cache clock cycle in the full frequency mode of bus operation and once every cache clock cycle for fractional bus frequency modes. Of course, alternative embodiments, may vary to bus width to greater than or less than 64 bits.</p><h4>Data Bus Integrity (BDI)</h4><p>In a 64-bit BD embodiment, this bus provides eight signals between the processor and cache that are intended to carry data integrity signals for the data bus. This bus is optional and may not exist on systems where it is not needed. Caches that implement this feature are required to treat these eight bits per chunk the same as data, storing them in the data array and returning them to the processor when requested. The actual usage is dependent upon the implementation of the processor. As an example, they could be used as parity bits, carrying byte wide parity for the data bus. Alternatively, the processor may choose to implement an error correcting code (ECC) scheme and use these eight bits accordingly. The signals on this bus are bi-directional and are driven at the same time as the data bus. The processor must be able to disable checking data integrity for systems that do not implement the necessary storage for these bits. When implementing BD embodiments of sizes other than 64 bits, BDI is adjusted accordingly.</p><h4>Data Bus Strobes (BSTB)</h4><p>In one embodiment, this set of signals is composed of four pairs of complementary strobe signals. These signals are used to clock the transfer of data between the cache RAMs and the processor when the interface is running at high frequency. The strobe signals are bi-directional and are driven by the agent that is driving the data and data integrity busses, BD[63:0] and BDI[7:0]. The strobe signals capture the data in the de-skew latches in the receiving agent before transfer into its core. Each pair of strobe signals, consisting of a true and complementary signal, is associated with sixteen data bus signals and two data integrity signals. It is implemented with a tight skew relationship with respect to its corresponding bus signals. The strobes BSTB[3] and BSTB[3]# are associated with the data bus BD[63:48] and BDI[7:6] and so on, in order, for the remaining strobe pairs. Alternatively, a different number of strobe signals may be used, or in some embodiments, one or more clock signals may replace the strobes.</p><h4>RAM Control Signals</h4><p>This group of signals is designed to control the operation of the RAMs used for the data array of the cache. According to one embodiment, BSRAMs are used. The signals are unidirectional and are driven by the processor to the BSRAMs. All of these signals are used in the one half or lower bus frequency modes of operation and are always driven and are active for a period no less than one cache clock period.</p><p>This group contains the BSRAM signals that are required for this bus to work and is not intended to cover all the control signals provided on the current industry standard BSRAMs. BSRAMs provide a second ADS that must be tied inactive when used with this bus protocol. The byte write controls on the BSRAMs are also not used as part of this protocol. Of course, when other types of RAM are used, the control signals varied.</p><p>In one embodiment, the signals in this group are:</p><h4>BSRAM Address Strobe (BADS#)</h4><p>In one embodiment, this signal is the strobe that initiates all operations for the BSRAMs. It latches the address and control inputs into the BSRAMs. It is driven for exactly one cache clock period. It is connected to the ADSC# signal on the BSRAMs. The ADSP# address strobe on the BSRAMs is tied inactive.</p><h4>Burst Advance (BADV#)</h4><p>In one embodiment, this signal to the BSRAMs is driven by the processor during a burst read or write operation to increment the burst counter within the BSRAMs. The signal is latched by the cache clock and is active for up to three cache clock cycles.</p><p>BSRAM Write Enable (BWE#)</p><p>In one embodiment, this signal is used to indicate a write operation to the BSRAMs. The signal is valid for four cache clock periods. This signal is connected to the BW# input on the BSRAMs. The BW[3:0]# signals of the BSRAMs are tied inactive.</p><h4>BSRAM Output Enable (BOE#)</h4><p>In one embodiment, this signal is used to enable and disable the data output drivers of the BSRAMs. It is primarily used to control the turn around of the data bus for read to write cases. This signal is held inactive during all writes for the entire duration of the data transfer, and conversely, is held active during the data transfer of processor read cycles to the L<b>2</b> cache memory.</p><h4>General Control Signals</h4><p>In one embodiment, the following set of signals are used to provide timing and control signals for the entire interface and are not transaction or protocol specific. They connect the processor to the cache tag, SRAM(s) and BSRAMs or the cache RAMs. The signals in this group are:</p><h4>Cache Clock (CCLK)</h4><p>In one embodiment, this set of four clocking signals are driven by the processor to the cache to provide all the necessary timing information for bus operation. There may be multiple copies of the same timing clock signal and may be presented in true and complement form. These signals have tight skew tolerance to each other. The L<b>2</b> cache may use these clock signals to directly control the timing of the internal events, or it may use an internal clock multiplier and phase locked loop (PLL) to achieve a higher internal frequency.</p><p>In alternative embodiments, the number of cache clock signals may be varied. Alternatively, timing information may be provided by one or more strobe signals.</p><h4>Cache Reset (CRST#)</h4><p>In one embodiment, this signal is driven by the processor to the cache tag and cache RAMs to reset their internal state. This signal can be asserted asynchronously but its release is synchronous to cache clock.</p><h4>Cache Synchronous Error (CSER)</h4><p>In one embodiment, this signal is used by the cache subsystem to signal an error or failure to the processor. The errors indicated on this signal are associated with a specific command from the processor. It is provided as a catch-all error signal that is not considered recoverable by the processor. The signal is active high. The signal must be active for no less than one cache clock period.</p><h4>BSRAM Address Signals</h4><p>In one embodiment, this group of signals connect the tag SRAM(s) to the BSRAMs for the cache configurations based upon these devices. These signals are contained within the cache RAMs and are not part of the interface. In one embodiment, the signals in this group are:</p><h4>BSRAM Set Address (BSA)</h4><p>In one embodiment, these thirteen signals carry the set address from the cache tag SRAM to the BSRAMs to address up to a maximum of 8 k sets in the cache. These can correspond to processor address bits A[17:5] for the largest cache. These signals are driven by the tag SRAM to the BSRAMs forming the data array and are held valid until the next cache command that accesses the data array. These signals are connected to the address inputs A[14:4] of the BSRAMs. Of course the BSA may comprise a different number of signals depending on the size of the sets contained in the cache memory.</p><h4>BSRAM Critical Chunk Address (BCA)</h4><p>In one embodiment, these two address bits from the tag SRAM are driven to the least significant address bits of the BSRAMs. They provide the address of the chunk within the cache line that must be driven out first in the burst of data. The BSRAMs' internal burst counter starts at the value specified on these signals and proceeds in the burst order shown in Table 3. These signals are connected to address inputs A[1:0] of the BSRAMs. Alternatively, the BCA signals may comprise a different number of bits depending on the size of the chunks used.</p><p><tables id=\"TABLE-US-00003\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217PT\"></colspec><thead valign=\"bottom\"><row><entry morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\">TABLE 3</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\">Burst order of data transfers</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"6\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"OFFSET\" colwidth=\"14PT\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"49PT\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"28PT\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"49PT\"></colspec><colspec align=\"center\" colname=\"4\" colwidth=\"28PT\"></colspec><colspec align=\"center\" colname=\"5\" colwidth=\"49PT\"></colspec><tbody valign=\"top\"><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Chunk</entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Address</entry><entry morerows=\"0\" valign=\"top\">00</entry><entry morerows=\"0\" valign=\"top\">01</entry><entry morerows=\"0\" valign=\"top\">10</entry><entry morerows=\"0\" valign=\"top\">11</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"5\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">First Address</entry><entry morerows=\"0\" valign=\"top\">X..X00</entry><entry morerows=\"0\" valign=\"top\">X..X01</entry><entry morerows=\"0\" valign=\"top\">X..X10</entry><entry morerows=\"0\" valign=\"top\">X..X11</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Second</entry><entry morerows=\"0\" valign=\"top\">X..X01</entry><entry morerows=\"0\" valign=\"top\">X..X00</entry><entry morerows=\"0\" valign=\"top\">X..X11</entry><entry morerows=\"0\" valign=\"top\">X..X10</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Address</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Third</entry><entry morerows=\"0\" valign=\"top\">X..X10</entry><entry morerows=\"0\" valign=\"top\">X..X11</entry><entry morerows=\"0\" valign=\"top\">X..X00</entry><entry morerows=\"0\" valign=\"top\">X..X01</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Address</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Fourth</entry><entry morerows=\"0\" valign=\"top\">X..X11</entry><entry morerows=\"0\" valign=\"top\">X..X10</entry><entry morerows=\"0\" valign=\"top\">X..X01</entry><entry morerows=\"0\" valign=\"top\">X..X00</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Address</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"5\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row></tbody></tgroup></table></tables></p><h4>BSRAM Way Address (BWY)</h4><p>In one embodiment, these two signals carry the way information to the BSRAMs. the signals are connected to the address lines A[3:2] of the BSRAMs and select amongst different memory locations that are logically treated as different ways. These signals are produced by a tag lookup and comparison, a path that has more latency than the rest of the BSRAM address signals. These signals are duplicated so that they have a lighter electrical load, making for shorter signal flight times, in order to compensate for this added latency. The implementation of this bus contains four physical signals which are unidirectional and driven from the Tag SRAM to the BSRAMs.</p><h4>Connecting the BSRAMs</h4><p>Table 4 below shows the order of interconnections between the tag SRAM(s) and the various BSRAM signals for a four way set-associative cache.</p><p><tables id=\"TABLE-US-00004\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217PT\"></colspec><thead valign=\"bottom\"><row><entry morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\">TABLE 4</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\">Connections to the BSRAM signals.</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"56PT\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"77PT\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"84PT\"></colspec><tbody valign=\"top\"><row><entry morerows=\"0\" valign=\"top\">Protocol Signals</entry><entry morerows=\"0\" valign=\"top\">BSRAM Signals</entry><entry morerows=\"0\" valign=\"top\">Description</entry></row><row><entry align=\"center\" morerows=\"0\" nameend=\"3\" namest=\"1\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\">BCA[1:0]</entry><entry morerows=\"0\" valign=\"top\">A[1:0]</entry><entry morerows=\"0\" valign=\"top\">These must be the</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BSRAM lowest order</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">address bits.</entry></row><row><entry morerows=\"0\" valign=\"top\">BWY[1:0]</entry><entry morerows=\"0\" valign=\"top\">A[3:2]</entry><entry morerows=\"0\" valign=\"top\">The way is selected with</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">the next pair of address</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">bits.</entry></row><row><entry morerows=\"0\" valign=\"top\">BSA[10:0]</entry><entry morerows=\"0\" valign=\"top\">A[14:4]</entry><entry morerows=\"0\" valign=\"top\">Signals can be connected</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">in any order for best</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">layout.</entry></row><row><entry morerows=\"0\" valign=\"top\">BSA[12:11]**</entry><entry morerows=\"0\" valign=\"top\">CE2, CE3#</entry><entry morerows=\"0\" valign=\"top\">Used as bank select</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">signals. CE1# is wired</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">active.</entry></row><row><entry align=\"center\" morerows=\"0\" nameend=\"3\" namest=\"1\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry align=\"left\" morerows=\"0\" nameend=\"3\" namest=\"1\" valign=\"top\">**When multiple banks of BSRAM are used. Otherwise, these are the upper address bits. </entry></row></tbody></tgroup></table></tables></p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Dan", "last_name": "Patterson", "name": ""}, {"first_name": "Bindi", "last_name": "Prasad", "name": ""}, {"first_name": "Gurbir", "last_name": "Singh", "name": ""}, {"first_name": "Peter", "last_name": "MacWilliams", "name": ""}, {"first_name": "Steve", "last_name": "Hunt", "name": ""}, {"first_name": "Phil G.", "last_name": "Lee", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTEL CORPORATION"}, {"first_name": "", "last_name": "SONY CORPORATION OF AMERICA", "name": ""}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711118"}, {"primary": false, "label": "711119"}, {"primary": false, "label": "711003"}, {"primary": false, "label": "711133"}, {"primary": false, "label": "711122"}, {"primary": false, "label": "711100"}, {"primary": false, "label": "711E12043"}], "ecla_classes": [{"label": "S06F212:601"}, {"label": "G06F  12/08B22L"}], "cpc_classes": [{"label": "G06F  12/0897"}, {"label": "G06F2212/601"}, {"label": "G06F  12/0897"}, {"label": "G06F2212/601"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1996-11-25", "application_date": "1997-05-06", "family_members": [{"ucid": "US-6202125-B1", "titles": [{"lang": "EN", "text": "Processor-cache protocol using simple commands to implement a range of cache configurations"}]}]}