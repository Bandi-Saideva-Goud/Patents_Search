{"patent_number": "US-6957327-B1", "publication_id": 74418738, "family_id": 35066302, "publication_date": "2005-10-18", "titles": [{"lang": "EN", "text": "Block-based branch target buffer"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50886700\"><p num=\"p-0001\">The invention provides a method and apparatus for branch prediction in a processor. A fetch-block branch target buffer is used in an early stage of pipeline processing before the instruction is decoded, which stores information about a control transfer instruction for a \u201cblock\u201d of instruction memory. The block of instruction memory is represented by a block entry in the fetch-block branch target buffer. The block entry represents one recorded control-transfer instruction (such as a branch instruction) and a set of sequentially preceding instructions, up to a fixed maximum length N. Indexing into the fetch-block branch target buffer yields an answer whether the block entry represents memory that contains a previously executed a control-transfer instruction, a length value representing the amount of memory that contains the instructions represented by the block, and an indicator for the type of control-transfer instruction that terminates the block, its target and outcome. Both the decode and execution pipelines include correction capabilities for modifying the block branch target buffer dependent on the results of the instruction decode and execution and can include a mechanism to correct malformed instructions.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00001\" num=\"00001\">\n<claim-text>1. A method for performing branch prediction in a pipelined processor, said method comprising the steps of:\n<claim-text>detecting a control transfer resulting from execution of a control transfer instruction;</claim-text>\n<claim-text>recording a set of information about the control transfer instruction in a block entry of a fetch-block branch target buffer, said set of information including a fetch-block address of a first fetch-block containing a plurality of instructions and including said control transfer instruction, a target address of said control transfer instruction, and a length value representing an amount of memory needed to contain the plurality of instructions in the first fetch-block;</claim-text>\n<claim-text>determining that said plurality of instructions from said first fetch-block will again be fetched;</claim-text>\n<claim-text>predicting whether said control transfer will occur when said control transfer instruction is again executed using the fetch-block address of the first fetch-block; and</claim-text>\n<claim-text>fetching a second fetch block, responsive to the step of predicting, for execution after execution of said control transfer instruction.</claim-text>\n</claim-text>\n</claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00002\" num=\"00002\">\n<claim-text>2. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref> wherein the step of determining includes steps of:\n<claim-text>maintaining a fetch-program counter register for driving an instruction fetch pipeline;</claim-text>\n<claim-text>applying a first address from said fetch-program counter register to said fetch-block branch target buffer to select said block entry associated with said first fetch-block; and</claim-text>\n<claim-text>loading a second address responsive to said block entry into said fetch-program counter register.</claim-text>\n</claim-text>\n</claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00003\" num=\"00003\">\n<claim-text>3. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref> wherein the control transfer instruction is one of a call instruction, a conditional call instruction, a return instruction, a conditional return instruction, an unconditional transfer instruction, a conditional transfer instruction, and a trap instruction.</claim-text>\n</claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00004\" num=\"00004\">\n<claim-text>4. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref> wherein the step of fetching further includes steps of:\n<claim-text>decoding said control transfer instruction; and</claim-text>\n<claim-text>validating said control transfer instruction.</claim-text>\n</claim-text>\n</claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00005\" num=\"00005\">\n<claim-text>5. The method of <claim-ref idref=\"CLM-00004\">claim 4</claim-ref> wherein the step of fetching further includes steps of:\n<claim-text>invalidating said block entry responsive to the step of validating; and</claim-text>\n<claim-text>flushing said control transfer instruction responsive to the step of validating.</claim-text>\n</claim-text>\n</claim>"}, {"num": 6, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00006\" num=\"00006\">\n<claim-text>6. The method of <claim-ref idref=\"CLM-00004\">claim 4</claim-ref> wherein the step of fetching further includes steps of:\n<claim-text>predicting that said control transfer instruction will cause said control transfer to a specified address;</claim-text>\n<claim-text>comparing said target address with said specified address;</claim-text>\n<claim-text>writing said block entry with said specified address responsive to the step of comparing;</claim-text>\n<claim-text>flushing a successor instruction; and</claim-text>\n<claim-text>fetching at said target address.</claim-text>\n</claim-text>\n</claim>"}, {"num": 7, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00007\" num=\"00007\">\n<claim-text>7. The method of <claim-ref idref=\"CLM-00004\">claim 4</claim-ref> wherein the step of fetching further includes passing said control transfer instruction to be executed to an instruction execute pipeline.</claim-text>\n</claim>"}, {"num": 8, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00008\" num=\"00008\">\n<claim-text>8. The method of <claim-ref idref=\"CLM-00004\">claim 4</claim-ref> wherein the step of validating further includes steps of:\n<claim-text>detecting that said control transfer instruction is malformed;</claim-text>\n<claim-text>invalidating said block entry responsive to the step of validating; and</claim-text>\n<claim-text>flushing said control transfer instruction responsive to the step of validating.</claim-text>\n</claim-text>\n</claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00009\" num=\"00009\">\n<claim-text>9. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref> further including steps of:\n<claim-text>resolving said target address; and</claim-text>\n<claim-text>adjusting said block entry associated with said control transfer instruction.</claim-text>\n</claim-text>\n</claim>"}, {"num": 10, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00010\" num=\"00010\">\n<claim-text>10. The method of <claim-ref idref=\"CLM-00009\">claim 9</claim-ref> further including steps of:\n<claim-text>determining that said control transfer instruction is a conditional control transfer instruction;</claim-text>\n<claim-text>detecting whether the step of predicting correctly predicted an outcome of said control transfer instruction as executed; and</claim-text>\n<claim-text>flushing, responsive to the step of detecting, an instruction execute pipeline.</claim-text>\n</claim-text>\n</claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00011\" num=\"00011\">\n<claim-text>11. The method of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref> further wherein the step of flushing also flushes said instruction fetch pipeline.</claim-text>\n</claim>"}, {"num": 12, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00012\" num=\"00012\">\n<claim-text>12. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref> further wherein the step of predicting uses a single bit predictor.</claim-text>\n</claim>"}, {"num": 13, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00013\" num=\"00013\">\n<claim-text>13. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref> further wherein the step of predicting uses a multiple bit predictor.</claim-text>\n</claim>"}, {"num": 14, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00014\" num=\"00014\">\n<claim-text>14. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref> further wherein the step of predicting uses a correlated predictor.</claim-text>\n</claim>"}, {"num": 15, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00015\" num=\"00015\">\n<claim-text>15. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, further comprising:\n<claim-text>selecting one of the length value associated with the first fetch-block and a maximum length; and</claim-text>\n<claim-text>fetching at least a portion of the first fetch-block using the selected length.</claim-text>\n</claim-text>\n</claim>"}, {"num": 16, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00016\" num=\"00016\">\n<claim-text>16. A method for performing branch prediction in a pipelined processor, the method comprising the steps of:\n<claim-text>detecting a control transfer resulting from execution of a control transfer instruction;</claim-text>\n<claim-text>recording a set of information about the control transfer instruction in a block entry of a fetch-block branch target buffer, the set of information including a fetch-block address of a first fetch-block containing a plurality of instructions and including the control transfer instruction, a target address of the control transfer instruction, and a length value;</claim-text>\n<claim-text>determining that the plurality of instructions from the first fetch-block will again be fetched;</claim-text>\n<claim-text>predicting whether the control transfer will occur when the control transfer instruction is again executed using the fetch-block address of the first fetch-block; and</claim-text>\n<claim-text>fetching a second fetch block, responsive to the step of predicting, for execution after execution of the control transfer instruction;</claim-text>\n<claim-text>wherein the step of recording includes determining \u201cblk<sub>\u2014</sub>length=tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length MOD MAX<sub>\u2014</sub>LENGTH\u201d and \u201cblk<sub>\u2014</sub>start=tmp<sub>\u2014</sub>blk<sub>\u2014</sub>start+tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length\u2212blk<sub>\u2014</sub>length\u201d;</claim-text>\n<claim-text>wherein blk<sub>\u2014</sub>length represents the length value;</claim-text>\n<claim-text>wherein tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length represents a temporary value associated with the length value;</claim-text>\n<claim-text>wherein MAX<sub>\u2014</sub>LENGTH represents a maximum size of the block entry;</claim-text>\n<claim-text>wherein blk<sub>\u2014</sub>start represents the fetch-block address of the first fetch-block; and</claim-text>\n<claim-text>wherein tmp<sub>\u2014</sub>blk<sub>\u2014</sub>start represents a temporary start address associated with the first fetch-block.</claim-text>\n</claim-text>\n</claim>"}, {"num": 17, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00017\" num=\"00017\">\n<claim-text>17. An apparatus comprising:\n<claim-text>an instruction fetch pipeline within a processor in communication with a memory;</claim-text>\n<claim-text>an instruction execute pipeline configured to execute a plurality of instructions fetched by the instruction fetch pipeline; and</claim-text>\n<claim-text>a branch prediction cache in communication with the instruction fetch pipeline, said memory and the instruction execution pipeline, the branch prediction cache capable of holding at least one block entry associating a first fetch-block with said plurality of instructions, the at least one block entry comprising a length value representing an amount of memory needed to contain the plurality of instructions associated with the first fetch-block.</claim-text>\n</claim-text>\n</claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00018\" num=\"00018\">\n<claim-text>18. The apparatus of <claim-ref idref=\"CLM-00017\">claim 17</claim-ref> configured to load said instruction fetch pipeline with said plurality of instructions by prefetching a length of said memory represented by said first fetch-block.</claim-text>\n</claim>"}, {"num": 19, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00019\" num=\"00019\">\n<claim-text>19. The apparatus of <claim-ref idref=\"CLM-00017\">claim 17</claim-ref> wherein said at least one block entry further associates a predictor, a target, and a type with said first fetch-block.</claim-text>\n</claim>"}, {"num": 20, "parent": 19, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00020\" num=\"00020\">\n<claim-text>20. The apparatus of <claim-ref idref=\"CLM-00019\">claim 19</claim-ref> wherein said predictor is a single bit predictor.</claim-text>\n</claim>"}, {"num": 21, "parent": 19, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00021\" num=\"00021\">\n<claim-text>21. The apparatus of <claim-ref idref=\"CLM-00019\">claim 19</claim-ref> wherein said predictor is a multiple bit predictor.</claim-text>\n</claim>"}, {"num": 22, "parent": 19, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00022\" num=\"00022\">\n<claim-text>22. The apparatus of <claim-ref idref=\"CLM-00019\">claim 19</claim-ref> wherein said predictor is a correlated predictor.</claim-text>\n</claim>"}, {"num": 23, "parent": 19, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00023\" num=\"00023\">\n<claim-text>23. The apparatus of <claim-ref idref=\"CLM-00019\">claim 19</claim-ref> wherein said plurality of instructions comprise a control transfer instruction, the branch prediction cache includes a target value associated with said plurality of instructions and said predictor determines whether to apply said target value to the instruction fetch pipeline.</claim-text>\n</claim>"}, {"num": 24, "parent": 23, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00024\" num=\"00024\">\n<claim-text>24. The apparatus of <claim-ref idref=\"CLM-00023\">claim 23</claim-ref> wherein the branch prediction cache includes a type value indicating that said control transfer instruction is one of a call instruction, a conditional call instruction, a return instruction, a conditional return instruction, an unconditional transfer instruction, and a conditional transfer instruction.</claim-text>\n</claim>"}, {"num": 25, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00025\" num=\"00025\">\n<claim-text>25. The apparatus of <claim-ref idref=\"CLM-00017\">claim 17</claim-ref> further including a return address predictor, the branch prediction cache further including a type value indicating said control transfer instruction is a return instruction, and a logic unit to apply a return address obtained from said return address predictor to the instruction fetch pipeline.</claim-text>\n</claim>"}, {"num": 26, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00026\" num=\"00026\">\n<claim-text>26. The apparatus of <claim-ref idref=\"CLM-00017\">claim 17</claim-ref> further including:\n<claim-text>a validation mechanism configured to validate a control transfer instruction in said plurality of instructions; and</claim-text>\n<claim-text>a flush mechanism configured to flush said instruction execute pipeline and said instruction fetch pipeline responsive to the validation mechanism.</claim-text>\n</claim-text>\n</claim>"}, {"num": 27, "parent": 26, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00027\" num=\"00027\">\n<claim-text>27. The apparatus of <claim-ref idref=\"CLM-00026\">claim 26</claim-ref> wherein the validation mechanism includes:\n<claim-text>a detection mechanism configured to detect that said control transfer instruction is malformed; and</claim-text>\n<claim-text>an invalidation mechanism configured to invalidate said block entry responsive to the detection mechanism.</claim-text>\n</claim-text>\n</claim>"}, {"num": 28, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00028\" num=\"00028\">\n<claim-text>28. An apparatus comprising:\n<claim-text>an instruction fetch pipeline within a processor in communication with a memory;</claim-text>\n<claim-text>an instruction execute pipeline configured to execute a plurality of instructions fetched by the instruction fetch pipeline;</claim-text>\n<claim-text>a branch prediction cache in communication with the instruction fetch pipeline, the memory and the instruction execution pipeline, the branch prediction cache capable of holding at least one block entry associating a first fetch-block with the plurality of instructions; and</claim-text>\n<claim-text>a fetch-block creation mechanism configured to create said first fetch-block including means for calculating \u201cblk<sub>\u2014</sub>length=tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length MOD MAX<sub>\u2014</sub>LENGTH,\u201d and means for calculating \u201cblk<sub>\u2014</sub>start=tmp<sub>\u2014</sub>blk<sub>\u2014</sub>start+tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length\u2212blk<sub>\u2014</sub>length\u201d;</claim-text>\n<claim-text>wherein blk<sub>\u2014</sub>length represents the length value;</claim-text>\n<claim-text>wherein tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length represents a temporary value associated with the length value;</claim-text>\n<claim-text>wherein MAX<sub>\u2014</sub>LENGTH represents a maximum size of the block entry;</claim-text>\n<claim-text>wherein blk<sub>\u2014</sub>start represents the fetch-block address of the first fetch-block; and</claim-text>\n<claim-text>wherein tmp<sub>\u2014</sub>blk<sub>\u2014</sub>start represents a temporary start address associated with the first fetch-block.</claim-text>\n</claim-text>\n</claim>"}, {"num": 29, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00029\" num=\"00029\">\n<claim-text>29. The apparatus of <claim-ref idref=\"CLM-00017\">claim 17</claim-ref>, further comprising a length multiplexer operable to select one of the length value associated with the first fetch-block and a maximum length; and\n<claim-text>wherein the instruction fetch pipeline is operable to fetch at least a portion of the first fetch-block using the selected length.</claim-text>\n</claim-text>\n</claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES15935720\">\n<?RELAPP description=\"Other Patent Relations\" end=\"lead\"?>\n<p num=\"p-0002\">This application claims the benefit of U.S. Provisional Application No. 60/114,297 filed on Dec. 31, 1998.</p>\n<h4>RELATED APPLICATIONS</h4>\n<p num=\"p-0003\">Inventions described herein can be used in combination or conjunction with inventions described in the following patent application(s):\n</p><ul><li id=\"ul0001-0001\" num=\"0000\"><ul><li id=\"ul0002-0001\" num=\"0003\">Provisional Application Ser. No. 60/114,296, filed Dec. 31, 1998, in the name of Anatoly Gelman, titled \u201cCall-Return Branch Prediction,\u201d assigned to the same assignee, and all pending cases claiming priority thereof.</li></ul></li></ul>\n<p num=\"p-0004\">These applications are each hereby incorporated by reference as if fully set forth herein. These applications are collectively referred to herein as \u201cincorporated disclosures.\u201d</p>\n<?RELAPP description=\"Other Patent Relations\" end=\"tail\"?>\n<?BRFSUM description=\"Brief Summary\" end=\"lead\"?>\n<h4>BACKGROUND OF THE INVENTION</h4>\n<p num=\"p-0005\">1. Field of the Invention</p>\n<p num=\"p-0006\">This invention relates to computer processor design.</p>\n<p num=\"p-0007\">2. Related Art</p>\n<p num=\"p-0008\">One way to achieve higher performance in computer processors employing pipelined architecture, is to keep each element of the pipeline busy. Usually, the next instruction to enter the computer pipeline is the next sequentially available instruction in program store. However, this is not the case when a change in a sequential program flow-occurs (for example by execution of a control transfer instruction). In order to avoid flushing and restarting the pipeline due to changes in sequential program flow, it is desirable to select a path on which instruction execution is more likely to proceed, and to attempt to process instructions on that more likely path. This technique is known as branch prediction. If the predicted path is correct, the processor need not be unduly delayed by processing of the control transfer instruction. However, if the predicted path is not correct, the processor will have to discard the results of instructions executed on incorrect path, flush its pipeline, and restart execution on correct path.</p>\n<p num=\"p-0009\">One known prediction method is to cache, for each control transfer instruction, some history as to whether the branch was taken and the target. Each such instruction is allocated a location in a branch target buffer, each location of which includes the relevant information. While this known method generally achieves the purpose of predicting the flow of execution, it is subject to several drawbacks. First, for superscalar processors, it is desirable for instructions to be fetched in batches, such as 2 or more instructions at once, and so the branch target buffer has added complexity for having to determine the first control transfer instruction in the batch, rather than merely whether there is history for any such control transfer instruction. Second, for computers with a variable-length instruction set, instruction boundaries are not known until instructions are decoded, and so the branch target buffer would need to be coupled to the decode stage of the pipeline and this would cause pipeline flushing for each predicted taken instruction.</p>\n<p num=\"p-0010\">Accordingly, it would be advantageous to provide an improved technique for branch prediction in a processor, in which the branch target buffer is coupled to an early pipeline stage of the computer processor, and in which batches of instructions can be fetched at once without presenting unnecessary timing delays that would negatively impact the performance.</p>\n<h4>SUMMARY OF THE INVENTION</h4>\n<p num=\"p-0011\">The invention provides a method and apparatus for branch prediction in a processor. A fetch-block branch target buffer is used, which stores information about a control transfer instruction for a \u201cblock\u201d of instruction memory. The block of instruction memory is represented by a block entry in the fetch-block branch target buffer. The block entry represents one recorded control-transfer instruction (such as a branch instruction) and a set of sequentially preceding instructions, up to a fixed maximum length N. Indexing into the fetch-block branch target buffer yields an answer whether the block represents memory that contains a previously executed control-transfer instruction, a length value representing the amount of memory that contains the instructions represented by the block, and an indicator for the type of control-transfer instruction that terminates the block, its target and predicted outcome. The decode and execute pipeline stages of the computer include correction capabilities for modifying the fetch block branch target buffer dependent on the results of the instruction decoding and execution.</p>\n<?BRFSUM description=\"Brief Summary\" end=\"tail\"?>\n<?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?>\n<description-of-drawings>\n<h4>DESCRIPTION OF THE DRAWINGS</h4>\n<p num=\"p-0012\"><figref idrefs=\"DRAWINGS\">FIG. 1</figref> shows a block diagram of a portion of a processor having a control-transfer predictor using a fetch-block branch target buffer.</p>\n<p num=\"p-0013\"><figref idrefs=\"DRAWINGS\">FIG. 2</figref> shows a method for using the control transfer predictor.</p>\n<p num=\"p-0014\"><figref idrefs=\"DRAWINGS\">FIGS. 3A &amp; 3B</figref> show a method used in the instruction fetch and decode pipeline to correct the fetch-block branch target buffer and adjust the pipeline accordingly.</p>\n<p num=\"p-0015\"><figref idrefs=\"DRAWINGS\">FIG. 4</figref> shows a method used in the execution and branch validation pipeline to correct the fetch-block branch target buffer and adjust the pipeline accordingly.</p>\n</description-of-drawings>\n<?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?>\n<?DETDESC description=\"Detailed Description\" end=\"lead\"?>\n<h4>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</h4>\n<p num=\"p-0016\">In the following description, a preferred embodiment of the invention is described with regard to preferred process steps and data structures. Embodiments of the invention can be implemented using circuits in a processor or other device, adapted to particular process steps and data structures described herein. Implementation of the process steps and data structures described herein would not require undue experimentation or further invention.</p>\n<p num=\"p-0017\">In a preferred embodiment, a fetch-block branch target buffer stores information (in a block entry) for a block of executed instructions (the last instruction of which may cause an altered control flow). This information can be stored in the fetch-block branch target buffer as a block entry upon detection of the execution of an instruction that changed the control flow of the program (a control-transfer). As the processor prepares to load instructions into the instruction fetch and decode pipeline, the address of the first instruction to be fetched can be applied to the fetch-block branch target buffer. If the fetch-block branch target buffer contains a block entry corresponding to the address, this embodiment determines how many instruction bytes can be loaded into the pipeline to reach the control transfer instruction that previously caused the control-transfer. This embodiment also continues to load addresses of instructions that were the target of the control transfer instruction responsive to prediction information contained in the block entry. Where the control transfer instruction specifies a return address (for example, but without limitation a call instruction, or trap instruction) the return address can be stored in a return-address predictor. Thus, the instruction fetch and decode pipeline is kept full. If, during decoding and execution of the control transfer instruction the control transfer is detected to have one or more incorrectly predicted attributes (for example, incorrect outcome, target, type etc.), the computer pipeline can be flushed and the block entry modified to update the predictor.</p>\n<p num=\"p-0018\">Each block entry in the fetch-block branch target buffer includes a length value that indicates the amount of memory that contains the instructions represented by the block entry. This memory is the fetch-block represented by the block entry. The block entry can also include an indicator for the type of control transfer instruction that terminates the block.</p>\n<p num=\"p-0019\"><figref idrefs=\"DRAWINGS\">FIG. 1</figref> illustrates a pipelined processor, indicated by general reference character <b>100</b>, that illustrates one embodiment of the invention. The pipelined processor <b>100</b> includes an \u2018instruction fetch and decode\u2019 pipeline <b>101</b> and an \u2018instruction execution and branch validation\u2019 pipeline <b>103</b>. The \u2018instruction fetch and decode\u2019 pipeline <b>101</b> fetches instructions from a memory subsystem <b>105</b>, decodes the fetched instructions and feeds the decoded instructions to the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> for execution. The pipeline stages of the processor operate concurrently on sequences of instructions in a pipelined manner. Pipeline operation is known in the art of processor design. If the executed instruction is a control transfer instruction that does not take the predicted path (the path prediction is subsequently described with respect to <figref idrefs=\"DRAWINGS\">FIG. 2</figref>), then the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> is flushed. In addition, the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> communicates this situation (via a \u2018flush fetch\u2019 signal <b>104</b>) back to the \u2018instruction fetch and decode\u2019 pipeline <b>101</b>. The \u2018instruction fetch and decode\u2019 pipeline <b>101</b> also flushes in response to this communication. Processes for correcting the prediction responsive to the decoding and execution of the fetched instruction are described with regard to <figref idrefs=\"DRAWINGS\">FIGS. 3A</figref>, <b>3</b>B, and <b>4</b>.</p>\n<p num=\"p-0020\">The memory subsystem <b>105</b> can be cached. Memory caching operations, as well as other aspects of reading and writing memory locations, are known in the art of computer memories, and so are not further described herein except where applicable to aspects of the invention.</p>\n<p num=\"p-0021\">The \u2018instruction fetch and decode\u2019 pipeline <b>101</b> can be loaded responsive to an address stored in a fetch-program counter register <b>107</b> (Fetch-PC). This address can be also communicated to a fetch-block branch target buffer <b>109</b> (BTB) that includes a branch prediction cache <b>111</b>.</p>\n<p num=\"p-0022\">The fetch-program counter register <b>107</b> can be loaded from a \u2018next-pc\u2019 logic <b>113</b> (that generates a \u2018next-pc\u2019 signal <b>114</b>) from values provided by an adder <b>115</b>, the branch prediction cache <b>111</b>, or a return address predictor <b>117</b> (RAP).</p>\n<p num=\"p-0023\">The \u2018instruction fetch and decode\u2019 pipeline <b>101</b> can fetch multiple instructions from the memory subsystem <b>105</b>. The amount of memory containing instructions to be fetched can be set by a \u2018fetch-length\u2019 signal <b>118</b> that is provided by a fetch length multiplexer <b>119</b> as is subsequently described.</p>\n<p num=\"p-0024\">The branch prediction cache <b>111</b> includes a block entry <b>121</b> that associates a number of values with an address provided from the fetch-program counter register <b>107</b>. The block entry <b>121</b> stores these values in a \u2018target\u2019 entry <b>123</b>, a \u2018length\u2019 entry <b>125</b>, a \u2018type\u2019 entry <b>127</b>, a \u2018taken\u2019 entry <b>129</b> and a \u2018tag valid\u2019 entry <b>131</b>. These values are made available from the fetch-block branch target buffer <b>109</b> responsive to the assertion of the address in the fetch-program counter register <b>107</b>. As is well known in the caching art, the \u2018tag valid\u2019 entry <b>131</b> can be used to determine a \u2018hit\u2019 signal <b>133</b>. The \u2018hit\u2019 signal <b>133</b> is provided to the fetch length multiplexer <b>119</b> to select either the maximum length of instruction memory that can be loaded into the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> or a \u2018length\u2019 signal <b>135</b> generated from the value stored in the \u2018length\u2019 entry <b>125</b> of the block entry <b>121</b> associated with the address from the fetch-program counter register <b>107</b>. The selected signal is the \u2018fetch-length\u2019 signal <b>118</b> that conditions the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> to fetch that amount of information (starting at the address held in the fetch-program counter register <b>107</b>) from the memory subsystem <b>105</b>.</p>\n<p num=\"p-0025\">The entries <b>123</b>, <b>125</b>, <b>127</b>, <b>129</b>, <b>131</b> are created and/or modified by the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> when a control transfer instruction executes by an \u2018update predictor\u2019 signal <b>134</b>. The operations performed by the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> are subsequently described. The block entry <b>121</b> can also be created and invalidated by the \u2018instruction fetch and decode\u2019 pipeline <b>101</b>.</p>\n<p num=\"p-0026\">When the branch prediction cache <b>111</b> receives an address from the fetch-program counter register <b>107</b> that retrieves the block entry <b>121</b>, the entries <b>123</b>, <b>125</b>, <b>127</b>, <b>129</b>, <b>131</b> generate the corresponding signals (a \u2018target address\u2019 signal <b>141</b>, the \u2018length\u2019 signal <b>135</b>, a \u2018type\u2019 signal <b>137</b>, a \u2018taken\u2019 signal <b>139</b>, and the \u2018hit\u2019 signal <b>133</b> respectively).</p>\n<p num=\"p-0027\">The fetch-program counter register <b>107</b> can be loaded from the \u2018next-pc\u2019 logic <b>113</b>. The fetch-program counter register <b>107</b> has as its inputs a signal from the adder <b>115</b>, the \u2018target address\u2019 signal <b>141</b> from the branch prediction cache <b>111</b>, and a return address value supplied by the return address predictor <b>117</b>. The signal from the adder <b>115</b> is the sum of the output of the fetch-program counter register <b>107</b> and the \u2018fetch-length\u2019 signal <b>118</b> from the fetch length multiplexer <b>119</b>. Thus, the address provided by the fetch-program counter register <b>107</b> to the fetch-block branch target buffer <b>109</b> can advance responsive to the \u2018length\u2019 entry <b>125</b> of the block entry <b>121</b>. In addition, the fetch-program counter register <b>107</b> can be loaded by the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> or the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> when either pipeline is flushed.</p>\n<p num=\"p-0028\">The selection of which value to load into the fetch-program counter register <b>107</b> is responsive to the \u2018type\u2019 signal <b>137</b> and the \u2018taken\u2019 signal <b>139</b> generated from the branch prediction cache <b>111</b>. If the \u2018hit\u2019 signal <b>133</b> indicates a cache miss, the \u2018taken\u2019 signal <b>139</b> indicates the same as if the branch is not to be taken. In this circumstance, the \u2018fetch-length\u2019 signal <b>118</b> will not be responsive to the \u2018length\u2019 signal <b>135</b> but instead will be the maximum fetch length.</p>\n<p num=\"p-0029\">If the \u2018hit\u2019 signal <b>133</b> indicates a cache hit, the fetch length multiplexer <b>119</b> is conditioned to use the \u2018length\u2019 signal <b>135</b>. The \u2018next-pc\u2019 logic <b>113</b> also selects the next value for the fetch-program counter register <b>107</b> responsive to the \u2018type\u2019 signal <b>137</b> and the \u2018taken\u2019 signal <b>139</b> from the \u2018target address\u2019 signal <b>141</b>, the output from the return address predictor <b>117</b> and the output from the adder <b>115</b>.</p>\n<p num=\"p-0030\">If the control transfer instruction that caused the creation of the block entry <b>121</b> is a return type instruction (RETURN) the address for the fetch-program counter register <b>107</b> is provided by the return address predictor <b>117</b>. A return type instruction can be an instruction that causes a control transfer back to an instruction following a prior control transfer instruction (for example, but without limitation, a return instruction, a return from trap instruction, and a return from interrupt instruction). Common embodiments for these instructions use return information from a stack. Similar return information is stored in the return address predictor <b>117</b> and is provided to the \u2018next-pc\u2019 logic <b>113</b>. The return information is selected at the \u2018next-pc\u2019 logic <b>113</b> when the \u2018type\u2019 signal <b>137</b> indicates the control transfer instruction is a return type instruction. The return address predictor <b>117</b> stack is popped to remove the return address from the stack when it is used.</p>\n<p num=\"p-0031\">If the control transfer instruction that caused the creation of the block entry <b>121</b> is an unconditional control transfer instruction (UNCND) the \u2018next-pc\u2019 logic <b>113</b> selects the \u2018target address\u2019 signal <b>141</b>.</p>\n<p num=\"p-0032\">If the control transfer instruction that caused the creation of the block entry <b>121</b> is a call control transfer instruction (CALL) the \u2018next-pc\u2019 logic <b>113</b> selects the \u2018target address\u2019 signal <b>141</b> and pushes the return address onto the stack maintained by the return address predictor <b>117</b>.</p>\n<p num=\"p-0033\">If the control transfer instruction that caused the creation of the block entry <b>121</b> is a conditional control transfer instruction (CND) the \u2018next-pc\u2019 logic <b>113</b> selects the \u2018target address\u2019 signal <b>141</b> or the output from the adder <b>115</b> dependent on the \u2018taken\u2019 signal <b>139</b>.</p>\n<p num=\"p-0034\">The \u2018taken\u2019 signal <b>139</b> can include a single, multiple bit, or correlated predictor state as is known in the art of branch prediction.</p>\n<p num=\"p-0035\">The branch prediction cache <b>111</b> can be disposed as a four-way set associative content addressable memory (CAM). However, there is no particular requirement for this storage format. In alternative embodiments, the branch prediction cache <b>111</b> can include a direct mapped content addressable memory (CAM), fully associative CAM, a memory array, a heap, a tree, a trie, a linked list, a hash table, or some other storage format.</p>\n<p num=\"p-0036\">The \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> eventually executes the control transfer instruction fetched by the \u2018instruction fetch and decode\u2019 pipeline <b>101</b>. As the instruction is executed, the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> writes the block entry <b>121</b> into the branch prediction cache <b>111</b>. If the instruction has previously executed, the block entry <b>121</b> can be updated. If the block entry <b>121</b> does not exist, it is created. The entries <b>123</b>, <b>125</b>, <b>127</b>, <b>129</b>, <b>131</b> are updated as:\n</p><ul><li id=\"ul0003-0001\" num=\"0000\"><ul><li id=\"ul0004-0001\" num=\"0037\">For a return-type instruction: the \u2018taken\u2019 entry <b>129</b> is set true, the \u2018type\u2019 entry <b>127</b> is set to RETURN, the \u2018target\u2019 entry <b>123</b> is set to an arbitrary value (because the target address is provided by the return address predictor <b>117</b>), and the \u2018length\u2019 entry <b>125</b> is set to the maximum length value or the amount of memory prior to and including the return-type instruction from the start of currently executed fetch-block. In addition, the return address predictor <b>117</b> is popped so as to correspond with executed program flow.</li><li id=\"ul0004-0002\" num=\"0038\">For an unconditional jump control transfer instruction: the \u2018taken\u2019 entry <b>129</b> is set true, the \u2018type\u2019 entry <b>127</b> is set to UNCND, the \u2018target\u2019 entry <b>123</b> is set to the target address of the control transfer instruction, and the \u2018length\u2019 entry <b>125</b> is set to the maximum length value or the amount of memory prior to and including the unconditional control transfer instruction from the start of currently executed fetch-block.</li><li id=\"ul0004-0003\" num=\"0039\">For a call control transfer instruction: the \u2018taken\u2019 entry <b>129</b> is set true, the \u2018type\u2019 entry <b>127</b> is set to CALL, the \u2018target\u2019 entry <b>123</b> is set to the target address of the control transfer instruction, and the \u2018length\u2019 entry <b>125</b> is set to the maximum length value or the amount of memory prior to and including the call control transfer instruction from the start of currently executed fetch-block. In addition, the return address is pushed onto stack of the return address predictor <b>117</b>.</li><li id=\"ul0004-0004\" num=\"0040\">For a conditional control transfer instruction: the \u2018taken\u2019 entry <b>129</b> is set dependent on the result of the execution of the conditional control transfer instruction (one skilled in the art will understand that the \u2018taken\u2019 entry <b>129</b> can be single bit, multiple bit, or correlated predictor, the \u2018type\u2019 entry <b>127</b> is set to CND, the \u2018target\u2019 entry <b>123</b> is set to the target address of the control transfer instruction, and the \u2018length\u2019 entry <b>125</b> is set to the maximum length value or the amount of memory prior to and including conditional control transfer instruction from the start of currently executed fetch-block. In addition, if the result of the execution of the conditional control transfer instruction is different than that predicted, the new address is loaded into the fetch-program counter register <b>107</b> and the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> and the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> are flushed.</li></ul></li></ul>\n<p num=\"p-0037\">In each case above, a tag generated from the address of the executed control transfer instruction is stored and made valid in the \u2018tag valid\u2019 entry <b>131</b>.</p>\n<p num=\"p-0038\">The process continues for the new address loaded into the fetch-program counter register <b>107</b>. Thus, the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> is preloaded with instructions starting at the target address.</p>\n<p num=\"p-0039\">The architecture of <figref idrefs=\"DRAWINGS\">FIG. 1</figref> is used by the subsequently described processes. <figref idrefs=\"DRAWINGS\">FIG. 2</figref> illustrates the prefetch prediction process. <figref idrefs=\"DRAWINGS\">FIGS. 3A and 3B</figref> illustrate the block entry correction and pipe flush processes within the \u2018instruction fetch and decode\u2019 pipeline <b>101</b>. <figref idrefs=\"DRAWINGS\">FIG. 4</figref> illustrates the block entry correction and pipe flush processes within the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b>.</p>\n<p num=\"p-0040\"><figref idrefs=\"DRAWINGS\">FIG. 2</figref> illustrates a prefetch prediction process, indicated by general reference character <b>200</b>, used by the pipelined processor <b>100</b> to select which address to input to the \u2018instruction fetch and decode\u2019 pipeline <b>101</b>. Information that the prefetch prediction process <b>200</b> provides to the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> includes the fetch-pc (the memory address from which to fetch instructions that will be executed by the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b>), the block length of the memory represented by the block entry <b>121</b>, the type of the block entry <b>121</b>, and whether the fetch-pc address hit the block entry <b>121</b>.</p>\n<p num=\"p-0041\">The prefetch prediction process <b>200</b> starts at a \u2018ready\u2019 step <b>201</b> where the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> is ready to accept an address and length to memory containing instructions. Once started, the prefetch prediction process <b>200</b> continues to an \u2018apply address\u2019 step <b>203</b> that applies the value in the fetch-program counter register <b>107</b> to the fetch-block branch target buffer <b>109</b>. An \u2018entry exists decision\u2019 step <b>205</b> determines whether an entry exists in the branch prediction cache <b>111</b> that corresponds to the supplied address. If no entry exists, the prefetch prediction process <b>200</b> continues to a \u2018set next-pc step <b>209</b> that selects the \u2018next-pc\u2019 signal <b>114</b> to be the output of the adder <b>115</b> (thus, next-pc=fetch-pc+MAX<sub>\u2014</sub>LENGTH). This value is loaded into the fetch-program counter register <b>107</b>. A \u2018start fetch and decode pipeline\u2019 step <b>211</b> then starts the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> using the value of the fetch-program counter register <b>107</b>, the \u2018length\u2019 signal <b>135</b>, the \u2018type\u2019 signal <b>137</b>, and the \u2018tag valid\u2019 entry <b>131</b>. The prefetch prediction process <b>200</b> then continues back to the \u2018ready\u2019 step <b>201</b> to prefetch more instructions.</p>\n<p num=\"p-0042\">However if the \u2018entry exists decision\u2019 step <b>205</b> determines that a matching block entry exists for the provided address, the prefetch prediction process <b>200</b> continues to an \u2018access length and type\u2019 step <b>213</b> that determines the \u2018length\u2019 signal <b>135</b> and the \u2018type\u2019 signal <b>137</b> from the block entry <b>121</b> in the branch prediction cache <b>111</b> that corresponds to the provided address. The \u2018hit\u2019 signal <b>133</b> is also set to TRUE (from the \u2018tag valid\u2019 entry <b>131</b>). A \u2018select type\u2019 step <b>215</b> then determines which steps are to be processed responding to the \u2018type\u2019 signal <b>137</b>. The prefetch prediction process <b>200</b> determines whether the block entry <b>121</b> corresponds to a \u2018conditional branch\u2019 select <b>217</b>, an \u2018unconditional branch\u2019 select <b>219</b>, a \u2018call branch\u2019 select <b>221</b>, or a \u2018return branch\u2019 select <b>223</b>.</p>\n<p num=\"p-0043\">The actual length used is the \u2018fetch-length\u2019 signal <b>118</b> resulting from the fetch length multiplexer <b>119</b> (thus, the length is either the MAX<sub>\u2014</sub>LENGTH or the \u2018length\u2019 signal <b>135</b>).</p>\n<p num=\"p-0044\">If the \u2018type\u2019 signal <b>137</b> is a RETURN, the prefetch prediction process <b>200</b> continues to the \u2018return branch\u2019 select <b>223</b> and to a \u2018load return pc\u2019 step <b>225</b> that selects the \u2018next-pc\u2019 signal <b>114</b> to be that returned by the return address predictor <b>117</b> and the prefetch prediction process <b>200</b> continues to the \u2018start fetch and decode pipeline\u2019 step <b>211</b> for processing as has been previously described.</p>\n<p num=\"p-0045\">If the \u2018type\u2019 signal <b>137</b> is a CALL, the prefetch prediction process <b>200</b> continues to the \u2018call branch\u2019 select <b>221</b> and to a \u2018load return address predictor\u2019 step <b>227</b> that loads the return address into the return address predictor <b>117</b> for retrieval by the corresponding return branch. Next, the prefetch prediction process <b>200</b> continues to a \u2018load target pc\u2019 step <b>229</b> that loads the \u2018target address\u2019 signal <b>141</b> into the fetch-program counter register <b>107</b>. Next the prefetch prediction process <b>200</b> continues to the \u2018start fetch and decode pipeline\u2019 step <b>211</b> for processing as has been previously described.</p>\n<p num=\"p-0046\">If the \u2018type\u2019 signal <b>137</b> is UNCND, the prefetch prediction process <b>200</b> continues to the \u2018unconditional branch\u2019 select <b>219</b> and to the \u2018load target pc\u2019 step <b>229</b> that loads the \u2018target address\u2019 signal <b>141</b> into the fetch-program counter register <b>107</b>. Next the prefetch prediction process <b>200</b> continues to the \u2018start fetch and decode pipeline\u2019 step <b>211</b> for processing as has been previously described.</p>\n<p num=\"p-0047\">If the \u2018type\u2019 signal <b>137</b> is CND, the prefetch prediction process <b>200</b> continues to the \u2018conditional branch\u2019 select <b>217</b> and then to a \u2018conditional branch taken decision step <b>231</b> that uses the information in the \u2018taken\u2019 entry <b>129</b> of the block entry <b>121</b> to predict whether the branch will be taken. If the prediction is that the branch will not be taken, the prefetch prediction process <b>200</b> continues to the \u2018set next-pc step <b>209</b> that sets the value in the fetch-program counter register <b>107</b> to be the output of the adder <b>115</b>. Next the prefetch prediction process <b>200</b> continues to the \u2018start fetch and decode pipeline\u2019 step <b>211</b> for processing as has been previously described.</p>\n<p num=\"p-0048\">One skilled in the art will understand that additional instruction types can be handled by the invention. In particular, \u201cconditional call instructions\u201d and \u201cconditional return instructions\u201d can be handled using techniques similar to those described.</p>\n<p num=\"p-0049\">However, if the prediction is that the branch will be taken, the prefetch prediction process <b>200</b> continues to the \u2018load target pc\u2019 step <b>229</b> that loads the \u2018target address\u2019 signal <b>141</b> into the fetch-program counter register <b>107</b>. Next the prefetch prediction process <b>200</b> continues to the \u2018start fetch and decode pipeline\u2019 step <b>211</b> for processing as has been previously described.</p>\n<p num=\"p-0050\">One skilled in the art will understand that the prefetch prediction process <b>200</b> can be implemented in many different, but equivalent, ways other than the way used by the previously described embodiment. Such a one also will understand that there exist many techniques that can be used to pipeline or parallelize performance of these steps.</p>\n<p num=\"p-0051\"><figref idrefs=\"DRAWINGS\">FIG. 3A</figref> illustrates a first prediction correction process, indicated by general reference character <b>300</b>, for correcting a block entry during operation of the \u2018instruction fetch and decode\u2019 pipeline <b>101</b>. This process is applied after the instruction is fetched from the memory subsystem <b>105</b>. This process feeds the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> and (if required) corrects the fetch-block branch target buffer <b>109</b> and flushes the \u2018instruction fetch and decode\u2019 pipeline <b>101</b>.</p>\n<p num=\"p-0052\">In response to a reset condition (such as by a power on condition or other initialization condition) the process <b>300</b> initiates at a \u2018reset\u2019 step <b>301</b> and advances to a \u2018set StOB TRUE\u2019 step <b>303</b> that indicates that the process is at a start of a block. The process <b>300</b> continues to an \u2018A\u2019 flow point <b>305</b> that is the destination step for subsequent iterations. Next, the process <b>300</b> continues to a \u2018decode instruction\u2019 step <b>307</b> that decodes the fetched instruction. An \u2018StOB decision\u2019 step <b>309</b> then determines whether the start-of-block signal is True. If so, the tmp<sub>\u2014</sub>blk<sub>\u2014</sub>start register is initialized, by an \u2018initialize temporary start address\u2019 step <b>311</b>, to the program counter that corresponds to the instruction decoded by the \u2018decode instruction\u2019 step <b>307</b>. In addition, the \u2018initialize temporary start address\u2019 step <b>311</b> initializes the tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length value to zero. Once tmp<sub>\u2014</sub>blk<sub>\u2014</sub>start is initialized (or if the \u2018StOB decision\u2019 step <b>309</b> determines that the start-of-block signal is False), the process <b>300</b> continues to an \u2018initialize values\u2019 step <b>313</b>.</p>\n<p num=\"p-0053\">The maximum size of the memory represented by the block entry is the MAX<sub>\u2014</sub>LENGTH value.</p>\n<p num=\"p-0054\">The \u2018initialize values\u2019 step <b>313</b> adds the instruction length to the tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length value; sets a blk<sub>\u2014</sub>length value to the tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length MOD MAX<sub>\u2014</sub>LENGTH; and sets the blk<sub>\u2014</sub>start value to tmp<sub>\u2014</sub>blk<sub>\u2014</sub>start+tmp<sub>\u2014</sub>blk<sub>\u2014</sub>length\u2212blk<sub>\u2014</sub>length. Thus, blk<sub>\u2014</sub>start represents an index into the memory represented by the block entry <b>121</b> from which the instruction is being fetched and blk<sub>\u2014</sub>length is the amount of memory that is to be fetched.</p>\n<p num=\"p-0055\">These values are updated for every instruction that is decoded and are used when correcting, invalidating, or creating the block entry <b>121</b> that corresponds to the instruction.</p>\n<p num=\"p-0056\">The process <b>300</b> advances to a continuation of the first prediction correction process, indicated by general reference character <b>320</b> and shown in <figref idrefs=\"DRAWINGS\">FIG. 3B</figref> through a \u2018B\u2019 flow point <b>315</b>.</p>\n<p num=\"p-0057\">A \u2018block hit\u2019 decision step <b>321</b> determines whether the fetched instruction supplied to the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> generated the \u2018hit\u2019 signal <b>133</b> from the branch prediction cache <b>111</b>. If not, the process <b>320</b> continues to a \u2018control transfer instruction\u2019 decision step <b>323</b> that determines whether the instruction decoded at the \u2018decode instruction\u2019 step <b>307</b> is a control transfer instruction. If the instruction is not a control transfer instruction the process <b>320</b> continues to a \u2018set StOB false\u2019 step <b>325</b>. A \u2018pass instruction to execution pipe\u2019 step <b>327</b> then passes the instruction to the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b> for execution and the process <b>300</b> continues to the \u2018A\u2019 flow point <b>305</b> on <figref idrefs=\"DRAWINGS\">FIG. 3A</figref>.</p>\n<p num=\"p-0058\">However, if the \u2018block hit\u2019 decision step <b>321</b> determines that the \u2018hit\u2019 signal <b>133</b> was present (indicating that the instruction has previously been executed) the process <b>320</b> continues to a \u2018malformed instruction\u2019 decision step <b>329</b> that verifies that the instruction is a valid instruction (for example, that the branch predictor correctly terminated the fetch-block on the last code byte of the decoded instruction and not other code bytes within that instruction). If the instruction is valid (that is, not malformed) the process <b>320</b> advances to a \u2018control transfer instruction\u2019 decision step <b>331</b> that determines whether the instruction is a control transfer instruction. If so, the instruction is next checked to verify that the type of the control transfer instruction is valid at a \u2018valid type\u2019 decision step <b>333</b>. If any of these steps fail, the process <b>320</b> continues to an \u2018invalidate block entry\u2019 step <b>335</b> that invalidates the block entry <b>121</b> that associated with the instruction (that is, the block entry <b>121</b> associated with the value of blk<sub>\u2014</sub>start). In addition a \u2018flush instruction\u2019 step <b>337</b> flushes the \u2018instruction fetch and decode\u2019 pipeline <b>101</b> starting at the current instruction and fetches instructions from the memory subsystem <b>105</b> starting at the current PC. This includes resetting the fetch-program counter register <b>107</b> to the current PC and performing the prefetch prediction process <b>200</b> but as applied to the block entry <b>121</b> in the branch prediction cache <b>111</b> now invalidated, this will cause the branch prediction step (performed while refetching the instruction residing in program memory at the current PC) to miss in the fetch-block branch target buffer <b>109</b>. The process <b>320</b> then continues to the \u2018A\u2019 flow point <b>305</b> to continue processing new instructions.</p>\n<p num=\"p-0059\">However, if the \u2018valid type\u2019 decision step <b>333</b> determines that the type of the control transfer instruction is valid, the process <b>320</b> continues to a \u2018prediction valid\u2019 decision step <b>339</b> that determines whether the \u2018taken\u2019 entry <b>129</b> in the block entry <b>121</b> indicates the branch is to be taken. If not, the process <b>320</b> continues to a \u2018set StOB true\u2019 step <b>341</b> that indicates that sets start-of-block to TRUE and the instruction is passed to the \u2018pass instruction to execution pipe\u2019 step <b>327</b> for execution. The process <b>320</b> then continues to the \u2018A\u2019 flow point <b>305</b> to process additional instructions.</p>\n<p num=\"p-0060\">However, if the \u2018prediction valid\u2019 decision step <b>339</b> determines that the branch is to be taken, the process <b>320</b> continues to a \u2018target available and correct\u2019 decision step <b>343</b> that determines whether the instruction contains the target address within the instruction and that the target address provided by the block entry <b>121</b> is correct as compared with the specified address contained within the instruction. If so, the process <b>320</b> continues to the \u2018set StOB true\u2019 step <b>341</b> as has been previously described.</p>\n<p num=\"p-0061\">If the target address is incorrect at the \u2018target available and correct\u2019 decision step <b>343</b>, the process <b>320</b> continues to a \u2018write block entry\u2019 step <b>345</b> that writes the block entry <b>121</b> using values in blk<sub>\u2014</sub>length and blk<sub>\u2014</sub>start. Next, a \u2018flush successor instruction\u2019 step <b>347</b> flushes the pipeline of instructions having been fetched after the current instruction and starts the fetch process at the target address (that is, the fetch-program counter register <b>107</b> is reset to the target address). Then a \u2018set StOB true\u2019 step <b>349</b> is performed and the process <b>320</b> continues to the \u2018A\u2019 flow point <b>305</b> without passing the instruction to the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b>.</p>\n<p num=\"p-0062\">Looking again at the \u2018control transfer instruction\u2019 decision step <b>323</b>, if the fetched instruction is a conditional control transfer instruction, the process <b>320</b> continues to the \u2018target available and correct\u2019 decision step <b>343</b> for processing as has been previously described. Otherwise, the instruction is passed to the \u2018instruction execution and branch validation\u2019 pipeline <b>103</b>.</p>\n<p num=\"p-0063\"><figref idrefs=\"DRAWINGS\">FIG. 4</figref> illustrates an execute-time BTB correction process, indicated by general reference character <b>400</b>, used to detect when the execution of the control transfer instruction is different from the predicted outcome and target, and to adjust the fetch-block branch target buffer appropriately. The process <b>400</b> repeats through a \u2018ready to execute instruction\u2019 flow point <b>401</b> and continues to a \u2018control transfer instruction\u2019 decision step <b>403</b> that examines the decoded instruction to determine whether the instruction is a control transfer instruction. If the instruction is not a control transfer instruction, the process <b>400</b> continues to an \u2018execute instruction\u2019 step <b>405</b> that executes the instruction.</p>\n<p num=\"p-0064\">However, if the instruction at the \u2018control transfer instruction\u2019 decision step <b>403</b> is a control transfer instruction, the process <b>400</b> then continues to an \u2018initialize bad<sub>\u2014</sub>outcome signal\u2019 step <b>406</b> that sets the bad<sub>\u2014</sub>outcome signal to FALSE. Next, the process <b>400</b> determines whether the instruction is a conditional control transfer instruction at a \u2018conditional CTI\u2019 decision step <b>407</b>. If the control transfer instruction is not conditional, the process <b>400</b> continues to a \u2018resolve target address\u2019 step <b>409</b> that evaluates the target address of the control transfer instruction. Next, an \u2018adjust BTB\u2019 step <b>411</b> adjusts the prediction (the \u2018taken\u2019 entry <b>129</b>) and the \u2018target\u2019 entry <b>123</b> in the block entry <b>121</b> at the address in blk<sub>\u2014</sub>start. An \u2018operation OK\u2019 decision step <b>413</b> evaluates whether the target resolved by the \u2018resolve target address\u2019 step <b>409</b> was the same as the predicted target and that the NOT bad<sub>\u2014</sub>outcome signal are TRUE (thus, whether the execution of the instruction occurred as predicted). If so, the process <b>400</b> continues to the \u2018ready to execute instruction\u2019 flow point <b>401</b> to execute the next instruction.</p>\n<p num=\"p-0065\">However, if the \u2018conditional CTI\u2019 decision step <b>407</b> determines that the control transfer instruction is a conditional CTI, the process <b>400</b> continues to a \u2018resolve outcome\u2019 step <b>415</b> that determines whether the conditional branch is to be taken (and sets the bad<sub>\u2014</sub>outcome signal FALSE). Next, a \u2018prediction OK\u2019 decision step <b>417</b> determines whether the outcome of the execution of the instruction was the same as the outcome predicted by the block entry <b>121</b>. If the outcome of the execution was as predicted the process <b>400</b> continues to the \u2018resolve target address\u2019 step <b>409</b> and continues as previously described.</p>\n<p num=\"p-0066\">However, if the \u2018prediction OK\u2019 decision step <b>417</b> determines that the execution of the instruction resulted in an outcome different than the predicted outcome, the process <b>400</b> continues to a \u2018set bad<sub>\u2014</sub>outcome signal\u2019 step <b>419</b> that sets the bad<sub>\u2014</sub>outcome signal TRUE. The process <b>400</b> continues to the \u2018resolve target address\u2019 step <b>409</b> and continues as previously described.</p>\n<p num=\"p-0067\">Looking again at the \u2018operation OK\u2019 decision step <b>413</b>. The \u2018operation OK\u2019 decision step <b>413</b> evaluates whether the target resolved by the \u2018resolve target address\u2019 step <b>409</b> was the same as the predicted target and that the NOT bad<sub>\u2014</sub>outcome signal are TRUE. If not, the process <b>400</b> continues to a \u2018flush execution pipeline and refresh\u2019 step <b>421</b> that flush successor instructions from the pipelines and restarts the instruction fetch pipeline at the target address.</p>\n<p num=\"p-0068\">From the foregoing, it will be appreciated that the invention has (without limitation) the following advantages:</p>\n<p num=\"p-0069\">1) The invention's use of the block entry concept enables preloading of the fetch pipeline responsive to control transfer instructions prior to those instructions being fetched and decoded, that is, the processor does not waste any cycles to flush a fetch pipeline for execution of an instruction that alters sequential flow of instructions where the alteration in the control flow is correctly predicted.</p>\n<p num=\"p-0070\">2) The invention provides a way for preloading multiple instructions into the fetch pipeline even across control transfer instructions.</p>\n<p num=\"p-0071\">3) The invention provides a way for pre loading multiple instructions into the fetch pipeline without extra hardware that would have been required to check if there is branch history for each and every instruction recorded in the branch target buffer.</p>\n<p num=\"p-0072\">Although preferred embodiments are disclosed herein, many variations are possible which remain within the concept, scope, and spirit of the invention, and these variations would become clear to those skilled in the art after perusal of this application. In particular, one skilled in the art would be able to design hardware or software embodiments of the disclosed steps.</p>\n<?DETDESC description=\"Detailed Description\" end=\"tail\"?>\n</description>"}], "inventors": [{"first_name": "Anatoly", "last_name": "Gelman", "name": ""}, {"first_name": "Russell", "last_name": "Schnapp", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "STMICROELECTRONICS, INC."}, {"first_name": "", "last_name": "METAFLOW TECHNOLOGIES, INC.", "name": ""}, {"first_name": "", "last_name": "STMICROELECTRONICS, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F   9/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F   9/00        20060101A I20070224RMEP"}, {"label": "G06F   9/38        20060101A I20080531RMEP"}], "national_classes": [{"primary": true, "label": "712238"}, {"primary": false, "label": "712237"}, {"primary": false, "label": "712E09051"}], "ecla_classes": [{"label": "G06F   9/38E2D"}], "cpc_classes": [{"label": "G06F   9/321"}, {"label": "G06F   9/3844"}, {"label": "G06F   9/3844"}, {"label": "G06F   9/321"}, {"label": "G06F   9/3806"}, {"label": "G06F   9/3806"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1998-12-31", "application_date": "1999-10-28", "family_members": [{"ucid": "US-8171260-B2", "titles": [{"lang": "EN", "text": "Fetching all or portion of instructions in memory line up to branch instruction based on branch prediction and size indicator stored in branch target buffer indexed by fetch address"}]}, {"ucid": "US-7552314-B2", "titles": [{"lang": "EN", "text": "Fetching all or portion of instructions in memory line up to branch instruction based on branch prediction and size indicator stored in branch target buffer indexed by fetch address"}]}, {"ucid": "US-6957327-B1", "titles": [{"lang": "EN", "text": "Block-based branch target buffer"}]}, {"ucid": "US-20100017586-A1", "titles": [{"lang": "EN", "text": "FETCHING ALL OR PORTION OF INSTRUCTIONS IN MEMORY LINE UP TO BRANCH INSTRUCTION BASED ON BRANCH PREDICTION AND SIZE INDICATOR STORED IN BRANCH TARGET BUFFER INDEXED BY FETCH ADDRESS"}]}, {"ucid": "US-20060036836-A1", "titles": [{"lang": "EN", "text": "Block-based branch target buffer"}]}]}