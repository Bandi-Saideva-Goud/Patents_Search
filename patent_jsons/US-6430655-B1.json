{"patent_number": "US-6430655-B1", "publication_id": 73113253, "family_id": 23964693, "publication_date": "2002-08-06", "titles": [{"lang": "EN", "text": "Scratchpad RAM memory accessible in parallel to a primary cache"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50359069\"><p>A low-latency scratchpad RAM memory system is disclosed. The scratchpad RAM memory system can be accessed in parallel to a primary cache. Parallel access to the scratchpad RAM memory can be designed to be independent of a corresponding cache tag RAM, thereby enabling the scratchpad RAM memory to be sized to any specification, independent of the size of the primary cache data RAMs.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00001\" num=\"1\"><claim-text>1. A random access memory system, comprising:</claim-text><claim-text>at least one cache data RAM having a first port by which an index signal can be received and a second port by which data stored at a location that is identified by the received index signal can be output; </claim-text><claim-text>at least one scratchpad data RAM having a first port by which the index signal can be received and a second port by which data stored at a location that is identified by the received index signal can be output; </claim-text><claim-text>at least one cache tag RAM having a first port by which the index signal can be received and a second port by which tag data stored at a location that is identified by the received index signal can be output, wherein each of said at least one cache tag RAM is associated with one of said at least one cache data RAM; </claim-text><claim-text>at least one first determining circuit that is coupled to said second port of a corresponding cache tag RAM and being operative to determine whether an identified address corresponds to an address output by said corresponding cache tag RAM; and </claim-text><claim-text>at least one second determining circuit being operative to determine whether said identified address corresponds to a value that is produced independently of the index signal, </claim-text><claim-text>wherein results from said at least one first determining circuit and said at least one second determining circuit are used to determine whether said at least one cache data RAM or said at least one scratchpad data RAM should be accessed. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00002\" num=\"2\"><claim-text>2. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00001\">claim 1</claim-ref>, further comprising a multiplexer that is coupled to said second port of each of said at least one cache data RAM and to said second port of each of said at least one scratchpad data RAM, said multiplexer being operative to receive a result signal from said at least one first determining circuit and said at least one second determining circuit.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00003\" num=\"3\"><claim-text>3. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00001\">claim 1</claim-ref>, comprising a plurality of cache data RAMs and a plurality of cache tag RAMs.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00004\" num=\"4\"><claim-text>4. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00001\">claim 1</claim-ref>, comprising a plurality of scratchpad data RAMs.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00005\" num=\"5\"><claim-text>5. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00001\">claim 1</claim-ref>, comprising one scratchpad data RAM.</claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00006\" num=\"6\"><claim-text>6. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00001\">claim 1</claim-ref>, further comprising a programmable per line valid bit register that is coupled to said second determining circuit.</claim-text></claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00007\" num=\"7\"><claim-text>7. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00001\">claim 1</claim-ref>, wherein said second determining circuit compares said identified address to a value that does not change in accordance with the index signal.</claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00008\" num=\"8\"><claim-text>8. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00007\">claim 7</claim-ref>, further comprising a programmable address register that is coupled to said second determining circuit.</claim-text></claim>"}, {"num": 9, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00009\" num=\"9\"><claim-text>9. A random access memory system, comprising:</claim-text><claim-text>at least one cache data RAM having a first port by which an index signal can be received and a second port by which data stored at a location that is identified by the received index signal can be output; </claim-text><claim-text>at least one scratchpad data RAM having a first port by which the index signal can be received and a second port by which data stored at a location that is identified by the received index signal can be output; </claim-text><claim-text>at least one cache tag RAM having a first port by which the index signal can be received and a second port by which tag data stored at a location that is identified by the received index signal can be output, wherein each of said at least one cache tag RAM is associated with one of said at least one cache data RAM; </claim-text><claim-text>at least one first determining circuit that is coupled to said second port of a corresponding cache tag RAM and being operative to determine whether an identified address corresponds to an address output by said corresponding cache tag RAM; </claim-text><claim-text>at least one second determining circuit being operative to determine whether said identified address corresponds to a memory location mapped by said at least one scratchpad data RAM; and </claim-text><claim-text>a programmable base address register that is coupled to said second determining circuit, </claim-text><claim-text>wherein results from said at least one first determining circuit and said at least one second determining circuit are used to determine whether said at least one cache data RAM or said at least one scratchpad data RAM should be accessed. </claim-text></claim>"}, {"num": 10, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00010\" num=\"10\"><claim-text>10. A random access memory system, comprising:</claim-text><claim-text>at least one cache data RAM having a first port by which an index signal can be received and a second port by which data stored at a location that is identified by the received index signal can be output; </claim-text><claim-text>at least one scratchpad data RAM having a first port by which the index signal can be received and a second port by which data stored at a location that is identified by the received index signal can be output; </claim-text><claim-text>at least one cache tag RAM having a first port by which the index signal can be received and a second port by which tag data stored at a location that is identified by the received index signal can be output, wherein each of said at least one cache tag RAM. is associated with one of said at least one cache data RAM; </claim-text><claim-text>at least one first determining circuit that is coupled to said second port of a corresponding cache tag RAM and being operative to determine whether an identified address corresponds to an address output by said corresponding cache tag RAM; </claim-text><claim-text>at least one second determining circuit being operative to determine whether said identified address corresponds to a memory location mapped by said at least one scratchpad data RAM; and </claim-text><claim-text>a programmable global valid bit register that is coupled to said second determining circuit, </claim-text><claim-text>wherein results from said at least one first determining circuit and said at least one second determining circuit are used to determine whether said at least one cache data RAM or said at least one scratchpad data RAM should be accessed. </claim-text></claim>"}, {"num": 11, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00011\" num=\"11\"><claim-text>11. A random access memory system, comprising:</claim-text><claim-text>a primary cache that includes cache data RAM and corresponding cache tag RAM, wherein access to said cache data RAM is based on a determination of whether an identified address corresponds to at least part of a tag value, generated in response to an index signal, that is output by said corresponding cache tag RAM; and </claim-text><claim-text>a scratchpad data RAM that can be accessed in parallel to said primary cache, wherein access to said scratchpad data RAM is based on a determination of whether an identified address corresponds to a value that is produced independently of said index signal. </claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00012\" num=\"12\"><claim-text>12. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00011\">claim 11</claim-ref>, wherein a size of said scratchpad data RAM corresponds to a size of a way of said primary cache.</claim-text></claim>"}, {"num": 13, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00013\" num=\"13\"><claim-text>13. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00011\">claim 11</claim-ref>, wherein a size of said scratchpad data RAM does not correspond to a size of a way of said primary cache.</claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00014\" num=\"14\"><claim-text>14. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00013\">claim 13</claim-ref>, wherein said scratchpad data RAM is greater in size than a way of said primary cache.</claim-text></claim>"}, {"num": 15, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00015\" num=\"15\"><claim-text>15. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00013\">claim 13</claim-ref>, wherein said scratchpad data RAM is smaller in size than a way of said primary cache.</claim-text></claim>"}, {"num": 16, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00016\" num=\"16\"><claim-text>16. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00011\">claim 11</claim-ref>, wherein said scratchpad data RAM maps a single region of memory.</claim-text></claim>"}, {"num": 17, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00017\" num=\"17\"><claim-text>17. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00011\">claim 11</claim-ref>, wherein said scratchpad data RAM maps a plurality of regions of memory.</claim-text></claim>"}, {"num": 18, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00018\" num=\"18\"><claim-text>18. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00011\">claim 11</claim-ref>, wherein said value does not change in accordance with the index signal.</claim-text></claim>"}, {"num": 19, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00019\" num=\"19\"><claim-text>19. The random access memory system of <claim-ref idref=\"US-6430655-B1-CLM-00018\">claim 18</claim-ref>, wherein said value is produced by a programmable address register.</claim-text></claim>"}, {"num": 20, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00020\" num=\"20\"><claim-text>20. A random access memory system, comprising:</claim-text><claim-text>a primary cache that includes cache data RAM and corresponding cache tag RAM, wherein access to said cache data RAM is based on a determination of whether an identified address corresponds to at least part of a tag value, generated in response to an index signal, that is output by said corresponding cache tag RAM; and </claim-text><claim-text>one or more input/output registers that can be accessed in parallel to said primary cache, wherein access to said one or more input/output registers is based on a determination of whether an identified address corresponds to a value that is produced independently of said index signal. </claim-text></claim>"}, {"num": 21, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00021\" num=\"21\"><claim-text>21. A computer program product comprising:</claim-text><claim-text>computer-readable program code for causing a computer to describe a primary cache, wherein said primary cache includes cache data RAM and corresponding cache tag RAM, and wherein access to said cache data RAM is based on a determination of whether an identified address corresponds to at least part of a tag value, generated in response to an index signal, that is output by said corresponding cache tag RAM; </claim-text><claim-text>computer-readable program code for causing a computer to describe a scratchpad data RAM, wherein said scratchpad data RAM can be accessed in parallel to said primary cache, and wherein access to said scratchpad data RAM is based on a determination of whether an identified address corresponds to a a value that is produced independently of said index signal; and </claim-text><claim-text>a computer-usable medium configured to store the computer-readable program codes. </claim-text></claim>"}, {"num": 22, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00022\" num=\"22\"><claim-text>22. A method for accessing a random access memory system, the method comprising the steps of:</claim-text><claim-text>(a) determining whether an identified address corresponds to an address, generated in response to an index signal, that is output by at least one cache tag RAM; </claim-text><claim-text>(b) determining whether said identified address corresponds to a value that is produced independently of said index signal; and </claim-text><claim-text>(c) selecting based upon results from steps (a) and (b) whether a cache data RAM or a scratchpad data RAM should be accessed. </claim-text></claim>"}, {"num": 23, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00023\" num=\"23\"><claim-text>23. The method of <claim-ref idref=\"US-6430655-B1-CLM-00022\">claim 22</claim-ref>, wherein step (b) comprises the step of comparing said identified address to at least one value, said value being representative of an address region being mapped by a scratchpad data RAM.</claim-text></claim>"}, {"num": 24, "parent": 23, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00024\" num=\"24\"><claim-text>24. The method of <claim-ref idref=\"US-6430655-B1-CLM-00023\">claim 23</claim-ref>, wherein step (b) comprises the step of comparing said identified address to one value.</claim-text></claim>"}, {"num": 25, "parent": 23, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00025\" num=\"25\"><claim-text>25. The method of <claim-ref idref=\"US-6430655-B1-CLM-00023\">claim 23</claim-ref>, wherein step (b) comprises the step of comparing said identified address to multiple values.</claim-text></claim>"}, {"num": 26, "parent": 23, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00026\" num=\"26\"><claim-text>26. The method of <claim-ref idref=\"US-6430655-B1-CLM-00023\">claim 23</claim-ref>, wherein step (b) comprises the step of comparing said identified address to a value stored in a register.</claim-text></claim>"}, {"num": 27, "parent": 23, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00027\" num=\"27\"><claim-text>27. The method of <claim-ref idref=\"US-6430655-B1-CLM-00023\">claim 23</claim-ref>, wherein said address region is greater than a cache line of said cache data RAM.</claim-text></claim>"}, {"num": 28, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00028\" num=\"28\"><claim-text>28. The method of <claim-ref idref=\"US-6430655-B1-CLM-00022\">claim 22</claim-ref>, wherein step (c) comprises the step of forwarding results from steps (a) and (b) to a multiplexer.</claim-text></claim>"}, {"num": 29, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00029\" num=\"29\"><claim-text>29. A method for accessing a random access memory system, comprising:</claim-text><claim-text>determining whether an identified address corresponds to an address, generated in response to an index signal, that is output by at least one cache tag RAM; </claim-text><claim-text>determining whether said identified address corresponds to a value that is produced independently of said index signal; and </claim-text><claim-text>selecting based upon said determinations whether a cache data RAM or a scratchpad data RAM should be accessed. </claim-text></claim>"}, {"num": 30, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00030\" num=\"30\"><claim-text>30. A method for enabling a computer to generate a random memory access system, comprising:</claim-text><claim-text>transmitting computer-readable program code to a computer, said computer-readable program code including: </claim-text><claim-text>computer-readable program code for causing a computer to describe a primary cache, wherein said primary cache includes cache data RAM and corresponding cache tag RAM, and wherein access to said cache data RAM is based on a determination of whether an identified address corresponds to at least part of a tag value, generated in response to an index signal, that is output by said corresponding cache tag RAM; and </claim-text><claim-text>computer-readable program code for causing a computer to describe a scratchpad data RAM, wherein said scratchpad data RAM can be accessed in parallel to said primary cache, and wherein access to said scratchpad data RAM is based on a determination of whether an identified address corresponds to a value that is produced independently of said index signal. </claim-text></claim>"}, {"num": 31, "parent": 30, "type": "dependent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00031\" num=\"31\"><claim-text>31. The method of <claim-ref idref=\"US-6430655-B1-CLM-00030\">claim 30</claim-ref>, wherein computer-readable program code is transmitted to said computer over the Internet.</claim-text></claim>"}, {"num": 32, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00032\" num=\"32\"><claim-text>32. A computer data signal embodied in a transmission medium comprising:</claim-text><claim-text>computer-readable program code for causing a computer to describe a primary cache, wherein said primary cache includes cache data RAM and corresponding cache tag RAM, and wherein access to said cache data RAM is based on a determination of whether an identified address corresponds to at least part of a tag value, generated in response to an index signal, that is output by said corresponding cache tag RAM; and </claim-text><claim-text>computer-readable program code for causing a computer to describe a scratchpad data RAM, wherein said scratchpad data RAM can be accessed in parallel to said primary cache, and wherein access to said scratchpad data RAM is based on a determination of whether an identified address corresponds to a value that is produced independently of said index signal. </claim-text></claim>"}, {"num": 33, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00033\" num=\"33\"><claim-text>33. A memory system, comprising:</claim-text><claim-text>a primary cache that includes cache data RAM and corresponding cache tag RAM; and </claim-text><claim-text>a scratchpad data RAM that can be accessed in parallel to said primary cache, wherein access to said scratchpad data RAM is based on a determination circuit that operates independently of said cache data RAM. </claim-text></claim>"}, {"num": 34, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00034\" num=\"34\"><claim-text>34. A memory system, comprising:</claim-text><claim-text>a primary cache that includes cache data RAM and corresponding cache tag RAM; and </claim-text><claim-text>a scratchpad data RAM that can be accessed in parallel to said primary cache, wherein access to said scratchpad data RAM is based on a determination circuit that compares an identified address to a value representative of an address range, said address range being greater than a cache line of said primary cache. </claim-text></claim>"}, {"num": 35, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6430655-B1-CLM-00035\" num=\"35\"><claim-text>35. A method for accessing a random access memory system, the method comprising: determining whether an identified address corresponds to an address output by a cache tag RAM;</claim-text><claim-text>determining whether said identified address corresponds to a memory location mapped by a scratchpad data RAM, said determining including comparing said identified address to a value that is representative of an address region greater than a cache line; and </claim-text><claim-text>selecting based upon said determination whether said cache data RAM or said scratchpad data RAM should be accessed.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53612514\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND</h4><p>1. Field of the Invention</p><p>The present invention relates generally to internal memory systems, and more particularly, to a low-latency scratchpad RAM.</p><p>2. Discussion of the Related Art</p><p>Cache memory systems are well known and provide fast temporary data storage in a manner essentially transparent to the user. FIG. 1 illustrates a conventional memory architecture <b>100</b>. Memory architecture includes microprocessor <b>110</b>, which further includes cache controller <b>112</b> and primary cache <b>114</b>. Primary cache <b>114</b> is an internal cache memory, typically with a size of 8 kilobytes-32 kilobytes. Primary cache <b>114</b> can be split into separate portions, one portion containing data (D-cache) and the other portion containing instructions (I-cache).</p><p>In a typical memory access, microprocessor <b>110</b>, through on-chip cache controller <b>112</b>, attempts to access the next instruction or data in primary cache <b>114</b>. If the instruction or data is present in primary cache <b>114</b>, a primary-cache hit occurs and microprocessor <b>110</b> retrieves the instruction or data from primary cache <b>114</b>. If the instruction or data is not present in primary cache <b>114</b>, a primary-cache miss occurs. Microprocessor <b>110</b> may then attempt to retrieve the instruction or data from an optional secondary cache <b>120</b>. Secondary cache <b>120</b> is an external cache memory, typically with a size of 128 kilobytes to 4 Megabytes, that is accessed via bus interface unit (BIU) <b>116</b>. If the instruction or data is not present in secondary cache <b>120</b> a secondary-cache miss occurs, at which time, microprocessor <b>110</b> would attempt to retrieve the instruction or data from further levels of cache or from main memory <b>130</b>. As illustrated in FIG. 1, BIU <b>116</b> can also be configured to control the main memory bus interface.</p><p>In addition to the memory elements described above, it may also be desired to have a scratchpad RAM memory that can be reserved for direct and private usage by the microprocessor for tasks such as temporary storage or for communicating between processes. As the scratchpad RAM memory is a direct and private resource of the microprocessor, low latency in the access of the scratchpad RAM memory is desired.</p><h4>SUMMARY OF THE INVENTION</h4><p>The present invention addresses the aforementioned needs by providing a low-latency scratchpad RAM memory system that can be accessed in parallel to a primary cache. In accordance with the present invention, parallel access to the scratchpad RAM memory can be designed to be independent of a corresponding cache tag RAM. Accordingly, it is a feature of the present invention that the scratchpad RAM memory can be sized to any specification, independent of the size of the primary cache data RAMs.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>The foregoing and other features and advantages of the invention will be apparent from the following, more particular description of a preferred embodiment of the invention, as illustrated in the accompanying drawings.</p><p>FIG. 1 illustrates a generic memory structure.</p><p>FIG. 2 illustrates an embodiment of a primary cache memory system.</p><p>FIGS. 3-5 illustrate embodiments of a primary cache memory system having a scratchpad RAM memory.</p><p>FIG. 6 illustrates a programmable per line valid bit register.</p><p>FIG. 7 illustrates an example of an addressing scheme for a primary cache.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</h4><p>A preferred embodiment of the invention is discussed in detail below. While specific implementations are discussed, it should be understood that this is done for illustration purposes only. A person skilled in the relevant art will recognize that other components and configurations may be used without parting from the spirit and scope of the invention.</p><p>Cache memory systems are well known and provide fast temporary data storage. An important factor in determining the effectiveness of the cache relates to how the cache is mapped to system memory. There are three different ways that a cache can be mapped to system memory: direct mapping, fully associative mapping, and N-way set associative mapping.</p><p>In a direct mapped cache, the system memory is divided into portions based upon the number of cache lines in the cache. Each portion is associated with a single cache line. The single cache line is the sole location in the cache where data from the corresponding portion can be stored.</p><p>In a fully associative cache, there is no correspondence between locations in system memory and locations in the cache. Accordingly, any cache line can store the contents of any memory location.</p><p>Finally, in an N-way set associative cache (e.g., N=2, 3, 4, etc.), the cache is divided into sets where each set contains N cache lines. The system memory is then divided into portions based on the number of sets of cache lines in the cache. Each memory address is therefore assigned a set, and can be cached in any one of the N cache lines within that set. In other words, within each set, the cache is fully associative.</p><p>Conceptually, the direct mapped and fully associative caches are special cases of the N-way set associative cache. If N is set to one to make a one-way set associative cache, then there is only one cache line per set. This one-way set associative cache is the same as a direct mapped cache. On the other hand, if N is set to the number of lines in the cache, then only one set containing all the cache lines exists. Every memory location points to the one set, therefore representing a fully associative cache.</p><p>Direct mapped and set associative caches are more common in typical memory applications. Direct mapping is often used for secondary caches on the motherboard, while the higher-performance set associative cache is often used on the smaller primary caches contained within the microprocessor.</p><p>FIG. 2 illustrates an embodiment of an N-way set associative primary cache. The N-way set associative primary cache includes cache tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N and cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N. Cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N can be designed to store data or instructions. Cache tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N are operative to keep track of where in cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N the data or instructions reside.</p><p>Each cache data RAM <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N represents a \u201cway\u201d-sized section of memory within the microprocessor; i.e., an entire \u201cway\u201d of the primary cache is configured in each data RAM. Each cache data RAM <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N has a corresponding tag RAM <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N that enables the microprocessor to determine what is stored in that \u201cway.\u201d</p><p>When the microprocessor attempts to retrieve the instruction or data information from primary cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N, all of the N \u201cways\u201d are searched. This search is initiated through the provision by processor core <b>210</b> of an index value on address line <b>261</b> to an input port on each of cache tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N and each of cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N. The index value includes a set of bits that are sufficient to identify the total number of sets of cache lines in the primary cache. The index value can be based on a physical address or a virtual address. In a preferred embodiment, the cache arrays are virtually indexed, but the lower-based bits that are used are the same for both virtual and physical addresses.</p><p>Upon the receipt of the index value, tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N each provide on an output port a tag value (i.e., a set of address bits) on data lines <b>263</b>-<b>1</b>, <b>263</b>-<b>2</b>, <b>263</b>-N, respectively. As the artisan would appreciate, the particular number of address bits that are stored in the entries of tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N is based upon the dimensions of the primary cache and the size of the system memory being mapped. The address bits output by a cache tag RAM <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N identifies the contents of the cache line that is stored in the corresponding data RAM <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N.</p><p>Consider, for example, cache tag RAM <b>220</b>-<b>1</b>. Upon the receipt of the index value on an input port coupled to address line <b>261</b>, cache tag RAM <b>220</b>-<b>1</b> provides on an output port coupled to data line <b>263</b>-<b>1</b> a set of address bits. This set of address bits identifies the contents of the cache line that is stored in cache data RAM <b>230</b>-<b>1</b> at the location identified by the index value. More particularly, the set of address bits identifies the contents of a particular \u201cway\u201d in the set identified by the index value. Collectively, the outputs of cache tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N identify the contents of the N cache lines that make up the N \u201cways\u201d of the set identified by the index value.</p><p>As further illustrated in FIG. 2, cache tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N each also output a single valid bit and a single lock bit. The N valid bits output by tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N are received by processor core <b>210</b> on data line <b>265</b>, and the N lock bits output by tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N are received by processor core <b>210</b> on data line <b>266</b>. The N valid bits inform processor core <b>210</b> of the validity of the data stored in the N cache lines of the set identified by the index value. The N lock bits inform processor core <b>210</b> of whether one or more of the N cache lines of the set identified by the index value are reserved and cannot be overwritten. As will be described in greater detail below, the lock bit provides the general functionality of preventing the scratchpad data RAM from being selected for replacement. As would be readily apparent, any signal that informs processor core <b>210</b> of the existence of the scratchpad data RAM can also be used to implement the lock bit functionality.</p><p>The tag values output by tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N are provided to circuits <b>240</b>-<b>1</b>, <b>240</b>-<b>2</b>, <b>240</b>-N via data lines <b>263</b>-<b>1</b>, <b>263</b>-<b>2</b>, <b>263</b>-N, respectively. Circuits <b>240</b>-<b>1</b>, <b>240</b>-<b>2</b>, <b>240</b>-N are operative to compare a tag value with the address value being provided by processor core <b>210</b> on address line <b>264</b>. This address value represents the memory location of the instruction or data that the microprocessor is requesting from the primary cache. The N comparison results generated by circuits <b>240</b>-<b>1</b>, <b>240</b>-<b>2</b>, <b>240</b>-N are output on signal lines <b>265</b>-<b>1</b>, <b>265</b>-<b>2</b>, <b>265</b>-N, respectively. The states of signal lines <b>265</b>-<b>1</b>, <b>265</b>-<b>2</b>, <b>265</b>-N are returned to processor core <b>210</b> via data line <b>268</b> as a match signal. This match signal informs processor core <b>210</b> of whether a primary cache hit or primary cache miss occurred. If a primary cache miss occurred, then a secondary cache search would be initiated by the microprocessor.</p><p>If a primary cache hit occurred, then processor core <b>210</b> proceeds to retrieve the requested cache line data. The cache line data is made available to data line <b>267</b> based upon the control of multiplexer <b>250</b>. Multiplexer <b>250</b> receives, on data lines <b>266</b>-<b>1</b>, <b>266</b>-<b>2</b>, <b>266</b>-N, the N cache lines of data that are output by cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N, respectively. As noted, cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N are responsive to the index value provided to the input port coupled to address line <b>261</b>. Based on the receipt of the index value, cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>, <b>230</b>-N provide on the output ports the data for the N \u201cways\u201d in the set identified by the index value. Multiplexer <b>250</b> chooses which cache line data (or which \u201cway\u201d) to forward to data line <b>267</b> based upon the match results that are received on status lines <b>265</b>-<b>1</b>, <b>265</b>-<b>2</b>, <b>265</b>-N. All or part of the selected cache line is then returned to processor core <b>210</b> via data line <b>267</b>.</p><p>As noted, the primary cache embodiment of FIG. 2 enables a microprocessor to reserve individual cache lines of the primary cache by setting the lock bit in the cache line's corresponding entry in one of cache tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N. The reserved cache lines can then be used directly by the processor as scratchpad RAM memory. This per cache line reservation, however, comes at the expense of the overhead of cache tag RAMs <b>220</b>-<b>1</b>, <b>220</b>-<b>2</b>, <b>220</b>-N. Alternatively, a scratchpad RAM can be implemented on the outside of-the bus interface unit. This implementation, however, subjects the scratchpad RAM memory to the long latency characteristics of main memory.</p><p>In accordance with the present invention, a scratchpad RAM is implemented in internal memory and can be accessed in parallel with the primary cache RAM access. This parallel access is a low-latency access and is enabled without the expense of the overhead of an associated tag RAM.</p><p>A first embodiment of an implementation of a scratchpad RAM is illustrated in FIG. <b>3</b>. In this embodiment, the scratchpad RAM is \u201cway\u201d-sized, i.e., an entire \u201cway\u201d of the primary cache has been configured as a scratchpad RAM memory. More specifically, as compared to the primary cache implementation of FIG. 2, data RAM <b>230</b>-N has been configured as scratchpad data RAM <b>330</b>.</p><p>As illustrated in FIG. 3, access to scratchpad data RAM <b>330</b> is in parallel to cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>. Scratchpad data RAM <b>330</b> and cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b> output stored data or instructions based upon the receipt of an index value on address line <b>261</b>. The outputs of scratchpad data RAM <b>330</b> and cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b> are provided to multiplexer <b>250</b> via data lines <b>366</b>, <b>266</b>-<b>1</b>, and <b>266</b>-<b>2</b>, respectively.</p><p>Multiplexer <b>250</b> forwards data to data line <b>267</b> based upon control signals generated by circuits <b>240</b>-<b>1</b>, <b>240</b>-<b>2</b>, and <b>340</b>. As described in the context of FIG. 2, circuits <b>240</b>-<b>1</b> and <b>240</b>-<b>2</b> compare the outputs of cache tag RAMs <b>220</b>-<b>1</b> and <b>220</b>-<b>2</b>, respectively, with the address provided on address line <b>264</b>. These comparisons control the access by processor core <b>210</b> to data stored in cache data RAMs <b>230</b>-<b>1</b>, <b>230</b>-<b>2</b>.</p><p>Access to scratchpad RAM <b>330</b>, however, is not based upon the contents of a corresponding cache tag RAM. In other words, a cache tag RAM is not used to implement a per-cache-line reservation of a cache data RAM. Instead, access to scratchpad RAM <b>330</b> is based on a comparison by circuit <b>340</b> of the address provided on address line <b>264</b> with a constant value. This constant value is based on a set of address bits that uniquely identify an address range assigned to memory contained within scratchpad data RAM <b>330</b>.</p><p>In operation, whenever processor core <b>210</b> desires to access scratchpad data RAM <b>330</b>, circuit <b>340</b> determines whether the address value on address line <b>264</b> includes the set of address bits contained within the constant value. If circuit <b>340</b> identifies a match between the address value on address line <b>264</b> and the constant value, circuit <b>340</b> instructs multiplexer <b>250</b>, via control line <b>365</b>, to provide the data output by scratchpad data RAM <b>330</b> to processor core <b>210</b>. The control value on control line <b>365</b> is also fed back to processor core <b>210</b> as a scratchpad hit signal.</p><p>The operation of circuit <b>340</b> in determining whether scratchpad data RAM <b>330</b> should be accessed is illustrated in the following example. Assume that a 16 kilobyte primary cache is four-way set associative with four-word (16-byte) cache lines. In this arrangement, each \u201cway\u201d of the primary cache would have 4 kilobytes/16 bytes=256 cache lines.</p><p>Each 4k \u201cway\u201d of memory can be addressed using 12 bits. These 12 address bits are illustrated in FIG. 7 in the context of an M-bit (e.g., 32 bit) address signal. The M-bit address signal includes sections <b>710</b>, <b>720</b>, and <b>730</b>. Section <b>710</b> includes four address bits, designated as bit positions <b>3</b>:<b>0</b>. This four-bit section is an address into the four-word (or 16 byte) cache lines.</p><p>Section <b>720</b> includes eight address bits, designated as bit positions <b>11</b>:<b>4</b>. This eight-bit section is an index signal for the 256 sets of cache lines in the primary cache. As illustrated, the index signal is carried on address line <b>261</b> and provided to the cache tag RAMs, cache data RAMs, and scratchpad data RAM.</p><p>Section <b>730</b> includes the remainder of the M-bit address, designated as bit positions (M-<b>1</b>):<b>12</b>. Bit positions (M-<b>1</b>):<b>12</b> uniquely identify a 4k (or 12-bit) address range. Bit positions (M-<b>1</b>):<b>12</b> can therefore be used as the constant value that is input to circuit <b>340</b>. If circuit <b>340</b> determines that bits (M-<b>1</b>):<b>12</b> of the address appearing on address line <b>264</b> match the corresponding bits of the constant value, then an access into scratchpad data RAM <b>330</b> has been identified. After a match has been identified, circuit <b>340</b> instructs multiplexer <b>250</b> to forward the data output by scratchpad data RAM <b>330</b> to processor core <b>210</b>.</p><p>As noted, scratchpad data RAM <b>330</b> does not rely on a corresponding tag RAM. More specifically, cache tag ram <b>220</b>-N of FIG. 2 has been replaced by logic level \u201c1\u201d sources. These logic level \u201c1\u201d sources are provided to valid status line <b>265</b> and lock status line <b>266</b>. The provision of a logic level \u201c1\u201d onto valid status line <b>265</b> ensures that processor core <b>210</b> will recognize all contents of scratchpad data RAM <b>330</b> as being valid. The provision of a logic level \u201c1\u201d onto lock status line <b>266</b> ensures that processor core <b>210</b> will recognize that the entire \u201cway\u201d represented by scratchpad data RAM <b>330</b> is not available for caching instructions or data.</p><p>As described above, a single \u201cway\u201d-sized cache data RAM (i.e., cache data RAM <b>230</b>-N) can be configured into a scratchpad data RAM <b>330</b>. It should be noted that the size of a scratchpad data RAM is not limited to a single \u201cway.\u201d In alternative embodiments, a plurality of \u201cway\u201d-sized cache data RAMs can be configured into scratchpad data RAMs. For example, in a four-way set associative primary cache, two \u201cway\u201d-sized cache data RAMs can be reconfigured as scratchpad data RAMs. As access to each of these ways can be controlled by a different constant value, each of these \u201cways\u201d can be mapped to different address regions. In general, any number of \u201cways,\u201d including all \u201cways,\u201d can be configured as scratchpad data RAMs.</p><p>More generally, a scratchpad data RAM need not be configured in \u201cway\u201d-sized sections. A scratchpad data RAM can be sized to a desired dimension that may be larger or smaller than a \u201cway.\u201d Consider first a scratchpad data RAM <b>330</b> that is smaller than a \u201cway.\u201d This configuration would also be supported by the embodiment illustrated in FIG. <b>3</b>.</p><p>Access to a variable-sized scratchpad data RAM would be controlled by circuit <b>340</b>. Circuit <b>340</b> determines whether the address value on address line <b>264</b> includes the set of address bits contained within the constant value. This constant value is based on a set of address bits that uniquely identify the variable-sized address range assigned to memory contained within scratchpad data RAM <b>330</b>.</p><p>Assume for example that a \u201cway\u201d is sized at 4k and that the variable-sized address range is specified as 2k. This 2k address range can be addressed using 11 bits (i.e., bits <b>10</b>:<b>0</b>). Thus, address bits (M-<b>1</b>):<b>11</b> uniquely identify the 2k address range and would represent the constant value. As illustrated in FIG. 7, bit position <b>11</b> is one of the cache index bits. Accordingly, circuit <b>340</b> would use an additional address bit in its comparison.</p><p>It should be noted that circuit <b>340</b> can also be configured to compare an address on address line <b>264</b> to multiple constant values. These multiple constant values can represent multiple distinct portions (and sizes) of memory to which sections of the scratchpad data RAM are being mapped. For example, assume 2k of the scratchpad data RAM is being mapped to two 1k sections of addressable memory. Each of these 1k sections of addressable memory would be uniquely identified by a constant value that includes address bits (M-<b>1</b>):<b>10</b>. As would be apparent to one of ordinary skill in the relevant art, the index mechanism into scratchpad data RAM <b>330</b> would ensure that the two 1k sections of addressable memory would not overlap. In determining whether scratchpad data RAM <b>330</b> is being accessed, circuit <b>340</b> would determine whether the address on address line <b>264</b> matched one of the two constant values. If the address matched either constant value, then a scratchpad hit signal would result.</p><p>Scratchpad data RAMs can also be larger in size than a \u201cway.\u201d An embodiment that supports this configuration is illustrated in the embodiment of FIG. <b>4</b>. As described above, the index signal that is provided on address line <b>261</b> includes a number of bits that is sufficient to index the total number of cache lines in a particular \u201cway.\u201d This index signal is insufficient to properly index scratchpad data RAM <b>430</b>, which is larger in size than a \u201cway.\u201d Accordingly, one or more additional index bits are required. These additional index bits are provided by processor core <b>210</b> via address line <b>461</b>. The additional index bits are combined with the original set of index bits carried on address line <b>261</b> to produce an enhanced set of index bits that enables processor core <b>210</b> to completely address the number of lines of memory within scratchpad data RAM <b>430</b>.</p><p>For example, consider the above-described scenario where a 16k primary cache is fourway set associative with four-word cache lines. In this arrangement, each 4k \u201cway\u201d of memory can be addressed using 12 bits, wherein bit positions <b>11</b>:<b>4</b> represent the index signal. Assume further that scratchpad data RAM <b>430</b> is sized at 16k. This 16k section of memory is four times the size of each \u201cway\u201d and therefore requires two additional index bits. In this example, the two additional index bits are provided on address line <b>461</b> and combined with the eight other address bits that are provided on address line <b>261</b> to produce an enhanced 10-bit index signal that addresses the 1024lines of memory in scratchpad data RAM <b>430</b>.</p><p>Again, it should be noted that the scratchpad data RAM can be mapped to multiple regions of memory. For example, a 10k scratchpad data RAM <b>430</b> can be mapped to one 8k region and one 2k region of addressable memory. Each of these regions would have an associated constant value that would enable circuit <b>440</b> to determine whether scratchpad data RAM <b>430</b> was being accessed.</p><p>As thus described, a scratchpad data RAM can be configured as part of internal memory and can be accessed in parallel to the primary cache RAM access. It is a feature of the present invention that the size of the scratchpad data RAM is not based upon the size of a \u201cway\u201d in the primary cache. The scratchpad data RAM can be larger, smaller, or equivalent in size to a \u201cway.\u201d It is a further feature of the present invention that one or more regions of memory can be mapped by the scratchpad data RAM.</p><p>In accordance with another embodiment of the present invention, all or part of the scratchpad data RAM can be replaced with a plurality of input/output (I/O) registers. Access to the plurality of I/O registers would be based upon the same access techniques as that of the scratchpad data RAM. Accordingly, a selected address range can be mapped to the plurality of I/O registers, which thereby enables low-latency access to the I/O registers. This embodiment represents an alternative to a co-processor like port.</p><p>It should be noted that access to the scratchpad data RAM has been described above in association with the reading of data. As would be apparent, the parallel mechanism of searching the primary cache and scratchpad data RAM would similarly be used in association with the writing of data into the primary cache or scratchpad data RAM. In particular, the concepts of the present invention can be used in caches that implement either a write-back or write-through policy. When used in association with a write-through cache implementation, additional logic would be included to ensure that main memory would not be updated upon a write into the scratchpad data RAM.</p><p>Further features of the present invention are now described with reference to the additional embodiment illustrated in FIG. 5. A first additional feature is a programmable base address. The programmable base address feature is enabled through the addition of base address register <b>510</b>. Base address register <b>510</b> stores the base address of scratchpad data RAM <b>530</b>. In other words, base address register <b>510</b> stores the constant value that is used by circuit <b>440</b> in determining whether the address on address line <b>264</b> matches an address mapped by scratchpad data RAM <b>530</b>. Base address register <b>510</b> is programmable. The value to be stored in base address register <b>510</b> is provided by processor core <b>210</b> via data line <b>504</b>. Through this programmable feature, software can dynamically change the physical address that scratchpad data RAM <b>530</b> is mapping.</p><p>A second additional feature is a programmable global valid bit. This programmable global valid bit feature is enabled through the addition of valid bit register <b>520</b>. The valid bit in register <b>520</b> can also be set by software. The state of the valid bit is provided to circuit <b>440</b> via line <b>506</b>. Until the valid bit is set, all references to scratchpad data RAM <b>530</b> would appear to be misses, thereby causing main memory access (e.g., refilling from slow flash RAM). This action results because circuit <b>440</b> would not generate a scratchpad hit signal. This feature allows scratchpad data RAM <b>530</b> to be filled via normal cache refill operations. Once scratchpad data RAM <b>530</b> is filled, software can write the valid bit and all future accesses will be handled by the scratchpad data RAM <b>530</b>.</p><p>In an alternative embodiment, the valid bit is a programmable per line valid bit. Instead of a global programmable valid bit, an array of programmable valid bits is provided. This array of valid bits is stored in register <b>600</b>, illustrated in FIG. <b>6</b>. Once a given line in scratchpad data RAM <b>530</b> is written, its corresponding valid bit is set in register <b>600</b>. All future accesses to that line will then be handled by scratchpad data RAM <b>530</b>.</p><p>In addition to implementations of the invention using hardware, the invention can be embodied in a computer usable medium configured to store a computer readable program code. The program code causes the enablement of the functions or fabrication, or both, of the invention disclosed herein.</p><p>For example, this can be accomplished through the use of general programming languages (e.g., C, C++, etc.), hardware description languages (HDL) including Verilog HDL, VHDL, AHDL (Altera Hardware Description Language) and so on, or other programming and/or circuit (i.e., schematic) capture tools available in the art.</p><p>The program code can be disposed in any known computer usable (e.g., readable) medium including semiconductor memory, magnetic disk, optical disc (e.g., CD-ROM, DVD-ROM, etc.) and as a computer data signal embodied in a computer usable (e.g., readable) transmission medium (e.g., carrier wave or any other medium including digital, optical or analog-based medium). As such, the code can be transmitted over communication networks including the Internet and intranets.</p><p>It is understood that the functions accomplished by the invention as described above can be represented in a core which is embodied in programming code and transformed to hardware as part of the production of integrated circuits. Also, the invention may be embodied as a combination of hardware and software.</p><p>While the invention has been described in detail and with reference to specific embodiments thereof, it will be apparent to one skilled in the art that various changes and modifications can be made therein without departing from the spirit and scope thereof. Thus, it is intended that the present invention cover the modifications and variations of this invention provided they come within the scope of the appended claims and their equivalents.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "David A.", "last_name": "Courtright", "name": ""}, {"first_name": "Ryan C.", "last_name": "Kinter", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "MIPS TECHNOLOGIES, INC."}, {"first_name": "", "last_name": "ARM FINANCE OVERSEAS LIMITED", "name": ""}, {"first_name": "", "last_name": "BRIDGE CROSSING, LLC", "name": ""}, {"first_name": "", "last_name": "MIPS TECHNOLOGIES, INC.", "name": ""}, {"first_name": "", "last_name": "JEFFERIES FINANCE LLC, AS COLLATERAL AGENT", "name": ""}, {"first_name": "", "last_name": "MIPS TECHNOLOGIES, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711118"}, {"primary": false, "label": "711E12017"}], "ecla_classes": [{"label": "G06F  12/12B6"}, {"label": "S06F212:2515"}, {"label": "S06F12:08B10"}, {"label": "G06F  12/08B"}, {"label": "S06F12:08B18"}], "cpc_classes": [{"label": "G06F  12/126"}, {"label": "G06F2212/2515"}, {"label": "G06F  12/0888"}, {"label": "G06F  12/0864"}, {"label": "G06F  12/0864"}, {"label": "G06F  12/0802"}, {"label": "G06F  12/126"}, {"label": "G06F  12/0888"}, {"label": "G06F  12/0802"}, {"label": "G06F2212/2515"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "2000-01-31", "application_date": "2000-01-31", "family_members": [{"ucid": "US-6430655-B1", "titles": [{"lang": "EN", "text": "Scratchpad RAM memory accessible in parallel to a primary cache"}]}]}