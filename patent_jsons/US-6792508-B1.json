{"patent_number": "US-6792508-B1", "publication_id": 73975595, "family_id": 8242199, "publication_date": "2004-09-14", "titles": [{"lang": "EN", "text": "Cache with multiple fill modes"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11745723\" source=\"national office\"><p>A cache architecture (16) for use in a processing device includes a RAM set cache for caching a contiguous block of main memory (20). The RAM set cache can be used in conjunction with other cache types, such as a set associative cache or a direct mapped cache. A register (32) define a starting address for the contiguous block of main memory (20). The data array (38) associated with the RAM set may be filled on a line by line basis, as lines are requested by the processing core, or on a set-fill basis which fills the data array (38) when the starting address is loaded into the register (32). As addresses are received from the processing core hit miss logic (46) the starting address register (32), a global valid bit (34), line valid bits (37) and control bits (24, 26) are used to determine whether the data is present in the RAM set or whether the data must be loaded from main memory (20). The hit/miss logic (46) also determines whether a line should be loaded into the RAM set data array (38) or in the associated cache.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50722017\"><p>A cache architecture (<b>16</b>) for use in a processing device includes a RAM set cache for caching a contiguous block of main memory (<b>20</b>). The RAM set cache can be used in conjunction with other cache types, such as a set associative cache or a direct mapped cache. A register (<b>32</b>) define a starting address for the contiguous block of main memory (<b>20</b>). The data array (<b>38</b>) associated with the RAM set may be filled on a line by line basis, as lines are requested by the processing core, or on a set-fill basis which fills the data array (<b>38</b>) when the starting address is loaded into the register (<b>32</b>). As addresses are received from the processing core hit miss logic (<b>46</b>) the starting address register (<b>32</b>), a global valid bit (<b>34</b>), line valid bits (<b>37</b>) and control bits (<b>24, 26</b>) are used to determine whether the data is present in the RAM set or whether the data must be loaded from main memory (<b>20</b>). The hit/miss logic (<b>46</b>) also determines whether a line should be loaded into the RAM set data array (<b>38</b>) or in the associated cache.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00001\" num=\"1\"><claim-text>1. A processing device comprising:</claim-text><claim-text>a processing core having circuitry for generating addresses to access a main memory; </claim-text><claim-text>a cache comprising: </claim-text><claim-text>a data memory having a plurality of addressable entries, where a contiguous block of information from said main memory is cached over contiguous addressable entries of said data memory; </claim-text><claim-text>a tag register for storing address information defining an address range for the contiguous block of information from main memory mapped to said data memory; </claim-text><claim-text>a global valid bit to be set to either a valid state indicating that the data stored in the corresponding data memory is valid or an invalid state indicating that the data stored in the corresponding data memory is not valid; and </claim-text><claim-text>logic for determining cache hits in said cache based on a comparison of the address information in said tag register with corresponding bits from an address from said processing core and the state of said global valid bit. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00002\" num=\"2\"><claim-text>2. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00001\">claim 1</claim-ref> wherein said data memory comprises a plurality of entries and further comprising a valid entry bit array having a valid entry bit for each entry in said data memory, where each valid entry bit is set to either a valid state indicating that the data stored in the corresponding entry of said data memory is valid and an invalid state indicating that the data stored in the corresponding entry of said data memory is not valid.</claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00003\" num=\"3\"><claim-text>3. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00002\">claim 2</claim-ref> wherein said logic comprises logic for determining cache hits in said cache based on a comparison of the address information in said tag register with corresponding bits from an address from said processing core, the state of said global valid bit, and the state of a valid entry bit associated with said address.</claim-text></claim>"}, {"num": 4, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00004\" num=\"4\"><claim-text>4. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00003\">claim 3</claim-ref> and further comprising a cache disable status bit.</claim-text></claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00005\" num=\"5\"><claim-text>5. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00004\">claim 4</claim-ref> wherein said logic comprises logic for determining cache hits in said cache based on a comparison of the address information in said tag register with corresponding bits from an address from said processing core, the state of said global valid bit, the state of a valid entry bit associated with said address, and said cache disable status bit.</claim-text></claim>"}, {"num": 6, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00006\" num=\"6\"><claim-text>6. A processing device comprising:</claim-text><claim-text>a processing core having circuitry for generating addresses to access a main memory; </claim-text><claim-text>a cache comprising: </claim-text><claim-text>a data memory having a plurality of addressable entries, where a contiguous block of information from said main memory is cached over contiguous addressable entries of said data memory; </claim-text><claim-text>a tag register defining an address range for the contiguous block of information from main memory mapped to said data memory; </claim-text><claim-text>control circuitry for selectively filling said data memory either by set fill mode where all locations of said data memory are filled after setting said tag register or line-by-line fill mode where entries in said data memory are filled in response to an access by said processing core to a corresponding address in said main memory; and </claim-text><claim-text>logic for determining whether information accessed by said processing core is stored in said data memory. </claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00007\" num=\"7\"><claim-text>7. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00006\">claim 6</claim-ref> wherein said circuitry for selectively filling comprises direct memory access circuitry.</claim-text></claim>"}, {"num": 8, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00008\" num=\"8\"><claim-text>8. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00006\">claim 6</claim-ref> wherein said cache and further comprises a global status bit.</claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00009\" num=\"9\"><claim-text>9. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00008\">claim 8</claim-ref> wherein, in set fill mode, said global status bit is set to a predetermined value response to the completion of filling said data memory with data from said main memory.</claim-text></claim>"}, {"num": 10, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00010\" num=\"10\"><claim-text>10. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00008\">claim 8</claim-ref> wherein said cache further comprises a valid entry bit array having a valid entry bit for each entry in said data memory, where each valid entry bit is set to either a valid state indicating that the data stored in the corresponding entry of said data memory is valid and an invalid state indicating that the data stored in the corresponding entry of said data memory is not valid.</claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00011\" num=\"11\"><claim-text>11. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00010\">claim 10</claim-ref> wherein, in line-by-line fill mode, said global status bit is set to a predetermined value responsive to setting said tag register with a desired address and, in response to a memory access to an address by said processing core, said control circuitry fills the corresponding entry in said data memory if said tag register is set to said predetermined value and said valid entry bit corresponding to the entry is in an invalid state.</claim-text></claim>"}, {"num": 12, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00012\" num=\"12\"><claim-text>12. The processing device of <claim-ref idref=\"US-6792508-B1-CLM-00010\">claim 10</claim-ref> wherein said valid entry bits are set to invalid states upon setting the tag register with said desired address.</claim-text></claim>"}, {"num": 13, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00013\" num=\"13\"><claim-text>13. A cache system comprising:</claim-text><claim-text>a data memory having a plurality of entries addressable entries, where a contiguous block of information from said main memory is cached over contiguous addressable entries of said data memory; </claim-text><claim-text>a tag register for storing address information defining an address range for the contiguous block of formation from main memory mapped to said data memory; </claim-text><claim-text>a global valid bit to be set to either a valid state indicating that the data stored in the corresponding data memory is valid or an invalid state indicating that the data stored in the corresponding data memory is not valid; and </claim-text><claim-text>logic for determining cache hits in said cache based on a comparison of the address information in said tag register with corresponding bits from an address from a processing core and the state of said global valid bit. </claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00014\" num=\"14\"><claim-text>14. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00013\">claim 13</claim-ref> wherein said data memory comprises a plurality of entries and further comprising a valid entry bit array having a valid entry bit for each entry in said data memory, where each valid entry bit is set to either a valid state indicating that the data stored in the corresponding entry of said data memory is valid and an invalid state indicating that the data stored in the corresponding entry of said data memory is not valid.</claim-text></claim>"}, {"num": 15, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00015\" num=\"15\"><claim-text>15. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00014\">claim 14</claim-ref> wherein said logic comprises logic for determining cache hits in said cache based on a comparison of the address information in said tag register with corresponding bits from an address from said processing core, the state of said global valid bit, and the state of a valid entry bit associated with said address.</claim-text></claim>"}, {"num": 16, "parent": 15, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00016\" num=\"16\"><claim-text>16. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00015\">claim 15</claim-ref> and further comprising a cache disable status bit.</claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00017\" num=\"17\"><claim-text>17. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00016\">claim 16</claim-ref> wherein said logic comprises logic for determining cache hits in said cache based on a comparison of the address information in said tag register with corresponding bits from an address from said processing core, the state of said global valid bit, the state of a valid entry bit associated with said address, and said cache disable status bit.</claim-text></claim>"}, {"num": 18, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00018\" num=\"18\"><claim-text>18. A cache system comprising:</claim-text><claim-text>a data memory having a plurality of addressable entries, where a contiguous block of information from said main memory is cached over contiguous addressable entries of said data memory; </claim-text><claim-text>a tag register defining an address range for the contiguous block of information from main memory mapped to said data memory; </claim-text><claim-text>control circuitry for selectively filling said data memory either by set fill mode where all locations of said data memory are filled after setting said tag register or line-by-line fill mode where entries in said data memory are filled in response to an access by said processing core to a corresponding address in said main memory; and </claim-text><claim-text>logic for determining whether information accessed by a processing core is stored in said data memory. </claim-text></claim>"}, {"num": 19, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00019\" num=\"19\"><claim-text>19. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00018\">claim 18</claim-ref> wherein said circuitry for selectively filling comprises direct memory access circuitry.</claim-text></claim>"}, {"num": 20, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00020\" num=\"20\"><claim-text>20. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00018\">claim 18</claim-ref> wherein said cache and further comprises a global status bit.</claim-text></claim>"}, {"num": 21, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00021\" num=\"21\"><claim-text>21. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00020\">claim 20</claim-ref> wherein, in set fill mode, said global status bit is set to a predetermined value response to the completion of filling said data memory with data from said main memory.</claim-text></claim>"}, {"num": 22, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00022\" num=\"22\"><claim-text>22. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00020\">claim 20</claim-ref> wherein said cache further comprises a valid entry bit array having a valid entry bit for each entry in said data memory, where each valid entry bit is set to either a valid state indicating that the data stored in the corresponding entry of said data memory is valid and an invalid state indicating that the data stored in the corresponding entry of said data memory is not valid.</claim-text></claim>"}, {"num": 23, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00023\" num=\"23\"><claim-text>23. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00022\">claim 22</claim-ref> wherein, in line-by-line fill mode, said global status bit is set to a predetermined value responsive to setting said tag register with a desired address and, in response to a memory access to an address by said processing core, said control circuitry fills the corresponding entry in said data memory if said tag register is set to said predetermined value and said valid entry bit corresponding to the entry is in an invalid state.</claim-text></claim>"}, {"num": 24, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6792508-B1-CLM-00024\" num=\"24\"><claim-text>24. The cache system of <claim-ref idref=\"US-6792508-B1-CLM-00022\">claim 22</claim-ref> wherein said valid entry bits are set to invalid states upon setting the tag register with said desired address.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54298022\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>CROSS-REFERENCE TO RELATED APPLICATIONS</h4><p>Not Applicable</p><h4>STATEMENT OF FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT</h4><p>Not Applicable</p><h4>BACKGROUND OF THE INVENTION</h4><p>1. Technical Field</p><p>This invention relates in general to processing devices and, more particularly, to a cache architecture for a processing device.</p><p>2. Description of the Related Art</p><p>Most processing devices use a cache architecture to increase the speed of retrieving information from a main memory. A cache memory is a high speed memory that is situated between the processing core of a processing device and the main memory. The main memory is generally much larger than the cache, but also significantly slower. Each time the processing core requests information from the main memory, the cache controller checks the cache memory to determine whether the address being accessed is currently in the cache memory. If so, the information is retrieved from the faster cache memory instead of the slower main memory. If the information is not in the cache, the main memory is accessed, and the cache memory is updated with the information.</p><p>As processing cores increase in speed relative to memory designs, the efficiency of the cache architecture becomes more significant. One way to increase efficiency is to increase the size of the cache. Since a larger cache memory can store more information, the likelihood of a cache hit is similarly increased. In most cases, however, increasing cache size has diminishing returns after a certain point. Further, increasing the cache size will increase the size of the chip (assuming the cache is integrated with the processing core). Even more importantly, access time will be increased, defeating the initial purpose of the cache. Accordingly, merely increasing the size of a cache will in many cases not produce worthwhile results.</p><p>In many devices, certain routines will have critical time constraints or will otherwise need a predictable execution time. In these cases, it can be critical to eliminate latencies due to cache misses. Some cache systems provide mechanisms for locking entries in a cache, so that the cache entries will not be overwritten as other locations are accessed. This mechanism is useful for entries that will be used repeatedly; however, locking entries of a cache reduces the size and associativity of the cache. For instance, in a 2-way set associative cache, locking some entries will result in a portion of the cache acting as a direct map, greatly reducing the efficiency of the cache. A similar solution uses a local memory working in parallel with the cache system. This solution requires address decoding for the local memory and a cache disabling mechanism, which can result in latencies. Further, while an implementation with a local RAM may work with routines specifically written to use the local RAM, other routines, specifically OS (operating system) routines not written in anticipation of the specific local RAM configuration will not be able to control the local RAM in the manner that the cache is controlled.</p><p>Therefore, a need has arisen for a cache architecture that increases cache performance and predictability.</p><h4>BRIEF SUMMARY OF THE INVENTION</h4><p>In a first embodiment of the present invention, a processing device comprises a processing core having circuitry for generating addresses to access a main memory and a cache. The cache comprises a data memory having a plurality of entries for storing information from the main memory, a tag register for storing address information defining a contiguous block of main memory addresses mapped to the data memory, a global valid bit to be set to either a valid state indicating that the data stored in the corresponding data memory is valid or an invalid state indicating that the data stored in the corresponding data memory is not valid, and logic for determining cache hits in the cache by based on a comparison of the address information in said tag register with corresponding bits from an address from the processing core and the state of said global valid bit.</p><p>In a second embodiment of the invention, associated with the address, a processing device comprises a processing core having circuitry for generating addresses to access a main memory and a cache. The cache comprises a data memory having a plurality of entries for storing information from the main memory, a tag register defining a contiguous block of main memory addresses mapped to the data memory, control circuitry for selectively filling the data memory either by set fill mode where all locations of the data memory are filled after setting the tag register or line-by-line fill mode where entries in the data memory are filled in response to an access by the processing core to a corresponding address sin the main memory, and logic for determining whether information accessed by the processing core is stored in the data memory.</p><p>The present invention provides significant advantages over the prior art. First, the RAM set cache (mapped to a contiguous block of main memory addresses) can significantly improve the operation of a processing device performing real-time operations, since a desired block of code can be stored in the RAM set cache for fast retrieval. Second, there is no extra penalty for accessing a larger data memory for a RAM set, cache as long as the access time of the RAM set is not bigger than the access time of the standard cache. Third, the addition of one or more RAM set caches can be provided with a minimal amount of circuitry over a conventional cache. Fourth, the RAM set caches can be configured in a very flexible manner with other caches, such as a set associative or direct map cache, as desired. Fifth, the RAM set cache provides advantages over a local RAM, because a separate mechanism for loading the data memory is not necessary for the RAM set cache and no specific address decoding in serial with the memory access time is required. Sixth, the cache can be controlled by the OS or other software in the same manner as an ordinary cache\u2014loading, flushing, line invalidation, and so on, can be performed by the software without knowledge of the specific architecture of the cache, or with minor modifications to a driver for the OS.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS</h4><p>For a more complete understanding of the present invention, and the advantages thereof, reference is now made to the following descriptions taken in conjunction with the accompanying drawings, in which:</p><p>FIG. 1 illustrates a block diagram of a processing device incorporating a cache;</p><p>FIG. 2 illustrates a block diagram of a preferred embodiment of a cache architecture;</p><p>FIG. 3 is a diagram showing the mapping of a portion of main memory onto a RAM set cache; and</p><p>FIG. 4 illustrates a flow diagram describing operation of the hit/miss logic of FIG. <b>2</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE INVENTION</h4><p>The present invention is beset understood in relation to FIGS. 1-4 of the drawings, like numerals being used for like elements of the various drawings.</p><p>FIG. 1 illustrates a block diagram of a processing device <b>10</b>. Processing device <b>10</b> includes a processing core <b>12</b>, data memory <b>14</b>, instruction cache <b>16</b>, and subsystem memory interface <b>18</b>. Subsystem memory interface <b>18</b> interfaces with main memory <b>20</b>, which is typically an external memory.</p><p>As described in greater detail below, in the preferred embodiment, the instruction cache is a 3-way cache with one cache way being a \u201cRAM set\u201d cache memory. The RAM set cache is designed to cache a contiguous block of memory starting from a chosen main address location. The other two cache ways can be configured as RAM set cache memories, or use another architecture. For example, the instruction cache <b>16</b> could be configured as one RAM set cache and a 2-way set associative cache.</p><p>In operation, the processing core <b>12</b> accesses main memory <b>20</b> within a given address space. If the information at a requested address in main memory is also stored in the instruction cache <b>16</b>, the data is retrieved from the instruction cache. If information for requested address is not stored in the instruction cache, the information is retrieved from the main memory <b>20</b> and the instruction cache is updated with the retrieved information.</p><p>FIG. 2 illustrates a more detailed block diagram of the instruction cache <b>16</b>, in an embodiment with a RAM set cache and a two-way set associative cache.</p><p>A cache controller <b>22</b> controls operation of the instruction cache <b>16</b>. Cache controller <b>22</b> includes four status bits: RAM_fill_mode <b>24</b>, Cache_Enable <b>26</b>, DM/<b>2</b>SA <b>28</b> and Full_RAM_base <b>30</b>. Cache controller <b>22</b> is coupled to Full_Set_Tag registers <b>32</b> (individually referenced as registers <b>32</b><sub>1 </sub>through <b>32</b><sub>3</sub>), Global_Valid bits <b>34</b> (individually referenced as bits <b>34</b><sub>1 </sub>through <b>34</b><sub>3</sub>), tag memories <b>36</b> (individually referenced as tag memories <b>36</b><sub>2 </sub>and <b>36</b><sub>3</sub>), valid entry bit arrays <b>37</b> (individually referenced as bit arrays <b>37</b><sub>1 </sub>through <b>37</b><sub>3</sub>) and data arrays <b>38</b> (individually referenced as data arrays <b>38</b><sub>1 </sub>through <b>38</b><sub>3</sub>). Comparators <b>40</b> (individually referenced as comparators <b>40</b><sub>1 </sub>through <b>40</b><sub>3</sub>) are coupled to respective Full_Set_Tag registers <b>32</b>. Comparators <b>42</b> (individually referenced as comparators <b>42</b><sub>2 </sub>and <b>42</b><sub>3</sub>) are coupled to respective tag memories <b>36</b>. Output buffers <b>44</b> (individually referenced as buffers <b>44</b><sub>1 </sub>through <b>44</b><sub>3</sub>) are coupled to respective data arrays <b>38</b>. Hit/Miss logic <b>46</b> (individually referenced as logic <b>46</b><sub>1 </sub>through <b>46</b><sub>3</sub>) is coupled to comparators <b>40</b>, global valid bits <b>34</b>, valid bits <b>37</b>, RAM_fill_mode bit <b>24</b> and Cache_Enable bit <b>26</b>.</p><p>In operation, instruction cache <b>16</b> is configured using the control bits <b>24</b>, <b>26</b>, <b>28</b> and <b>30</b>. The Cache_Enable <b>26</b> allows the instruction cache to be enabled or disabled as in standard cache architecture. If the instruction cache <b>16</b> is disabled (Cache Enable=0) instruction read accesses are performed on the main memory <b>20</b> via the subsystem memory interface <b>18</b>, without using the instruction cache <b>16</b>. If the instruction cache is enabled (Cache_Enable=1), instructions executed from the instruction cache <b>16</b>, in cases where such instructions are present in the instruction cache <b>16</b>. If a miss occurs, a line (for example, 16 bytes) is fetched from main memory <b>20</b> and provided to the core <b>12</b>. This is also standard cache behavior.</p><p>The size of the data array <b>38</b><sub>1 </sub>can be different than the size of the data arrays <b>38</b><sub>2,3 </sub>for the other ways of the cache. For illustration purposes, it will be assumed that data arrays <b>38</b><sub>2 </sub>and <b>38</b><sub>3 </sub>are each 8 Kbytes in size, configured as 512 lines, with each line holding eight two-byte instructions. Data array <b>38</b><sub>1 </sub>is 16 Kbytes in size, configured as 1024 lines, each line holding eight two byte instructions. ADDR[L] is used to address one line of the data array <b>38</b> and valid bit array <b>37</b> (and tag memory <b>36</b> where applicable). Accordingly for the 1024-line first way, ADDR[L] will include bits [<b>13</b>:<b>4</b> ] of an address from the core. For the 512-line second and third ways, ADDR[L] will include bits [<b>12</b>:<b>4</b> ] of an address from the core. ADDR[H] defines which set is mapped to a line. Hence, assuming a 4 Gbyte (2 Gword) address space, ADDR[H] uses bits [<b>31</b>:<b>14</b> ] of an address from the core for the first way and uses bits [<b>31</b>:<b>13</b> ] for each of the second and third ways of the cache <b>16</b>.</p><p>The tag memories <b>36</b> and comparators <b>42</b> are used for a 2-way set associative cache. When the core <b>12</b> performs a memory access, the tag memories <b>36</b> are accessed at the low order bits of the address (ADDR[L]). The tag memory locations store the high order address bits of the main memory address of the information stored in a corresponding line of the data array <b>38</b>. These high order address bits are compared with the high order address bits (ADDR[H]) of the address from the core <b>12</b>. If the ADD[H] matches the contents of the tag memory at ADDR[L], a hit occurs if the valid bit associated with the low order bits (V[ADDR[L]]) indicates that the cache entry is valid. If there is a cache hit, the data from the corresponding data array <b>38</b> at ADDR[L] may be provided to the core <b>12</b> by enabling the proper output buffer <b>44</b>. As described below, data from the 2-way cache is presented to the core <b>12</b> only if there is a miss in the RAM set cache. By itself, the operation of the 2-way set associative cache and the direct map cache can be conventional and is not affected by the RAM set cache. Other cache techniques could also be used in conjunction with the RAM set cache.</p><p>The RAM set cache stores a contiguous block of main memory <b>20</b> starting at an address defined by the Full_set_tag register <b>32</b> for the RAM set. This block of information is mapped to the corresponding data array <b>38</b> of the RAM set. Only the high order bits of the starting address are stored in the Full_set_tag register <b>32</b>. FIG. 3 illustrates this mapping for a single RAM set. As shown, the contents of Full_set_tag register <b>32</b><sub>1 </sub>defines the starting address for a contiguous block of memory cached in data array <b>38</b><sub>1</sub>.</p><p>A RAM set miss occurs when the high order bits of the address from the core <b>12</b> do not match the contents of the Full_set_TAG register <b>32</b> or the global valid bit equals \u201c0\u201d. In either case, when there is a RAM set miss, the instruction cache <b>16</b> behaves like a normal 2-way cache logic\u2014if there is a hit in the 2-way cache, then an instruction is presented to the core <b>12</b> from the 2-way set associative cache; otherwise the instruction is retrieved from main memory <b>20</b>.</p><p>A RAM set hit situation occurs when the high order bits of the address from the core <b>12</b> match the contents of the Full_set_TAG register <b>32</b> and the global valid bit equals \u201c1\u201d (the setting of the global valid bit is described in greater detail hereinbelow). The RAM set comparison has the highest priority by default. A hit situation indicates that the requested instruction is mapped to the RAM set. If the Valid entry bit <b>37</b> corresponding to the line containing the instruction is set to \u201c1\u201d, the logic <b>40</b> generates a hit-hit signal, because the address hit the RAM set and the instruction is present in the RAM set. If the corresponding valid bit of the RAM set entry <b>37</b> is \u201c0\u201d, the logic generates a hit-miss because the address hit the RAM set but the instruction is not yet present in the RAM set. In that case, the instruction is fetched from main memory <b>20</b> and is loaded into the data array <b>38</b> of the RAM set. A hit in the RAM set logic takes precedence over the normal cache logic. The standard logic of the 2-way cache always generates a miss when the RAM set logic generates a hit. Information can reside in both the RAM set and the 2-way cache without causing any misbehavior; the duplicated cache entry in the 2-way cache will eventually be evicted by the replacement mechanism of the two-way cache, because it will never be used</p><p>To set up a RAM set for operation, the Full_set_tag register <b>32</b> must be loaded with the start address (set_start_addr) and the RAM_fill_mode bit <b>24</b> must be configured to a desired fill mode. The circuitry for filling the cache can be the same as that used to fill lines of the set associative cache. In the preferred embodiment, two fill modes are provided: a line-by-line fill mode or set fill mode.</p><p>For a line-by-line fill (RAM_fill_mode=0), the global valid bit <b>34</b> is set to \u201c1\u201d and the valid entry bits <b>37</b> are set to \u201c0\u201d when the Full_set_tag register <b>32</b> is loaded with the starting address. At this point, the data array <b>38</b> is empty (it is assumed that the Cache_Enable bit <b>26</b> is set to \u201c1\u201d to allow operation of the instruction cache). Upon receiving an address from the core <b>12</b>, a valid entry bit <b>37</b> is selected based on the low order bits of the address. As provide above, if the RAM set is 16 Kbytes in size, organized as an array of 1K\u00d716 bytes, where 16 bytes is equivalent to a block line in the associated 2 way cache, the Full_start_TAG register will store 18 bits [<b>31</b>:<b>14</b> ] of the starting address (set_start_addr). The address indexing each entry of the RAM set (ADDR[L]) will have 10 bits [<b>13</b>:<b>4</b> ] and the instruction address used to access one instruction in the line, will have 3 bits [<b>3</b>:<b>1</b>] (assuming instructions are 2 bytes wide). A line of the data array <b>38</b> (at ADDR[L]) is loaded from main memory <b>20</b> each time that a hit-miss situation occurs because (1) the comparator <b>40</b> determines a match between ADDR[H] and Set_start_addr, (2) the Global valid bit <b>34</b> is set to \u201c1\u201d and (3) the valid bit <b>37</b> associated with the line at ADDR[L] is cleared (V[ADDR[L]]=\u201c0\u201d). This situation indicates that the selected line is mapped to the RAM set, but has not yet been loaded into the RAM set's data array <b>38</b>. When the line is loaded into the data array <b>38</b> from main memory <b>20</b>, the valid bit <b>37</b> corresponding to the line is set to \u201c1\u201d. This loading procedure has the same time penalty as a normal cache line load, but the entry will stay in the RAM set like a locked entry and therefore,the processing device will not be penalized on a subsequent access.</p><p>On the other hand, if a set fill (RAM_fill_mode) is chosen, the global valid bit <b>34</b> is initially set to \u201c0\u201d and remains \u201c0\u201d after the Full_set_tag register is loaded with the starting address. The valid bits <b>37</b> are also set to \u201c0\u201d. When the starting address is written tothe Full_set_tag register <b>32</b>, the associated data array <b>38</b> is filled through a DMA (direct memory access) process. As each line is loaded from main memory <b>20</b>, the valid entry bit <b>37</b> corresponding to the line is set to \u201c1\u201d. After the data array <b>38</b> has been completely loaded from main memory <b>20</b>, the global valid bit <b>34</b> is set to \u201c1\u201d. This initialization of the data array <b>38</b> takes longer than the line-by-line fill mode, but all critical real-time routines are available after initialization and the system latency is deterministic. After the RAM set is initialized in set fill mode, there will never be a miss on code mapped to the RAM set, even on the first access.</p><p>In either set-fill or line-by-line fill modes, the contents of a RAM set can be changed simply by writing a new Set_start_addr into the Full_set_tag register <b>32</b>. Writing to this register flushes the contents of the respective set and initiates a load process according to the fill mode. The control circuitry <b>22</b> can use the same circuitry for flushing lines of the RAM set cache as is used for the set associative cache. Flushing an entire RAM set cache can be accomplished simply by writing to the appropriate Full_set_tag register <b>32</b>. Similarly, the control circuitry <b>22</b> can use the same circuitry for filling lines of the RAM set cache as is used for the set associative cache. The operation for filling an entire cache in set fill mode is slightly different because multiple lines, rather than a single line, are accessed from the main memory <b>20</b> and stored in the data array <b>38</b>. The RAM set cache can be used with an OS that is not specifically designed to operate with a RAM set cache through the use of minor driver modifications.</p><p>The operation of the Hit/Miss logic is described in connection with the flow chart of FIG. <b>4</b>. In step <b>50</b>, an address is received from the core <b>12</b> in connection with a read operation. If the instruction cache is disabled in step <b>52</b>, the instruction is retrieved from main memory <b>20</b> in step <b>54</b>. If the cache is enabled, then if either the high order bits of the address from the core (ADDR[H]) do not match the high order bits of the starting address (Set_start_addr) or the global valid bit <b>34</b> is set to \u201c0\u201d (step <b>56</b>), then there is a RAM set miss. In this case, if there is a cache hit in the 2-way set associative cache (step <b>58</b>), then the information retrieved from the 2-way set associative cache is presented to the core <b>12</b>. If there is a miss in the 2-way set associative cache, the line is loaded into the 2-way cache.</p><p>Returning again to step <b>56</b>, if both the high order bits of the address from the core (ADDR[H]) match the high order bits of the starting address (Set_start_addr) and the global valid bit <b>34</b> is set to \u201c1\u201d, then there is a RAM set hit at the line corresponding to ADDR[L], and the valid entry bits are used to determine whether it is a hit-hit situation (where the requested instruction is present in the RAM set and can be presented to the core <b>12</b>) or a hit-miss situation (where the requested instruction is mapped to the RAM set, but the information needs to be loaded into the RAM set's data array <b>38</b> from the main memory <b>20</b>). If, in step <b>64</b>, the valid entry bit <b>37</b> for the line indicates that the line is valid (V[ADDR[L]]=1), the instruction is present in the RAM set and is presented to the core <b>12</b> through the RAM set's output buffer <b>44</b>. If, on the other hand, the valid entry bit <b>37</b> for the line indicates that the line is not valid (V[ADDR[L]]=0), the line is loaded into the data array <b>38</b> of the RAM set from main memory in step <b>68</b>.</p><p>The flow chart of FIG. 4 can be easily implemented using combinational logic.</p><p>In the preferred embodiment, the cache <b>416</b> provides flexibility in providing one, two, or thee RAM sets, since different applications for the processing device <b>10</b> have different real-time requirements. In this embodiment, control bits DM/<b>2</b>SA <b>28</b> and Full_RAM_base <b>30</b> define the allocation of RAM sets in the 3-way cache architecture. Table I describes the possibilities for the illustrated embodiment.</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE I</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Cache Configurations</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"4\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"offset\" colwidth=\"14pt\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"63pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"42pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"98pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry>Full_RAM_base</entry><entry>DM/2SA</entry><entry>Configuration</entry></row><row><entry></entry><entry align=\"center\" nameend=\"3\" namest=\"offset\" rowsep=\"1\"></entry></row><row><entry></entry><entry>0</entry><entry>0</entry><entry>One 2-way set associative</entry></row><row><entry></entry><entry></entry><entry></entry><entry>cache and one RAM set cache</entry></row><row><entry></entry><entry>1</entry><entry>0</entry><entry>One direct map cache and</entry></row><row><entry></entry><entry></entry><entry></entry><entry>a two set RAM cache</entry></row><row><entry></entry><entry>1</entry><entry>1</entry><entry>Three set RAM cache</entry></row><row><entry></entry><entry align=\"center\" nameend=\"3\" namest=\"offset\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>The Full_set_tag register <b>32</b> uses a number of bits equal to the length of ADDR[H] for the associated way of the cache. Hence, Full_set_tag register <b>32</b><sub>1 </sub>stores bits [<b>31</b>:<b>14</b> ] and Full_set_registers <b>32</b><sub>2 </sub>and <b>32</b><sub>3 </sub>store bits [<b>31</b>:<b>13</b> ], for the specific data array sizes and configurations defined herein.</p><p>In a 2-way set associative cache, both tag memories <b>36</b> are used; in a direct map cache a single tag memory <b>36</b> is used. The tag memories <b>36</b> are not used for any of the caches configured as RAM set caches. Thus, for the configuration using a single RAM set cache and a 2-way associative cache, the RAM set cache uses Full_set_tag register <b>32</b><sub>1</sub>, global valid bit <b>34</b><sub>1</sub>, valid entry bits <b>37</b><sub>1</sub>, data array <b>38</b><sub>1</sub>, comparator <b>40</b><sub>1</sub>, Hit/miss logic <b>46</b><sub>1</sub>, and output buffer <b>44</b><sub>1</sub>. The 2-way set associative cache would use tag memories <b>36</b><sub>2 </sub>and <b>36</b><sub>3</sub>, valid bits <b>37</b><sub>2 </sub>and <b>37</b><sub>3</sub>, data arrays <b>38</b><sub>2 </sub>and <b>38</b><sub>3</sub>, Hit/miss logic <b>46</b><sub>2 </sub>and <b>46</b><sub>3 </sub>and output buffers <b>44</b><sub>2 </sub>and <b>44</b><sub>3</sub>. For a configuration using two RAM sets and a direct mapped cache, the RAM sets would use Full_set_tag registers <b>32</b><sub>1 </sub>and <b>32</b><sub>2</sub>, global valid bits <b>34</b><sub>1 </sub>and <b>34</b><sub>2</sub>, valid entry bits <b>37</b><sub>1 </sub>and <b>37</b><sub>2</sub>, data arrays <b>38</b><sub>1 </sub>and <b>38</b><sub>2</sub>, comparators <b>40</b><sub>1 </sub>and <b>40</b><sub>2</sub>, Hit/miss logic <b>46</b><sub>1 </sub>and <b>46</b><sub>2</sub>, and output buffers <b>44</b><sub>1 </sub>and <b>44</b><sub>2</sub>. The direct mapped cache would use tag memory <b>36</b><sub>3</sub>, valid bits <b>37</b><sub>3</sub>, data array <b>38</b><sub>3</sub>, Hit/miss logic <b>46</b><sub>3 </sub>and output buffer <b>44</b><sub>3</sub>. For a configuration using three RAM sets, the RAM sets would use Full_set_tag registers <b>32</b><sub>1</sub>, <b>32</b><sub>2 </sub>and <b>32</b><sub>3</sub>, global valid bits <b>34</b><sub>1</sub>, <b>34</b><sub>2 </sub>and <b>34</b><sub>2</sub>, valid entry bits <b>37</b><sub>1</sub>, <b>37</b><sub>2 </sub>and <b>37</b><sub>3</sub>, data arrays <b>38</b><sub>1</sub>, <b>38</b><sub>2 </sub>and <b>38</b><sub>3</sub>, comparators <b>40</b><sub>1</sub>, <b>40</b><sub>2 </sub>and <b>40</b><sub>3</sub>, Hit/miss logic <b>46</b><sub>1</sub>, <b>46</b><sub>2 </sub>and <b>46</b><sub>3</sub>, and output buffers <b>44</b><sub>1</sub>, <b>44</b><sub>2 </sub>and <b>44</b><sub>3</sub>.</p><p>While the embodiment shown-provides a 3-way cache, any number of cache-ways could be provided. For example, a 4-way cache could be configured to use and combination of RAM set and set associative, or other, cache architectures. The only additional hardware needed for the additional RAM set cache would be the additional Full_set_tag register and the global valid bit.</p><p>The RAM set cache is compatible with self-modifying code. If the processing core <b>12</b> changes an instruction dynamically, the line containing the modified location is flushed from the cache (i.e., its corresponding valid bit <b>37</b> is set to \u201c0\u201d) in parallel with the write operation to main memory. The next time that the instruction is requested by the core <b>12</b>, the corresponding valid bit will be set to \u201c0\u201d causing a hit-miss condition. The line containing the requested instruction will be loaded into the RAM set cache from main memory. In the preferred embodiment, instructions are not modified in the cache directly, eliminating the need to update the main memory when replacing a line in the cache.</p><p>While the invention has been discussed in connection with an instruction cache, it could also be used as a data cache, or as a unified instruction/data cache.</p><p>The present invention provides significant advantages over the prior art. First, the RAM set cache can significantly improve the operation of a processing device performing real-time operations, since a desired block of code can be stored in the Ram set for fast retrieval. Second, there is no extra penalty for accessing a larger data array <b>38</b> for a RAM set cache, as long as the access time of the RAM set is not bigger than the access time of the 2-way cache. Third, the addition of one or more RAM set caches can be provided with a minimal amount of circuitry over a conventional cache. The only additional circuitry required is one or more Full_Set_Tag registers <b>32</b> and the associated global valid bits <b>34</b> (the valid bits <b>37</b> are necessary for the RAM set(s) only when a line-by-line fill mode is available or self-modifying code is allowed; if the RAM set only supports set fill without self-modifying code, the valid bits <b>37</b> would be unnecessary). The valid bits <b>37</b> of a set associative or other cache can be used for the RAM set as well, if the valid bits are not included in the tag memory itself. Fourth, the RAM sets can be configured in a very flexible manner with other caches, such as a set associative or direct map cache, as desired. Fifth, the RAM set cache provides advantages over a local RAM, because a separate mechanism for loading the RAM is not necessary for the RAM set cache and no specific address decoding in serial with the memory access time is required. Sixth, the cache can be controlled by the OS or other software in the same manner as an ordinary cache\u2014loading, flushing, line invalidation, and so on, can be performed by the software with minor software adaptation using conventional cache management.</p><p>While the present invention has been shown for a specific embodiment herein, it could be used in a number of implementations. First, the RAM set cache architecture could be used in any type of processing device, including microprocessors, DSPs, mixed analog/digital processors, and co-processors. Second, the sizes of the data arrays could be varied as needed for a certain implementation with minor modifications. For example, it may be desirable to have a RAM set with a larger data array than the set associative cache, or vice-versa, depending upon the size of the application with real-time constraints. Third, while the preferred embodiment allows the cache types to be mixed in a flexible manner, it maybe preferable in some circumstances to have set cache types, such as a single RAM set and a set associative cache. Fourth, the architecture used to implement non-RAM set caches (i.e., the set associative and direct mapped caches) could used different architecture from that shown herein; for example, a CAM (content addressable memory) could be used for the Tag memories <b>36</b>.</p><p>Although the Detailed Description of the invention has been directed to certain exemplary embodiments, various modifications of these embodiments, as well as alternative embodiments, will be suggested to those skilled in the art The invention encompasses any modifications or alternative embodiments that fall within the scope of the Claims.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Gerard", "last_name": "Chauvel", "name": ""}, {"first_name": "Serge", "last_name": "Lasserre", "name": ""}, {"first_name": "Dominique Benoit Jacques", "last_name": "D'Inverno", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "TEXAS INSTRUMENTS INCORPORATED"}, {"first_name": "", "last_name": "TEXAS INSTRUMENTS INCORPORATED", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/08"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/0802      20160101A I20171124RMEP"}, {"label": "G06F  12/0864      20160101A N20171124RMEP"}, {"label": "G06F  12/0895      20160101A N20171124RMEP"}, {"label": "G06F  12/0862      20160101A I20171124RMEP"}, {"label": "G06F  13/00        20060101AFI20060101BMKR"}], "national_classes": [{"primary": true, "label": "711128"}, {"primary": false, "label": "711E12057"}, {"primary": false, "label": "711145"}, {"primary": false, "label": "711E12017"}, {"primary": false, "label": "711133"}, {"primary": false, "label": "711144"}], "ecla_classes": [{"label": "G06F  12/08B8"}, {"label": "G06F  12/08B"}], "cpc_classes": [{"label": "G06F  12/0895"}, {"label": "G06F  12/0864"}, {"label": "G06F  12/0802"}, {"label": "G06F2212/2515"}, {"label": "G06F  12/0862"}, {"label": "G06F2212/1016"}, {"label": "G06F  12/0802"}, {"label": "G06F  13/28"}, {"label": "G06F2212/2515"}, {"label": "G06F  12/0862"}, {"label": "G06F  13/00"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1999-12-06", "application_date": "2000-06-09", "family_members": [{"ucid": "KR-100814982-B1", "titles": [{"lang": "KO", "text": "\ub2e4\uc218\uc758 \ucc44\uc6c0 \ubaa8\ub4dc\ub97c \uad6c\ube44\ud55c \uce90\uc2dc"}, {"lang": "EN", "text": "CACHE WITH MULTIPLE FILL MODE"}]}, {"ucid": "EP-1111511-B1", "titles": [{"lang": "DE", "text": "Cachespeicher mit mehreren F\u00fcllungsmoden"}, {"lang": "EN", "text": "Cache with multiple fill modes"}, {"lang": "FR", "text": "Ant\u00e9m\u00e9moire avec plusieurs modes de remplissage"}]}, {"ucid": "KR-20010062174-A", "titles": [{"lang": "EN", "text": "CACHE WITH MULTIPLE FILL MODE"}, {"lang": "KO", "text": "\ub2e4\uc218\uc758 \ucc44\uc6c0 \ubaa8\ub4dc\ub97c \uad6c\ube44\ud55c \uce90\uc2dc"}]}, {"ucid": "US-6792508-B1", "titles": [{"lang": "EN", "text": "Cache with multiple fill modes"}]}, {"ucid": "JP-2001297036-A", "titles": [{"lang": "JA", "text": "\u591a\u91cd\u57cb\u3081\u30e2\u30fc\u30c9\u3092\u6709\u3059\u308b\u30ad\u30e3\u30c3\u30b7\u30e5"}, {"lang": "EN", "text": "CACHE WITH MULTIPLE-EMBEDDING MODE"}]}, {"ucid": "EP-1111511-A1", "titles": [{"lang": "FR", "text": "Ant\u00e9m\u00e9moire avec plusieurs modes de remplissage"}, {"lang": "EN", "text": "Cache with multiple fill modes"}, {"lang": "DE", "text": "Cachespeicher mit mehreren F\u00fcllungsmoden"}]}]}