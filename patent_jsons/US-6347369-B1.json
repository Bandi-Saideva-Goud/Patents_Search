{"patent_number": "US-6347369-B1", "publication_id": 72915743, "family_id": 26746121, "publication_date": "2002-02-12", "titles": [{"lang": "EN", "text": "Method and circuit for single cycle multiple branch history table access"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11296761\" source=\"national office\"><p>Disclosed is a circuit and method for multiple access of a branch history table during a single clock cycle. In accordance thereto, a first branch history table index is generated which is used for accessing the branch history table. A first counter value is read from the branch history table in response to accessing the branch history table using the first branch history table index. A second branch history table index is also generated for accessing the branch history table. A pair of counter values are read from the branch history table in response to accessing the branch history table using the second branch history table index. One of the pair of counter values is selected based upon the value of the first counter value read from the branch history table. The first and second counter values in turn are used for predicting corresponding first and second branch instructions. The first and second branch history table indexes are generated in the same cycle. Likewise, the first counter value and the pair of counter values are read from the branch history table in the same clock cycle. Lastly, the second counter value is selected from the pair of counter values in the same cycle.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50275259\"><p>Disclosed is a circuit and method for multiple access of a branch history table during a single clock cycle. In accordance thereto, a first branch history table index is generated which is used for accessing the branch history table. A first counter value is read from the branch history table in response to accessing the branch history table using the first branch history table index. A second branch history table index is also generated for accessing the branch history table. A pair of counter values are read from the branch history table in response to accessing the branch history table using the second branch history table index. One of the pair of counter values is selected based upon the value of the first counter value read from the branch history table. The first and second counter values in turn are used for predicting corresponding first and second branch instructions. The first and second branch history table indexes are generated in the same cycle. Likewise, the first counter value and the pair of counter values are read from the branch history table in the same clock cycle. Lastly, the second counter value is selected from the pair of counter values in the same cycle.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00001\" num=\"1\"><claim-text>1. A method of operating a microprocessor, the method comprising:</claim-text><claim-text>generating a first branch history table index; </claim-text><claim-text>accessing a branch history table using the first branch table history index; </claim-text><claim-text>reading a first counter value from the branch history table in response to accessing the branch history table using the first branch history table index; </claim-text><claim-text>generating a second branch history table index; </claim-text><claim-text>accessing the branch history table using the second branch history table index; </claim-text><claim-text>reading a pair of counter values from the branch history table in response to accessing the branch history table using the second branch history table index. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00002\" num=\"2\"><claim-text>2. The method of <claim-ref idref=\"US-6347369-B1-CLM-00001\">claim 1</claim-ref> wherein the first branch history table index is generated as a function of a first branch history value and at least a portion of a fetch address of a first branch instruction.</claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00003\" num=\"3\"><claim-text>3. The method of <claim-ref idref=\"US-6347369-B1-CLM-00002\">claim 2</claim-ref> where the first branch history table index is generated by XORing the first branch history value and the at least the portion of the fetch address of the first branch instruction.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00004\" num=\"4\"><claim-text>4. The method of <claim-ref idref=\"US-6347369-B1-CLM-00001\">claim 1</claim-ref> wherein the second branch history table index is generated as a function of a second branch history value and at least a portion of a fetch address of a second branch instruction.</claim-text></claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00005\" num=\"5\"><claim-text>5. The method of <claim-ref idref=\"US-6347369-B1-CLM-00004\">claim 4</claim-ref> where the second branch history table index is generated by XORing the second branch history value and the at least the portion of the fetch address of the second branch instruction.</claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00006\" num=\"6\"><claim-text>6. The method of <claim-ref idref=\"US-6347369-B1-CLM-00001\">claim 1</claim-ref> wherein the first branch history table index is generated as a function of a first M-bit branch history value and the second branch history table index is generated as a function the (M-1) least significant bits of the first branch history value.</claim-text></claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00007\" num=\"7\"><claim-text>7. The method of <claim-ref idref=\"US-6347369-B1-CLM-00001\">claim 1</claim-ref> wherein the first counter value and the pair of counter values are read from the branch history table during one clock cycle.</claim-text></claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00008\" num=\"8\"><claim-text>8. The method of <claim-ref idref=\"US-6347369-B1-CLM-00001\">claim 1</claim-ref> further comprising selecting the one of the pair of counter values based on a value of the first counter value.</claim-text></claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00009\" num=\"9\"><claim-text>9. The method <claim-ref idref=\"US-6347369-B1-CLM-00001\">claim 1</claim-ref> wherein the first and second branch table indexes are generated prior to accessing the branch history table with the first branch table index.</claim-text></claim>"}, {"num": 10, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00010\" num=\"10\"><claim-text>10. A method of operating a microprocessor, the method comprising:</claim-text><claim-text>generating a first branch history table index; </claim-text><claim-text>accessing a branch history table using a first branch history table index; </claim-text><claim-text>reading a first pair of counter values from the branch history table in response to accessing the branch history table using the first branch history table index; </claim-text><claim-text>generating a second branch history table index; </claim-text><claim-text>accessing the branch history table using the second branch history table index; </claim-text><claim-text>reading a second pair of counter values from the branch history table in response to accessing the branch history table using the second branch history table index. </claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00011\" num=\"11\"><claim-text>11. The method of <claim-ref idref=\"US-6347369-B1-CLM-00010\">claim 10</claim-ref> wherein the first branch history table index is generated as a function of a M-bit branch history value, and wherein the second branch history table index value is generated as a function of the (M-1) least significant bits of the M-bit branch history value.</claim-text></claim>"}, {"num": 12, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00012\" num=\"12\"><claim-text>12. The method of <claim-ref idref=\"US-6347369-B1-CLM-00010\">claim 10</claim-ref> wherein the first and second pairs of counter values are read from the branch history table during one clock cycle.</claim-text></claim>"}, {"num": 13, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00013\" num=\"13\"><claim-text>13. The method of <claim-ref idref=\"US-6347369-B1-CLM-00010\">claim 10</claim-ref> further comprising selecting one of the first pair of counter values based on the least significant bit of the first branch history table index.</claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00014\" num=\"14\"><claim-text>14. The method of <claim-ref idref=\"US-6347369-B1-CLM-00013\">claim 13</claim-ref> further comprising selecting one of the second pair of counter values based on the selected one of the first pair of counter values.</claim-text></claim>"}, {"num": 15, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00015\" num=\"15\"><claim-text>15. The method of <claim-ref idref=\"US-6347369-B1-CLM-00010\">claim 10</claim-ref> wherein the first and second branch history table indexes are generated as a function of first and second branch instruction fetch addresses, respectively.</claim-text></claim>"}, {"num": 16, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00016\" num=\"16\"><claim-text>16. The method of <claim-ref idref=\"US-6347369-B1-CLM-00010\">claim 10</claim-ref> wherein the first and second branch history table indexes are generated prior to accessing the branch history table using the first branch history table index.</claim-text></claim>"}, {"num": 17, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00017\" num=\"17\"><claim-text>17. A processor comprising:</claim-text><claim-text>a branch history storage device configured to store a M-bit branch history value; </claim-text><claim-text>a branch history table circuit configured to store a plurality of counter values; </claim-text><claim-text>a branch history index generator coupled between the branch history table circuit and the branch history storage device, wherein the branch history index generator is configured to generate first and second branch history table indexes, wherein the branch history table circuit is configured to receive the first and second branch history table indexes, wherein the branch history table circuit is configured to output a first counter value in response to the branch history table circuit receiving the first branch history table index, wherein the branch history table circuit is configured to output a pair of counter values in response to the branch history table circuit receiving the second branch history table index; </claim-text><claim-text>a selection circuit coupled to the branch history table circuit, wherein the selection circuit is configured to receive the pair of counter values outputted from the branch history table circuit, and wherein the selection circuit is configured to select for output therefrom one of the pair of counter values outputted from the branch history table circuit. </claim-text></claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00018\" num=\"18\"><claim-text>18. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00017\">claim 17</claim-ref> wherein the selection circuit is configured to receive the first counter value, wherein the selection circuit is configured to select one of the pair of counter values based on the first counter value.</claim-text></claim>"}, {"num": 19, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00019\" num=\"19\"><claim-text>19. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00017\">claim 17</claim-ref> wherein the selection circuit includes a multiplexer having a pair of data inputs coupled to receive the pair of counter values outputted from the branch history table and a selection input coupled to receive the first counter value, wherein the multiplexer selects for output one of the pair of counter values in response to the selection input receiving the first counter value.</claim-text></claim>"}, {"num": 20, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00020\" num=\"20\"><claim-text>20. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00017\">claim 17</claim-ref> wherein the branch history table circuit includes a dual ported storage device for storing the plurality of counter values, wherein the dual ported storage device is configured to concurrently receive the first and second branch history table indexes, and wherein the dual ported storage device is configured to concurrently output the first counter value and the pair of counter values in response to the dual ported storage device concurrently receiving the first and second branch history table indexes.</claim-text></claim>"}, {"num": 21, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00021\" num=\"21\"><claim-text>21. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00017\">claim 17</claim-ref> wherein the branch history index generator is configured to generate the first branch history index as a function of the M-bit branch history value stored in the branch history storage device.</claim-text></claim>"}, {"num": 22, "parent": 21, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00022\" num=\"22\"><claim-text>22. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00021\">claim 21</claim-ref> wherein the branch history index generator is configured to generate the first branch history index as a function of the M-bit branch history value stored in the branch history storage device and at least a portion of a fetch address of a first branch instruction.</claim-text></claim>"}, {"num": 23, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00023\" num=\"23\"><claim-text>23. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00022\">claim 22</claim-ref> wherein the branch history index generator is configured to generate the first branch history index by XORing the M-bit branch history value with the at least the portion of the fetch address of the first branch instruction.</claim-text></claim>"}, {"num": 24, "parent": 23, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00024\" num=\"24\"><claim-text>24. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00023\">claim 23</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index from the (M-1) least significant bits of the M-bit branch history value stored in the branch history storage device.</claim-text></claim>"}, {"num": 25, "parent": 24, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00025\" num=\"25\"><claim-text>25. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00024\">claim 24</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index as a function of the (M-1) least significant bits of the M-bit branch history value and the least a portion of a fetch address of a second branch instruction.</claim-text></claim>"}, {"num": 26, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00026\" num=\"26\"><claim-text>26. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00025\">claim 25</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index by XORing the (M-1) least significant bits of the M-bit branch history value with the at least the portion of the fetch address of the second branch instruction.</claim-text></claim>"}, {"num": 27, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00027\" num=\"27\"><claim-text>27. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00017\">claim 17</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index from the (M-1) least significant bits of the M-bit branch history value stored in the branch history storage device.</claim-text></claim>"}, {"num": 28, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00028\" num=\"28\"><claim-text>28. The microprocessor of <claim-ref idref=\"US-6347369-B1-CLM-00017\">claim 17</claim-ref> wherein the branch history index generator is configured to generate the first and second branch history table indexes during one clock cycle.</claim-text></claim>"}, {"num": 29, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00029\" num=\"29\"><claim-text>29. The microprocessor of <claim-ref idref=\"US-6347369-B1-CLM-00017\">claim 17</claim-ref> wherein the branch history table circuit is configured to output the first counter value and the pair of counter values during one clock cycle.</claim-text></claim>"}, {"num": 30, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00030\" num=\"30\"><claim-text>30. The microprocessor <claim-ref idref=\"US-6347369-B1-CLM-00029\">claim 29</claim-ref> wherein the branch history index generator is configured to generate the first and second branch history table indexes during the one clock cycle.</claim-text></claim>"}, {"num": 31, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00031\" num=\"31\"><claim-text>31. A processor comprising:</claim-text><claim-text>a branch history storage device configured to store a M-bit branch history value; </claim-text><claim-text>a branch history table circuit configured to store a plurality of counter values; </claim-text><claim-text>a branch history index generator coupled between the branch history table circuit and the branch history storage device, wherein the branch history index generator is configured to generate first and second branch history table indexes, wherein the branch history table circuit is configured to receive the first and second branch history table indexes, wherein the branch history table circuit is configured to output a first pair of counter values in response to the branch history table circuit receiving the first branch history table index, wherein the branch history table circuit is configured to output a second pair of counter values in response to the branch history table circuit receiving the second branch history table index; </claim-text><claim-text>a selection circuit coupled to the branch history table circuit, wherein the selection circuit is configured to receive the first and second pairs of counter values outputted from the branch history table circuit, and wherein the selection circuit is configured to select for output therefrom one of the first pair of counter values and one of the second pair of counter values. </claim-text></claim>"}, {"num": 32, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00032\" num=\"32\"><claim-text>32. The microprocessor of <claim-ref idref=\"US-6347369-B1-CLM-00031\">claim 31</claim-ref> wherein the selection circuit is configured to select the one of the pair of second counter values based on the selected one of the first pair of counter values.</claim-text></claim>"}, {"num": 33, "parent": 32, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00033\" num=\"33\"><claim-text>33. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00032\">claim 32</claim-ref> wherein the selection circuit comprises a multiplexer having a pair of data inputs for sequentially receiving the first and second pairs of counter values from the branch history table circuit.</claim-text></claim>"}, {"num": 34, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00034\" num=\"34\"><claim-text>34. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00031\">claim 31</claim-ref> wherein the branch history table circuit includes a single ported storage device for storing the plurality of counter values, wherein the single ported storage device is configured to sequentially receive the first and second branch history table indexes, and wherein the single ported storage device is configured to sequentially output the first and second pairs of counter values in response to the single ported storage device sequentially receiving the first and second branch history table indexes.</claim-text></claim>"}, {"num": 35, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00035\" num=\"35\"><claim-text>35. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00031\">claim 31</claim-ref> wherein the branch history index generator is configured to generate the first branch history index as a function of the M-bit branch history value stored in the branch history storage device.</claim-text></claim>"}, {"num": 36, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00036\" num=\"36\"><claim-text>36. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00031\">claim 31</claim-ref> wherein the branch history index generator is configured to generate the first branch history index as a function of the M-bit branch history value stored in the branch history storage device and at least a portion of a fetch address of a first branch instruction.</claim-text></claim>"}, {"num": 37, "parent": 36, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00037\" num=\"37\"><claim-text>37. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00036\">claim 36</claim-ref> wherein the branch history index generator is configured to generate the first branch history index by XORing the M-bit branch history value with the at least the portion of the fetch address of the first branch instruction.</claim-text></claim>"}, {"num": 38, "parent": 37, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00038\" num=\"38\"><claim-text>38. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00037\">claim 37</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index as a function of the (M-1) least significant bits of the M-bit branch history value.</claim-text></claim>"}, {"num": 39, "parent": 38, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00039\" num=\"39\"><claim-text>39. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00038\">claim 38</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index as a function of the (M-1) least significant bits of the M-bit branch history value and the least a portion of a fetch address of a second branch instruction.</claim-text></claim>"}, {"num": 40, "parent": 39, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00040\" num=\"40\"><claim-text>40. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00039\">claim 39</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index by XORing the (M-1) least significant bits of the M-bit branch history value with the at least the portion of the fetch address of the second branch instruction.</claim-text></claim>"}, {"num": 41, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00041\" num=\"41\"><claim-text>41. The processor of <claim-ref idref=\"US-6347369-B1-CLM-00031\">claim 31</claim-ref> wherein the branch history index generator is configured to generate the second branch history table index as a function of the (M-1) least significant bits of the M-bit branch history value.</claim-text></claim>"}, {"num": 42, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00042\" num=\"42\"><claim-text>42. The microprocessor of <claim-ref idref=\"US-6347369-B1-CLM-00031\">claim 31</claim-ref> wherein the branch history index generator is configured to generate the first and second branch history table indexes during one clock cycle.</claim-text></claim>"}, {"num": 43, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00043\" num=\"43\"><claim-text>43. The microprocessor of <claim-ref idref=\"US-6347369-B1-CLM-00031\">claim 31</claim-ref> wherein the branch history table circuit is configured to output the first and second pairs of counter values during one clock cycle.</claim-text></claim>"}, {"num": 44, "parent": 43, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00044\" num=\"44\"><claim-text>44. The microprocessor <claim-ref idref=\"US-6347369-B1-CLM-00043\">claim 43</claim-ref> wherein the branch history index generator is configured to generate the first and second branch history table indexes during the one clock cycle.</claim-text></claim>"}, {"num": 45, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00045\" num=\"45\"><claim-text>45. A computer system comprising:</claim-text><claim-text>a processor, the processor comprising; </claim-text><claim-text>a branch history storage device configured to store a M-bit branch history value; </claim-text><claim-text>a branch history table circuit configured to store a plurality of counter values; </claim-text><claim-text>a branch history index generator coupled between the branch history table circuit and the branch history storage device, wherein the branch history index generator is configured to generate first and second branch history table indexes, wherein the branch history table circuit is configured to receive the first and second branch history table indexes, wherein the branch history table circuit is configured to output a first counter value in response to the branch history table circuit receiving the first branch history table index, wherein the branch history table circuit is configured to output a pair of counter values in response to the branch history table circuit receiving the second branch history table index; </claim-text><claim-text>a selection circuit coupled to the branch history table circuit, wherein the selection circuit is configured to receive the pair of counter values outputted from the branch history table circuit, and wherein the selection circuit is configured to select for output therefrom one of the pair of counter values outputted from the branch history table circuit; </claim-text><claim-text>an input/output device coupled to said processor, wherein the input/output device is configured to communicate between said computer system and another computer system to which said input/output device is coupled. </claim-text></claim>"}, {"num": 46, "parent": 45, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00046\" num=\"46\"><claim-text>46. The computer system of <claim-ref idref=\"US-6347369-B1-CLM-00045\">claim 45</claim-ref> further comprising a second processor.</claim-text></claim>"}, {"num": 47, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00047\" num=\"47\"><claim-text>47. A computer system comprising:</claim-text><claim-text>a processor, the processor comprising; </claim-text><claim-text>a branch history storage device configured to store a M-bit branch history value; </claim-text><claim-text>a branch history table circuit configured to store a plurality of counter values; </claim-text><claim-text>a branch history index generator coupled between the branch history table circuit and the branch history storage device, wherein the branch history index generator is configured to generate first and second branch history table indexes, wherein the branch history table circuit is configured to receive the first and second branch history table indexes, wherein the branch history table circuit is configured to output a first pair of counter values in response to the branch history table circuit receiving the first branch history table index, wherein the branch history table circuit is configured to output a second pair of counter values in response to the branch history table circuit receiving the second branch history table index; </claim-text><claim-text>a selection circuit coupled to the branch history table circuit, wherein the selection circuit is configured to receive the first and second pairs of counter values outputted from the branch history table circuit, and wherein the selection circuit is configured to select for output therefrom one of the first pair of counter values and one of the second pair or counter values; </claim-text><claim-text>an input/output device coupled to said processor, wherein the input/output device is configured to communicate between said computer system and another computer system to which said input/output device is coupled. </claim-text></claim>"}, {"num": 48, "parent": 47, "type": "dependent", "paragraph_markup": "<claim id=\"US-6347369-B1-CLM-00048\" num=\"48\"><claim-text>48. The computer system of <claim-ref idref=\"US-6347369-B1-CLM-00047\">claim 47</claim-ref> further comprising a second processor.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53518316\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><p>This application claims priority to provisional application 60/065,878 filed Nov. 17, 1997.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. Field of the Invention</p><p>The present invention is related to the field of processors and, more particularly, to multiple branch history table access during a single clock.</p><p>2. Description of the Related Art</p><p>Superscalar processors attempt to achieve high performance by dispatching and executing multiple instructions per clock cycle, and by operating at the shortest possible clock cycle time consistent with the design. As used herein, the term clock cycle means a period of time allocated to a superscalar processing stage for accomplishing the function assigned to that stage. To the extent that a given processor is successful at dispatching and/or executing multiple instructions per clock cycle, high performance may be realized. In order to increase the average number of instructions dispatched per clock cycle, processor designers have been designing superscalar processors which employ wider issue rates. A \u201cwide issue\u201d superscalar processor is capable of dispatching (or issuing) a larger maximum number of instructions per clock cycle than a \u201cnarrow issue\u201d superscalar processor is capable of dispatching. During clock cycles in which a number of dispatchable instructions is greater than the narrow issue processor can handle, the wide issue processor may dispatch more instructions, thereby achieving a greater average number of instructions dispatched per clock cycle.</p><p>In order to support wide issue rates, it is desirable for the superscalar processor to be capable of fetching a large number of instructions per clock cycle (on the average). For brevity, a processor capable of fetching a large number of instructions per clock cycle (on the average) will be referred to herein as having a \u201chigh fetch bandwidth\u201d. If the superscalar processor is unable to achieve a high fetch bandwidth, then the processor may be unable to take advantage of the wide issue hardware due to a lack of instructions being available for issue.</p><p>Several factors may impact the ability of a particular processor to achieve a high fetch bandwidth. For example, many code sequences have a high frequency of branch instructions, which may redirect the fetching of subsequent instructions within that code sequence to a branch target address specified by the branch instruction. Accordingly, the processor may identify the branch target address after fetching the branch instruction. Subsequently, the next instructions within the code sequence may be fetched using the branch target address. Processors attempt to minimize the impact of branch instructions on the fetch bandwidth by employing highly accurate branch prediction mechanisms and by generating the subsequent fetch address (either branch target or sequential) as rapidly as possible. They are several different branch prediction mechanisms currently in use within microprocessors. One branch prediction mechanism employs a branch history storage device for storing a multi-bit branch history value, each bit of which identifies the resolution of a previously predicted branch instruction. This multi-bit branch history value is used, alone or in combination with the instruction address of the branch instruction to be predicted, to index bimodal counters in a branch history table. The bimodal counters have four states, and branch instructions are predicted \u201ctaken\u201d or \u201cnot taken\u201d depending on the value of the bimodal counter read from the history table.</p><p>As used herein, a branch instruction is an instruction which specifies the address of the next instructions to be fetched. The address may be the sequential address identifying the instruction immediately subsequent to the branch instruction within memory, or a branch target address identifying a different instruction stored elsewhere in memory. Unconditional branch instructions always select the branch target address, while conditional branch instructions select either the sequential address or the branch target address based upon a condition specified by the branch instruction. For example, the processor may include a set of condition codes which indicate the results of executing previous instructions, and the branch instruction may test one or more of the condition codes to determine if the branch selects the sequential address or the target address. A branch instruction is referred to as taken if the branch target address is selected via execution of the branch instruction, and not taken if the sequential address is selected. Similarly, if a conditional branch instruction is predicted via a branch prediction mechanism, the branch instruction is referred to as predicted taken if the branch target address is predicted to be selected upon execution of the branch instruction and is referred to as predicted not taken if the sequential address is predicted to be selected upon execution of the branch instruction.</p><p>Typically, a plurality of instructions are fetched by the superscalar processor, the plurality containing at least two conditional branch instructions. In order to take advantage of wide issue superscalar architecture, it is sometimes necessary to predict both fetched branch instructions in the same clock cycle. However, prior art branch prediction mechanisms are configured for only one branch prediction per clock cycle. In these prior art processors, two clock cycles may be needed particularly when the first instruction is predicted as not taken or taken to a target address just prior to the second branch instruction. The need for two clock cycles to predict the pair of branch instructions may have adverse impact on processor performance. It would be desirable to sustain two branch predictions per clock cycle, especially since many of the pairs of conditional branch instructions fetched per clock cycle are predicted not taken or taken with a target address just prior to the second conditional branch instruction.</p><h4>SUMMARY OF THE INVENTION</h4><p>The problems outlined above in large part are solved by the present invention which allows at least two branch instructions to be predicted in a single clock cycle. The present invention sustains the at least two branch instruction predictions by providing a circuit and method for multiple branch history table access in a single clock cycle. In accordance with the present invention, a circuit and method is provided for generating a first branch history table index which is used to access a branch history table. A first counter value is read from the branch history table in response to accessing the branch history table using the first branch history table index. Additionally, a second branch history table index is generated which is used for accessing the branch history table. In response to accessing the branch history table using the second branch history table index, a pair of counter values are read therefrom. One of the pair of counter values is selected as the second counter, the selection being based upon the value of the first counter value. The first counter value is used to predict a first branch instruction while the counter value is used to protect a second branch instruction.</p><p>The first and second branch history table indexes are generated within one clock cycle. Moreover, the first and second values are provided in the one clock cycle. This allows the first and second branch instructions to be predicted in the one clock cycle.</p><p>In accordance with another embodiment of the present invention, the first branch history table index is generated as a function of a first branch history value stored in a branch history storage device. The second branch history table index is generated as a function of a second branch history value where the second branch history value is formed from the (M-1) least significant bits of the first branch history value. The second branch history table index can be generated without updating the branch history storage device with the first branch prediction.</p><p>One advantage of the present invention is that the first and second counter values can be obtained from the branch history table in a single clock cycle.</p><p>Another advantage of the present invention is that it enables the prediction of two branch instructions within one clock cycle.</p><p>Yet another advantage of the present invention is that it enables prediction of multiple branch instructions contained within a single instruction run provided by an I-cache.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>Other objects and advantages of the invention will become apparent upon reading the following detailed description and upon reference to the accompanying drawings in which:</p><p>FIG. 1 is a block diagram of one embodiment of a processor employing the present invention;</p><p>FIG. 2 is a block diagram of one embodiment of a fetch/scan unit shown in FIG. 1;</p><p>FIG. 3 is a block diagram of one embodiment of a branch history table index generator and branch history table circuit shown in FIG. 2;</p><p>FIG. 4 is a block diagram of illustrating another embodiment of the branch history index generator and branch history table circuit shown in FIG. 2; and</p><p>FIG. 5 is a block diagram of the computer system including the processor shown in FIG. <b>1</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><p>While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.</p><h4>DETAILED DESCRIPTION OF THE INVENTION</h4><p>Turning now to FIG. 1, a block diagram of one embodiment of a superscalar processor <b>10</b> employing the present invention is shown. Other embodiments employing the present invention are possible and contemplated. In the embodiment shown in FIG. 1, processor <b>10</b> includes a predecode unit <b>12</b>, an L1 I-cache <b>14</b>, an L0 I-cache <b>16</b>, a fetch/scan unit <b>18</b>, an instruction queue <b>20</b>, an alignment unit <b>22</b>, a look ahead/collapse unit <b>24</b>, a future file <b>26</b>, a reorder buffer/register file <b>28</b>, a first instruction window <b>30</b>A, a second instruction window <b>30</b>B, a plurality of functional units <b>32</b>A, <b>32</b>B, <b>32</b>C, and <b>32</b>D, a plurality of address generation units <b>34</b>A, <b>34</b>B, <b>34</b>C, and <b>34</b>D, a load/store unit <b>36</b>, an L1 D-cache <b>38</b>, an FPU/multimedia unit <b>40</b>, and an external interface unit <b>42</b>. Elements referred to herein by a particular reference number followed by various letters will be collectively referred to using the reference number alone. For example, functional units <b>32</b>A, <b>32</b>B, <b>32</b>C, and <b>32</b>D will be collectively referred to as functional units <b>32</b>.</p><p>In FIG. 1, external interface unit <b>42</b> is coupled to predecode unit <b>12</b>, L1 D-cache <b>38</b>, an L<b>2</b> interface <b>44</b>, and a bus interface <b>46</b>. Predecode unit <b>12</b> is further coupled to L1 I-cache <b>14</b>. L1 I-cache <b>14</b> is coupled to L0 I-cache <b>16</b> and to fetch/scan unit <b>18</b>. Fetch/scan unit <b>18</b> is also coupled to L0 I-cache <b>16</b> and to instruction queue <b>20</b>. Instruction queue <b>20</b> is coupled to alignment unit <b>22</b>, which is further coupled to look ahead/collapse unit <b>24</b>. Look ahead/collapse unit <b>24</b> is further coupled to future file <b>26</b>, reorder buffer/register file <b>28</b>, load/store unit <b>36</b>, first instruction window <b>30</b>A, second instruction window <b>30</b>B, and FPU/multimedia unit <b>40</b>. FPU/multimedia unit <b>40</b> is coupled to load/store unit <b>36</b> and to reorder buffer/register file <b>28</b>. Load/store unit <b>36</b> is coupled to L1 D-cache <b>38</b>. First instruction window <b>30</b>A is coupled to functional units <b>32</b>A-<b>32</b>B and to address generation units <b>34</b>A-<b>34</b>B. Similarly, second instruction window <b>30</b>B is coupled to functional units <b>32</b>C-<b>32</b>D and address generation units <b>34</b>C-<b>34</b>D. Each of L1 D-cache <b>38</b>, functional units <b>32</b>, and address generation units <b>34</b> are coupled to a plurality of result buses <b>48</b> which are further coupled to load/store unit <b>36</b>, first instruction window <b>30</b>A, second instruction window <b>30</b>B, reorder buffer/register file <b>28</b>, and future file <b>26</b>.</p><p>Generally speaking, processor <b>10</b> is configured to fetch instructions from L0 I-cache <b>16</b>. Fetch/scan unit <b>18</b> is configured to scan the fetched instructions in order to detect the branch instructions included therein, and is further configured to predict the detected branch instructions. If a branch instruction is predicted taken and has a forward branch target address, fetch/scan unit <b>18</b> is configured to selectively cancel one or more of the fetched instructions subsequent to the predicted branch instruction while retaining other fetched instructions subsequent to the predicted branch instruction. More particularly, if the forward branch target address is within a predetermined range of the branch fetch address (i.e., the instruction address of the corresponding branch instruction), the instructions between the predicted branch instruction and a subsequent instruction (i.e., the instruction corresponding to the branch target address) within the plurality of fetched instructions, are cancelled, while the subsequent instruction and any instructions succeeding the subsequent instruction within the plurality of instructions are retained. Thus, one or more of the instructions at the target address have already been fetched concurrent with the branch instruction and are retained within the pipeline of processor <b>10</b>.</p><p>Advantageously, the achievable fetch bandwidth may be improved by retaining target instructions which are fetched concurrently with the branch instruction having a forward branch target address. Instead of discarding the target instructions which have already been fetched and fetching those same target instructions during a subsequent fetch using the forward branch target address, the target instructions are retained and instructions sequential to the previously fetched target instructions are fetched.</p><p>In one embodiment, fetch/scan unit <b>18</b> is configured to detect and predict up to two two branch instructions within a run of instructions fetched from L0 I-cache <b>16</b> during a single clock cycle. If the first detected branch instruction is predicted taken and has a forward branch target address, instructions may be selectively cancelled as described above. In such a case, fetch/scan unit <b>18</b> then determines if the second detected branch instruction is still within the run of instructions (i.e. the second branch instruction was not cancelled). If the second detected branch instruction was not cancelled, is predicted taken, and has a forward branch target address, instructions subsequent to the second detected branch instruction may be selectively cancelled and retained in a manner similar to the processing of the first detected branch instruction. Advantageously, up to two branch instructions may be predicted per fetch, and fetch bandwidth may be even further increased.</p><p>As used herein, the term \u201cforward branch target address\u201d refers to a branch target address which is numerically greater than the fetch address of the branch instruction specifying the branch target address. The fetch address of the branch instruction (or 25 \u201cbranch fetch address\u201d) is the address at which the branch instruction is stored.</p><p>Furthermore, the term canceling instructions refers to invalidating the instructions within the pipeline subsequent to fetching the instructions. For example, the instructions may be invalidated within instruction queue <b>20</b>. The term \u201csquashing instructions\u201d may also be used herein to refer to canceling the instructions. An instruction is referred to as being between a branch instruction and a subsequent target instruction if the instruction is stored at a fetch address which is numerically greater than the branch fetch address and numerically less then the branch target address specified by the branch instruction stored at the branch fetch address. Additionally, a forward target address is \u201cwithin a predetermined range\u201d of the corresponding branch fetch address if the difference between the branch fetch address and the branch target address is less than or equal to a predetermined value (e.g. 64 bytes, in one embodiment).</p><p>Predecode unit <b>12</b> receives instruction bytes fetched by external interface unit <b>42</b> and predecodes the instruction bytes prior to their storage within L1 I-cache <b>14</b>. Predecode information generated by predecode unit <b>12</b> is stored in L1 I-cache <b>14</b> as well. Generally, predecode information is provided to aid in the identification of instruction features which may be useful during the fetch and issue of instructions but which may be difficult to generate rapidly during the fetch and issue operation. The term \u201cpredecode\u201d, as used herein, refers to decoding instructions to generate predecode information which is later stored along with the instruction bytes being decoded in an instruction cache (e.g. L1 I-cache <b>14</b> and/or L0 I-cache <b>16</b>).</p><p>In one embodiment, processor <b>10</b> employs two bits of predecode information per instruction byte. One of the bits, referred to as the \u201cstart bit\u201d, indicates whether or not the instruction byte is the initial byte of an instruction. When a group of instruction bytes is fetched, the corresponding set of start bits identifies the boundaries between instructions within the group of instruction bytes. Accordingly, multiple instructions may be concurrently selected from the group of instruction bytes by scanning the corresponding start bits. While start bits are used to locate instruction boundaries by identifying the initial byte of each instruction, end bits could alternatively be used to locate instruction boundaries by identifying the final byte of each instruction.</p><p>The second predecode bit used in this embodiment, referred to as the \u201ccontrol transfer\u201d bit, identifies which instructions are branch instructions. The control transfer bit corresponding to the initial byte of an instruction indicates whether or not the instruction is a branch instruction. The control transfer bit corresponding to subsequent bytes of the instruction is a don't care except for relative branch instructions having a small displacement field. According to one particular embodiment, the small displacement field is an 8 bit field. Generally, a \u201csmall displacement field\u201d refers to a displacement field having fewer bits than the target address generated by branch instructions. For relative branch instructions having small displacement fields, the control transfer bit corresponding to the displacement byte is used as described below.</p><p>In addition to generating predecode information corresponding to the instruction bytes, predecode unit <b>12</b> is configured to recode the displacement field of relative branch instructions to actually store the target address in the present embodiment. In other words, predecode unit <b>12</b> adds the displacement of the relative branch instruction to the address corresponding to the relative branch instruction as defined by the instruction set employed by processor <b>10</b>. The resulting target address is encoded into the displacement field as a replacement for the displacement, and the updated displacement field is stored into L1 I-cache <b>14</b> instead of the original displacement field. Target address generation is simplified by precomputing relative target addresses, and hence the branch prediction mechanism may operate more efficiently.</p><p>In one embodiment of processor <b>10</b> which employs the x86 instruction set, predecode unit <b>12</b> is configured to recode eight bit and 32 bit displacement fields. The 32 bit displacement fields may store the entirety of the target address. On the other hand, the eight bit displacement field is encoded. More particularly, the eight bit displacement field and corresponding control transfer predecode bit is divided into a cache line offset portion and a relative cache line portion. The cache line offset portion is the cache line offset portion of the target address. The relative cache line portion defines the cache line identified by the target address (the \u201ctarget cache line\u201d) in terms of a number of cache lines above or below the cache line storing the relative branch instruction. A first cache line is above a second cache line if each byte within the first cache line is stored at an address which is numerically greater than the addresses at which the bytes within the second cache line are stored. Conversely, a first cache line is below the second cache line if each byte within the first cache line is stored at an address which is numerically less than the addresses at which the bytes within a second cache line are stored. A signed eight bit displacement specifies an address which is +/\u2212128 bytes of the address corresponding to the branch instruction. Accordingly, the number of above and below cache lines which can be reached by a relative branch instruction having an eight bit displacement is limited. The relative cache line portion encodes this limited set of above and below cache lines. Generally, branch instructions having a small displacement field have displacements within a predefined range, whereas larger displacement fields may store values outside the predefined range.</p><p>Tables 1 and 2 below illustrates an exemplary encoding of the predecode information corresponding to a byte in accordance with one embodiment of processor <b>10</b>.</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE 1</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Predecode Encoding</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"35pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"70pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"112pt\"></colspec><tbody valign=\"top\"><row><entry>Start Bit</entry><entry>Control Transfer Bit</entry><entry>Meaning</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>1</entry><entry>0</entry><entry>Start byte of an instruction which is</entry></row><row><entry></entry><entry></entry><entry>not a branch.</entry></row><row><entry>1</entry><entry>1</entry><entry>Start byte of a branch instruction.</entry></row><row><entry>0</entry><entry>x</entry><entry>Not an instruction boundary. Control</entry></row><row><entry></entry><entry></entry><entry>Transfer Bit corresponding to dis-</entry></row><row><entry></entry><entry></entry><entry>placement is used on 8-bit relative</entry></row><row><entry></entry><entry></entry><entry>branches to encode target address as</entry></row><row><entry></entry><entry></entry><entry>shown in Table 2 below.</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p><tables id=\"TABLE-US-00002\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE 2</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Target Address Encoding</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"56pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"91pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"70pt\"></colspec><tbody valign=\"top\"><row><entry>Control Transfer</entry><entry>Displacement Byte</entry><entry></entry></row><row><entry>Bit</entry><entry>Most Significant Bits (binary)</entry><entry>Meaning</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>0</entry><entry>00</entry><entry>Within Current Cache</entry></row><row><entry></entry><entry></entry><entry>Line</entry></row><row><entry>0</entry><entry>01</entry><entry>One Cache Line</entry></row><row><entry></entry><entry></entry><entry>Above</entry></row><row><entry>0</entry><entry>10</entry><entry>Two Cache Line</entry></row><row><entry></entry><entry></entry><entry>Above</entry></row><row><entry>1</entry><entry>01</entry><entry>One Cache Line</entry></row><row><entry></entry><entry></entry><entry>Below</entry></row><row><entry>1</entry><entry>10</entry><entry>Two Cache Lines</entry></row><row><entry></entry><entry></entry><entry>Below</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>Note: Remaining displacement byte bits are the offset within the target cache line. Control Transfer Bit is effectively a direction, and the most significant bits of the lines.</p><p>Predecode unit <b>12</b> conveys received instruction bytes and corresponding precode information to L1 I-cache <b>14</b> for storage. L1 I-cache <b>14</b> is a high speed cache memory for storing instruction bytes and predecode information. L1 I-cache <b>14</b> may employ any suitable configuration, including directing direct mapped and set associative configurations. In one particular embodiment, L1 I-cache <b>14</b> is a 128 KB, two way set associative cache employing 64 byte cache lines. L1 I-cache <b>14</b> includes additional storage for the predecode information corresponding to the instruction bytes stored therein. The additional storage is organized similar to the instruction bytes storage. As used herein, the term \u201ccache line \u201drefers to the unit of allocation of storage in a particular cache. Gernerally, the bytes within a cache line are manipulated (i.e. allocated and deallocated) by the cache as a unit.</p><p>In one embodiment, L1 I-cache <b>14</b> is linearly addressed and physically tagged. A cache is linearly addressed if at least one of the address bits used to index the cache is a linear address bit which is subsequently translated to a physical address bit. The tags of a linearly address/physically tagged cache include each translated bit in addition to the bits not used to index. As specified by the x86 architecture, instructions are defined to generate logical addresses which are translated through a segmentation translation mechanism to a linear address which in turn is further translated through a page translation mechanism to a physical address. It is becoming increasingly common to employ flat addressing mode, in which the logical address and corresponding linear address are equal. Processor <b>10</b> may be configured to assume flat addressing mode. Accordingly, fetch addresses, target addresses, etc. as generated by executing instructions are linear addresses. In order to determine if a hit is detected in L1 I-cache <b>14</b>, the linear address presented thereto by fetch/scan unit <b>18</b> is translated using a translation lookaside buffer (TLB) to a corresponding physical address which is compared to the physical tags from the indexed cache lines to determine a hit/miss. When flat addressing mode is not used, processor <b>10</b> may still execute code but additional clock cycles may be used to generate linear addresses from logical addresses.</p><p>L0 I-cache <b>16</b> is also a high speed cache memory for storing instruction bytes. Because L1 I-cache <b>14</b> is large, the access time of L1 I-cache <b>14</b> may be large. In one particular embodiment, L1 I-cache <b>14</b> uses a two clock cycle access time. In order to allow for single cycle fetch access, L0 I-cache <b>16</b> is employed. L0 I-cache <b>16</b> is comparably smaller than L1 I-cache <b>14</b>, and hence may support a more rapid access time. In one particular embodiment, L0 I-cache <b>16</b> is a 512 byte fully associative cache. Similar to L1 I-cache <b>14</b>, L0 I-cache <b>16</b> is configured to store cache lines of instruction bytes and corresponding predecode information (e.g. 512 bytes stores eight 64 byte cache lines and corresponding predecode data is stored in additional storage). In one embodiment, L0 I-cache <b>16</b> may be linearly addressed and linearly tagged.</p><p>Fetch/scan unit <b>18</b> is configured to generate fetch addresses for L0 I-cache <b>16</b> and fetch or prefetch addresses for L1 I-cache <b>14</b>. Instructions fetched from L0 I-cache <b>16</b> are scanned by fetch/scan unit <b>18</b> to identify instructions for dispatch as well as to locate branch instructions and to form branch predictions corresponding to the located branch instructions. Instruction scan information and corresponding instruction bytes are stored into instruction queue <b>20</b> by fetch/scan unit <b>18</b>. Additionally, the identified branch instructions and branch predictions are used to generate subsequent fetch addresses for L0 I-cache <b>16</b>.</p><p>Fetch/scan unit <b>18</b> employs a prefetch algorithm to attempt to prefetch cache lines from L1 I-cache <b>14</b> to L0 I-cache <b>16</b> prior to the prefetched cache lines being fetched by fetch/scan unit <b>18</b> for dispatch into processor <b>10</b>. Any suitable prefetch algorithm may be used. One embodiment of the prefetch algorithm is set forth in more detail below.</p><p>Fetch/scan unit <b>18</b> employs an aggressive branch prediction mechanism in attempt to fetch larger \u201cruns\u201d of instructions during a clock cycle. As used herein, a \u201crun\u201d of instructions is a set of one or more instructions predicted to be executed in the sequence specified within the set. For example, fetch/scan unit <b>18</b> may fetch runs of 24 instruction bytes from L0 I-cache <b>16</b>. Each run is divided into several sections which fetch/scan unit <b>18</b> scans in parallel to identify branch instructions and to generate instruction scan information for instruction queue <b>20</b>. According to one embodiment, fetch/scan unit <b>18</b> attempts to predict up to two branch instructions per clock cycle, as will be more fully described below, in order support large instruction runs.</p><p>Instruction queue <b>20</b> is configured to store instruction bytes provided by fetch/scan unit <b>18</b> for subsequent dispatch. Instruction queue <b>20</b> may operate as a first-in, first-out (FIFO) buffer. In one embodiment, instruction queue <b>20</b> is configured to store multiple entries, each entry comprising: a run of instructions, scan data identifying up to five instructions within each section of the run, and addresses corresponding to each section of the run. Additionally, instruction queue <b>20</b> may be configured to select up to six instructions within up to four consecutive run sections for presentation to alignment unit <b>22</b>. Instruction queue <b>20</b> may, for example, employ 2-3 entries.</p><p>Alignment unit <b>22</b> is configured to route instructions identified by instruction queue <b>20</b> to a set of issue positions within look ahead/collapse unit <b>24</b>. In other words, alignment unit <b>22</b> selects the bytes which form each instruction from the run sections provided by instruction queue <b>20</b> responsive to the scan information provided by instruction queue <b>20</b>. The instructions are provided into the issue positions in program order (i.e. the instruction which is first in program order is provided to the first issue position, the second instruction in program order is provided to the second issue position, etc.).</p><p>Look ahead/collapse unit <b>24</b> decodes the instructions provided by alignment unit <b>22</b>. FPU/multimedia instructions detected by look ahead/collapse unit <b>24</b> are routed to FPU/multimedia unit <b>40</b>. Other instructions are routed to first instruction window <b>30</b>A, second instruction window <b>30</b>B, and/or load/store unit <b>36</b>. In one embodiment, a particular instruction is routed to one of first instruction window <b>30</b>A or second instruction window <b>30</b>B based upon the issue position to which the instruction was aligned by alignment unit <b>22</b>. According to one particular embodiment, instructions from alternate issue positions are routed to alternate instruction windows <b>30</b>A and <b>30</b>B. For example, instructions from issue positions zero, two, and four may be routed to the first instruction window <b>30</b>A and instructions from issue positions one, three, and five may be routed to the second instruction window <b>30</b>B. Instructions which include a memory operation are also routed to load/store unit <b>36</b> for access to L1 D-cache <b>38</b>.</p><p>Additionally, look ahead/collapse unit <b>24</b> attempts to generate look ahead addresses or execution results for certain types of instructions. Look ahead address/result generation may be particularly beneficial for embodiments employing the x86 instruction set. Because of the nature the x86 instruction set, many of the instructions in a typical code sequence are versions of simple moves. One reason for this feature is that x86 instructions include two operands, both of which are source operands and one of which is a destination operand. Therefore, one of the source operands of each instruction is overwritten with an execution result. Furthermore, the x86 instruction set specifies very few registers for storing register operands. Accordingly, many instructions are moves of operands to and from a stack maintained within memory. Still further, many instruction dependencies are dependencies upon the ESP/EBP registers and yet many of the updates to these registers are increments and decrements of the previously stored values.</p><p>To accelerate the execution of these instructions, look ahead/collapse unit <b>24</b> generates lookahead copies of the ESP and EBP registers for each of instructions decoded during a clock cycle. Additionally, lookahead/collapse unit <b>24</b> accesses future file <b>26</b> for register operands selected by each instruction. For each register operand, future file <b>26</b> may be storing either an execution result or a tag identifying a reorder buffer result queue entry corresponding to the most recent instruction having that register as a destination operand.</p><p>In one embodiment, lookahead/collapse unit <b>24</b> attempts to perform an address calculation for each instruction which includes: (i) a memory operand; and (ii) register operands used to form the address of the memory operand available from future file <b>26</b> or lookahead copies of ESP/EBP. Additionally, lookahead/collapse unit <b>24</b> attempts to perform a result calculation for each instruction which: (i) does not include a memory operand; (ii) specifies an add/subtract operation (including increment and decrement); and (iii) includes register operands available from future file <b>26</b> or lookahead copies of ESP/EBP. In this manner, many simple operations may be completed prior to instructions being sent to instruction windows <b>30</b>A-<b>30</b>B.</p><p>Lookahead/collapse unit <b>24</b> detects dependencies between a group of instructions being dispatched and collapses any execution results generated therein into instructions dependent upon those instruction results. Additionally, lookahead/collapse unit <b>24</b> updates future file <b>26</b> with the lookahead execution results. Instruction operations which are completed by lookahead/collapse unit <b>24</b> (i.e. address generations and/or instruction results are generated and load/store unit <b>36</b> or future file <b>26</b> and the result queue are updated) are not dispatched to instruction windows <b>30</b>A-<b>30</b>B.</p><p>Lookahead/collapse unit <b>24</b> allocates a result queue entry in reorder buffer/register file <b>28</b> for each instruction dispatched. In one particular embodiment, reorder buffer/register file <b>28</b> includes a result queue organized in a line-oriented fashion in which storage locations for execution results are allocated and deallocated in lines having enough storage for execution results corresponding to a maximum number of concurrently dispatchable instructions. If less than the maximum number of instructions are dispatched, then certain storage locations within the line are empty. Subsequently dispatched instructions use the next available line, leaving the certain storage locations empty. In one embodiment, the result queue includes 40 lines, each of which may store up to six execution results corresponding to concurrently dispatched instructions. Execution results are retired from the result queue into the register file included within reorder buffer/register file <b>28</b>. Additionally, the reorder buffer handles branch mispredictions, transmitting the corrected fetch address generated by the execution of the branch instruction to fetch/scan unit <b>18</b>. Similarly, instructions which generate other exceptions are handled within the reorder buffer. Results corresponding to instructions subsequent to the exception-generating instruction are discarded by the reorder buffer. The register file comprises a storage location for each architected register. For example, the x86 instruction set defines 8 architected registers. The register file for such an embodiment includes eight storage locations. The register file may further include storage locations used as temporary registers by a microcode unit in embodiments employing microcode units.</p><p>Future file <b>26</b> maintains the speculative state of each architected register as instructions are dispatched by lookahead/collapse unit <b>24</b>. As an instruction having a register destination operand is decoded by lookahead/collapse unit <b>24</b>, and the tag identifying the storage location within the result queue portion of reorder buffer/register file <b>28</b> assigned to the instruction is stored into the future file <b>26</b> storage location corresponding to that register. When the corresponding execution result is provided, the execution result is stored into the corresponding storage location (assuming that a subsequent instruction which updates the register has not been dispatched).</p><p>It is noted that, in one embodiment, a group of up to six instructions is selected from instruction queue <b>20</b> and moves through the pipeline within lookahead/collapse unit <b>24</b> as a unit. If one or more instructions within the group generates a stall condition, the entire group stalls. An exception to this rule is if lookahead/collapse unit <b>24</b> generates a split line condition due to the number of ESP updates within the group. Such a group of instructions is referred to as a \u201cline\u201d of instructions herein.</p><p>Instruction windows <b>30</b> receive instructions from lookahead/collapse unit <b>24</b>. Instruction windows <b>30</b> store the instructions until the operands corresponding to the instructions are received, and then select the instructions for execution. Once the address operands of an instruction including a memory operation have been received, the instruction is transmitted to one of the address generation units <b>34</b>. Address generation units <b>34</b> generate an address from the address operands and forward the address to load/store unit <b>36</b>. On the other hand, once the execution operands of an instruction have been received, the instruction is transmitted to one of the functional units <b>32</b> for execution. In one embodiment, each integer window <b>30</b>A-<b>30</b>B includes 25 storage locations for instructions. Each integer window <b>30</b>A-<b>30</b>B is configured to select up to two address generations and two functional unit operations for execution each clock cycle in the address generation units <b>34</b> and functional units <b>32</b> connected thereto. In one embodiment, instructions fetched from L0 I-cache <b>16</b> remain in the order fetched until stored into one of instruction windows <b>30</b>, at which point the instructions may be executed out of order.</p><p>In embodiments of processor <b>10</b> employing the x86 instruction set, an instruction may include implicit memory operations for load/store unit <b>36</b> as well as explicit functional operations for functional units <b>32</b>. Instructions having no memory operand do not include any memory operations, and are handled by functional units <b>32</b>. Instructions having a source memory operand and a register destination operand include an implicit load memory operation handled by load/store unit <b>36</b> and an explicit functional operation handled by functional units <b>32</b>. Instructions having a memory source/destination operand include implicit load and store memory operations handled by load/store unit <b>36</b> and an explicit functional operation handled by functional units <b>32</b>. Finally, instructions which do not have an explicit functional operation are handled by load/store unit <b>36</b>. Each memory operation results in an address generation handled either by lookahead/collapse unit <b>24</b> or address generation units <b>34</b>. Memory operations and instructions (i.e. functional operations) may be referred to herein separately, but may be sourced from a single instruction.</p><p>Address generation units <b>34</b> are configured to perform address generation operations, thereby generating addresses for memory operations in load/store unit <b>36</b>. The generated addresses are forwarded to load/store unit <b>36</b> via result buses <b>48</b>. Functional units <b>32</b> are configured to perform integer arithmetic/logical operations and execute branch instructions. Execution results are forwarded to future file <b>26</b>, reorder buffer/register file <b>28</b>, and instruction windows <b>30</b>A-<b>30</b>B via result buses <b>48</b>. Address generation units <b>34</b> and functional units <b>32</b> convey the result queue tag assigned to the instruction being executed upon result buses <b>48</b> to identify the instruction being executed. In this manner, future file <b>26</b>, reorder buffer/register file <b>28</b>, instruction windows <b>30</b>A-<b>30</b>B, and load/store unit <b>36</b> may identify execution results with the corresponding instruction. FPU/multimedia unit <b>40</b> is configured to execute floating point and multimedia instructions.</p><p>Load/store unit <b>36</b> is configured to interface with L1 D-cache <b>38</b> to perform memory operations. A memory operation is a transfer of data between processor <b>10</b> and an external memory. The memory operation may be an explicit instruction, or may be implicit portion of an instruction which also includes operations to be executed by functional units <b>32</b>. Load memory operations specify a transfer of data from external memory to processor <b>10</b>, and store memory operations specify a transfer of data from processor to external memory. If a hit is detected for a memory operation within L1 D-cache <b>38</b>, the memory operation is completed therein without access to external memory. Load/store unit <b>36</b> may receive addresses for memory operations from lookahead/collapse unit <b>24</b> (via lookahead address calculation) or from address generation units <b>34</b>. In one embodiment, load/store unit <b>36</b> is configured perform up to three memory operations per clock cycle to L1 D-cache <b>38</b>. For this embodiment, load/store unit <b>36</b> may be configured to buffer up to <b>30</b> load/store memory operations which have not yet accessed D-cache <b>38</b>. The embodiment may further be configured to include a <b>96</b> entry miss buffer for buffering load memory operations which miss D-cache <b>38</b> and a <b>32</b> entry store data buffer. Load/store unit <b>36</b> is configured to perform memory dependency checking between load and store memory operations.</p><p>L1 D-cache <b>38</b> is a high speed cache memory for storing data. Any suitable configuration may be used for L1 D-cache <b>38</b>, including set associative and direct mapped configurations. In one particular embodiment, L1 D-cache <b>38</b> is a 128 KB two way set associative cache employing 64 byte lines. L1 D-cache <b>38</b> may be organized as, for example, 32 banks of cache memory per way. Additionally, L1 D-cache <b>38</b> may be a linearly addressed/physically tagged cache employing a TLB similar to L1 I-cache <b>14</b>.</p><p>External interface unit <b>42</b> is configured to transfer cache lines of instruction bytes and data bytes into processor <b>10</b> in response to cache misses. Instruction cache lines are routed to predecode unit <b>12</b>, and data cache lines are routed to L1 D-cache <b>38</b>. Additionally, external interface unit <b>42</b> is configured to transfer cache lines discarded by L1 D-cache <b>38</b> to memory if the discarded cache lines have been modified by processor <b>10</b>. As shown in FIG. 1, external interface unit <b>42</b> is configured to interface to an external L2 cache via L2 interface <b>44</b> as well as to interface to a computer system via bus interface <b>46</b>. In one embodiment, bus interface unit <b>46</b> comprises an EV/6 bus interface.</p><p>Turning now to FIG. 2, a block diagram of one embodiment of fetch/scan unit <b>18</b> is shown. Other embodiments of fetch/scan unit <b>18</b> are possible and contemplated, and the present invention should not be limited to that shown in FIG. <b>2</b>. Fetch/scan unit <b>18</b> includes a prefetch control unit <b>50</b>, branch history table circuit <b>52</b>, branch history table index generator <b>54</b>, branch history storage <b>56</b>, branch scanner <b>58</b>, and instruction run storage <b>60</b>. Instruction run storage <b>60</b> is coupled to branch scanner <b>58</b> which, in turn, is coupled to branch history table index generator <b>54</b>. Branch history table index generator <b>54</b> is also coupled to branch history storage <b>56</b> and branch history table circuit <b>52</b>. Prefetch control unit <b>50</b> is coupled to branch history table circuit <b>52</b>.</p><p>Instruction run storage <b>60</b> is configured to receive a run or plurality of instructions from L1 I-cache <b>14</b> or L0 I-cache <b>16</b>. Branch scanner <b>58</b> scans the instruction run in storage <b>60</b> in parallel with an instruction scanner (not shown in FIG. <b>2</b>). Branch scanner <b>58</b> scans the start bits and control transfer bits of the instruction run to identify two branch instructions (i.e., first and second branch instructions) within the instruction run. As described above, a branch instruction is identified by the control transfer bit corresponding to the start byte of an instruction (as identified by the start bit) being set. The fetch addresses of each branch instruction (determined from the fetch address of the run section including each branch instruction and the position of the branch instruction within this section) are routed to branch history table index generator <b>54</b>.</p><p>Branch history storage device <b>56</b> is configured to store a multi-bit branch history value. Often times the branch history storage device is a shift register, and the remaining description of the preferred embodiments may refer to branch history storage device <b>56</b> as branch shift register <b>56</b>. Each bit of the branch history value stored in branch shift register <b>56</b> corresponds to the resolution of a previously executed conditional branch instruction. More particularly, each bit of the branch history value indicates whether a previously executed branch instruction was resolved as taken or not taken. The resolutions of previously executed branch instructions can come from functional units <b>32</b>A-<b>32</b>D (not shown in FIG. <b>2</b>). The branch history value stored within branch shift registers <b>56</b> is updated upon prediction of each branch instruction. The update occurs by shifting into the least significant bit of the stored history value, the appropriate value (i.e., logical 1 or logical 0) corresponding to the taken or not taken prediction (e.g., logical 1 for taken and logical 0 for not taken), while the most significant bit of the branch history value is shifted out and discarded. However, given that branch mispredictions occur, the contents of the branch shift register are stored in a check point register (not shown in FIG. 2) prior to update on prediction and later reloaded into branch shift register <b>56</b>, and correctly changed, if the initial prediction is deemed incorrect upon resolution.</p><p>Branch history table index generator is configured to generate, in one clock cycle, a pair of branch history table indexes based on the combination of the contents of the branch shift register <b>56</b> and the branch fetch addresses provided by branch scanner <b>58</b>. The generated branch history table indexes are provided to branch history table circuit <b>52</b>.</p><p>Branch history table circuit <b>52</b> is configured to receive the pair of branch history table indexes from branch history table index generator <b>54</b>, and in response thereto, outputs a pair of counter values to prefetch control unit <b>50</b>. Branch history table circuit <b>52</b> includes a branch history table, which stores a plurality of bimodal counters. These bimodal counters are typically 2-bit values, the most significant bit of which is used to predict a corresponding branch instruction. More particularly, the more significant bit (e.g., the counter value) of each bimodal counter indicates the taken/not taken prediction (e.g., taken or set, not taken or clear). This table is updated after actual resolution of branch instructions. Each time a branch instruction is actually taken, a corresponding bimodal counter is incremented, and each time a branch instruction is actually resolved as not taken, a corresponding counter is decremented. Each bimodal counter is saturating. In other words, each bimodal counter saturates at a minimum and maximum value (i.e., subsequent decrements of the minimum value and increments of the maximum value cause no change in the counter). The counter values (taken/not taken) are provided to prefetch control unit <b>50</b>. Prefetch control unit <b>50</b> uses counter values to determine to determine the L1 prefetch address or the L0 prefetch address for use by the L1 I-cache <b>14</b> and L0 I-cache <b>16</b>, respectively.</p><p>As noted above, branch scanner <b>58</b> identifies two branch instructions within instruction run storage <b>60</b>. The mechanism shown in FIG. 2 is configured to select and provide two counter values to prefetch control unit <b>50</b>, in one clock cycle, corresponding to the two branch instructions detected by branch scanner <b>58</b>. The counter values are in essence the predictions for the branch instructions. The counter value selection corresponding to the detected second branch instruction is dependent upon the counter value of the first branch instruction. The branch history table circuit <b>52</b> selects the second counter value by reading both of the counter values which might be selected (i.e., the counter values that would be selected if the first branch instruction is predicted not taken) and then chooses one of the two selected counter values based on the counter value selected for the first branch instruction. In this fashion, the second counter value is selected without waiting for the branch shift register to be updated with the first counter value or the prediction of the first instruction.</p><p>FIG. 3 shows one embodiment of the branch history table index generator <b>54</b> and branch history table circuit <b>52</b> of FIG. <b>2</b>. Branch history table index generator <b>54</b> includes a pair of XOR circuits <b>70</b> and <b>72</b> coupled to branch shift register <b>56</b> and coupled to receive the branch fetch addresses (branch fetch address <b>1</b> and branch fetch address <b>2</b>) provided by branch scanner <b>58</b>. The first and second branch fetch addresses correspond to the first and second branch instructions detected in instruction run storage <b>60</b> by branch scanner <b>58</b>. XOR circuit <b>70</b> is configured to generate the first branch history table index corresponding to the detected first branch instruction. The first branch history table index is generated as a function of the first branch fetch address and the M-bit branch history value stored in branch register <b>56</b>. In one embodiment, the first branch history table index is generated by XORing the M-bit branch history value with a portion of the first branch fetch address corresponding to the first branch instruction. More particularly in this embodiment, the most significant bit of the branch history value is XORed with the most significant bit within the portion of the first branch fetch address, and so forth through the least significant bit of the branch history value being XORed with the least significant bit within the portion of the first branch fetch address. XOR circuit <b>72</b> operates substantially similar to XOR circuit <b>70</b> in generating the second branch history table index. However, where XOR circuit <b>70</b> uses the full M-bits of the branch history value stored in branch shift register <b>56</b> to generate the first branch history table index, XOR circuit <b>72</b> uses the least significant (M-1) bits of the branch history value. The least significant bits of the branch history value will be referred to as the second or speculative branch history value. XOR circuit <b>72</b> then operates to XOR a portion of the second branch fetch address corresponding to the second detected branch instruction with the speculative M-bit branch history value to generate the second branch history table index. More particularly, the most significant bit of the speculative branch history value is XORed with the most significant bit within the portion of the second branch fetch address, and so forth through the least significant bit of the speculative branch history being XORed with the least significant bit within the portion of the second branch fetch address. Again, it is noted that the first and second branch history table indexes are generated within one clock cycle which is consistent with the general goal of the present invention to access the branch history table twice within one clock cycle.</p><p>Branch history table circuit <b>52</b> in FIG. 3 comprises a dual port branch history table storage array <b>74</b> for storing the plurality of bimodal counters described above. The dual port storage array is configured to allow simultaneous read accesses. The dual port storage array <b>74</b> includes a pair or row/column (RC) decoders <b>76</b> and <b>80</b>, and sense amplifiers <b>82</b>-<b>86</b>. The dual port storage array is configured to simultaneously output (1) the first counter value in response to RC decoder <b>76</b> receiving the first branch history table index and (2) a pair of counter values, one of which is subsequently chosen to be the second counter value, in response to RC decoder <b>80</b> receiving the second branch history table index. Branch history table circuit <b>52</b> also includes a selection circuit <b>90</b>, which, in one embodiment, comprises a multiplexer.</p><p>RC decode <b>76</b> asserts the appropriate column and row lines within the storage array so that the first counter value from one storage element corresponding to the first branch history table index, can be read by sense amplifier <b>82</b> (FIG. 3 shows only column select and bit lines). In contrast RC decode <b>80</b> asserts the appropriate row line and pair of column select lines so that a pair of counter values from adjacent storage elements in one row can be sensed and outputted to multiplexer <b>90</b> by sense amplifiers <b>84</b> and <b>86</b>, wherein the adjacent storage elements correspond to the second branch history table index. The second counter value is chosen from pair of counters by multiplexer <b>90</b> based upon the first counter value corresponding to the first branch instruction. The first counter value is not known in advance of selecting the pair of counter values. However, it is either taken or not taken. If, for example, the first branch instruction is predicted as taken (i.e., the first counter value is a logical 1), then the second counter value will come from one of the pair of adjacent storage elements activated by RC decoder <b>80</b>. If the first branch instruction is predicted as not taken (i.e., the first counter value is a logical 0), then the second counter value will come from the other of the pair of adjacent storage elements activated by RC decoder <b>80</b>.</p><p>The outputs of sense amps <b>84</b> and <b>86</b> are provided to data inputs of multiplexer <b>90</b> while the output of sense amp <b>82</b> is provided to selection input of multiplexer <b>90</b>. The first counter value outputted by sense amp <b>82</b> is used to select between the two speculative counter values provided to the inputs of multiplexer <b>90</b>. Accordingly, if the first counter value is a logical one, multiplexer <b>90</b> selects for output the counter value provided by sense amplifier <b>84</b>. In contrast, if the first counter value is a logical zero, multiplexer <b>90</b> selects for output therefrom the counter value provided by sense amp <b>86</b>. Accordingly, it can be seen that multiplexer <b>90</b> selects the second counter based upon the value of the first counter.</p><p>FIG. 4 shows an alternative embodiment of the branch history table circuit <b>52</b> shown in FIG. <b>2</b>. More particularly, FIG. 4 shows a single ported branch history table storage array <b>92</b> coupled to selection circuit <b>94</b>. Single ported storage array <b>92</b> in FIG. 4 includes a decoder with selected delay circuit <b>96</b> coupled to receive the first and second branch history table indexes. Selected delay circuit <b>96</b> ignores the least significant bit of the first branch history table index. In response to receiving either the first or second branch history table indexes, decode with selected delay circuit <b>96</b> asserts the appropriate row select line and pairs of column select lines within the storage array to enable sense amplifiers <b>98</b> and <b>100</b> to sense a pair of counter values stored in adjacent storage elements (FIG. 4 shows only column select and bit lines).</p><p>Selection circuit <b>94</b> comprises, in one embodiment, multiplexer <b>102</b> having a pair of data inputs configured to receive the outputs of sense amplifiers <b>96</b> and <b>100</b>, an output coupled to storage unit <b>104</b>, and a selection input coupled to mux control <b>106</b>. Mux control unit <b>106</b> is configured to receive and pass either the least significant bit of the first branch history table index or the contents of storage unit <b>104</b>.</p><p>Decode with selected delay circuit <b>96</b> operates to double pump the storage array to enable sequential read access thereof within a single clock cycle. In operation, decode with select delay circuit <b>96</b> simultaneously receives the first and second branch history table indexes. Decode with selective delay circuit <b>96</b> immediately asserts the appropriate row select and pair of column select lines within the storage array corresponding to the (M-1) most significant bits of the first branch history table index. Sense amplifiers <b>96</b> and <b>100</b> sense the values stored within the adjacent storage elements of the asserted row and the asserted pair of columns. The output of the sense amplifiers <b>96</b> and <b>100</b> are provided to multiplexer <b>102</b>. Mux control unit <b>106</b> simultaneously receives the least significant bit of the first branch history table index. Mux control <b>106</b> passes the least significant bit to the selection input of multiplexer <b>102</b>. In response, multiplexer <b>102</b> selects one of the two counter values provided by sense amplifier <b>96</b> or sense amplifier <b>100</b> based on the value of the least significant bit of the first branch history table index. The selected counter value is stored within storage unit <b>104</b> as the first counter value. After a slight delay, decode with selected delay circuit <b>96</b> asserts the appropriate row select line and pair of column select lines associated with the second branch history table index. Sense amplifiers <b>96</b> and <b>100</b>, in turn, sense a pair of counter values stored in adjacent storage elements from the selected row and pair of columns. The pair of counter values are provided to multiplexer <b>102</b>. Mux control <b>106</b> then passes the first counter value stored within storage unit <b>104</b> to selection input of multiplexer <b>102</b>. In response, multiplexer <b>102</b> selects one of the pair of counter values provided by sense <b>20</b> amplifier <b>96</b> or sense amplifier <b>100</b> for output as the second counter value.</p><p>The embodiments shown within FIGS. 3 and 4 illustrate accessing branch history table circuit <b>52</b> with branch history table indexes generated as a function of the branch history value and branch fetch addresses. However, it is to be understood that the present <b>25</b> application has application to accessing branch history table circuit <b>52</b> with branch history table indexes which are generated solely as a function of the branch history value.</p><p>Turning now to FIG. 5, a block diagram of one embodiment of a computer system <b>200</b> including processor <b>10</b> coupled to a variety of system components through a bus bridge <b>202</b> is shown. Other embodiments are possible and contemplated. In the depicted system, a main memory <b>204</b> is coupled to bus bridge <b>202</b> through a memory bus <b>206</b>, and a graphics controller <b>208</b> is coupled to bus bridge <b>202</b> through an AGP bus <b>210</b>. Finally, a plurality of PCI devices <b>212</b>A-<b>212</b>B are coupled to bus bridge <b>202</b> through a PCI bus <b>214</b>. A secondary bus bridge <b>216</b> may further be provided to accommodate an electrical interface to one or more EISA or ISA devices <b>218</b> through an EISA/ISA bus <b>220</b>. Processor is coupled to bus bridge <b>202</b> through bus interface <b>46</b>.</p><p>Bus bridge <b>202</b> provides an interface between processor <b>10</b>, main memory <b>204</b>, graphics controller <b>208</b>, and devices attached to PCI bus <b>214</b>. When an operation is received from one of the devices connected to bus bridge <b>202</b>, bus bridge <b>202</b> identifies the target of the operation (e.g. a particular device or, in the case of PCI bus <b>214</b>, that the target is on PCI bus <b>214</b>). Bus bridge <b>202</b> routes the operation to the targeted device. Bus bridge <b>202</b> generally translates an operation from the protocol used by the source device or bus to the protocol used by the target device or bus.</p><p>In addition to providing an interface to an ISA/EISA bus for PCI bus <b>214</b>, secondary bus bridge <b>216</b> may further incorporate additional functionality, as desired. For example, in one embodiment, secondary bus bridge <b>216</b> includes a master PCI arbiter (not shown) for arbitrating ownership of PCI bus <b>214</b>. An input/output controller (not shown), either external from or integrated with secondary bus bridge <b>216</b>, may also be included within computer system <b>200</b> to provide operational support for a keyboard and mouse <b>222</b> and for various serial and parallel ports, as desired. An external cache unit (not shown) may further be coupled to bus interface <b>46</b> between processor <b>10</b> and bus bridge <b>202</b> in other embodiments. Alternatively, the external cache may be coupled to bus bridge <b>202</b> and cache control logic for the external cache may be integrated into bus bridge <b>202</b>.</p><p>Main memory <b>204</b> is a memory in which application programs are stored and from which processor <b>10</b> primarily executes. A suitable main memory <b>204</b> comprises DRAM (Dynamic Random Access Memory), and preferably a plurality of banks of SDRAM (Synchronous DRAM).</p><p>PCI devices <b>212</b>A-<b>212</b>B are illustrative of a variety of peripheral devices such as, for example, network interface cards, video accelerators, audio cards, hard or floppy disk drives or drive controllers, SCSI (Small Computer Systems Interface) adapters and telephony cards. Similarly, ISA device <b>218</b> is illustrative of various types of peripheral devices, such as a modem, a sound card, and a variety of data acquisition cards such as GPIB or field bus interface cards.</p><p>Graphics controller <b>208</b> is provided to control the rendering of text and images on a display <b>226</b>. Graphics controller <b>208</b> may embody a typical graphics accelerator generally known in the art to render three-dimensional data structures which can be effectively shifted into and from main memory <b>204</b>. Graphics controller <b>208</b> may therefore be a master of AGP bus <b>210</b> in that it can request and receive access to a target interface within bus bridge <b>202</b> to thereby obtain access to main memory <b>204</b>. A dedicated graphics bus accommodates rapid retrieval of data from main memory <b>204</b>. For certain operations, graphics controller <b>208</b> may further be configured to generate PCI protocol transactions on AGP bus <b>210</b>. The AGP interface of bus bridge <b>202</b> may thus include functionality to support both AGP protocol transactions as well as PCI protocol target and initiator transactions. Display <b>226</b> is any electronic display upon which an image or text can be presented. A suitable display <b>226</b> includes a cathode ray tube (\u201cCRT\u201d), a liquid crystal display (\u201cLCD\u201d), etc.</p><p>It is noted that, while the AGP, PCI, and ISA or EISA buses have been used as examples in the above description, any bus architectures may be substituted as desired. It is further noted that computer system <b>200</b> may be a multiprocessing computer system including additional processors (e.g. processor <b>10</b><i>a </i>shown as an optional component of computer system <b>200</b>). Processor <b>10</b><i>a </i>may be similar to processor <b>10</b>. More particularly, processor <b>10</b><i>a </i>may be an identical copy of processor <b>10</b>. Processor <b>10</b><i>a </i>may share bus interface <b>46</b> with processor <b>10</b> (as shown in FIG. 13) or may be connected to bus bridge <b>202</b> via an independent bus.</p><p>Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "David B.", "last_name": "Witt", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "ADVANCED MICRO DEVICES, INC."}, {"first_name": "", "last_name": "ADVANCED MICRO DEVICES, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F   9/40"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMEP"}, {"label": "G06F   9/30        20060101A I20051008RMEP"}, {"label": "G06F   9/38        20060101A I20051008RMEP"}, {"label": "G06F   9/32        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "712240"}, {"primary": false, "label": "711E12057"}, {"primary": false, "label": "712E09077"}, {"primary": false, "label": "712E0905"}, {"primary": false, "label": "712E09056"}, {"primary": false, "label": "712E09047"}, {"primary": false, "label": "712E0902"}, {"primary": false, "label": "712E0908"}, {"primary": false, "label": "711E12043"}], "ecla_classes": [{"label": "G06F   9/30A3C"}, {"label": "G06F   9/30A1C"}, {"label": "G06F   9/38E1"}, {"label": "G06F   9/38B2"}, {"label": "G06F   9/30A3S"}, {"label": "G06F   9/38D2"}, {"label": "G06F  12/08B8"}, {"label": "G06F  12/08B22L"}], "cpc_classes": [{"label": "G06F   9/3838"}, {"label": "G06F   9/383"}, {"label": "G06F   9/3804"}, {"label": "G06F  12/0862"}, {"label": "G06F   9/30069"}, {"label": "G06F   9/3804"}, {"label": "G06F   9/30021"}, {"label": "G06F   9/3838"}, {"label": "G06F   9/30069"}, {"label": "G06F  12/0862"}, {"label": "G06F   9/383"}, {"label": "G06F   9/30058"}, {"label": "G06F  12/0897"}, {"label": "G06F   9/30058"}, {"label": "G06F  12/0897"}, {"label": "G06F   9/30021"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1997-11-17", "application_date": "1998-09-24", "family_members": [{"ucid": "US-6347369-B1", "titles": [{"lang": "EN", "text": "Method and circuit for single cycle multiple branch history table access"}]}]}