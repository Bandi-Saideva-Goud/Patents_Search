{"patent_number": "US-6175908-B1", "publication_id": 72535280, "family_id": 22095023, "publication_date": "2001-01-16", "titles": [{"lang": "EN", "text": "Variable byte-length instructions using state of function bit of second byte of plurality of instructions bytes as indicative of whether first byte is a prefix byte"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11120699\" source=\"national office\"><p>A superscalar microprocesor is provided that includes a predecode unit adapted for predecoding variable byte-length instructions. The predecode unit predecodes the instructions prior to their storage within an instruction cache. In one system, a predecode unit is configured to generate a plurality of predecode bits including a start bit, an end bit, and a functional bit for each instruction byte. The plurality of predecode bits associated with each instruction byte are collectively referred to as a predecode tag. An instruction alignment unit then uses the predecode tags to dispatch the variable byte-length instructions to a plurality of decode units within the superscalar microprocessor. The predecode unit is configured such that the meaning of the functional bit of a particular predecode tag is dependent upon the status of the start bit. The predecode unit is further configured to generate a functional bit associated with each byte of an instruction other than the starting byte, which indicate whether the associated byte is a prefix or opcode. The encoding of the predecode tags is such that a relatively large amount of predecode information may be conveyed with a relatively small number of predecode bits.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72498523\"><p>A superscalar microprocesor is provided that includes a predecode unit adapted for predecoding variable byte-length instructions. The predecode unit predecodes the instructions prior to their storage within an instruction cache. In one system, a predecode unit is configured to generate a plurality of predecode bits including a start bit, an end bit, and a functional bit for each instruction byte. The plurality of predecode bits associated with each instruction byte are collectively referred to as a predecode tag. An instruction alignment unit then uses the predecode tags to dispatch the variable byte-length instructions to a plurality of decode units within the superscalar microprocessor. The predecode unit is configured such that the meaning of the functional bit of a particular predecode tag is dependent upon the status of the start bit. The predecode unit is further configured to generate a functional bit associated with each byte of an instruction other than the starting byte, which indicate whether the associated byte is a prefix or opcode. The encoding of the predecode tags is such that a relatively large amount of predecode information may be conveyed with a relatively small number of predecode bits.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00001\" num=\"1\"><claim-text>1. A microprocessor comprising:</claim-text><claim-text>an instruction cache for storing a plurality of variable byte-length instructions; </claim-text><claim-text>a predecode unit coupled to said instruction cache and configured to generate at least one predecode tag associated with at least one byte of an instruction, wherein said at least one predecode tag includes a start bit having a value indicative of whether said at least one byte is a starting byte of said instruction, an end bit having a value indicative of whether said at least one byte is an ending byte of said instruction, and a functional bit that conveys a meaning dependent upon said value of said start bit, wherein a state of said functional bit of a second byte of each of said plurality of variable byte-length instructions and a state of said end bit of a first byte of each of said plurality of variable byte-length instructions is indicative of whether or not said first byte of each of said variable byte-length instructions is a prefix byte; </claim-text><claim-text>a plurality of decode units for decoding designated instructions which correspond to said plurality of variable byte-length instructions; and </claim-text><claim-text>an instruction alignment unit coupled between said instruction cache and said plurality of decode units for providing decodable instructions to said plurality of decode units. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00002\" num=\"2\"><claim-text>2. The microprocessor as recited in claim <b>1</b> wherein said instruction alignment unit is configured to provide said instruction to one of said plurality of decode units.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00003\" num=\"3\"><claim-text>3. The microprocessor as recited in claim <b>1</b> wherein each of said plurality of said decode units is configured to decode a predetermined subset of an instruction set including said plurality of variable byte-length instructions.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00004\" num=\"4\"><claim-text>4. The microprocessor as recited in claim <b>1</b> wherein at least one decode unit is configured to identify prefix bytes as a function of the functional and end bits.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00005\" num=\"5\"><claim-text>5. The microprocessor as recited in claim <b>1</b> wherein the at least one decode unit includes a circuit which logically ANDs an inverted end bit associated with one byte of the instruction with the functional bit of another byte of the instruction.</claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00006\" num=\"6\"><claim-text>6. The microprocessor of claim <b>1</b> further comprising a microcode unit, wherein the microcode unit is configured to translate second instructions into first instructions, wherein the decode units are configured to decode first instructions.</claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00007\" num=\"7\"><claim-text>7. The microprocessor as recited in claim <b>6</b> wherein at least one decode unit is configured to identify prefix bytes as a function of the functional and end bits.</claim-text></claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00008\" num=\"8\"><claim-text>8. The microprocessor as recited in claim <b>1</b> wherein said instruction alignment unit is configured to provide said predecode tag to at least one of said plurality of decode units.</claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00009\" num=\"9\"><claim-text>9. The microprocessor as recited in claim <b>8</b> wherein at least one of the decode units is configured to detect said predecode tag to determine a boundary of said instruction.</claim-text></claim>"}, {"num": 10, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00010\" num=\"10\"><claim-text>10. The microprocessor as recited in claim <b>1</b> further comprising a plurality of functional units configured to receive output signals from said plurality of decode units.</claim-text></claim>"}, {"num": 11, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00011\" num=\"11\"><claim-text>11. A microprocessor comprising:</claim-text><claim-text>an instruction cache for storing a plurality of instruction bytes; and </claim-text><claim-text>a predecode unit coupled to said instruction cache, wherein said predecode unit is configured to predecode said plurality of instruction bytes prior to their storage within said instruction cache, wherein said predecode unit is configured to generate a functional bit and an end bit for each of said plurality of instruction bytes, wherein a state of said functional bit of a second byte of said plurality of instruction bytes and a state of said end bit of a first byte of said plurality of instruction bytes is indicative of whether or not said first byte of said plurality of instruction bytes is a prefix byte. </claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00012\" num=\"12\"><claim-text>12. The microprocessor as recited in claim <b>11</b>, wherein said predecode unit is further configured to generate a plurality of predecode bits for each of said plurality of instruction bytes, wherein said plurality of predecode bits includes said functional bit, a start bit, and said end bit.</claim-text></claim>"}, {"num": 13, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00013\" num=\"13\"><claim-text>13. The microprocessor as recited in claim <b>11</b>, wherein said instruction cache is further configured to store said predecode bits.</claim-text></claim>"}, {"num": 14, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00014\" num=\"14\"><claim-text>14. The microprocessor as recited in claim <b>11</b> further comprising:</claim-text><claim-text>a plurality of decode units coupled to receive decodable instructions corresponding to variable byte length instructions, wherein said variable byte length instructions are formed form said plurality of instruction bytes, wherein said plurality of decode units are configured to decode said decodable instructions. </claim-text></claim>"}, {"num": 15, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00015\" num=\"15\"><claim-text>15. The microprocessor as recited in claim <b>14</b>, wherein said plurality of decode units logically AND said functional bit associated with said second byte of said plurality of instruction bytes with a logical inverse of said end bit of said first byte of said plurality of instruction bytes to identify whether or not said first byte of said plurality of instruction bytes is said prefix byte.</claim-text></claim>"}, {"num": 16, "parent": 15, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00016\" num=\"16\"><claim-text>16. The microprocessor as recited in claim <b>15</b>, wherein if the result of said logical ANDing operation is a logical one, then said first byte of said plurality of instruction bytes is said prefix byte, wherein if the result of said logical ANDing operation is a logical zero, then said first byte of said plurality of instruction bytes is not said prefix byte.</claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00017\" num=\"17\"><claim-text>17. The microprocessor as recited in claim <b>16</b> further comprises:</claim-text><claim-text>an instruction alignment unit coupled to said plurality of decode units, wherein said instruction alignment unit is further coupled to said instruction cache, wherein said instruction alignment unit is configured to provide said decodable instructions from said instruction cache to said plurality of decode units. </claim-text></claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00018\" num=\"18\"><claim-text>18. The microprocessor as recited in claim <b>17</b>, wherein said plurality of decode units is configured to determine a location of said prefix byte and an opcode byte without having to first determine whether said variable byte length instruction is a fast path instruction or a microcode instruction.</claim-text></claim>"}, {"num": 19, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00019\" num=\"19\"><claim-text>19. The microprocessor as recited in claim <b>18</b> further comprises:</claim-text><claim-text>a microcode unit coupled to said instruction cache, wherein said microcode unit is configured to implement selected variably byte length instructions in microcode, wherein said plurality of decode units are configured to not decode in microcode. </claim-text></claim>"}, {"num": 20, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00020\" num=\"20\"><claim-text>20. A microprocessor comprising:</claim-text><claim-text>an instruction cache for storing a plurality of instruction bytes; and </claim-text><claim-text>a predecode unit coupled to said instruction cache, wherein said predecode unit is configured to predecode said plurality of instruction bytes prior to their storage within said instruction cache, wherein said predecode unit is further configured to generate a functional bit for each of said plurality of instruction bytes, wherein a state of said functional bit of a second byte of said plurality of instruction bytes is indicative of whether or not a first byte of said plurality of instruction bytes is a prefix byte. </claim-text></claim>"}, {"num": 21, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00021\" num=\"21\"><claim-text>21. The microprocessor as recited in claim <b>20</b>, wherein said state of said functional bit of said second byte of said plurality of instruction bytes and a state of an end bit of said first byte of said plurality of instruction bytes is indicative of whether or not said first byte of said plurality of instruction bytes is said prefix byte.</claim-text></claim>"}, {"num": 22, "parent": 21, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00022\" num=\"22\"><claim-text>22. The micro processor as recited in claim <b>21</b>, wherein said predecode unit is configured to generate a plurality of predecode bits for each of said plurality of instruction bytes, wherein said plurality of predecode bits includes said functional bit, a start bit, and said end bit.</claim-text></claim>"}, {"num": 23, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00023\" num=\"23\"><claim-text>23. The microprocessor as recited in claim <b>20</b>, wherein said instruction cache is further configured to store said predecode bits.</claim-text></claim>"}, {"num": 24, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00024\" num=\"24\"><claim-text>24. The microprocessor as recited in claim <b>20</b> further comprising:</claim-text><claim-text>a plurality of decode units coupled to receive decodable instructions corresponding to variable byte length instructions, wherein said variable byte length instructions are formed form said plurality of instruction bytes, wherein said plurality of decode units are configured to decode said decodable instructions. </claim-text></claim>"}, {"num": 25, "parent": 24, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00025\" num=\"25\"><claim-text>25. The microprocessor as recited in claim <b>24</b>, wherein said plurality of decode units logically AND said functional bit associated with said second byte of said plurality of instruction bytes with a logical inverse of an end bit of said first byte of said plurality of instruction bytes to identify whether or not said first byte of said plurality of instruction bytes is said prefix byte.</claim-text></claim>"}, {"num": 26, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00026\" num=\"26\"><claim-text>26. The microprocessor as recited in claim <b>25</b>, wherein if the result of said logical ANDing operation is a logical one, then said first byte of said plurality of instruction bytes is said prefix byte, wherein if the result of said logical ANDing operation is a logical zero, then said first byte of said plurality of instruction bytes is not said prefix byte.</claim-text></claim>"}, {"num": 27, "parent": 26, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00027\" num=\"27\"><claim-text>27. The microprocessor as recited in claim <b>26</b> further comprises:</claim-text><claim-text>an instruction alignment unit coupled to said plurality of decode units, wherein said instruction alignment unit is further coupled to said instruction cache, wherein said instruction alignment unit is configured to provide said decodable instructions from said instruction cache to said plurality of decode units. </claim-text></claim>"}, {"num": 28, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00028\" num=\"28\"><claim-text>28. The microprocessor as recited in claim <b>27</b>, wherein said plurality of decode units is configured to determine a location of said prefix byte without having to first determine whether said variable byte length instruction is said fast path instruction or said microcode instruction.</claim-text></claim>"}, {"num": 29, "parent": 28, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00029\" num=\"29\"><claim-text>29. The microprocessor as recited in claim <b>28</b> further comprises:</claim-text><claim-text>a microcode unit coupled to said instruction cache, wherein said microcode unit is configured to implement selected variable byte length instructions in microcode, wherein said plurality of decode units are configured to not decode in microcode. </claim-text></claim>"}, {"num": 30, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00030\" num=\"30\"><claim-text>30. A method for predecoding variable byte length instructions in a microprocessor comprising:</claim-text><claim-text>receiving a plurality of instruction bytes forming variable byte length instructions; </claim-text><claim-text>generating a functional bit corresponding to each of said plurality of instruction bytes, wherein a state of said functional bit of a second byte of said plurality of instruction bytes is indicative of whether or not a first byte of said plurality of instruction bytes is a prefix byte. </claim-text></claim>"}, {"num": 31, "parent": 30, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00031\" num=\"31\"><claim-text>31. The method for predecoding variable byte length instructions as recited in claim <b>30</b> further comprising:</claim-text><claim-text>generating an end bit corresponding to each of said plurality of instruction bytes, wherein said state of said functional bit of said second byte of said plurality of instruction bytes and a state of said end bit of said first byte of said plurality of instruction bytes is indicative of whether or not said first byte of said plurality of instruction bytes is said prefix byte. </claim-text></claim>"}, {"num": 32, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00032\" num=\"32\"><claim-text>32. The method for predecoding variable byte length instructions as recited in claim <b>31</b> further comprising:</claim-text><claim-text>generating a plurality of predecode bits for each of said plurality of instruction bytes, wherein said plurality of predecode bits includes said functional bit, a start bit, and said end bit. </claim-text></claim>"}, {"num": 33, "parent": 32, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00033\" num=\"33\"><claim-text>33. The method for predecoding variable byte length instructions as a recited in claim <b>32</b>, wherein said start bit is set if a corresponding one of said plurality of instruction bytes is a first byte of one of said variable byte length instructions, wherein said end bit is set if a corresponding one of said plurality of instruction bytes is a last byte of one of said variable byte length instructions.</claim-text></claim>"}, {"num": 34, "parent": 33, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00034\" num=\"34\"><claim-text>34. The method for predecoding variable byte length instructions as recited in claim <b>33</b> further comprising:</claim-text><claim-text>determining the exact location of said prefix byte and an opcode byte without having to first determine whether said variable byte length instruction is a fast path instruction or a microcode instruction. </claim-text></claim>"}, {"num": 35, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00035\" num=\"35\"><claim-text>35. A computer system comprising:</claim-text><claim-text>a microprocessor comprising: </claim-text><claim-text>an instruction cache for storing a plurality of instruction bytes; </claim-text><claim-text>a predecode unit coupled to said instruction cache, wherein said predecode unit is configured to predecode said plurality of instruction bytes prior to their storage within said instruction cache, wherein said predecode unit is further configured to generate a functional bit for each of said plurality of instruction bytes, wherein a state of said functional bit of a second byte of said plurality of instruction bytes is indicative of whether or not a first byte of said plurality of instruction bytes is a prefix byte; and </claim-text><claim-text>an input/output device configured to communicate between said computer system and another computer system to which said input/output device is capable of being coupled. </claim-text></claim>"}, {"num": 36, "parent": 35, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00036\" num=\"36\"><claim-text>36. The computer system as recited in claim <b>35</b>, wherein said input/output device is a modem.</claim-text></claim>"}, {"num": 37, "parent": 35, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00037\" num=\"37\"><claim-text>37. The computer system as recited in claim <b>35</b>, wherein said input/output device is a peripheral device.</claim-text></claim>"}, {"num": 38, "parent": 35, "type": "dependent", "paragraph_markup": "<claim id=\"US-6175908-B1-CLM-00038\" num=\"38\"><claim-text>38. The computer system as recited in claim <b>35</b> further comprising:</claim-text><claim-text>an audio input/output device.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54481544\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. Field of the Invention</p><p>This invention relates to superscalar microprocessors and, more particularly, to the predecoding of variable byte-length computer instructions within high performance and high frequency superscalar microprocessors.</p><p>2. Description of the Relevant Art</p><p>Superscalar microprocessors are capable of attaining performance characteristics which surpass those of conventional scalar processors by performing concurrent execution of multiple instructions. Due to the widespread acceptance of the x86 family of microprocessors, efforts have been undertaken by microprocessor manufacturers to develop superscalar microprocessors which execute x86 instructions. Such superscalar microprocessors achieve relatively high performance characteristics while advantageously maintaining backwards compatibility with a vast amount of existing software developed for previous microprocessor generations such as the 8086, 80286, 80386, and 80486.</p><p>The x86 instruction set is relatively complex and is characterized by a plurality of variable byte-length instructions. An x86 instruction consists of from one to five optional prefix bytes, followed by an operation code (opcode) field, an optional addressing mode (Mod R/M) byte, an optional scale-index-base (SIB) byte, an optional displacement field, and an optional immediate data field.</p><p>The opcode field defines the basic operation for a particular instruction. The default operation of a particular opcode may be modified by one or more prefix bytes. For example, a prefix byte may be used to change the address or operand size for an instruction, to override the default segment used in memory addressing, or to instruct the processor to repeat a string operation a number of times. The opcode field follows the prefix bytes, if any, and may be one or two bytes in length. It is understood that when the opcode field is two bytes, the first byte thereof is considered a prefix. The addressing mode (MODRM) byte specifies the registers used as well as memory addressing modes. The scale-index-base (SIB) byte is used only in 32-bit base-relative addressing using scale and index factors. A base field of the SIB byte specifies which register contains the base value for the address calculation, and an index field specifies which register contains the index value. A scale field specifies the power of two by which the index value will be multiplied before being added, along with any displacement, to the base value. The next instruction field is the optional displacement field, which may be from one to four bytes in length. The displacement field contains a constant used in address calculations. The optional immediate field, which may also be from one to four bytes in length, contains a constant used as an instruction operand. The 80286 sets a maximum length for an instruction at 10 bytes, while the 80386 and 80486 both allow instruction lengths of up to 15 bytes.</p><p>The complexity of the x86 instruction set poses difficulties in implementing high performance x86 compatible superscalar microprocessors. One difficulty arises from the fact that instructions must be aligned with respect to the parallel-coupled instruction decoders of such processors before proper decode can be effectuated. In contrast to most RISC instruction formats, since the x86 instruction set consists of variable byte-length instructions, the start bytes of successive instructions within a line are not necessarily equally spaced, and the number of instructions per line is not fixed. As a result, employment of simple, fixed-length shifting logic to align the instructions with the decoders cannot be achieved with x86 instructions.</p><p>Superscalar microprocessors have been proposed (but not published or otherwise made part of the prior art) that employ instruction predecoding techniques to help solve the problem of quickly aligning, decoding and executing a plurality of variable byte-length instructions in parallel. In one such superscalar microprocessor, when instructions are written within the instruction cache from an external main memory, a predecoder appends three predecode bits (e.g., a start bit, a functional bit and an end bit, referred to collectively as a predecode tag) to each byte. The start bit is set to one for the start byte of every instruction, and is zero otherwise. The end bit is set to one for the end byte of every instruction, and is zero otherwise. The functional bit is the predecode bit with a unique purpose. The functional bit associated with the end byte is set to zero for fast path instructions, and set to one for MROM instructions. The remaining functional bits from the start bit to the end bit (not including the end bit) are set according to whether the bytes are prefixes or not. In particular, all prefix bytes have their associated functional bit set to one and all non-prefix bytes have their functional bit set to zero for both fast path and MROM instructions.</p><p>As noted, the decode stage processes the prefix bytes to properly decode instructions. Predecoding instructions using the above identified proposed predecode tag encoding is advantageous in that the decode stage need not perform extra calculations to determine the location of the prefix bytes within an instruction since all the prefix bytes are identified with a set functional bit. Additionally, because the opcode byte follows the prefix bytes, if any, the decode stage need not perform extra calculations to identify the location of the opcode since the opcode is identified as the first byte with a cleared functional bit. Avoiding the extra step of identifying prefixes in an instruction reduces circuitry and delay within the decode stages. However, the above identified proposed predecode tag encoding presents a problem. Namely, it is impossible to determine whether an instruction is fast path or MROM until the end byte is scanned. This presents a problem for split line instructions in which the start byte of a particular is located in a first set of sixteen bytes while the end byte of the instruction is located in a subsequent set of sixteen bytes.</p><h4>SUMMARY OF THE INVENTION</h4><p>The problems outlined above are in large part solved by a superscalar microprocesor employing a predecode unit adapted for predecoding variable byte-length instructions in accordance with the present invention. In one embodiment, a predecode unit is provided which is capable of predecoding variable byte-length instructions prior to their storage within an instruction cache. The predecode unit is configured to generate a plurality of predecode bits for each instruction byte. The plurality of predecode bits associated with each instruction byte are collectively referred to as a predecode tag. An instruction alignment unit then uses the predecode tags to dispatch the variable byte-length instructions to a plurality of decode units within the superscalar microprocessor. Additionally, one or more instruction decode stages within the superscalar microprocessor use the predecode tags in decoding the instructions prior to their execution.</p><p>In one implementation, the predecode unit generates three predecode bits associated with each byte of instruction code: a \u201cstart\u201d bit, an \u201cend\u201d bit, and a \u201cfunctional\u201d bit. The start bit is set if the associated byte is the first byte of the instruction. The start bit is cleared otherwise. Similarly, the end bit is set if the associated byte is the last byte of the instruction. The end bit is cleared otherwise. The encoding of the functional bit is dependent on the start byte of the instruction. If the instruction is a fast path instruction, the functional bit associated with the start byte is cleared. If the instruction is MROM, the functional bit associated with the start byte is set. For bytes of an instruction other than the start byte, the encoding of the functional bit is dependent on whether the associated byte is a prefix or opcode. Namely, the functional bit is set when the associated byte is a prefix or opcode, and the functional bit is cleared when the associated byte is not a prefix or opcode, thereby identifying the position of the prefix and opcode bytes. Since only functional bits associated with the prefix and opcode bytes are set, identifying the opcode byte position is made easier in that it is the byte associated with the last set functional bit.</p><p>The plurality of decode units to which the variable byte length instructions are aligned utilize the predecode tags to attain relatively fast decoding of the instructions. More particularly, with the information conveyed by the functional bits, the decode units know the exact location of the opcode and/or prefix bytes without having to first determine whether the instruction containing the opcode and/or prefix bytes is fast path or MROM. Additionally, since the prefix and/or opcode bytes (except for the prefix or opcode byte associated with the start byte) are uniformly identified by set functional bits, the logic needed within the decode units to identify the prefix and/or opcode byte positions, is simplified in that there is no need to invert functional bits associated with an MROM instruction in order to place the predecode tags in a condition which is recognizable by circuitry which identifies prefix and opcode bytes by set functional bits.</p><p>Broadly speaking, the present invention contemplates a superscalar microprocessor comprising an instruction cache for storing a plurality of variable byte-length instructions and a predecode unit coupled to the instruction cache and configured to generate a predecode tag associated with each byte of an instruction. The predecode tag includes a start bit having a value indicative of whether the byte is a starting byte of the instruction, an end bit having a value indicative of whether the byte is an end byte, and a functional bit whose meaning is dependent on the value of the start bit. The superscalar microprocessor further includes a plurality of decode units for decoding designated instructions which correspond to the plurality of variable byte-length instructions, and an instruction alignment unit coupled between the instruction cache and the plurality of decode units for providing decodable instructions to the plurality of decode units.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>Other objects and advantages of the invention will become apparent upon reading the following detailed description and upon reference to the accompanying drawings in which:</p><p>FIG. 1 is a block diagram of one embodiment of a superscalar microprocessor.</p><p>FIG. 2 is a block diagram of one embodiment of a pair of decode units shown in FIG. <b>1</b>.</p><p>FIG. 3 is a block diagram of one embodiment of an instruction cache and an instruction alignment unit shown in FIG. <b>1</b>.</p><p>FIG. 4 is a more detailed block diagram illustrating one embodiment of the instruction alignment unit shown in FIG. <b>3</b>.</p><p>FIG. 5 is a diagram illustrating instruction identification information corresponding to one instruction within an instruction block according to one embodiment of the instruction alignment unit.</p><p>FIG. 6 is a diagram illustrating instruction identification information which is shared among the instructions within an instruction block according to one embodiment of the instruction alignment unit.</p><p>FIG. 7 is a diagram illustrating instruction identification information stored in an instruction position within a second byte queue according to one embodiment of the instruction alignment unit.</p><p>FIG. 8 is a block diagram of one embodiment of a computer system including the microprocessor shown in FIG. <b>1</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><p>While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.</p><h4>DETAILED DESCRIPTION OF THE INVENTION</h4><p>Turning now to FIG. 1, a block diagram of one embodiment of a microprocessor <b>10</b> is shown. Microprocessor <b>10</b> includes a prefetch/predecode unit <b>12</b>, a branch prediction unit <b>14</b>, an instruction cache <b>16</b>, an instruction alignment unit <b>18</b>, a plurality of decode units <b>20</b>A-<b>20</b>C, a plurality of reservation stations <b>22</b>A-<b>22</b>C, a plurality of functional units <b>24</b>A-<b>24</b>C, a load/store unit <b>26</b>, a data cache <b>28</b>, a register file <b>30</b>, a reorder buffer <b>32</b>, and an MROM unit <b>34</b>. Elements referred to herein with a particular reference number followed by a letter will be collectively referred to by the reference number alone. For example, decode units <b>20</b>A-<b>20</b>C will be collectively referred to as decode units <b>20</b>.</p><p>Prefetch/predecode unit <b>12</b> is coupled to receive instructions from a main memory subsystem (not shown), and is further coupled to instruction cache <b>16</b> and branch prediction unit <b>14</b>. Similarly, branch prediction unit <b>14</b> is coupled to instruction cache <b>16</b>. Still further, branch prediction unit <b>14</b> is coupled to decode units <b>20</b> and functional units <b>24</b>. Instruction cache <b>16</b> is further coupled to MROM unit <b>34</b> and instruction alignment unit <b>18</b>. Instruction alignment unit <b>18</b> is in turn coupled to decode units <b>20</b>. Each decode unit <b>20</b>A-<b>20</b>C is coupled to load/store unit <b>26</b> and to respective reservation stations <b>22</b>A-<b>22</b>C. Reservation stations <b>22</b>A-<b>22</b>C are further coupled to respective functional units <b>24</b>A-<b>24</b>C. Additionally, decode units <b>20</b> and reservation stations <b>22</b> are coupled to register file <b>30</b> and reorder buffer <b>32</b>. Functional units <b>24</b> are coupled to load/store unit <b>26</b>, register file <b>30</b>, and reorder buffer <b>32</b> as well. Data cache <b>28</b> is coupled to load/store unit <b>26</b> and to the main memory subsystem. Finally, MROM unit <b>34</b> is coupled to decode units <b>20</b>.</p><p>Generally speaking, instruction alignment unit <b>18</b> is configured to receive instruction blocks from instruction cache <b>16</b> and to align instructions from the instruction blocks to decode units <b>20</b>. Instruction alignment unit <b>18</b> employs a first byte queue for storing the instruction blocks. Instruction alignment unit <b>18</b> selects instructions from the first byte queue and stores them into a second byte queue. Based upon predetermined selection criteria, instruction alignment unit <b>18</b> selects one or more instructions from the second byte queue for conveyance to decode units <b>20</b>. Advantageously, the relatively large number of instructions available in the instruction blocks is reduced to a smaller number of instructions via the first stage of selection from the first byte queue into the second byte queue. Because the second byte queue stores a smaller number of instructions, the selection criteria for selecting instructions for dispatch to the decode units <b>20</b> may be applied even in a high frequency implementation. Additionally, the selection criteria may be more complex, thereby allowing more instructions to be selected for concurrent dispatch than selection criteria applied to a larger number of instructions. Multiple instructions may thereby be identified for dispatch.</p><p>An instruction block, as used herein, comprises a fixed number of bytes within which up to a maximum number of instructions per block are identified. A particular instruction block may include fewer instructions than the maximum number of instructions per block within its fixed number of bytes. Alternatively, a given fixed number of bytes within instruction cache <b>16</b> may include more instructions than the maximum number of instructions per block. In the latter case, two or more instruction blocks are formed from the given fixed number of bytes. Each instruction block includes the fixed number of bytes but identifies different instructions within the fixed number of bytes as comprising the instruction block. The fixed number of bytes are aligned to a boundary of the fixed number of bytes. In one embodiment, instruction blocks comprise eight bytes aligned on an eight byte boundary and the maximum number of instructions per block is three. The maximum number of instructions per block is selected because the average length of an x86 instruction is three bytes. Therefore, each eight bytes of instruction code includes 2\u2154 instructions on average. It is noted that the maximum number of instructions per block may be varied in various embodiments as a matter of design choice.</p><p>Instruction cache <b>16</b> is a high speed cache memory provided to store instructions. Instructions are fetched from instruction cache <b>16</b> and dispatched to decode units <b>20</b>. In one embodiment, instruction cache <b>16</b> is configured to store up to 32 kilobytes of instructions in a 4 way set associative structure having 32 byte lines (a byte comprises 8 binary bits). Instruction cache <b>16</b> may additionally employ a way prediction scheme in order to speed access times to the instruction cache. Instead of accessing tags identifying each line of instructions and comparing the tags to the fetch address to select a way, instruction cache <b>16</b> predicts the way that is accessed. In this manner, the way is selected prior to accessing the instruction storage. The access time of instruction cache <b>16</b> may be similar to a direct-mapped cache. A tag comparison is performed and, if the way prediction is incorrect, the correct instructions are fetched and the incorrect instructions are discarded. It is noted that instruction cache <b>16</b> may be implemented as a fully associative, set associative, or direct mapped configuration.</p><p>Instructions are fetched from main memory and stored into instruction cache <b>16</b> by prefetch/predecode unit <b>12</b>. Instructions may be prefetched prior to the request thereof from instruction cache <b>16</b> in accordance with a prefetch scheme. A variety of prefetch schemes may be employed by prefetch/predecode unit <b>12</b>. As prefetch/predecode unit <b>12</b> transfers instructions from main memory to instruction cache <b>16</b>, prefetch/predecode unit <b>12</b> generates three predecode bits for each byte of the instructions: a start bit, an end bit, and a functional bit. The predecode bits form tags indicative of the boundaries of each instruction. The predecode tags may also convey additional information such as whether a given instruction can be decoded directly by decode units <b>20</b> or whether the instruction is executed by invoking a microcode procedure controlled by MROM unit <b>34</b>, as will be described in greater detail below. Still further, prefetch/predecode unit <b>12</b> may be configured to detect branch instructions and to store branch prediction information corresponding to the branch instructions into branch prediction unit <b>14</b>.</p><p>One encoding of the predecode tags for an embodiment of microprocessor <b>10</b> employing a variable byte length instruction set will next be described. A variable byte length instruction set is an instruction set in which different instructions may occupy differing numbers of bytes. An exemplary variable byte length instruction set employed by one embodiment of microprocessor <b>10</b> is the x86 instruction set.</p><p>In the exemplary encoding, if a given byte is the first byte of an instruction, the start bit for that byte is set. If the byte is the last byte of an instruction, the end bit for that byte is set. Instructions which may be directly decoded by decode units <b>20</b> are referred to as \u201cfast path\u201d instructions. The remaining x86 instructions are referred to as MROM instructions, according to one embodiment. The type of instruction may be determined by examining the functional bit corresponding to the start byte. If that functional bit is clear, the instruction is a fast path instruction. Conversely, if that functional bit is set the instruction is an MROM instruction. Regardless of whether the instruction is fast path or MROM, the functional bit associated with each prefix or opcode byte, other than the start byte, is set. The opcode of an instruction may thereby be located within either fast path or MROM instructions as the byte associated with the last set functional bit in the instruction. For example, a fast path instruction including two prefix bytes, an opcode byte, and two displacement bytes in sequence would have start, end, and functional bits as follows:</p><p>Start bits 10000</p><p>End bits 00001</p><p>Functional bits 01100</p><p>An MROM instruction including two prefix bytes, an opcode byte, and two displacement bytes in sequence would have start, end, and functional bits as follows:</p><p>Start bits 10000</p><p>End bits 00001</p><p>Functional bits 11100</p><p>MROM instructions are instructions which are determined to be too complex for decode by a single decode unit <b>20</b>A-<b>20</b>C and for execution by a single functional unit <b>24</b>A-<b>24</b>C. MROM instructions may be an example of microcode instructions. Generally, microcode instructions are instructions which are separated by a microcode unit (e.g. MROM unit <b>34</b>) into two or more instructions, each of which may be decoded by a single decode unit <b>20</b>A-<b>20</b>C and executed by a corresponding functional unit <b>24</b>A-<b>24</b>C. MROM instructions are executed by invoking MROM unit <b>34</b>. More specifically, when an MROM instruction is encountered, MROM unit <b>34</b> parses and issues the instruction into a subset of defined fast path instructions to effectuate the desired operation. MROM unit <b>34</b> dispatches the subset of fast path instructions to decode units <b>20</b>. A listing of exemplary x86 instructions categorized as fast path instructions will be provided further below.</p><p>Microprocessor <b>10</b> employs branch prediction in order to speculatively fetch instructions subsequent to conditional branch instructions. Branch prediction unit <b>14</b> is included to perform branch prediction operations. In one embodiment, up to two branch target addresses are stored with respect to each 16 byte portion of each cache line in instruction cache <b>16</b>. Prefetch/predecode unit <b>12</b> determines initial branch targets when a particular line is predecoded. Subsequent updates to the branch targets corresponding to a cache line may occur due to the execution of instructions within the cache line. Instruction cache <b>16</b> provides an indication of the instruction address being fetched, so that branch prediction unit <b>14</b> may determine which branch target addresses to select for forming a branch prediction. Decode units <b>20</b> and functional units <b>24</b> provide update information to branch prediction unit <b>14</b>. Because branch prediction unit <b>14</b> stores two targets per 16 byte portion of the cache line, some branch instructions within the line may not be stored in branch prediction unit <b>14</b>. Decode units <b>20</b> detect branch instructions which were not predicted by branch prediction unit <b>14</b>. Functional units <b>24</b> execute the branch instructions and determine if the predicted branch direction is incorrect. The branch direction may be \u201ctaken\u201d, in which subsequent instructions are fetched from the target address of the branch instruction. Conversely, the branch direction may be \u201cnot taken\u201d, in which subsequent instructions are fetched from memory locations consecutive to the branch instruction. When a mispredicted branch instruction is detected, instructions subsequent to the mispredicted branch are discarded from the various units of microprocessor <b>10</b>. A variety of suitable branch prediction algorithms may be employed by branch prediction unit <b>14</b>.</p><p>Instructions fetched from instruction cache <b>16</b> are conveyed to instruction alignment unit <b>18</b>. As instructions are fetched from instruction cache <b>16</b>, the corresponding predecode data (i.e., predecode tags consisting of start, end, and functional bits) is scanned to provide information to instruction alignment unit <b>18</b> (and to MROM unit <b>34</b>) regarding the instructions being fetched. The predecode data is scanned to identify the type of instruction (i.e., fast path or MROM) in order to determine whether MROM unit <b>34</b> is to parse the instruction, and to determine the boundaries of the instructions for proper alignment. Instruction alignment unit <b>18</b> utilizes the scanning data to align an instruction to each of decode units <b>20</b>. In one embodiment, instruction alignment unit <b>18</b> aligns instructions from three sets of eight instruction bytes to decode units <b>20</b>. Decode unit <b>20</b>A receives an instruction which is prior to instructions concurrently received by decode units <b>20</b>B and <b>20</b>C (in program order). Similarly, decode unit <b>20</b>B receives an instruction which is prior to the instruction concurrently received by decode unit <b>20</b>C in program order.</p><p>Decode units <b>20</b> are configured to decode instructions received from instruction alignment unit <b>18</b>. Register operand information is detected and routed to register file <b>30</b> and reorder buffer <b>32</b>. Additionally, if the instructions require one or more memory operations to be performed, decode units <b>20</b> dispatch the memory operations to load/store unit <b>26</b>. Each instruction is decoded into a set of control values for functional units <b>24</b>, and these control values are dispatched to reservation stations <b>22</b> along with operand address information and displacement or immediate data which may be included with the instruction.</p><p>Microprocessor <b>10</b> supports out of order execution, and thus employs reorder buffer <b>32</b> to keep track of the original program sequence for register read and write operations, to implement register renaming, to allow for speculative instruction execution and branch misprediction recovery, and to facilitate precise exceptions. A temporary storage location within reorder buffer <b>32</b> is reserved upon decode of an instruction that involves the update of a register to thereby store speculative register states. If a branch prediction is incorrect, the results of speculatively-executed instructions along the mispredicted path can be invalidated in the buffer before they are written to register file <b>30</b>. Similarly, if a particular instruction causes an exception, instructions subsequent to the particular instruction may be discarded. In this manner, exceptions are \u201cprecise\u201d (i.e. instructions subsequent to the particular instruction causing the exception are not completed prior to the exception). It is noted that a particular instruction is speculatively executed if it is executed prior to instructions which precede the particular instruction in program order. Preceding instructions may be a branch instruction or an exception-causing instruction, in which case the speculative results may be discarded by reorder buffer <b>32</b>.</p><p>The instruction control values and immediate or displacement data provided at the outputs of decode units <b>20</b> are routed directly to respective reservation stations <b>22</b>. In one embodiment, each reservation station <b>22</b> is capable of holding instruction information (i.e., instruction control values as well as operand values, operand tags and/or immediate data) for up to three pending instructions awaiting issue to the corresponding functional unit. It is noted that for the embodiment of FIG. 1, each reservation station <b>22</b> is associated with a dedicated functional unit <b>24</b>. Accordingly, three dedicated \u201cissue positions\u201d are formed by reservation stations <b>22</b> and functional units <b>24</b>. In other words, issue position <b>0</b> is formed by reservation station <b>22</b>A and functional unit <b>24</b>A. Instructions aligned and dispatched to reservation station <b>22</b>A are executed by functional unit <b>24</b>A. Similarly, issue position <b>1</b> is formed by reservation station <b>22</b>B and functional unit <b>24</b>B; and issue position <b>2</b> is formed by reservation station <b>22</b>C and functional unit <b>24</b>C.</p><p>Upon decode of a particular instruction, if a required operand is a register location, register address information is routed to reorder buffer <b>32</b> and register file <b>30</b> simultaneously. Those of skill in the art will appreciate that the x86 register file includes eight 32 bit real registers (i.e., typically referred to as EAX, EBX, ECX, EDX, EBP, ESI, EDI and ESP). In embodiments of microprocessor <b>10</b> which employ the x86 microprocessor architecture, register file <b>30</b> comprises storage locations for each of the 32 bit real registers. Additional storage locations may be included within register file <b>30</b> for use by MROM unit <b>34</b>. Reorder buffer <b>32</b> contains temporary storage locations for results which change the contents of these registers to thereby allow out of order execution. A temporary storage location of reorder buffer <b>32</b> is reserved for each instruction which, upon decode, is determined to modify the contents of one of the real registers. Therefore, at various points during execution of a particular program, reorder buffer <b>32</b> may have one or more locations which contain the speculatively executed contents of a given register. If following decode of a given instruction it is determined that reorder buffer <b>32</b> has a previous location or locations assigned to a register used as an operand in the given instruction, the reorder buffer <b>32</b> forwards to the corresponding reservation station either: 1) the value in the most recently assigned location, or 2) a tag for the most recently assigned location if the value has not yet been produced by the functional unit that will eventually execute the previous instruction. If reorder buffer <b>32</b> has a location reserved for a given register, the operand value (or reorder buffer tag) is provided from reorder buffer <b>32</b> rather than from register file <b>30</b>. If there is no location reserved for a required register in reorder buffer <b>32</b>, the value is taken directly from register file <b>30</b>. If the operand corresponds to a memory location, the operand value is provided to the reservation station through load/store unit <b>26</b>.</p><p>In one particular embodiment, reorder buffer <b>32</b> is configured to store and manipulate concurrently decoded instructions as a unit. This configuration will be referred to herein as \u201cline-oriented\u201d. By manipulating several instructions together, the hardware employed within reorder buffer <b>32</b> may be simplified. For example, a line-oriented reorder buffer included in the present embodiment allocates storage sufficient for instruction information pertaining to three instructions (one from each decode unit <b>20</b>) whenever one or more instructions are dispatched by decode units <b>20</b>. By contrast, a variable amount of storage is allocated in conventional reorder buffers, dependent upon the number of instructions actually dispatched. A comparatively larger number of logic gates may be required to allocate the variable amount of storage. When each of the concurrently decoded instructions has executed, the instruction results are stored into register file <b>30</b> simultaneously. The storage is then free for allocation to another set of concurrently decoded instructions. Additionally, the amount of control logic circuitry employed per instruction is reduced because the control logic is amortized over several concurrently decoded instructions. A reorder buffer tag identifying a particular instruction may be divided into two fields: a line tag and an offset tag. The line tag identifies the set of concurrently decoded instructions including the particular instruction, and the offset tag identifies which instruction within the set corresponds to the particular instruction. It is noted that storing instruction results into register file <b>30</b> and freeing the corresponding storage is referred to as \u201cretiring\u201d the instructions. It is further noted that any reorder buffer configuration may be employed in various embodiments of microprocessor <b>10</b>.</p><p>As noted earlier, reservation stations <b>22</b> store instructions until the instructions are executed by the corresponding functional unit <b>24</b>. An instruction is selected for execution if: (i) the operands of the instruction have been provided; and (ii) the operands have not yet been provided for instructions which are within the same reservation station <b>22</b>A-<b>22</b>C and which are prior to the instruction in program order. It is noted that when an instruction is executed by one of the functional units <b>24</b>, the result of that instruction is passed directly to any reservation stations <b>22</b> that are waiting for that result at the same time the result is passed to update reorder buffer <b>32</b> (this technique is commonly referred to as \u201cresult forwarding\u201d). An instruction may be selected for execution and passed to a functional unit <b>24</b>A-<b>24</b>C during the clock cycle that the associated result is forwarded. Reservation stations <b>22</b> route the forwarded result to the functional unit <b>24</b> in this case.</p><p>In one embodiment, each of the functional units <b>24</b> is configured to perform integer arithmetic operations of addition and subtraction, as well as shifts, rotates, logical operations, and branch operations. The operations are performed in response to the control values decoded for a particular instruction by decode units <b>20</b>. It is noted that a floating point unit (not shown) may also be employed to accommodate floating point operations. The floating point unit may be operated as a coprocessor, receiving instructions from MROM unit <b>34</b> and subsequently communicating with reorder buffer <b>32</b> to complete the instructions. Additionally, functional units <b>24</b> may be configured to perform address generation for load and store memory operations performed by load/store unit <b>26</b>.</p><p>Each of the functional units <b>24</b> also provides information regarding the execution of conditional branch instructions to the branch prediction unit <b>14</b>. If a branch prediction was incorrect, branch prediction unit <b>14</b> flushes instructions subsequent to the mispredicted branch that have entered the instruction processing pipeline, and causes fetch of the required instructions from instruction cache <b>16</b> or main memory. It is noted that in such situations, results of instructions in the original program sequence which occur after the mispredicted branch instruction are discarded, including those which were speculatively executed and temporarily stored in load/store unit <b>26</b> and reorder buffer <b>32</b>.</p><p>Results produced by functional units <b>24</b> are sent to reorder buffer <b>32</b> if a register value is being updated, and to load/store unit <b>26</b> if the contents of a memory location are changed. If the result is to be stored in a register, reorder buffer <b>32</b> stores the result in the location reserved for the value of the register when the instruction was decoded. A plurality of result buses <b>38</b> are included for forwarding of results from functional units <b>24</b> and load/store unit <b>26</b>. Result buses <b>38</b> convey the result generated, as well as the reorder buffer tag identifying the instruction being executed.</p><p>Load/store unit <b>26</b> provides an interface between functional units <b>24</b> and data cache <b>28</b>. In one embodiment, load/store unit <b>26</b> is configured with a load/store buffer having eight storage locations for data and address information for pending loads or stores. Decode units <b>20</b> arbitrate for access to the load/store unit <b>26</b>. When the buffer is full, a decode unit must wait until load/store unit <b>26</b> has room for the pending load or store request information. Load/store unit <b>26</b> also performs dependency checking for load memory operations against pending store memory operations to ensure that data coherency is maintained. A memory operation is a transfer of data between microprocessor <b>10</b> and the main memory subsystem. Memory operations may be the result of an instruction which utilizes an operand stored in memory, or may be the result of a load/store instruction which causes the data transfer but no other operation. Additionally, load/store unit <b>26</b> may include a special register storage for special registers such as the segment registers and other registers related to the address translation mechanism defined by the x86 microprocessor architecture.</p><p>In one embodiment, load/store unit <b>26</b> is configured to perform load memory operations speculatively. Store memory operations are performed in program order, but may be speculatively stored into the predicted way. If the predicted way is incorrect, the data prior to the store memory operation is subsequently restored to the predicted way and the store memory operation is performed to the correct way. In another embodiment, stores may be executed speculatively as well. Speculatively executed stores are placed into a store buffer, along with a copy of the cache line prior to the update. If the speculatively executed store is later discarded due to branch misprediction or exception, the cache line may be restored to the value stored in the buffer. It is noted that load/store unit <b>26</b> may be configured to perform any amount of speculative execution, including no speculative execution.</p><p>Data cache <b>28</b> is a high speed cache memory provided to temporarily store data being transferred between load/store unit <b>26</b> and the main memory subsystem. In one embodiment, data cache <b>28</b> has a capacity of storing up to sixteen kilobytes of data in an eight way set associative structure. Similar to instruction cache <b>16</b>, data cache <b>28</b> may employ a way prediction mechanism. It is understood that data cache <b>28</b> may be implemented in a variety of specific memory configurations, including a set associative configuration.</p><p>In one particular embodiment of microprocessor <b>10</b> employing the x86 microprocessor architecture, instruction cache <b>16</b> and data cache <b>28</b> are linearly addressed. The linear address is formed from the offset specified by the instruction and the base address specified by the segment portion of the x86 address translation mechanism. Linear addresses may optionally be translated to physical addresses for accessing a main memory. The linear to physical translation is specified by the paging portion of the x86 address translation mechanism. It is noted that a linear addressed cache stores linear address tags. A set of physical tags (not shown) may be employed for mapping the linear addresses to physical addresses and for detecting translation aliases. Additionally, the physical tag block may perform linear to physical address translation.</p><p>Turning now to FIG. 2, a block diagram of one embodiment of decode units <b>20</b>B and <b>20</b>C is shown. Each decode unit <b>20</b> receives an instruction from instruction alignment unit <b>18</b>. Additionally, MROM unit <b>34</b> is coupled to each decode unit <b>20</b> for dispatching fast path instructions corresponding to a particular MROM instruction. Decode unit <b>20</b>B comprises early decode unit <b>40</b>B, multiplexor <b>42</b>B, and opcode decode unit <b>44</b>B. Similarly, decode unit <b>20</b>C includes early decode unit <b>40</b>C, multiplexor <b>42</b>C, and opcode decode unit <b>44</b>C.</p><p>Certain instructions in the x86 instruction set are both fairly complicated and frequently used. In one embodiment of microprocessor <b>10</b>, such instructions include more complex operations than the hardware included within a particular functional unit <b>24</b>A-<b>24</b>C is configured to perform. Such instructions are classified as a special type of MROM instruction referred to as a \u201cdouble dispatch\u201d instruction. These instructions are dispatched to a pair of opcode decode units <b>44</b>. It is noted that opcode decode units <b>44</b> are coupled to respective reservation stations <b>22</b>. Each of opcode decode units <b>44</b>A-<b>44</b>C forms an issue position with the corresponding reservation station <b>22</b>A-<b>22</b>C and functional unit <b>24</b>A-<b>24</b>C. Instructions are passed from an opcode decode unit <b>44</b> to the corresponding reservation station <b>22</b> and further to the corresponding functional unit <b>24</b>.</p><p>Multiplexor <b>42</b>B is included for selecting between the instructions provided by MROM unit <b>34</b> and by early decode unit <b>40</b>B. During times in which MROM unit <b>34</b> is dispatching instructions, multiplexor <b>42</b>B selects instructions provided by MROM unit <b>34</b>. At other times, multiplexor <b>42</b>B selects instructions provided by early decode unit <b>40</b>B. Similarly, multiplexor <b>42</b>C selects between instructions provided by MROM unit <b>34</b>, early decode unit <b>40</b>B, and early decode unit <b>40</b>C. The instruction from MROM unit <b>34</b> is selected during times in which MROM unit <b>34</b> is dispatching instructions. During times in which the early decode unit within decode unit <b>20</b>A (not shown) detects a double dispatch instruction, the instruction from early decode unit <b>40</b>B is selected by multiplexor <b>42</b>C. Otherwise, the instruction from early decode unit <b>40</b>C is selected. Selecting the instruction from early decode unit <b>40</b>B into opcode decode unit <b>44</b>C allows a fast path instruction decoded by decode unit <b>20</b>B to be dispatched concurrently with a double dispatch instruction decoded by decode unit <b>20</b>A.</p><p>According to one embodiment employing the x86 instruction set, early decode units <b>40</b> perform the following operations:</p><p>(i) merge the prefix bytes of the instruction into an encoded prefix byte;</p><p>(ii) decode unconditional branch instructions (which may include the unconditional jump, the CALL, and the RETURN) which were not detected during branch prediction;</p><p>(iii) decode source and destination flags;</p><p>(iv) decode the source and destination operands which are register operands and generate operand size information; and</p><p>(v) determine the displacement and/or immediate size so that displacement and immediate data may be routed to the opcode decode unit.</p><p>The functional bits of the predecode data, in one embodiment, are used by the early decode units <b>40</b> to identify prefixes prior to their merger into an encoded prefix. As noted above, the prefix and opcode bytes, other than the start byte, are designated by functional bits set to logical one. To identify whether a particular byte is a prefix, the decode unit logically ANDs the functional bit associated with a subsequent byte (i.e.,) with the logical inverse of the end bit of the particular byte in question (i.e., Prefix[I]=Func[i+1]&amp;\u02dcEnd[i] where i represents the position of the particular byte in question). It is noted that ANDing the inverse of the end bit accounts for the case where the opcode of the instruction is the last byte. If the result of the logical ANDing operation yields a logical one, the particular byte in question is a prefix, and can be further processed as such. If the result of the logical ANDing operation yields a logical zero, the particular byte in question is not a prefix. Using this logical operation, the decode unit, or any other unit within processor <b>10</b>, can easily identify each prefix in an instruction notwithstanding the fact that the functional bit associated with the start byte is used to identify the instruction as fast path or MROM. Prefixes, including those which are contained in an instruction split between two blocks, can be identified using the logical ANDing function. However, with respect to a split instruction, a split instruction bit is provided by the predecode unit and is used as the subsequent functional bit in the logical ANDing function to identify whether the last byte of the split instruction is a prefix. The split instruction bit becomes, in effect, the most significant bit of the functional bits in the predecode data. Additionally, since the opcode byte follows the prefix bytes, if any, the first logical zero produced by the logical ANDing function set forth above identifies the opcode position of the instruction.</p><p>Opcode decode units <b>44</b> are configured to decode the opcode of the instruction, producing control values for functional unit <b>24</b>. Displacement and immediate data are routed with the control values to reservation stations <b>22</b>.</p><p>Since early decode units <b>40</b> detect operands, the outputs of multiplexors <b>42</b> are routed to register file <b>30</b> and reorder buffer <b>32</b>. Operand values or tags may thereby be routed to reservation stations <b>22</b>. Additionally, memory operands are detected by early decode units <b>40</b>. Therefore, the outputs of multiplexors <b>42</b> are routed to load/store unit <b>26</b>. Memory operations corresponding to instructions having memory operands are stored by load/store unit <b>26</b>.</p><p>Turning now to FIG. 3, a block diagram of one embodiment of instruction cache <b>16</b> and instruction alignment unit <b>18</b> is shown. Instruction cache <b>16</b> includes an instruction cache storage and control block <b>50</b> and an instruction scanning unit <b>52</b>. Instruction alignment unit <b>18</b> includes a first byte queue <b>54</b> and a second byte queue <b>56</b>.</p><p>Instruction cache storage and control block <b>50</b> includes storage for instruction cache lines and related control circuitry for fetching instructions from the storage, for selecting cache lines to discard when a cache miss is detected, etc. Instruction cache storage and control block <b>50</b> receives fetch addresses from branch prediction unit <b>14</b> (shown in FIG. 1) in order to fetch instructions for execution by microprocessor <b>10</b>. Instruction bytes fetched from instruction cache storage and control block <b>50</b> are conveyed to instruction scanning unit <b>52</b> upon an instructions bus <b>60</b>. Instruction bytes are conveyed upon instructions bus <b>60</b>, as well as corresponding predecode data (e.g. start, end, and functional bits). In one embodiment, sixteen bytes stored in contiguous memory locations are conveyed upon instructions bus <b>60</b> along with the corresponding predecode data. The sixteen bytes form either the upper or lower half of the 32 byte cache line employed by instruction cache <b>16</b> according to the present embodiment. The upper half of the cache line is the half stored in memory addresses having larger numerical values, while the lower half is stored in memory addresses having smaller numerical values. Additionally, instruction scanning unit <b>52</b> receives information regarding the bytes within the sixteen bytes which are to be conveyed as instructions to instruction alignment unit <b>18</b>. Instruction bytes at the beginning of the sixteen bytes may be ignored if the bytes are fetched as the target of a branch instruction, and the target address identifies a byte other than the first byte of the sixteen bytes. Additionally, if a branch instruction is within the sixteen bytes and branch prediction unit <b>14</b> predicts the branch taken, then bytes subsequent to the branch instruction within the sixteen bytes are ignored.</p><p>Instruction scanning unit <b>52</b> scans the predecode data associated with the bytes which are to be conveyed as instructions to instruction alignment unit <b>18</b>. Instruction scanning unit <b>52</b> divides the sixteen bytes conveyed by instruction cache storage and control block <b>50</b> into two portions comprising eight contiguous bytes each. One portion forms the lower half of the sixteen bytes (i.e. the bytes stored at smaller numerical addresses than the bytes forming the upper half of the sixteen bytes). The other portion forms the upper half of the sixteen bytes. Therefore, an eight byte portion forms one of four quarters of the 32 byte cache line employed by instruction cache storage and control block <b>50</b>, according to the present embodiment. As used herein, bytes are contiguous if they are stored in contiguous memory locations in the main memory subsystem. It is noted that particular sizes of various components are used herein for clarity of the description. Any size may be used for each component within the spirit and scope of the appended claims.</p><p>Instruction scanning unit <b>52</b> scans the predecode data of each portion of the instruction bytes independently and in parallel. These portions scanned by scanning unit <b>52</b> comprise the fixed number of bytes defined to be an instruction block. Instruction scanning unit <b>52</b> therefore scans the predecode data to identify up to the maximum number of instructions per block.</p><p>The instruction bytes and instruction identification information generated by instruction scanning unit <b>52</b> are conveyed to first byte queue <b>54</b> upon an instructions bus <b>62</b> and an instruction data bus <b>64</b>, respectively. As shown in FIG. 3, instructions bus <b>62</b> includes an instructions-block A bus <b>62</b>A and an instructions-block B bus <b>62</b>B. Instructions-block A bus <b>62</b>A conveys the instruction bytes corresponding to the first instruction block being scanned by instruction scanning unit <b>52</b> (in program order). Similarly, instructions-block B bus <b>62</b>B conveys the instruction bytes corresponding to the second instruction block being scanned by instruction scanning unit <b>52</b>.</p><p>Instruction identification information corresponding to the instruction bytes conveyed upon instructions-block A bus <b>62</b>A is conveyed upon instruction data\u2014block A bus <b>64</b>A. Similarly, instruction identification information corresponding to the instruction bytes conveyed upon instructions-block B bus <b>62</b>B is conveyed upon instruction data-block B bus <b>64</b>B. Instruction data-block A bus <b>64</b>A and instruction data-block B bus <b>64</b>B comprise instruction data bus <b>64</b> as shown in FIG. <b>3</b>. Each eight byte portion and the corresponding instruction identification information forms an instruction block.</p><p>First byte queue <b>54</b> receives the instruction blocks conveyed and stores them into one of multiple subqueues included therein. In the embodiment shown, first byte queue <b>54</b> includes three subqueues: a first subqueue <b>66</b>A, a second subqueue <b>66</b>B, and a third subqueue <b>66</b>C. First subqueue <b>66</b>A stores the instruction block which is foremost among the instruction blocks stored in first byte queue <b>54</b> in program order. Second subqueue <b>66</b>B stores the instruction block which is second in program order, and third subqueue stores the instruction block which is third in program order.</p><p>If a particular eight byte portion as scanned by instruction scanning unit <b>52</b> includes more than the maximum number of instructions per block, then the particular eight byte portion is retained by instruction scanning unit <b>52</b>. During the following clock cycle, the particular eight byte portion is scanned again. The predecode data corresponding to the previously identified instructions included within the previously dispatched instruction block is invalidated such that instruction scanning unit <b>52</b> detects the additional instructions. If the other eight byte portion concurrently received with the particular eight byte portion is subsequent to the particular eight byte portion in program order, then the other eight byte portion is rescanned as well. First byte queue <b>54</b> discards the instruction block received from the other eight byte portion, in order to retain program order among the instruction blocks stored in the byte queue.</p><p>A control unit <b>70</b> within first byte queue <b>54</b> conveys a byte queue status upon byte queue status bus <b>68</b> to instruction scanning unit <b>52</b>. Byte queue status bus <b>68</b> includes a signal corresponding to each subqueue <b>66</b>. The signal is asserted if the subqueue <b>66</b> is storing an instruction block, and deasserted if the subqueue <b>66</b> is not storing an instruction block. In this manner, instruction scanning unit <b>52</b> may determine how many instruction blocks are accepted by first byte queue <b>54</b> during a clock cycle. If two instruction blocks are conveyed during a clock cycle and only one instruction block is accepted, instruction scanning unit <b>52</b> retains the rejected instruction block and rescans the instruction block in the subsequent clock cycle.</p><p>As noted above, an instruction block may contain up to a maximum number of instructions (e.g. three in the present embodiment). Additionally, eight contiguous bytes are conveyed for each instruction block. However, due to the variable byte length of the x86 instructions, an instruction may begin within one set of eight contiguous bytes and end in another set of eight contiguous bytes. Such an instruction is referred to as an overflow instruction. If an overflow instruction is detected, it is identified as the last of the maximum number of instructions. Instead of being indicated as a valid instruction within the instruction block, the overflow instruction is identified as an overflow. Instruction identification information is generated, but the instruction is handled somewhat differently, as will be explained in more detail below.</p><p>In one embodiment, the instruction identification information for each instruction includes: (i) start and end pointers identifying the bytes at which the identified instruction begins and ends within the instruction block; (ii) a valid mask including a bit for each of the bytes within the instruction block; (iii) a bit indicative of whether the instruction is MROM or fast path; (iv) an instruction valid bit indicating that the instruction is valid; and (v) an overflow bit for the last instruction indicating whether or not it is an overflow. The valid mask includes a binary one bit corresponding to each byte included within the particular instruction (i.e. the bits between the start pointer and end pointer, inclusive, are set). Zero bits are included for the other bytes.</p><p>Additional information conveyed with the instruction identification information includes the taken/not taken prediction if the instruction is a branch instruction, bits indicating which of the quarters of the 32 byte cache line the eight bytes correspond to, the functional bits from the predecode data corresponding to the eight bytes, and a segment limit identifying the segment limit within the eight bytes for exception handling. The additional information is provided by instruction cache storage and control block <b>50</b> except for the branch prediction, which is provided by branch prediction unit <b>14</b>.</p><p>Control unit <b>70</b> examines the instruction identification information stored in the subqueues <b>66</b> to select instructions from first byte queue <b>54</b>. Control unit <b>70</b> selects a number of instructions for conveyance to second byte queue <b>56</b> depending upon the number of instructions currently stored in the second byte queue, and the number of instruction blocks containing those instructions. Generally, control unit <b>70</b> selects as many instructions as possible for conveyance to second byte queue <b>56</b> based upon the available storage within second byte queue <b>56</b> for instruction blocks and instructions. In other words, control unit <b>70</b> selects a number of instructions which either fill instruction position storages <b>74</b> or the corresponding instruction blocks which are not already stored in instruction bytes storages <b>72</b> fill instruction bytes storages <b>72</b>.</p><p>Second byte queue <b>56</b> includes a plurality of instruction bytes storages <b>72</b>A-<b>72</b>C, a plurality of instruction position storages <b>74</b>A-<b>74</b>C, and a control unit <b>76</b>. Each instruction bytes storage <b>72</b> is configured to store the instruction bytes comprising an instruction block. Therefore, in the embodiment shown, second byte queue <b>56</b> may concurrently store instructions which are drawn from up to three different instruction blocks. Each instruction position storage is configured to store an instruction identifier corresponding to one instruction. Generally speaking, an \u201cinstruction identifier\u201d is information which locates a particular instruction within instruction bytes storages <b>72</b>A-<b>72</b>C. The information can be used to select the instruction bytes which comprise the instruction from instruction bytes storage <b>72</b>A-<b>72</b>C. Therefore, in the embodiment shown, second byte queue <b>56</b> may concurrently store instruction identifiers for up to three instructions within the instruction bytes stored in instruction bytes storages <b>72</b>.</p><p>Control unit <b>76</b> is configured to select instructions from second byte queue <b>56</b> for conveyance to decode units <b>20</b>. The instruction represented within each instruction position storage <b>74</b> is dispatched to a corresponding decode unit <b>20</b>, subject to a selection criteria employed by control unit <b>76</b>. Generally, the instruction represented within instruction position storage <b>74</b>A may be dispatched to decode unit <b>20</b>A during a clock cycle (assuming no pipeline stalls from decode units <b>20</b> or subsequent pipeline stages). If control unit <b>76</b> determines that the instruction represented within instruction position storage <b>74</b>B may be concurrently dispatched with the instruction represented within instruction position storage <b>74</b>A, then the instruction may be dispatched to decode unit <b>20</b>B. Similarly, if control unit <b>76</b> determines that the instruction represented within instruction position storage <b>74</b>C may be concurrently dispatched with the instructions represented within instruction position storages <b>74</b>A-<b>74</b>B, then the instruction may be dispatched to decode unit <b>20</b>C. Upon dispatching one or more instructions, control unit <b>76</b> causes the information within instruction position storages <b>74</b>A-<b>74</b>C to be shifted into adjacent instruction position storages <b>74</b>A-<b>74</b>B, thereby allowing for additional instructions to be conveyed from first byte queue <b>54</b> into second byte queue <b>56</b> while maintaining the identified instructions in program order.</p><p>According to one embodiment, the selection criteria employed by control unit <b>76</b> is as follows:</p><p>(i) instructions are dispatched in program order;</p><p>(ii) up to three fast path instructions can be concurrently dispatched;</p><p>(iii) an MROM instruction can be dispatched if a synchronization signal from MROM unit <b>34</b> is asserted indicating that NROM unit <b>34</b> is ready to dispatch an MROM instruction;</p><p>(iv) an MROM instruction being dispatched to decode unit <b>20</b>A may concurrently be dispatched with a fast path instruction to decode position <b>20</b>B and vice-versa (referred to as \u201cpacking\u201d\u2014see further discussion below);</p><p>(v) at most one MROM instruction is dispatched concurrently;</p><p>(vi) an MROM instruction is not dispatched to decode unit <b>20</b>C (a corollary to criterion (iv));</p><p>(vii) at most one predicted taken branch is concurrently dispatched; and</p><p>(viii) instructions from at most two cache lines are concurrently dispatched (each cache line is represented by an address in reorder buffer <b>32</b>, and reorder buffer <b>32</b> employs two locations for storing addresses for each set of concurrently dispatched instructions in the present embodiment).</p><p>As mentioned above, an MROM instruction and a fast path instruction can be \u201cpacked\u201d together (i.e. concurrently dispatched). Some MROM instructions are parsed into two fast path instructions, thereby leaving a decode unit <b>20</b> available for the concurrent dispatch of a fast path instruction. If MROM unit <b>34</b> indicates that the MROM instruction to be dispatched is a two instruction MROM instruction, then control unit <b>76</b> selects both the MROM instruction and the adjacent fast path instruction for dispatch. Otherwise, the MROM instruction is dispatched during a different clock cycle than the adjacent fast path instruction. If no fast path instruction is adjacent to the MROM instruction, the MROM instruction is dispatched separate from other instructions regardless of whether or not the MROM instruction parses into two instructions or more than two instructions.</p><p>By using first byte queue <b>54</b> and second byte queue <b>56</b>, the location of variable byte length instructions within the instruction blocks is separated from the dispatch of instructions to decode units <b>20</b>A. These two operations are logically separate from each other and are generally serial in nature. Therefore, first byte queue <b>54</b> performs instruction location. Instruction identifiers locating the instructions are placed into instruction position storages <b>74</b>. By first locating a small number of instructions which are eligible for dispatch and conveying these instructions to second byte queue <b>56</b>, first byte queue <b>54</b> provides a smaller pool of instructions to which second byte queue <b>56</b> may apply the dispatch selection criteria. Since a relatively small number of instructions are examined, the selection criteria may be applied using a relatively small number of cascaded levels of logic. A high frequency implementation of instruction alignment may thereby be realized.</p><p>While the small pool of instructions stored by second byte queue <b>56</b> allows a high frequency implementation, the larger pool of instructions maintained by first byte queue <b>54</b> allows for more instructions to be fetched from instruction cache <b>16</b> during a given clock cycle than if second byte queue <b>56</b> were employed alone. Thus, first byte queue <b>54</b> may increase the average number of instructions dispatched during a given clock cycle by rapidly providing instructions into second byte queue <b>56</b> when instructions are dispatched. Advantageously, instruction alignment unit <b>18</b> may provide both a high bandwidth (i.e. instructions dispatched per clock cycle) and high frequency alignment of instructions to decode units <b>20</b>.</p><p>It is noted that it may be advantageous to physically locate control units <b>70</b> and <b>76</b> near each other to facilitate high speed communications therebetween. In addition, it may be advantageous to duplicate control logic between control units <b>70</b> and <b>76</b> to lessen the communication signals employed between the control units.</p><p>It is noted that MROM instructions are identified by instruction scanning unit <b>52</b> as well. Instruction scanning unit <b>52</b> routes the MROM instructions to MROM unit <b>34</b>. However, the MROM instructions may flow through instruction alignment unit <b>18</b> as well. In this manner, instruction alignment unit <b>18</b> may detect the MROM instruction and convey it to decode units <b>20</b>. MROM unit <b>34</b> may then insert the corresponding instructions between early decode units <b>40</b> and opcode decode units <b>44</b> when the MOM instruction arrives in early decode units <b>40</b>, as described above with respect to FIG. <b>2</b>.</p><p>Control unit <b>70</b>, upon detecting that all instructions within a given instruction block have been conveyed to second byte queue <b>56</b>, shifts the contents of each subqueue <b>66</b>B-<b>66</b>C into an adjacent subqueue <b>66</b>A-<b>66</b>B. In this manner, the instruction block which has been exhausted of instructions is discarded and other instruction blocks are maintained in program order. Additionally, the instruction identification information within a subqueue <b>66</b> is shifted such that the first field within the subqueue <b>66</b> stores the first instruction (in program order) remaining within the subqueue. However, overflow instructions remain in the last field within the subqueue. Control unit <b>70</b> further allocates subqueues <b>66</b> for storing instruction blocks provided by instruction scanning unit <b>52</b>.</p><p>Turning next to FIG. 4, a more detailed block diagram of one embodiment of first byte queue <b>54</b> and second byte queue <b>56</b> is shown. Each of subqueues <b>66</b> from first byte queue <b>54</b> are illustrated as having various fields, including a first instruction field (I<b>0</b>), a second instruction field (I<b>1</b>), and third instruction field (I<b>2</b>), and a shared field (SH). Each of the first instruction field, the second instruction field, and the third instruction field are configured to store instruction identification information corresponding to one instruction within the instruction block stored in that subqueue. The information stored in the instruction fields and the shared fields according to one embodiment of the subqueues is shown below. A second byte queue status bus <b>80</b> is coupled between control unit <b>76</b> and control unit <b>70</b>. Additionally, control unit <b>76</b> is coupled to a sync line <b>82</b> and a two instructions line <b>84</b> from MROM unit <b>34</b>. A plurality of instruction multiplexors <b>86</b>A-<b>86</b>C are coupled between subqueues <b>66</b>A-<b>66</b>C and instruction position storages <b>74</b>A-<b>74</b>C. A plurality of instruction bytes multiplexors <b>88</b>A-<b>88</b>B are coupled between subqueues <b>66</b>A-<b>66</b>C and instruction bytes storages <b>72</b>B-<b>72</b>C. Additionally, a plurality of output multiplexors <b>90</b>A-<b>90</b>C are coupled between instruction bytes storages <b>72</b>A-<b>72</b>C and decode units <b>20</b>.</p><p>Control unit <b>70</b> is coupled to provide multiplexor selection controls to instruction multiplexors <b>86</b>. Control unit <b>70</b> generates the multiplexor selection controls by scanning the instruction valid bits corresponding to the instruction fields within subqueues <b>66</b> and the information conveyed upon second byte queue status bus <b>80</b>. Second byte queue status bus <b>80</b> indicates which of instruction position storages <b>74</b> and which of instruction bytes storages <b>72</b> are empty upon dispatching instructions during a particular clock cycle. For example, second byte queue status bus <b>80</b> may comprise a signal corresponding to each instruction position storage <b>74</b>A-<b>74</b>C indicative, when asserted, that the corresponding instruction position storage <b>74</b> is storing an instruction subsequent to dispatch of instructions during the current clock cycle. Additionally, second byte queue status bus <b>80</b> may be include a signal corresponding to each instruction byte storage <b>72</b>A-<b>72</b>C indicative, when asserted, that the corresponding instruction bytes storage <b>72</b> is storing a block of instruction bytes subsequent to instruction dispatch during the current clock cycle.</p><p>Control unit <b>70</b> selects as many instructions as possible from subqueues <b>66</b> to fill instruction position storages <b>74</b>. Control unit <b>70</b> also considers availability of instruction bytes storages <b>72</b> in selecting instructions. Generally, control unit <b>70</b> selects a number of instructions for instruction position storages <b>74</b> which either fills instruction position storages <b>74</b> or fills instruction bytes storages <b>72</b>. Control unit <b>70</b> considers the validity of instructions within subqueues <b>66</b>A-<b>66</b>C in selecting instructions for instruction position storages <b>74</b>. Advantageously, the type of instruction (MROM or fast path) and other instruction properties stored in subqueues <b>66</b>A-<b>66</b>C (such as whether or not an instruction is a predicted taken branch instruction, etc.) need not be considered by control unit <b>70</b> in selecting instructions to fill instruction position storages <b>74</b>. The logic for performing the selection may be simplified, thereby allowing for a high frequency implementation.</p><p>As shown in FIG. 4, instruction multiplexor <b>86</b>A is coupled to receive instruction information from the <b>10</b> instruction field of each subqueue <b>66</b>A-<b>66</b>C. Since instruction position storage <b>74</b>A stores the instruction which is first in program order, among instructions in instruction position storages <b>74</b>A-<b>74</b>C, and since subqueues <b>66</b>A are shifted such that the first instruction in program order is the instruction in field I<b>0</b>, instruction multiplexor <b>86</b>A is connected to select from only the first instruction field of each subqueue <b>66</b>A-<b>66</b>C. Similarly, instruction multiplexor <b>86</b>B is coupled to select instruction information from either instruction fields I<b>0</b> and I<b>1</b>. Instruction multiplexor <b>86</b>B is coupled to select instruction information from any field within subqueues <b>66</b>.</p><p>Instruction bytes storages <b>72</b> are coupled to receive blocks of instructions from subqueues <b>66</b> via instruction bytes multiplexors <b>88</b>. Control unit <b>76</b> is coupled to provide selection controls for multiplexors <b>88</b> as shown in FIG. 4, but control unit <b>70</b> may provide selection controls as well. Instruction bytes storage <b>72</b> are maintained such that instruction bytes storage <b>72</b>A stores a block of instruction bytes corresponding to instructions which are prior to instructions corresponding to blocks of instruction bytes in instruction bytes storages <b>72</b>B and <b>72</b>C. Similarly, instruction bytes storage <b>72</b>B stores a block of instruction bytes corresponding to instructions which are prior to instructions corresponding to the block of instruction bytes in instruction bytes storage <b>72</b>C. Therefore, if instruction bytes storage <b>72</b>A receives a block of instruction bytes from subqueues <b>66</b>, the block of instruction bytes is drawn from subqueue <b>66</b>A. Blocks of instruction bytes in subqueues <b>66</b>B and <b>66</b>C are subsequent to the block of instruction bytes in subqueue <b>66</b>A. Additionally, instruction bytes storage <b>72</b>A may receive a block of instruction bytes shifted in from instruction bytes storage <b>72</b>B. Similarly, instruction bytes storage <b>72</b>A may receive a block of instruction bytes from subqueue <b>66</b>A or subqueue <b>66</b>B, while instruction bytes storage <b>72</b>C may receive a block of instruction bytes from any subqueue <b>66</b>.</p><p>For example, if instruction bytes storages <b>72</b>A-<b>72</b>C are empty during a clock cycle, instruction bytes storage <b>72</b>A may receive a block of instruction bytes from subqueue <b>66</b>A; instruction bytes storage <b>72</b>B may receive a block of instruction bytes from subqueues <b>66</b>B; and instruction bytes storage <b>72</b>C may receive a block of instruction bytes from subqueue <b>66</b>C. On the other hand, if instruction bytes storage <b>72</b>A is storing a block of instruction bytes during a clock cycle, instruction bytes storage <b>72</b>B may receive a block of instruction bytes from subqueue <b>66</b>A and instruction bytes storage <b>72</b>C may receive a block of instruction bytes from subqueue <b>66</b>B. Generally, a block of instruction bytes may be selected for storage into instruction bytes storages <b>72</b> via instruction bytes multiplexors <b>88</b>, and a particular block of instruction bytes may be validated if an instruction within the particular block of instruction bytes is conveyed into instruction position storages <b>74</b>.</p><p>Instruction identifiers stored in instruction position storages <b>74</b>A-<b>74</b>C are directly conveyed to corresponding decode units <b>20</b>A-<b>20</b>C. Control unit <b>76</b> signals which instructions have been selected for dispatch via a dispatch bus <b>92</b> coupled to decode units <b>20</b>. If a decode unit <b>20</b>A-<b>20</b>C receives an indication that the corresponding instruction is being dispatched, the decode unit <b>20</b> operates upon the received instruction information and corresponding instruction bytes selected via multiplexors <b>90</b>. It is noted that, in the case of overflow instructions, instruction bytes from more than one of instruction bytes storages <b>72</b> may be selected by a given output multiplexor <b>90</b>A-<b>90</b>C.</p><p>Control unit <b>76</b> receives synchronization signals from MROM unit <b>34</b> in order to dispatch MROM instructions. The sync signal upon sync line <b>82</b> indicates, when asserted, that MROM unit <b>34</b> is prepared to dispatch an MROM instruction. Control unit <b>76</b> does not select an MROM instruction for dispatch unless the sync signal is asserted. Control unit <b>76</b> asserts a similar sync signal to MROM unit <b>34</b> to indicate that the MROM instruction has been selected. Additionally, a two instruction line <b>84</b> carries an indication, when asserted, that the next MROM instruction to be dispatched translates into two fast path instructions. Control unit <b>76</b> uses the two instruction indication to determine if a fast path instruction can be concurrently dispatched with the MROM instruction.</p><p>It is noted that, although multiplexors <b>86</b>, <b>88</b>, and <b>90</b> as shown in FIG. 4 are individual multiplexors, the selection represented by each multiplexor may actually be performed by multiple multiplexors, arranged in cascade or in parallel.</p><p>Turning now to FIG. 5, a diagram is shown depicting exemplary information stored in a field <b>110</b> of subqueues <b>66</b>A-<b>66</b>C, according to one embodiment. For example, field <b>110</b> may be field I<b>0</b>, I<b>1</b>, or I<b>2</b> for the first, second, or third instruction within an instruction block. Each field stores equivalent information regarding different instructions. Field <b>110</b> stores a valid indication <b>112</b>, a start pointer <b>114</b>, an end pointer <b>116</b>, a valid mask <b>118</b>, an MROM/fast path indication <b>120</b>, and a branch prediction indication <b>122</b>.</p><p>Valid indication <b>112</b> identifies the validity or invalidity of the remainder of the information stored in field <b>110</b>. If the valid indication indicates validity, then instruction identification information is stored in field <b>110</b>. If the valid indication indicates invalidity, then instruction identification information is not stored within field <b>110</b> (i.e. field <b>110</b> is empty). In one embodiment, valid indication <b>112</b> comprises a bit indicative, when set, that instruction identification information is stored within field <b>110</b>. When clear, the bit indicates that instruction identification information is not stored within field <b>110</b>.</p><p>Start pointer <b>114</b> and end pointer <b>116</b> locate the byte positions within the instruction block at which the instruction identified in field <b>110</b> begins and ends, respectively. For embodiments in which an instruction block includes 8 bytes, start pointer <b>114</b> and end pointer <b>116</b> each comprise three bit values indicating the numerical position between zero and seven of the respective start or end point. Valid mask <b>118</b> is a mask of zeros and ones. Each bit in the mask corresponds to one of the bytes within the instruction block. Bits in the mask corresponding to bytes not included within the instruction identified by field <b>110</b> are set to zero. Conversely, bits in the mask corresponding to bytes included within the instruction are set to one. For example, if the instruction identified by field <b>110</b> begins at the third byte within the instruction block and ends at the fifth byte within the instruction block, the start pointer is 010, the end pointer is 100, and the mask is 00111000 (all expressed in binary format). The start pointer, end pointer, and mask are used to generate selection controls for selecting bytes within the instruction block when the instruction is selected for issue.</p><p>MROM/fast path indication <b>120</b> indicates the MROM or fast path nature of the instruction identified by field <b>110</b>. In one embodiment, indication <b>120</b> comprises a bit indicative, when set, that the instruction is an MROM instruction. When clear, the bit indicates that the instruction is a fast past instruction. Finally, branch prediction indication <b>122</b> comprises a bit indicative, when set, that the instruction is a branch instruction which is predicted taken. When clear, the bit indicates that the instruction is either not a branch instruction or is a branch instruction predicted not taken.</p><p>Turning now to FIG. 6, a diagram is shown depicting exemplary information stored in a shared field <b>130</b> of a subqueue <b>66</b>A-<b>66</b>C. Information stored in shared field <b>130</b> is shared information valid for the entire instruction block, according to one embodiment. An address bits field <b>132</b>, a functional bits field <b>134</b>, a segment limit field <b>136</b>, an overflow indication <b>138</b>, and an instruction bytes field <b>140</b> are included. Address bits field <b>132</b> stores a pair of address bits which identify the quarter of the cache line from which the instruction block was fetched. Functional bits field <b>134</b> stores the original functional bits from the predecode data associated with the instruction bytes within the instruction block.</p><p>Segment limit field <b>136</b> is used to detect instructions being dispatched from outside the code segment. As will be appreciated by those skilled in the art, the x86 microprocessor architecture divides the memory space into segments. One of these segments is the code segment, from which instructions are fetched. The segment has a defined limit, which may be of arbitrary size. If instruction execution proceeds outside of the code segment, a segment limit violation exception is signalled. Microprocessor <b>10</b> may handle segment limit violations as follows: if an entire set of instructions fetched from instruction cache <b>16</b> during a clock cycle lies outside the code segment, the instructions are not conveyed to instruction alignment unit <b>18</b>. Instead, the segment limit violation is signalled to reorder buffer <b>32</b> and to the control logic within instruction cache <b>16</b>. The control logic generates a signal to MROM unit <b>34</b>, causing MROM unit <b>34</b> to begin dispatching the exception service routine corresponding to the segment limit violation. If instructions prior to the segment limit violation retire successfully (as opposed to being discarded due to branch misprediction or other exception), then the exception may be taken at that time. However, the limit may be arbitrary and therefore may fall within the set of instructions fetched from instruction cache <b>16</b>. Segment limit field <b>136</b> is included for handling this case. If the limit is crossed within the instruction block, then segment limit field <b>136</b> indicates which byte position represents the segment limit. In one embodiment, segment limit field <b>136</b> comprises four bits to indicate a limit at one of the sixteen bytes within the instruction cache line. If an instruction beyond the limit imposed by segment limit field <b>136</b> is dispatched, an exception is signalled to reorder buffer <b>32</b>.</p><p>Overflow indication <b>138</b> indicates that one of the instructions within the instruction block overflows into the subsequent instruction block. Information regarding the overflowing instruction is stored in field I<b>2</b> of the corresponding subqueue <b>66</b>A-<b>66</b>C. In one embodiment, overflow indication <b>138</b> comprises a bit indicative, when set, that an instruction within the instruction block overflows. When clear, the bit indicates that no instruction within the instruction block overflows. If overflow indication <b>138</b> is set, then the valid indication within field I<b>2</b> is clear. Alternatively, overflow indication <b>138</b> is clear if the valid indication within field I<b>2</b> is set. In this manner, field I<b>2</b> is indicated either to store an overflow instruction or a valid instruction ending within the instruction block, but not both. Additionally, field I<b>2</b> is indicated to be not storing an instruction if both overflow indication <b>138</b> and the valid indication for position I<b>2</b> are clear. Instruction bytes field <b>140</b> stores the actual instruction bytes included within the instruction block. In one embodiment, instruction bytes field <b>140</b> is eight bytes wide.</p><p>Turning next to FIG. 7, an exemplary instruction identifier <b>150</b> stored by one embodiment of instruction position storages <b>74</b> is shown. Other embodiments may employ different instruction identifiers than the embodiment shown in FIG. <b>7</b>. As shown in FIG. 7, instruction identifier <b>150</b> includes valid indication <b>112</b>, start pointer <b>114</b>, end pointer <b>116</b>, valid mask <b>118</b>, MROM/fast path indication <b>120</b>, and branch prediction <b>122</b> from the instruction field of the subqueue <b>66</b>A-<b>66</b>C which stored the instruction when the instruction was conveyed into the instruction position storage <b>74</b>.</p><p>Additionally, instruction identifier <b>150</b> includes a start block field <b>152</b> and an end block field <b>154</b>. Start block field <b>152</b> identifies which of instruction bytes storages <b>72</b> stores the start byte of the instruction. Similarly, end block field <b>154</b> identifies which of instruction bytes storages <b>72</b> stores the end byte of the instruction. For non-overflow instructions, start block field <b>152</b> and end block field <b>154</b> store the same value. Using start block field <b>152</b>, end block field <b>154</b>, start pointer <b>114</b>, and end pointer <b>116</b>, control unit <b>76</b> may form select controls for output multiplexors <b>90</b>.</p><p>Turning now to FIG. 8, a computer system <b>200</b> including microprocessor <b>10</b> is shown. Computer system <b>200</b> further includes a bus bridge <b>202</b>, a main memory <b>204</b>, and a plurality of input/output (I/O) devices <b>206</b>A-<b>206</b>N. Plurality of I/O devices <b>206</b>A-<b>206</b>N will be collectively referred to as I/O devices <b>206</b>. Microprocessor <b>10</b>, bus bridge <b>202</b>, and main memory <b>204</b> are coupled to a system bus <b>208</b>. I/O devices <b>206</b> are coupled to an I/O bus <b>210</b> for communication with bus bridge <b>202</b>.</p><p>Bus bridge <b>202</b> is provided to assist in communications between I/O devices <b>206</b> and devices coupled to system bus <b>208</b>. I/O devices <b>206</b> typically require longer bus clock cycles than microprocessor <b>10</b> and other devices coupled to system bus <b>208</b>. Therefore, bus bridge <b>202</b> provides a buffer between system bus <b>208</b> and input/output bus <b>210</b>. Additionally, bus bridge <b>202</b> translates transactions from one bus protocol to another. In one embodiment, input/output bus <b>210</b> is an Enhanced Industry Standard Architecture (EISA) bus and bus bridge <b>202</b> translates from the system bus protocol to the EISA bus protocol. In another embodiment, input/output bus <b>210</b> is a Peripheral Component Interconnect (PCI) bus and bus bridge <b>202</b> translates from the system bus protocol to the PCI bus protocol. It is noted that many variations of system bus protocols exist. Microprocessor <b>10</b> may employ any suitable system bus protocol.</p><p>I/O devices <b>206</b> provide an interface between computer system <b>200</b> and other devices external to the computer system. Exemplary I/O devices include a modem, a serial or parallel port, a sound card, etc. I/O devices <b>206</b> may also be referred to as peripheral devices. Main memory <b>204</b> stores data and instructions for use by microprocessor <b>10</b>. In one embodiment, main memory <b>204</b> includes at least one Dynamic Random Access Memory (DRAM) and a DRAM memory controller.</p><p>It is noted that although computer system <b>200</b> as shown in FIG. 8 includes one bus bridge <b>202</b>, other embodiments of computer system <b>200</b> may include multiple bus bridges <b>202</b> for translating to multiple dissimilar or similar I/O bus protocols. Still further, a cache memory for enhancing the performance of computer system <b>200</b> by storing instructions and data referenced by microprocessor <b>10</b> in a faster memory storage may be included. The cache memory may be inserted between microprocessor <b>10</b> and system bus <b>208</b>, or may reside on system bus <b>208</b> in a \u201clookaside\u201d configuration. It is still further noted that the functions of bus bridge <b>202</b>, main memory <b>204</b>, and the cache memory may be integrated into a chipset which interfaces to microprocessor <b>10</b>.</p><p>It is still further noted that the present discussion may refer to the assertion of various signals. As used herein, a signal is \u201casserted\u201d if it conveys a value indicative of a particular condition. Conversely, a signal is \u201cdeasserted\u201d if it conveys a value indicative of a lack of a particular condition. A signal may be defined to be asserted when it conveys a logical zero value or, conversely, when it conveys a logical one value. Additionally, various values have been described as being discarded in the above discussion. A value may be discarded in a number of manners, but generally involves modifying the value such that it is ignored by logic circuitry which receives the value. For example, if the value comprises a bit, the logic state of the value may be inverted to discard the value. If the value is an n-bit value, one of the n-bit encodings may indicate that the value is invalid. Setting the value to the invalid encoding causes the value to be discarded. Additionally, an n-bit value may include a valid bit indicative, when set, that the n-bit value is valid. Resetting the valid bit may comprise discarding the value. Other methods of discarding a value may be used as well.</p><p>Table 1 below indicates fast path, double dispatch, and MROM instructions for one embodiment of microprocessor <b>10</b> employing the x86 instruction set:</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217PT\"></colspec><thead valign=\"bottom\"><row><entry morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\">TABLE 1</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" morerows=\"0\" nameend=\"1\" namest=\"1\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\">x86 Fast Path, Double Dispatch, and MROM Instructions</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"OFFSET\" colwidth=\"28PT\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"77PT\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"112PT\"></colspec><tbody valign=\"top\"><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">X86 Instruction</entry><entry morerows=\"0\" valign=\"top\">Instruction Category</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"2\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">AAA</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">AAD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">AAM</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">AAS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">ADC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">ADD</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">AND</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">ARPL</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BOUND</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BSF</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BSR</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BSWAP</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BT</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BTC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BTR</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">BTS</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CALL</entry><entry morerows=\"0\" valign=\"top\">fast path/double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CBW</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CWDE</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CLC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CLD</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CLI</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CLTS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMP</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMPS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMPSB</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMPSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMPSD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMPXCHG</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CMPXCHG8B</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CPUID</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CWD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">CWQ</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">DDA</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">DAS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">DEC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">DIV</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">ENTER</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">HLT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">IDIV</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">IMUL</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">IN</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INSB</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INSD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INTO</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INVD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">INVLPG</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">IRET</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">IRETD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">Jcc</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">JCXZ</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">JECXZ</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">JMP</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LAHF</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LAR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LDS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LES</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LFS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LGS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LSS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LEA</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LEAVE</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LGDT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LIDT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LLDT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LMSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LODS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LODSB</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LODSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LODSD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LOOP</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LOOPcond</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LSL</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">LTR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOV</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOVCC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOV.CR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOV.DR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOVS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOVSB</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOVSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOVSD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOVSX</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MOVZX</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">MUL</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">NEG</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">NOP</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">NOT</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">OR</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">OUT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">OUTS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">OUTSB</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">OUTSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">OUTSD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">POP</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">POPA</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">POPAD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">POPF</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">POPFD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">PUSH</entry><entry morerows=\"0\" valign=\"top\">fast path/double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">PUSHA</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">PUSHAD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">PUSHF</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">PUSHFD</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">RCL</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">RCR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">ROL</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">ROR</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">RDMSR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">REP</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">REPE</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">REPZ</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">REPNE</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">REPNZ</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">RET</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">RSM</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SAHF</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SAL</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SAR</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SHL</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SHR</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SBB</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SCAS</entry><entry morerows=\"0\" valign=\"top\">double dispatch</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SCASB</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SCASW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SCASD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SETcc</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SGDT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SIDT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SHLD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SHRD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SLDT</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SMSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STC</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STD</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STI</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STOS</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STOSB</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STOSW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STOSD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">STR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">SUB</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">TEST</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">VERR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">VERW</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">WBINVD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">WRMSR</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">XADD</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">XCHG</entry><entry morerows=\"0\" valign=\"top\">MROM</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">XLAT</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">XLATB</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry morerows=\"0\" valign=\"top\">XOR</entry><entry morerows=\"0\" valign=\"top\">fast path</entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"center\" morerows=\"0\" nameend=\"2\" namest=\"OFFSET\" rowsep=\"1\" valign=\"top\"></entry></row><row><entry morerows=\"0\" valign=\"top\"></entry><entry align=\"left\" morerows=\"0\" nameend=\"2\" namest=\"OFFSET\" valign=\"top\">Note: Instructions including an SIB byte are also considered double dispatch instructions. </entry></row></tbody></tgroup></table></tables></p><p>Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "James K.", "last_name": "Pickett", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "ADVANCED MICRO DEVICES, INC."}, {"first_name": "", "last_name": "GLOBALFOUNDRIES U.S. INC.", "name": ""}, {"first_name": "", "last_name": "GLOBALFOUNDRIES INC.", "name": ""}, {"first_name": "", "last_name": "GLOBALFOUNDRIES INC.", "name": ""}, {"first_name": "", "last_name": "ADVANCED MICRO DEVICES, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F   9/312"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F   9/30        20060101A I20051008RMEP"}, {"label": "G06F   9/38        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "712204"}, {"primary": false, "label": "712E09055"}, {"primary": false, "label": "712206"}, {"primary": false, "label": "712213"}, {"primary": false, "label": "712E09029"}, {"primary": false, "label": "712207"}], "ecla_classes": [{"label": "G06F   9/38C2"}, {"label": "G06F   9/30T2A"}, {"label": "G06F   9/38B9"}], "cpc_classes": [{"label": "G06F   9/30152"}, {"label": "G06F   9/30152"}, {"label": "G06F   9/382"}, {"label": "G06F   9/3816"}, {"label": "G06F   9/382"}, {"label": "G06F   9/3816"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1998-04-30", "application_date": "1998-04-30", "family_members": [{"ucid": "US-6175908-B1", "titles": [{"lang": "EN", "text": "Variable byte-length instructions using state of function bit of second byte of plurality of instructions bytes as indicative of whether first byte is a prefix byte"}]}]}