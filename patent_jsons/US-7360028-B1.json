{"patent_number": "US-7360028-B1", "publication_id": 88706903, "family_id": 39281711, "publication_date": "2008-04-15", "titles": [{"lang": "EN", "text": "Explicit store-to-instruction-space instruction for self-modifying code and ensuring memory coherence between instruction cache and shared memory using a no-snoop protocol"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA51291100\"><p num=\"p-0001\">A method and apparatus for performing a store-to-instruction-space instruction are provided. A unique opcode indicates that a data value is to be written to an instruction space in main memory. The instruction is received and executed. After the instruction space is modified to contain the data value, further processing is performed to ensure coherence between main memory and an instruction cache.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00001\" num=\"00001\">\n<claim-text>1. A method for self-modifying code comprising:\n<claim-text>distinguishing between a store-to-data-space instruction and a store-to-instruction-space instruction in an execution sequence of instructions;</claim-text>\n<claim-text>executing the store-to-data-space instruction to update a data space target in a memory shared amongst a plurality of processing units that each has a separate instruction cache;</claim-text>\n<claim-text>executing the store-to-instruction-space instruction to update an instruction space target in the shared memory;</claim-text>\n<claim-text>ensuring coherency between the instruction caches and the shared memory without snooping traffic that corresponds to a store-to-data-space instruction; and</claim-text>\n<claim-text>at least one of:\n<claim-text>updating a location in a data cache incident to the executing the store-to-instruction-space instruction when the location hosts content at an instruction space target indicated by the store-to-instruction-space instruction, wherein the data cache is accessible to the plurality of processing units;</claim-text>\n<claim-text>bypassing the data cache and writing directly to the shared memory incident to the executing the store-to-instruction-space instruction when the data cache does not represent an instruction space target indicated by the store-to-instruction-space instruction; or</claim-text>\n<claim-text>incident to the executing the store-to-instruction-space instruction wherein the store-to-instruction-space instructions indicates the instruction space target and new content, when the location in the data cache does not host content at the instruction space target, then copying content from the instruction space target to the location in the data cache, updating the data cache location with the new content, and copying the new content to the instruction space target from the data cache location.</claim-text>\n</claim-text>\n</claim-text>\n</claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00002\" num=\"00002\">\n<claim-text>2. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the instruction space and the data space are commingled in the shared memory.</claim-text>\n</claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00003\" num=\"00003\">\n<claim-text>3. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the ensuring coherency comprises:\n<claim-text>broadcasting the instruction space target to at least one of the plurality of processing units incident to execution of the store-to-instruction-space instruction; and</claim-text>\n<claim-text>invalidating a location in the instruction cache of the at least one of the plurality of processing units that corresponds to the instruction space target.</claim-text>\n</claim-text>\n</claim>"}, {"num": 4, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00004\" num=\"00004\">\n<claim-text>4. The method of <claim-ref idref=\"CLM-00003\">claim 3</claim-ref>, wherein the invalidated instruction cache location hosts content of the instruction space target.</claim-text>\n</claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00005\" num=\"00005\">\n<claim-text>5. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the ensuring coherency comprises installing a new line in at least one of the instruction caches of a first of the plurality of processing units incident to a second of the processing units executing the store-to-instruction-space instruction.</claim-text>\n</claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00006\" num=\"00006\">\n<claim-text>6. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the ensuring coherency comprises updating a line in at least one of the instruction caches of a first of the plurality of processing units incident to a second of the processing units executing the store-to-instruction-space instruction, wherein the line corresponds to the instruction space target.</claim-text>\n</claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00007\" num=\"00007\">\n<claim-text>7. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, comprising updating the location in a data cache incident to the executing the store-to-instruction-space instruction when the location hosts content at an instruction space target indicated by the store-to-instruction-space instruction, wherein the data cache is accessible to the plurality of processing units.</claim-text>\n</claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00008\" num=\"00008\">\n<claim-text>8. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, comprising bypassing the data cache and writing directly to the shared memory incident to the executing the store-to-instruction-space instruction when the data cache does not represent an instruction space target indicated by the store-to-instruction-space instruction.</claim-text>\n</claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00009\" num=\"00009\">\n<claim-text>9. The method of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, comprising:\n<claim-text>incident to the executing the store-to-instruction-space instruction wherein the store-to-instruction-space instructions indicates the instruction space target and new content, when the location in the data cache does not host content at the instruction space target, then copying content from the instruction space target to the location in the data cache, updating the data cache location with the new content, and copying the new content to the instruction space target from the data cache location.</claim-text>\n</claim-text>\n</claim>"}, {"num": 10, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00010\" num=\"00010\">\n<claim-text>10. An apparatus comprising:\n<claim-text>a memory operable to commingle data and instruction information in a single address space;</claim-text>\n<claim-text>a first processing unit and a second processing unit coupled to share the memory, each of the processing units having an instruction cache and each being adapted to execute both a store-to-data-space instruction and a store-to-instruction-space instruction, and ensure coherence between the respective instruction caches and the shared memory without snooping traffic that corresponds to a store-to-data-space instruction; and</claim-text>\n<claim-text>a data cache, wherein the processing units are adapted to update a location in the data cache incident to executing an instance of the store-to-instruction-space instruction when the location hosts content at an instruction space target indicated by the store-to-instruction-space instruction instance.</claim-text>\n</claim-text>\n</claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00011\" num=\"00011\">\n<claim-text>11. The apparatus of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref>, wherein the processing units being adapted to ensure coherence comprises the processing units being adapted to broadcast an instruction space target indicated by an instance of the store-to-instruction-space instruction incident to execution of the store-to-instruction-space instruction instance and adapted to invalidate a location in their respective instruction caches after receiving the broadcast.</claim-text>\n</claim>"}, {"num": 12, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00012\" num=\"00012\">\n<claim-text>12. The apparatus of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref>, wherein the processing units being adapted to ensure coherence comprises the processing units being adapted to install new lines in respective instruction caches thereof incident to execution of an instance of the store-to-instruction-space instruction.</claim-text>\n</claim>"}, {"num": 13, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00013\" num=\"00013\">\n<claim-text>13. The apparatus of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref>, wherein the processing units being adapted to ensure coherence comprises the processing units being adapted to update corresponding lines in respective instruction caches thereof incident to execution of an instance of the store-to-instruction-space instruction.</claim-text>\n</claim>"}, {"num": 14, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00014\" num=\"00014\">\n<claim-text>14. The apparatus of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref> further comprising an address bus coupled to the shared memory and the first and second processing units.</claim-text>\n</claim>"}, {"num": 15, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00015\" num=\"00015\">\n<claim-text>15. The apparatus of <claim-ref idref=\"CLM-00010\">claim 10</claim-ref> further comprising a network interface.</claim-text>\n</claim>"}, {"num": 16, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00016\" num=\"00016\">\n<claim-text>16. An apparatus comprising:\n<claim-text>a memory operable to commingle data and instruction information in a single address space; a first processing unit and a second processing unit coupled to share the memory, each of the processing units having an instruction cache and each being adapted to execute both a store-to-data-space instruction and a store-to-instruction-space instruction, and ensure coherence between the respective instruction caches and the shared memory without snooping traffic that corresponds to a store-to-data-space instruction; and</claim-text>\n<claim-text>a data cache, wherein the processing units are adapted to bypass the data cache and write directly to the memory incident to executing an instance of the store-to-instruction-space instruction when the data cache does not represent an instruction space target indicated by the store-to-instruction-space instruction instance.</claim-text>\n</claim-text>\n</claim>"}, {"num": 17, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00017\" num=\"00017\">\n<claim-text>17. An apparatus comprising:\n<claim-text>a memory operable to commingle data and instruction information in a single address space; a first processing unit and a second processing unit coupled to share the memory, each of the processing units having an instruction cache and each being adapted to execute both a store-to-data-space instruction and a store-to-instruction-space instruction, and ensure coherence between the respective instruction caches and the shared memory without snooping traffic that corresponds to a store-to-data-space instruction; and</claim-text>\n<claim-text>a data cache,</claim-text>\n<claim-text>wherein, incident to executing an instance of the store-to-instruction-space instruction that indicates an instruction space target and new content, the processing units are adapted to,\n<claim-text>when a location in the data cache does not host content at the instruction space target, copy content from the instruction space target to a location in the data cache,\n<claim-text>update the data cache location with the new content, and</claim-text>\n<claim-text>copy the new content to the instruction space target from the data cache location.</claim-text>\n</claim-text>\n</claim-text>\n</claim-text>\n</claim>"}, {"num": 18, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00018\" num=\"00018\">\n<claim-text>18. A computer program product encoded on one or more computer-readable storages, the computer program product comprising:\n<claim-text>at least one instance of a store-to-data-space instruction executable to write to a target in data space in a shared memory, the first instruction type including an opcode, a data space target specifier, and a source specifier; and</claim-text>\n<claim-text>at least one instance of a store-to-instruction-space instruction executable to write to a target in instruction space in the shared memory, the second instruction type including an instruction space target specifier, a source specifier, and an opcode to distinguish the store-to-instruction-space instruction from the store-to-data-space instruction,</claim-text>\n<claim-text>wherein data space targets and instruction space targets are commingled in the shared memory; and</claim-text>\n<claim-text>wherein the computer program product further comprises executable instructions for causing a computer to perform at least one of:\n<claim-text>updating a location in a data cache incident to execution of the store-to-instruction-space instruction when the location hosts content at the instruction space target, wherein the data cache is accessible to a plurality of processing units;</claim-text>\n<claim-text>bypassing the data cache and writing directly to the shared memory incident to execution of the store-to-instruction-space instruction when the data cache does not represent the instruction space target; or</claim-text>\n<claim-text>incident to execution of the store-to-instruction-space instruction wherein the store-to-instruction-space instructions indicates the instruction space target and new content, when the location in the data cache does not host content at the instruction space target, then copying content from the instruction space target to the location in the data cache, updating the data cache location with the new content, and copying the new content to the instruction space target from the data cache location.</claim-text>\n</claim-text>\n</claim-text>\n</claim>"}, {"num": 19, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00019\" num=\"00019\">\n<claim-text>19. The computer program product of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, wherein the instruction space target specifier of the store-to-instruction-space instruction encodes at least a portion of an address for a location in instruction space.</claim-text>\n</claim>"}, {"num": 20, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00020\" num=\"00020\">\n<claim-text>20. The computer program product of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, wherein the source specifier encodes at least one of a source register, a location in an instruction cache, one or more immediate values, or a location in the shared memory.</claim-text>\n</claim>"}, {"num": 21, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00021\" num=\"00021\">\n<claim-text>21. The computer program product of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, comprising executable instructions for causing a computer to perform:\n<claim-text>updating a location in a data cache incident to execution of the store-to-instruction-space instruction when the location hosts content at the instruction space target, wherein the data cache is accessible to a plurality of processing units.</claim-text>\n</claim-text>\n</claim>"}, {"num": 22, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00022\" num=\"00022\">\n<claim-text>22. The computer program product of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, comprising executable instructions for causing a computer to perform:\n<claim-text>bypassing the data cache and writing directly to the shared memory incident to execution of the store-to-instruction-space instruction when the data cache does not represent the instruction space target.</claim-text>\n</claim-text>\n</claim>"}, {"num": 23, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00023\" num=\"00023\">\n<claim-text>23. The computer program product of <claim-ref idref=\"CLM-00018\">claim 18</claim-ref>, comprising executable instructions for causing a computer to perform:\n<claim-text>incident to execution of the store-to-instruction-space instruction wherein the store-to-instruction-space instructions indicates the instruction space target and new content, when the location in the data cache does not host content at the instruction space target, then copying content from the instruction space target to the location in the data cache, updating the data cache location with the new content, and copying the new content to the instruction space target from the data cache location.</claim-text>\n</claim-text>\n</claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES16395684\">\n<?BRFSUM description=\"Brief Summary\" end=\"lead\"?>\n<h4>BACKGROUND OF THE INVENTION</h4>\n<p num=\"p-0002\">1. Field of the Invention</p>\n<p num=\"p-0003\">The present invention relates generally to microprocessors, and more particularly, to an STI instruction that explicitly indicates that a store instruction is being utilized to modify instruction space in a computer system.</p>\n<p num=\"p-0004\">2. Description of the Related Art</p>\n<p num=\"p-0005\">The present invention relates to two concepts discussed herein: multiple-thread processing and instruction sets. Regarding multiple-thread processing, an automated system for various processing applications may handle multiple events or processes concurrently. A single process is termed a thread of control, or \u201cthread\u201d, and is the basic unit of operation of independent dynamic action within the system. A program has at least one thread. A system performing concurrent operations typically has many threads, some of which are transitory and others enduring. Single-processor systems can only have illusory concurrent threads, typically attained by time-slicing of processor execution, shared among a plurality of threads. Systems that execute among multiple processors allow for true concurrent threads.</p>\n<p num=\"p-0006\">Some programming languages are particularly designed to support multiple-threading. One such language is the Java\u2122 programming language that is advantageously executed using an abstract computing machine, the Java Virtual Machine\u2122. A Java Virtual Machine\u2122 is capable of supporting multiple threads of execution at one time. The multiple threads independently execute Java code that operates on Java values and objects residing in a shared main memory. The multiple threads may be supported using multiple hardware processors, by time-slicing a single hardware processor, or by time-slicing many hardware processors. In 1990 programmers at Sun Microsystems developed a universal programming language, eventually known as \u201cthe Java\u2122 programming language\u201d. Java\u2122, Sun, Sun Microsystems and the Sun Logo are trademarks or registered trademarks of Sun Microsystems, Inc. in the United States and other countries. All SPARC trademarks, including UltraSPARC I and UltraSPARC II, are used under license and are trademarks of SPARC International, Inc. in the United States and other countries. Products bearing SPARC trademarks are based upon an architecture developed by Sun Microsystems, Inc.</p>\n<h4>SUMMARY OF THE INVENTION</h4>\n<p num=\"p-0007\">The present invention provides an explicit instruction for the implementation of self-modifying code. In one embodiment, an STI instruction is provided for a microprocessor that supports the use of data and instruction caches in a multi-thread processing environment.</p>\n<p num=\"p-0008\">At least one embodiment provides a method to implement a processor instruction. The method includes receiving a store-to-instruction-space (\u201cSTI\u201d) instruction where the instruction includes an opcode, a storage data register specifier that specifies a register containing a datum to be stored to instruction space. The instruction also includes an instruction address specifier that encodes an instruction address in main memory that is to be updated with the storage datum. The method further comprises modifying the instruction address to contain the storage datum and ensuring coherence between the modified main memory and at least one instruction cache. In at least one embodiment, the instruction is received as one of a plurality of instructions in an instruction word.</p>\n<p num=\"p-0009\">In at least one embodiment, the instruction address specifier encodes one or more address registers, with each address register containing at least a portion of the instruction address. In another embodiment, the instruction address specifier encodes an immediate address value. In another embodiment, the opcode is a particular unique bit pattern that indicates to the hardware that the storage datum is to be written to an instruction space, the instruction space including the instruction address.</p>\n<p num=\"p-0010\">At least one embodiment of the method further comprises determining whether the instruction address to be modified is already in the data cache. If so, then the proper cache line in the data cache is modified to contain the storage datum, and the storage datum is then transmitted from the data cache to the instruction address in main memory. In one embodiment, the storage datum is transmitted to the instruction address by copying the contents of the data cache line to the instruction address. In another embodiment, the storage datum is transmitted to the instruction address by moving the contents of the data cache line to the instruction address and then clearing the data cache line. In another embodiment, the method further comprises indicating, after the contents are moved from the data cache line to the instruction address, that the contents of the data cache line are no longer valid.</p>\n<p num=\"p-0011\">In another embodiment, if the contents of the instruction address are not available in the data cache, the storage datum is stored directly to the instruction address. In another embodiment, when the contents of the instruction address are not available in the data cache, the contents of the instruction address are copied from main memory to a data cache line. The contents of the data cache line are then modified to contain the storage datum, and the contents of the data cache line are then copied to the instruction address.</p>\n<p num=\"p-0012\">In at least one embodiment, the way that coherence is ensured is that the contents of a cache line in an instruction cache that corresponds to the instruction address are invalidated by broadcasting the instruction cache address to the at least one instruction cache. In another embodiment, updating the contents of the instruction cache to reflect the storage datum ensures coherence. In another embodiment, coherence is assured by allocating a new line in the instruction cache and updating the new line to contain the storage datum.</p>\n<p num=\"p-0013\">At least one embodiment of the present invention provides a processor that performs a store-to-instruction-space (\u201cSTI\u201d) instruction. The processor includes at least one functional unit, a main memory, and a module for receiving the STI instruction and executing it. In at least one embodiment, the processor includes a plurality of functional units. The STI instruction is received and executed on at least one functional unit. In at least one embodiment, the processor further comprises a data cache coupled to the main memory and an instruction cache coupled to the data cache.</p>\n<p num=\"p-0014\">The module for receiving the STI instruction and executing further comprises modules that perform the method described above.</p>\n<?BRFSUM description=\"Brief Summary\" end=\"tail\"?>\n<?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?>\n<description-of-drawings>\n<h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4>\n<p num=\"p-0015\">The present invention may be better understood, and its numerous objects, features, and advantages made apparent to those skilled in the art by referencing the accompanying drawings.</p>\n<p num=\"p-0016\"><figref idrefs=\"DRAWINGS\">FIG. 1</figref> is a schematic block diagram illustrating one embodiment of a multiple-thread processor.</p>\n<p num=\"p-0017\"><figref idrefs=\"DRAWINGS\">FIG. 2</figref> is a schematic block diagram showing the core of one embodiment of a multi-thread processor.</p>\n<p num=\"p-0018\"><figref idrefs=\"DRAWINGS\">FIG. 3</figref> illustrates the format of the STI instruction in accordance with one embodiment of the present invention.</p>\n<p num=\"p-0019\"><figref idrefs=\"DRAWINGS\">FIG. 4</figref> is a schematic block diagram that illustrates the data flow in an STI instruction.</p>\n<p num=\"p-0020\"><figref idrefs=\"DRAWINGS\">FIG. 5</figref> illustrates an exemplary format of a variable-length instruction packet <b>500</b> for processor <b>100</b>.</p>\n</description-of-drawings>\n<?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?>\n<?DETDESC description=\"Detailed Description\" end=\"lead\"?>\n<p num=\"h-0004\">The use of the same reference symbols in different drawings indicates similar or identical items.</p>\n<h4>DESCRIPTION OF THE PREFERRED EMBODIMENT(S)</h4>\n<p num=\"p-0021\">The present invention is an STI instruction that explicitly indicates that a store instruction is being utilized to modify instruction space in a computer system, thereby providing for self-modifying software code. For clarification, an exemplary computer processor capable of executing the STI instruction is discussed below. The exemplary computer processor supports the use of data and instruction caches in a multi-thread processing environment. The discussion below of an exemplary computer processor is followed by a detailed discussion of the STI instruction itself.</p>\n<p num=\"p-0022\">Referring to <figref idrefs=\"DRAWINGS\">FIG. 1</figref>, a schematic block diagram illustrates a processor <b>100</b> having an improved architecture for multiple-thread operation on the basis of a highly parallel structure including multiple independent parallel execution paths, shown herein as two media processing units <b>110</b> and <b>112</b>. The execution paths execute in parallel across threads and include a multiple-instruction parallel pathway within a thread. The multiple independent parallel execution paths include functional units executing an instruction set having special data-handling instructions that are advantageous in a multiple-thread environment.</p>\n<p num=\"p-0023\">The illustrative processor <b>100</b> is depicted in <figref idrefs=\"DRAWINGS\">FIG. 1</figref> as also comprising interface controllers. The interface controllers include an UltraPort Architecture Interconnect (UPA) controller <b>116</b> and a peripheral component interconnect (PCI) interconnect <b>120</b>. The processor also includes a memory interface <b>102</b> and a geometry decompressor (GPP) <b>104</b>.</p>\n<p num=\"p-0024\">The multiple-threading architecture of the processor <b>100</b> is advantageous for usage in executing multiple-threaded applications using a language such as the Java\u2122 language running under a multiple-threaded operating system on a multiple-threaded Java Virtual Machine\u2122. The illustrative processor <b>100</b> includes two independent processor elements, the media processing units <b>110</b> and <b>112</b>, forming two independent parallel execution paths. A language that supports multiple threads, such as the Java\u2122 programming language generates two threads that respectively execute in the two parallel execution paths with very little overhead incurred. The special instructions executed by the multiple-threaded processor include instructions for accessing arrays, and instructions that support garbage collection.</p>\n<p num=\"p-0025\">A single integrated circuit chip implementation of a processor <b>100</b> includes two media processing units <b>110</b> and <b>112</b> and a shared data cache <b>106</b>. The shared data cache <b>106</b> is a dual-ported storage that is shared among the media processing units <b>110</b> and <b>112</b> with one port allocated to each media processing unit. The data cache <b>106</b> is four-way set associative, follows a write-back protocol, and supports hits in the fill buffer (not shown). The data cache <b>106</b> allows fast data sharing and eliminates the need for a complex, error-prone cache coherency protocol between the media processing units <b>110</b> and <b>112</b>.</p>\n<p num=\"p-0026\"><figref idrefs=\"DRAWINGS\">FIG. 1</figref> also shows a general purpose processor (GPP) <b>104</b> connected to the shared data cache <b>106</b>, an Ultra Port Architecture (UPA) Controller <b>116</b>, and a memory interface <b>102</b>.</p>\n<p num=\"p-0027\">Referring to <figref idrefs=\"DRAWINGS\">FIG. 2</figref>, a schematic block diagram shows the core of the processor <b>100</b>. Each of the media processing units <b>110</b> and <b>112</b> include a pipeline control unit <b>226</b> coupled between the instruction buffer <b>214</b> and a plurality of execution units. The media processing units <b>110</b> and <b>112</b> each include a plurality of execution units <b>222</b>, <b>220</b><i>a</i>-<b>220</b><i>c </i>for executing instructions and an instruction cache <b>210</b>. The media processing units <b>110</b>, <b>112</b> each include from two to four functional units. In at least one embodiment, the media processing units <b>110</b> and <b>112</b> include four functional units FUa <b>222</b>, FU<b>1</b> <b>220</b><i>a</i>, FU<b>2</b> <b>220</b><i>b </i>and FU<b>3</b> <b>220</b><i>c</i>. FDa <b>222</b> is sometimes referred to herein as the general function unit (\u201cGFU\u201d). Each of the functional units <b>222</b>, <b>220</b><i>a</i>-<b>220</b><i>b </i>is allocated a separate segment of register files <b>224</b>. Each of the media processing units <b>110</b> and <b>112</b> includes a load/store unit <b>218</b> coupled with the register files <b>224</b>, the functional unit <b>222</b>, and the pipeline control unit <b>226</b>.</p>\n<p num=\"p-0028\"><figref idrefs=\"DRAWINGS\">FIG. 2</figref> also shows a Pipeline Control Unit (PCU) <b>226</b> between the instruction buffer <b>214</b> and the four functional units FU<b>0</b><b>222</b>, FU<b>1</b><b>220</b><i>a</i>, FU<b>2</b><b>220</b><i>b</i>, and FU<b>3</b><b>220</b><i>c</i>. The register file <b>216</b> includes register file segments <b>224</b>. Also shown in <figref idrefs=\"DRAWINGS\">FIG. 2</figref> is a Load/Store Unit <b>218</b>.</p>\n<p num=\"p-0029\">Each media processing unit <b>110</b>, <b>112</b> provides an individual independent parallel execution path. Each media processing unit <b>110</b>, <b>112</b> has operational units including instruction supply blocks and instruction preparation blocks, functional units <b>220</b> and <b>222</b><i>a</i>-<i>c</i>, and a register file <b>216</b> that are separate and independent from the operational units of other paths of the multiple independent parallel execution path(s) provided by other functional unit(s). The instruction supply blocks include a separate instruction cache <b>210</b> for the individual independent parallel execution paths, however the multiple independent parallel execution paths share a single data cache <b>106</b> since multiple threads sometimes share data. The data cache <b>106</b> is dual-ported, allowing data access in the execution paths provided by both media processing units <b>110</b> and <b>112</b> in a single cycle. Sharing of the data cache <b>106</b> among independent processor elements <b>110</b> and <b>112</b> advantageously simplifies data handling, avoiding a need for a cache coordination protocol and the overhead incurred in controlling the protocol.</p>\n<p num=\"p-0030\">In addition to the instruction cache <b>210</b>, the instruction supply blocks in an execution path include the instruction aligner <b>212</b>, and the instruction buffer <b>214</b> that precisely format and align a full instruction group of multiple instructions (\u201cinstruction word\u201d) to prepare to access the register file <b>216</b>. A fixed-length group of multiple instructions is called an instruction word. A variable-length group of instructions is called an \u201cinstruction packet.\u201d Although both an instruction word and an instruction packet may take up the same number of bits, not all entries in the instruction packet need necessarily contain a valid instruction. A variable-length instruction \u201cpacket\u201d may contain an instruction for the GFU <b>222</b> as well as for one or more of the functional units FU<b>1</b> through FU<b>3</b> <b>220</b><i>a</i>-<i>c. </i></p>\n<p num=\"p-0031\">The functional units FU<b>1</b>, FU<b>2</b>, and FU<b>3</b> <b>220</b><i>a</i>-<i>c </i>are multiple single-instruction-multiple-datapath (MSIMD) media functional units (\u201cMFU\u201d). Each of the media functional units <b>220</b> is capable of processing parallel 16-bit components. Various parallel 16-bit operations supply the single-instruction-multiple-datapath capability for the processor <b>100</b> including add, multiply-add, shift, compare, and the like. The media functional units <b>220</b> operate in combination as tightly coupled digital signal processors (DSPs). Each media functional unit <b>220</b> has a separate and individual sub-instruction stream, but all three media functional units <b>220</b> execute synchronously so that the subinstructions progress lock-step through pipeline stages.</p>\n<p num=\"p-0032\">The general functional unit <b>222</b> is a processor capable of executing arithmetic logic unit (ALU) operations, loads and stores, branches, and various specialized and esoteric functions such as parallel power operations, reciprocal square root operations, and many others. The general functional unit <b>222</b> supports less common parallel operations such as the parallel reciprocal square root instruction.</p>\n<p num=\"p-0033\">Regarding the details of the STI instruction, it will be understood from the discussion above that the illustrative instruction cache <b>210</b> is two-way set-associative and has a 16 Kbyte capacity. The instruction cache <b>210</b> mainly relies on the new STI instruction to maintain coherence. This allows allowing dynamic optimizations through self-modifying code. Software is used to indicate that the instruction storage is being modified when modifications occur. The programmer or compiler therefore have precise knowledge that they are modifying the instruction space. The 16K capacity is suitable for performing graphic loops, other multimedia tasks or processes, and general-purpose Java\u2122 code. Maintenance of coherence is minimally supported by hardware that implements writeback caching.</p>\n<p num=\"p-0034\">Software uses a new \u201cStore to Instruction Space\u201d (STI) instruction to maintain coherency with the instruction cache <b>210</b> so that the instruction caches <b>210</b> do not have to be snooped on every single store operation issued by the media processing unit <b>110</b>. An aim of the present invention is to support self-modifying code while simplifying and making more efficient the processing of self-modifying code by enabling the compiler that generates the modifying code to be aware that it is doing so. In prior art systems, the compiler or the programmer uses a STORE instruction to modify data space and to modify instruction space. Because the same instruction is used to modify both data and instructions, the processor cannot differentiate between the type of space being modified by the STORE instruction. The hardware must therefore pessimistically snoop the instruction cache for each STORE instruction just in case the STORE instruction is being used to modify instruction space. With the present invention, the compiler or the programmer uses the new STI to indicate that the STORE operation is modifying an instruction.</p>\n<p num=\"p-0035\"><figref idrefs=\"DRAWINGS\">FIGS. 1</figref>, <b>2</b>, and <b>5</b> provide background information useful to the following discussion of the STI instruction format. <figref idrefs=\"DRAWINGS\">FIG. 5</figref> illustrates an exemplary format of a variable-length instruction packet <b>500</b> for processor <b>100</b>. Instructions for the processor <b>100</b> are 32 bits in length. The processor <b>100</b> can issue multiple instructions simultaneously, one to each of its functional units <b>222</b>, <b>220</b><i>a</i>-<b>220</b><i>c</i>. In a processor having four functional units <b>222</b>, <b>220</b><i>a</i>-<b>220</b><i>c</i>, instructions are issued in four-quadrant instruction words <b>500</b>, with each quadrant <b>510</b>, <b>512</b>, <b>514</b>, <b>516</b> corresponding to a functional unit. Each quadrant <b>510</b>, <b>512</b>, <b>514</b>, <b>516</b> being capable of holding a 32-bit instruction, each instruction packet <b>500</b> includes 128 bits. Each instruction packet <b>500</b> is composed of one GFU instruction and zero to three MFU instructions. That is, when there isn't useful work to do on all the MFUs, MFU instructions need not be present.</p>\n<p num=\"p-0036\"><figref idrefs=\"DRAWINGS\">FIG. 3</figref> illustrates the format of an instruction for processor <b>100</b>, and more particularly for the STI instruction in accordance with one embodiment of the present invention. The two most significant bits of each instruction make up a 2-bit field known as the q field, which is also called the instruction \u201cquadrant.\u201d Each quadrant corresponds to a different functional unit. <figref idrefs=\"DRAWINGS\">FIG. 3</figref> illustrates that the two most significant bits of the STI instruction are 1b\u201800\u2019. The STI instruction is referred to as a GFU instruction because it has a q field of 1b\u201800\u2019 and resides in the GFU quadrant of the instruction packet <b>500</b>. A GFU instruction, including the STI instruction, can be executed on the GFU <b>222</b> or on any of the three MFU's, <b>220</b><i>a</i>-<b>220</b><i>c</i>. However, instructions in the other three instruction quadrants can only be executed on FU<b>3</b><b>220</b><i>c</i>, FU<b>2</b><b>220</b><i>b</i>, and FU<b>1</b><b>220</b><i>a. </i></p>\n<p num=\"p-0037\">As explained above, a GFU instruction always resides in the GFU quadrant of the instruction word and the q field for a GFU instruction is 1b\u201800\u2019. The q field values for the other three quadrants, corresponding to each of the zero to three MFU's, are set forth below in Table 1. All of the instructions in a single instruction packet are issued in the same cycle.</p>\n<p num=\"p-0038\">\n<tables id=\"TABLE-US-00001\" num=\"00001\">\n<table colsep=\"0\" frame=\"none\" rowsep=\"0\">\n<tgroup align=\"left\" cols=\"2\" colsep=\"0\" rowsep=\"0\">\n<colspec align=\"center\" colname=\"1\" colwidth=\"119pt\"></colspec>\n<colspec align=\"left\" colname=\"2\" colwidth=\"98pt\"></colspec>\n<thead>\n<row>\n<entry nameend=\"2\" namest=\"1\" rowsep=\"1\">TABLE 1</entry>\n</row>\n<row>\n<entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry>\n</row>\n<row>\n<entry>q field value</entry>\n<entry>Instruction quadrant</entry>\n</row>\n<row>\n<entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry>\n</row>\n</thead>\n<tbody valign=\"top\">\n<row>\n<entry>00</entry>\n<entry>GFU</entry>\n</row>\n<row>\n<entry>01</entry>\n<entry>MFU1</entry>\n</row>\n<row>\n<entry>10</entry>\n<entry>MFU2</entry>\n</row>\n<row>\n<entry>11</entry>\n<entry>MFU3</entry>\n</row>\n<row>\n<entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry>\n</row>\n</tbody>\n</tgroup>\n</table>\n</tables>\n</p>\n<p num=\"p-0039\"><figref idrefs=\"DRAWINGS\">FIG. 3</figref> further illustrates that the two next most significant bits, labeled as bits <b>29</b> and <b>28</b>, make up a field called opc2. The contents of opc2, along with the i bit and the contents of the opc6 field discussed below, constitute the opcode for the STI instruction. Opc2 is a two-bit field that, for the STI instruction, is a value of 1b\u201811\u2019. The value of 1b\u201811\u2019 in opc2 indicates to the media processing unit <b>110</b>, <b>112</b> that the instruction is a memory access operation.</p>\n<p num=\"p-0040\"><figref idrefs=\"DRAWINGS\">FIG. 3</figref> illustrates that the next most significant bit in the STI instruction, labeled as bit <b>27</b>, is the i bit. The i bit is a single-bit field that indicates whether the instruction includes an immediate value. When set to a value of 1b\u20181\u2019, the i bit value indicates that the least significant seven bits of the instruction contain an immediate value. An immediate value supplies the value of the operand itself, rather than supplying an address at which the value may be found. When reset to 1b\u20180\u2019, the i bit value indicates that the least significant seven bits contain a source register number, rs2.</p>\n<p num=\"p-0041\">The remaining bits of the opcode for the STI instruction reside in the opc6 field, labeled as bits <b>26</b> through <b>21</b> in <figref idrefs=\"DRAWINGS\">FIG. 3</figref>. Bits <b>26</b> through <b>21</b> of the STI opcode comprise \u201c111010.</p>\n<p num=\"p-0042\">Bits <b>20</b> through <b>14</b> of the STI instruction make up the rd field. The rd field is a seven-bit field that encodes a general purpose register number. In execution of the STI instruction, the data to be stored to instruction space is obtained from the register number encoded in the rd field.</p>\n<p num=\"p-0043\">Bits <b>13</b> through <b>7</b> make up the rs1 field. The rs1 field is a seven-bit field that encodes a general-purpose register number. In execution of the STI instruction, the effective instruction-space address to be modified is calculated, in part, from the contents of the register-number encoded in the rs1 field.</p>\n<p num=\"p-0044\">The calculation of the effective instruction-space address to be modified also involves the contents of bits <b>6</b> through <b>9</b> of the STI instruction. The bits <b>6</b> through <b>0</b> may contain either a register number or an immediate value that will be zero-extended when used. That is, bits <b>6</b> through <b>0</b> can make up either the rs2 field or the uimm7 field, respectively In either case, the contents of bits <b>6</b> through <b>0</b> are used in execution of the STI instruction to generate the effective address in instruction space that is to be altered by the STI instruction.</p>\n<p num=\"p-0045\">The value of the i bit dictates how the media processing unit <b>110</b>, <b>112</b> will calculate the effective address of the instruction space to be modified. If the i bit contains a value of 1b\u20181\u2019, then bits <b>6</b> through <b>0</b> will be treated as a uimm7 field. Using the contents of the uimm7 field, the media processing unit calculates the effective address as \u201cR[rs1]+zero_ext(uimm7\u00d74)\u201d. The immediate value in the uimm7 field is scaled by the size of the store (4 bytes) being performed. It is then zero-extended before it is added to the address portion residing in register R[rs1] to calculate the effective address.</p>\n<p num=\"p-0046\">If the i bit contains a value of 1b\u20180\u2019, then bits <b>6</b> through <b>0</b> are treated as an rs2 field. In such case the address portions residing in the register numbers encoded in rs1 and rs2 are combined to generate the effective address. When the value of the i bit is 1b\u20180\u2019, the effective address is therefore calculated as \u201cR[rs1]+R[rs2]\u201d.</p>\n<p num=\"p-0047\">The STI instruction illustrated in <figref idrefs=\"DRAWINGS\">FIG. 3</figref> stores one word of data from the register specified by register rd to the indicated instruction space address. Specifically, the media processing unit <b>110</b>, <b>112</b> executing a Store Register to Instruction Memory (STI) instruction stores a word from the general-purpose register number encoded in rd, that is, from R[rd], to the effective memory address encoded in bits <b>13</b> through <b>0</b>. The STI.W instruction uses a two-component effective address specification for the instruction space address. The effective address may be [rs1+rs2] or [rs1+imm7]. In an alternative embodiment, the effective address may also be [rs1]. In either embodiment, rs1 and rs2 are each registers that contain 7-bit portions of the effective address and imm7 is a 7-bit immediate address. When [rs1] is specified, the processor <b>100</b> infers an immediate zero for the second address component for the instruction. The use of an immediate value for the second component of the address sets the i-bit of the opcode.</p>\n<p num=\"p-0048\">The STI instruction guarantees consistency between memory and the instruction cache. Execution of the STI instruction ensures that the instruction cache remains consistent with the value stored to memory.</p>\n<p num=\"p-0049\">Because it stores one word of data, the preferred nomenclature uses an extension of an optional period followed by \u201cW\u201d. The instruction may therefore be written as \u201cSTI.W\u201d or \u201cSTIW\u201d. One skilled in the art will appreciate that, while the preferred embodiment stores one 4-byte word of data, the STI instruction may be implemented to operate on alternative sizes of data that are larger or smaller than a 4-byte word, such as a single 8-bit byte, a 2-byte halfword, and an 8-byte doubleword.</p>\n<p num=\"p-0050\">As shown in <figref idrefs=\"DRAWINGS\">FIG. 4</figref>, the processor <b>100</b> can include a memory interface <b>102</b> connected to the shared data cache <b>106</b>, and the media processing units <b>110</b>, <b>112</b> respectively include instruction caches <b>210</b><i>a</i>, <b>210</b><i>b. </i></p>\n<p num=\"p-0051\"><figref idrefs=\"DRAWINGS\">FIG. 4</figref> illustrates the data flow resulting from the STI.W instruction. For purposes of illustration, this discussion assumes that MPU<b>1</b><b>110</b> is processing the STI.W instruction. First, MPU<b>1</b><b>110</b> must determine whether the instruction line to be modified is already in the data cache <b>106</b>. MPU<b>1</b><b>110</b> therefore first checks to determine if the cache line containing the data addressed by bits <b>13</b>-<b>0</b> of the STI.W instruction is already in the data cache. If so, then the data cache line is updated with the data in R[rd]. Once the update has occurred, the data must be transmitted from the data cache to the proper instruction memory address. This may be accomplished one of two ways. The entire data cache line that has been updated is copied to the proper instruction address in main memory. Alternatively, the entire data cache line that has been updated is moved to the proper instruction address in main memory and may be cleared from the data cache. Under the alternative approach, the line in the data cache is now \u201cinvalid\u201d after its contents is moved to main memory.</p>\n<p num=\"p-0052\">If the cache line containing the data addressed by bits <b>13</b>-<b>0</b> of the STI.W instruction is not already in the data cache, then one of two approaches may be followed to store the data in R[rd] to the instruction address in main memory. In the first approach, the data from R[rd] is sent directly to the address in main memory that is encoded in bits <b>13</b>-<b>0</b> of the STI instruction. Alternatively, the second approach has three steps. First, the instruction line addressed by bits <b>13</b>-<b>0</b> of the STI.W instruction is brought from main memory into the data cache. The line in the data cache is then updated with the data in R[rd]. Finally, the entire data cache line that has been updated is copied to the correct instruction address in main memory.</p>\n<p num=\"p-0053\">A final stage in the execution of the STI.W instruction is to ensure coherence between main memory and the instruction cache. This may be accomplished according to one of several alternative embodiments. In the first embodiment, any line in the instruction cache that could contain the \u201cline of interest\u201d (i.e., the instruction line whose effective address is specified in bits <b>13</b>-<b>0</b> of the STI.W instruction) is invalidated. In a second embodiment, an instruction cache line is invalidated only if it does indeed contain the line of interest. In a third embodiment, coherence is achieved by \u201cinstalling\u201d or allocating a new line in the instruction cache, the new line containing the data specified in R[rd]. In a final alternative embodiment, if the cache line that was updated in main memory is also in the instruction cache, then the line in the instruction cache is updated with the data in R[rd].</p>\n<p num=\"p-0054\">If one of the invalidation approaches is followed, the invalidation is accomplished as follows. The effective address of the instruction cache line to be invalidated (that is, the line whose effective address is specified in bits <b>13</b>-<b>0</b> of the STI.W instruction) is broadcast to the instruction cache <b>210</b> in each MPU <b>110</b>, <b>112</b>, respectively instruction cache <b>210</b><i>a </i>and <b>210</b><i>b</i>. Broadcasting the address to each MPU <b>110</b>, <b>112</b> facilitates invalidation of the instruction address in both instruction caches <b>210</b> and thus keeps the instruction caches coherent with main memory.</p>\n<p num=\"p-0055\">To summarize, the preceding discussion illustrates that an explicit instruction that functions to modify code provides an advantage over prior art systems that do not have an explicit instruction for storing data to instruction space in main memory <b>102</b>. In prior art systems there is no indication whether or not the STORE instruction is to modify an instruction, and the processor must therefore be implemented to always assume that any STORE instruction might feasibly do so. In such case, the computer system must check, for every STORE instruction, to see if the line to be modified is an instruction in the instruction cache <b>210</b>. The STI instruction of the present invention eliminates such inefficiency, and the instruction cache <b>210</b> need not be snooped when processing a traditional STORE instruction.</p>\n<p num=\"p-0056\">Although particular embodiments of the present invention have been shown and described, it will be obvious to those skilled in the art that changes and modifications can be made without departing from the present invention in its broader aspects. For example, the present invention is not limited by any particular processor architecture, the presence or structure of caches or memory, or the number of bits in any register or memory location. The appended claims are to encompass within their scope all such changes and modifications that fall within the true scope of the present invention.</p>\n<?DETDESC description=\"Detailed Description\" end=\"tail\"?>\n</description>"}], "inventors": [{"first_name": "Marc", "last_name": "Tremblay", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "SUN MICROSYSTEMS, INC."}, {"first_name": "", "last_name": "Oracle America, Inc.", "name": ""}, {"first_name": "", "last_name": "SUN MICROSYSTEMS, INC.", "name": ""}], "ipc_classes": [], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/00        20060101AFI20080415BHUS"}], "national_classes": [{"primary": true, "label": "711141"}, {"primary": false, "label": "711E12039"}, {"primary": false, "label": "712E09053"}, {"primary": false, "label": "712226"}, {"primary": false, "label": "711E12038"}, {"primary": false, "label": "711E1204"}], "ecla_classes": [{"label": "G06F   9/30A2L"}, {"label": "G06F   9/38B6"}, {"label": "G06F  12/08B2"}, {"label": "G06F  12/08B4S"}, {"label": "G06F  12/08B4T"}], "cpc_classes": [{"label": "G06F   9/30043"}, {"label": "G06F  12/084"}, {"label": "G06F  12/0842"}, {"label": "G06F  12/0804"}, {"label": "G06F   9/3812"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "2000-05-05", "application_date": "2000-05-05", "family_members": [{"ucid": "US-7360028-B1", "titles": [{"lang": "EN", "text": "Explicit store-to-instruction-space instruction for self-modifying code and ensuring memory coherence between instruction cache and shared memory using a no-snoop protocol"}]}]}