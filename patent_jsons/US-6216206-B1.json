{"patent_number": "US-6216206-B1", "publication_id": 72628320, "family_id": 25536953, "publication_date": "2001-04-10", "titles": [{"lang": "EN", "text": "Trace victim cache"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72537854\"><p>A cache memory includes a data array and a trace victim cache. The data array is adapted to store a plurality of trace segments. Each trace segment includes at least one trace segment member. The trace victim cache is adapted to store plurality of entries. Each entry includes a replaced trace segment member selected for replacement from one of the plurality of trace segments. A method for accessing cached instructions, the cached instructions being stored in a data array, the cached instructions being organized in trace segments, the trace segment having a plurality of trace segment members, includes retrieving a first trace segment member of a first trace segment; identifying an expected location within the data array of at least one subsequent trace segment member of the first trace segment; determining if the subsequent trace segment member is stored in the data array at the expected location; and determining if the subsequent trace segment member is stored in a trace victim cache if the subsequent trace segment member is not stored in the data array at the expected location.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00001\" num=\"1\"><claim-text>1. A cache memory, comprising:</claim-text><claim-text>a data array to store a plurality of trace segment members which are linked to form a trace segment; and </claim-text><claim-text>a trace victim cache coupled to store a trace segment member replaced from the data array, the replaced trace segment member having an entry associated with maintaining a link to a previous trace segment member of the trace segment to re-establish the trace segment when the replaced trace segment member is retrieved, the replaced trace segment member also having a link to a subsequent trace segment member, if present, to continue the trace segment. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00002\" num=\"2\"><claim-text>2. The cache memory of claim <b>1</b>, wherein said data array operates as a primary cache memory and said data array is configured to have a plurality of sets and one trace segment member is stored per set.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00003\" num=\"3\"><claim-text>3. The cache memory of claim <b>1</b>, further comprising a tag array having a plurality or tag entries, in which the tag entries correspond to identify the trace segment members.</claim-text></claim>"}, {"num": 4, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00004\" num=\"4\"><claim-text>4. The cache memory of claim <b>3</b>, wherein each trace segment member includes at least one instruction and the cache memory further comprising a control logic coupled to retrieve the instruction or instructions from the trace segment member.</claim-text></claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00005\" num=\"5\"><claim-text>5. The cache memory of claim <b>4</b>, wherein the control logic retrieves the instruction or instructions from the replaced trace segment member, determines an expected location of the subsequent trace segment member within the data array based on its tag entry and provide the link to the subsequent trace segment member.</claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00006\" num=\"6\"><claim-text>6. The cache memory of claim <b>5</b>, wherein said data array is organized into N ways of S sets and wherein the tag entry includes a next way field indicating the way in which the subsequent trace segment member is stored.</claim-text></claim>"}, {"num": 7, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00007\" num=\"7\"><claim-text>7. The cache memory of claim <b>5</b>, wherein the control logic determines if the subsequent trace segment member to be linked is present in said data array.</claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00008\" num=\"8\"><claim-text>8. The cache memory of claim <b>7</b>, wherein the control logic stores the replaced trace segment member from the trace victim cache in the data array and the tag entry from the trace victim cache in the tag array.</claim-text></claim>"}, {"num": 9, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00009\" num=\"9\"><claim-text>9. The cache memory of claim <b>7</b>, wherein the tag data of the replaced trace segment member includes a next instruction pointer which is compared to a linear instruction pointer.</claim-text></claim>"}, {"num": 10, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00010\" num=\"10\"><claim-text>10. The cache memory of claim <b>2</b>, further comprising a control logic coupled to retrieve the replaced trace segment member from said trace victim cache and to link to the subsequent trace segment member of the trace segment.</claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00011\" num=\"11\"><claim-text>11. The cache memory or claim <b>10</b>, further comprising a set register coupled to said data array to store a set value corresponding to a set in the data array, wherein the set value corresponds to the set of a trace segment member currently in use.</claim-text></claim>"}, {"num": 12, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00012\" num=\"12\"><claim-text>12. The cache memory of claim <b>10</b>, further comprising a set register coupled to said data array to store a set value corresponding to a set in the data array, wherein the set value corresponds to the set in the data array corresponding to the replaced trace segment member before being replaced.</claim-text></claim>"}, {"num": 13, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00013\" num=\"13\"><claim-text>13. A cache memory, comprising:</claim-text><claim-text>a data array to store a plurality of trace segment members which are linked to form a trace segment; and </claim-text><claim-text>means for storing a trace segment member victimized from said data array, the victimized trace segment member having an entry associated with maintaining a link to a previous trace segment member of the trace segment to re-establish the trace segment when the victimized trace segment member is retrieved, the victimized trace segment member also having a link to a subsequent trace segment member to continue the trace segment. </claim-text></claim>"}, {"num": 14, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00014\" num=\"14\"><claim-text>14. An apparatus comprising:</claim-text><claim-text>a data array to store a plurality of data elements which are segment members linked together to form a trace segment, wherein each data element includes an entry to link to an adjacent element in the trace segment; and </claim-text><claim-text>a victim cache to store an element of the segment which is victimized in said data array, the entry for the victimized element allowing the victimized element to link to its previous element still in said data array to re-establish the trace segment when the victimized element is retrieved, the victimized element also having a link to a subsequent element to continue the trace segment. </claim-text></claim>"}, {"num": 15, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00015\" num=\"15\"><claim-text>15. The apparatus of claim <b>14</b>, wherein said data array operates as a primary cache memory and said data array is configured to have a plurality of sets and one data element is stored per set.</claim-text></claim>"}, {"num": 16, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00016\" num=\"16\"><claim-text>16. The apparatus of claim <b>14</b>, further comprising a tag array to store tag information associated with each element.</claim-text></claim>"}, {"num": 17, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00017\" num=\"17\"><claim-text>17. A method for caching comprising:</claim-text><claim-text>storing a segment member of a trace segment, comprised of a plurality of linked segment members, in a location of a victim cache when the segment member is victimized in a data array storing the trace segment; </claim-text><claim-text>retrieving the victimized trace segment member when retrieving the trace segment; </claim-text><claim-text>identifying a link entry in the victimized segment member to link to a previous segment member of the trace segment still in the data array and also to a subsequent segment member of the trace segment; and </claim-text><claim-text>determining if the subsequent segment member is stored in the data array at its expected location. </claim-text></claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00018\" num=\"18\"><claim-text>18. The method of claim <b>17</b> further comprising:</claim-text><claim-text>determining if the subsequent segment member is stored in the victim cache, if the subsequent segment member is not stored in the data array. </claim-text></claim>"}, {"num": 19, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00019\" num=\"19\"><claim-text>19. The method of claim <b>18</b> further comprising:</claim-text><claim-text>retrieving the subsequent segment member from the victim cache. </claim-text></claim>"}, {"num": 20, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00020\" num=\"20\"><claim-text>20. The method of claim <b>17</b> further comprising:</claim-text><claim-text>retrieving the subsequent segment member from the data array. </claim-text></claim>"}, {"num": 21, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00021\" num=\"21\"><claim-text>21. The method of claim <b>18</b> further comprising:</claim-text><claim-text>storing a set value in a set register, the set value corresponding to the location of the victimized segment member. </claim-text></claim>"}, {"num": 22, "parent": 21, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00022\" num=\"22\"><claim-text>22. The method of claim <b>21</b> further comprising:</claim-text><claim-text>retrieving the subsequent segment member; and </claim-text><claim-text>incrementing the set value corresponding to the retrieval of the subsequent segment member. </claim-text></claim>"}, {"num": 23, "parent": 21, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00023\" num=\"23\"><claim-text>23. The method of claim <b>21</b> further comprising:</claim-text><claim-text>retrieving the subsequent segment member from the victim cache; and </claim-text><claim-text>incrementing the set value corresponding to the retrieval of the subsequent segment member. </claim-text></claim>"}, {"num": 24, "parent": 21, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00024\" num=\"24\"><claim-text>24. The method of claim <b>21</b> further comprising:</claim-text><claim-text>retrieving the subsequent segment member from the data array, the set value corresponding to a location of the subsequent segment member within the data array. </claim-text></claim>"}, {"num": 25, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00025\" num=\"25\"><claim-text>25. The method of claim <b>22</b> further comprising:</claim-text><claim-text>retrieving branch prediction information from a branch prediction unit corresponding to the set value to determine correct branching for the trace segment. </claim-text></claim>"}, {"num": 26, "parent": 24, "type": "dependent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00026\" num=\"26\"><claim-text>26. The method of claim <b>24</b> further comprising:</claim-text><claim-text>retrieving branch prediction information from a branch prediction unit corresponding to the set value to determine correct branching for the trace segment. </claim-text></claim>"}, {"num": 27, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00027\" num=\"27\"><claim-text>27. A method of caching instructions, comprising:</claim-text><claim-text>storing a trace segment of instructions in a data array, the trace segment having a plurality of segment members which are linked to form the trace segment; </claim-text><claim-text>victimizing one of the segment members of the trace segment; </claim-text><claim-text>storing the victimized segment member in a trace victim cache; </claim-text><claim-text>retrieving the victimized segment member when retrieving the trace segment by a link to a previous segment member to the victimized segment member; and </claim-text><claim-text>linking a subsequent segment member of the trace segment still residing in the data array to the victimized segment member by using a link entry associated with the subsequent segment member re-establishing the trace segment without reloading the subsequent trace segment still residing in the data array. </claim-text></claim>"}, {"num": 28, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6216206-B1-CLM-00028\" num=\"28\"><claim-text>28. A microprocessor system, comprising:</claim-text><claim-text>a data array to store a plurality of segment members which are linked to form a trace segment; </claim-text><claim-text>a trace victim cache to store a segment member which is victimized in said data array, the victimized segment member having a link to a previous segment member and a link to a subsequent segment member; and </claim-text><claim-text>a control logic to retrieve the victimized segment member and to identify its subsequent segment member in the trace segment to re-establish the link without reloading the subsequent segment member into the data array. </claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54524826\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. FIELD OF THE INVENTION</p><p>The present invention relates to the field of computer systems. More specifically, the present invention relates to the art of caching decoded micro-operations with trace segments and providing a victim cache for replaced cache lines.</p><p>2. DESCRIPTION OF RELATED ART</p><p>Historically, cached instructions are stored and organized in an instruction cache in accordance with the instructions' memory addresses. Each cache line stores a number of instructions that are spatially adjacent each other in main memory. This historic approach to caching instructions has at least one disadvantage in that it typically requires multiple cache lines to be accessed when execution of a program necessitates branching from the middle of a cache line or branching into the middle of a cache line.</p><p>In a cache organized by instruction address, a full line of adjacent instructions is typically fetched from the main memory and loaded into the cache. If the cache becomes fill, an existing line in the cache memory is replaced to accommodate a new line of instructions required by the microprocessor. The replacement of a particular line does not impact any other lines in the cache.</p><p>An alternative approach to organizing cached instructions is known, whereby cached instructions are organized by instruction trace segments. Each cache line stores an instruction trace segment comprising one or more basic blocks of instructions that are predicted to be sequentially executed. For example, in an embodiment where each cache line comprises two basic blocks of instructions, the second basic block of instructions includes instructions to be executed if the branch instruction located at the end of the first basic block is taken. Assuming the branch is predicted taken, the second basic block is included in the same trace segment. A particular trace segment may extend over a number of cache lines. Each trace segment is retrieved based on the memory address of the first instruction in the trace segment.</p><p>A cache organized by trace segments is typically operated in one of two modes, an execution mode, and a build mode. Instructions are read from the cache memory during the execution mode and trace segments are built into the cache memory in the build mode. If an instruction required by the microprocessor is not present in the cache memory, a cache miss is generated and the cache memory switches to build mode. A switch to build mode results in a performance penalty due to the latency generated as new instructions must be fetched, decoded, and supplied to the microprocessor.</p><p>In a trace cache arrangement, a line replacement is more costly than in a traditional cache arrangement. For example, consider a trace segment occupying six cache lines. The fourth line of the trace segment is replaced. Because the trace segment can only be accessed through the address of the first instruction in the first cache line (i.e. the head of the trace segment), only lines one, two, and three, will be accessible after the replacement of the fourth line. Lines, five and six will be unavailable because they were cut off from the trace segment when the fourth line was replaced.</p><p>As a result, when the processor accesses the trace segment to retrieve instructions, a cache miss will occur after the third line. The processor will then switch to build mode to begin a new trace segment including the replaced fourth line and cut off fifth and sixth lines. As a result, the instructions contained in the fifth and sixth lines will be cached twice.</p><p>Thus, it is desirable to have a new approach for caching instructions that reduces the performance penalty caused by cache line replacements and reduces the degree of code redundancy present in the cache.</p><h4>SUMMARY OF THE INVENTION</h4><p>An aspect of the invention is seen in a cache memory including a data array and a trace victim cache. The data array is adapted to store a plurality of trace segments. Each trace segment includes at least one trace segment member. The trace victim cache is adapted to store plurality of entries. Each entry includes a replaced trace segment member selected for replacement from one of the plurality of trace segments.</p><p>Another aspect of the invention is seen in a method for accessing cached instructions. The cached instructions are stored in a data array and organized in trace segments. The trace segment has a plurality of trace segment members. The method includes retrieving a first trace segment member of a first trace segment; identifying an expected location within the data array of at least one subsequent trace segment member of the first trace segment; determining if the subsequent trace segment member is stored in the data array at the expected location; and determining if the subsequent trace segment member is stored in a trace victim cache if the subsequent trace segment member is not stored in the data array at the expected location.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1 is a block diagram of a processor core including a cache memory suitable for practicing the invention;</p><p>FIG. 2 is a block diagram illustrating one embodiment of the cache memory of FIG. 1;</p><p>FIG. 3 is a block diagram illustrating the manner in which cached instructions are organized in the cache data array in accordance with the present invention;</p><p>FIGS. 4 , <b>5</b>, and <b>6</b> illustrate the content of a cache tag entry, a data line, and a micro-op, respectively;</p><p>FIG. 7 is a state diagram illustrating the manner in which control logic operates the cache memory of FIG. 2 in an execution mode;</p><p>FIG. 8 is a state diagram illustrating the manner in which control logic operates the cache memory of FIG. 2 in a trace segment build mode; and</p><p>FIG. 9 illustrates the content of a trace victim cache entry.</p><p>While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof have been shown by way of example in the drawings and are herein described in detail. It should be understood, however, that the description herein of specific embodiments is not intended to limit the invention to the particular forms disclosed, but on the contrary, the intention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the invention as defined by the appended claims.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF SPECIFIC EMBODIMENTS</h4><p>The following examples are included to demonstrate preferred embodiments of the invention. It should be appreciated by those skilled in the art that the techniques disclosed in the examples that follow represent techniques discovered by the inventor to function well in the practice of the invention. However, those skilled in the art should, in light of the present disclosure, appreciate that many changes can be made in the specific embodiments disclosed herein without departing from the spirit and scope of the invention.</p><p>Referring first to FIG. 1, one embodiment of a computer system <b>100</b> suitable for practicing the present invention is illustrated. As shown, the computer system <b>100</b> includes a cache memory <b>105</b>. The computer system <b>100</b> includes a trace branch prediction unit (TBPU) <b>110</b> (which includes branch target address calculation circuitry as well as next IP calculation circuitry), microcode sequencer <b>115</b>, multiplexer <b>120</b>, execution units <b>125</b>, instruction translation look-aside buffer (ITLB) <b>135</b>, and decoder <b>140</b>.</p><p>The structure and operation of the cache memory <b>105</b> is described in greater detail below in reference to FIG. <b>2</b>. The other elements <b>110</b>-<b>140</b> are intended to represent a broad category of these types of elements found in the art. In one embodiment, the elements are disposed in the same processor integrated circuit (chip).</p><p>Referring now to FIG. 2, a block diagram illustrating one embodiment of the cache memory <b>105</b> of the present invention is shown. As illustrated, the cache memory <b>105</b> includes a data array <b>200</b> and control logic <b>210</b>, coupled to each other as shown. For the illustrated embodiment, the cache memory <b>105</b> further comprises a tag array <b>220</b>, a trace victim cache (TVC) <b>230</b>, a set register <b>235</b>, an immediate extractor <b>240</b>, and fill buffers <b>250</b>, coupled to each other and to the above enumerated elements as shown.</p><p>As in conventional cache memories, the data array <b>200</b> comprises a plurality of data lines shown in FIG. <b>5</b>), and the tag array <b>220</b> comprises a plurality of tag entries shown in FIG. 4) corresponding to the data lines. The combination of the data lines and tag entries form cache lines of the cache memory <b>105</b>. However, unlike conventional cache memories, the control logic <b>210</b> operates the cache memory <b>105</b> to cache decoded micro-ops in the data array <b>200</b>, organizing the cached micro-ops by trace segments, e.g. <b>260</b>, including trace segments that span multiple data lines. Each trace segment <b>260</b> includes one or more trace segment members of one or more instructions, with each trace segment member occupying one data line, and the data lines of a multi-line trace segment being sequentially associated (logically). Retrieval of the trace segment members of a multi-line trace segment is accomplished by first locating the data line storing the first is trace segment member of the multi-line trace segment, and then successively locating the remaining data lines storing the remaining trace segment members based on the data lines' logical associations as described in more detail below. Although the specification describes caching micro-ops of macro instructions, the invention is not so limited. The invention may be applied to caching any type of instructions, with a micro-op being an illustrative example of one such instruction type.</p><p>Those skilled in the art will also appreciate that by trace caching instructions or decoded micro-ops in this manner, i.e. allowing a trace segment to span multiple data lines, the amount of instructions that can be supplied to the execution units of a processor will be larger than the rate that can be sustained by the prior art approaches. Furthermore, by virtue of allowing multi-data line trace caching, the size of the program loops that will be automatically unrolled will be larger, effectively eliminating the need for a compiler to perform loop unrolling optimization to \u201cmaximize\u201d exploitation of processor performance. As a result, the generated code of programs will be more compact, which in turn will lead to memory space and instruction fetch time savings.</p><p>Also, although the invention is described in reference to storing trace segments, the invention may be applied to storing any data element of one or more data sub elements stored in one or more lines in a data array <b>200</b>.</p><p>FIG. 3 illustrates two trace segments <b>260</b> and <b>260</b>\u2032 of the present invention in further detail. In the illustrated embodiment, the data array <b>200</b> is a 4-way, 256-set embodiment. Based on the descriptions to follow, those skilled in the art will appreciate that other sizes of set associative cache, as well as other non-set associative organizations may be employed to practice the present invention. For ease of illustration, the first trace segment member of a trace segment (e.g., trace segment <b>260</b>\u2032) is referred to as a trace segment head <b>261</b>. The intermediate trace segment members are referred to as trace segment bodies <b>262</b>, and the last trace segment member of a trace segment <b>260</b>\u2032 is referred to as a trace segment tail <b>263</b>. In the degenerate case of a two-member trace segment, the second trace segment member is a trace segment body <b>262</b> as well as a trace segment tail <b>263</b>, and in the degenerate case of a single member trace segment, the singular trace segment member is a trace segment head <b>261</b>, a trace segment body <b>262</b>, as well as a trace segment tail <b>263</b>. Micro-ops of each trace segment are accessed by way of the memory address of the first micro-op of the trace segment head <b>261</b> as defined by information contained within the tag array <b>220</b>.</p><p>For the illustrated embodiment, a location address is maintained for each data line storing the first trace segment member of a trace segment. The data line storing the first trace segment member of a trace segment is located by address matching an access address against the location addresses maintained. Furthermore, the address matching is performed using a subset of the address bits, and a matching data line is validated as to whether the data line indeed contains the first trace segment member being sought. Additionally, storing of trace segment members is further qualified with a criteria of ensuring the address matching subset of the location addresses maintained in association with the various ways of a data line set, if any, is unique.</p><p>In an alternate embodiment, other trace segment members are also associated with memory addresses. In yet another alternate embodiment, address matching is performed using all address bits.</p><p>For the illustrated embodiment, partial control information sequentially associating each data line storing a trace segment body or tail with its predecessor data line in a logical manner is maintained. Similarly, partial control information sequentially associating each data line storing a trace segment head or body with its successor data line in a logical manner is also maintained. The successive data lines of a multi-line trace segment are located, relying in part on the partial sequential association control information maintained. More specifically, for each data line storing a trace segment body or tail, a way index indexing into a way of the set of the predecessor data line is maintained, and for each data line storing a trace segment head or body, a way index indexing into a way of the set of the successor data line is maintained. Additionally, a predetermined set relationship between the successive data lines of a multi-line segment is maintained.</p><p>For the illustrated embodiment, a number of data line terminating conditions are employed to terminate caching of micro-ops of the trace segment <b>260</b> in one data line, and continue caching of the micro-ops of the trace segment <b>260</b> in another data line. Furthermore, a number of trace segment terminating conditions are also employed to terminate caching of micro-ops as one trace segment <b>260</b>, and continue caching of instructions as a new trace segment (e.g., <b>260</b>\u2032).</p><p>For the illustrated embodiment, the data line terminating conditions include the encountering of a complex macro-instruction that decodes into a large number of micro-ops. Only a predetermined number of micro-ops of the encountered complex macro-instruction are stored in the current data line, and the micro-ops of the next macro-instruction will be cached in a new data line. The determination of what constitutes a complex macro-instruction is application specific. It will be appreciated by those skilled in the art that the present invention may be practiced with none or all of the decoded micro-ops of a complex macro-instruction being cached.</p><p>For the illustrated embodiment, the data line terminating conditions further include the encountering of a branch micro-op after a predetermined threshold of maximum allowable branch micro-ops per trace segment has been reached. The branch micro-op will be cached in a new data line. In one embodiment, the predetermined threshold is two. However, it will be appreciated by those skilled in the art that the present invention may be practiced with or without a predetermined threshold for maximum allowable branch micro-ops per trace segment, and if one is employed, the threshold may be less than or greater than two.</p><p>For the illustrated embodiment, the data line terminating conditions further include the condition of not having enough room for all the micro-ops of a new macro-instruction. The micro-ops of the new macro-instruction will be cached in a new data line. In other words, for the illustrated embodiment, all micro-ops of a macro-instruction are cached in the same data line. However, it will be appreciated by those skilled in the art that the present invention may be practiced with micro-ops of a macro-instruction cached in more than one data line.</p><p>For the illustrated embodiment, the data line terminating conditions further include the condition of the fill buffers <b>250</b> being fill. However, it will be appreciated by those skilled in the art that the present invention may be practiced with a data line taking multiple fills from a fill buffer.</p><p>For the illustrated embodiment, the trace segment terminating conditions include the encountering of an indirect branch macro-instruction, a call, or a return. However, it will be appreciated by those skilled in the art that with additional tracking, the present invention may be practiced with each trace segment <b>260</b> having more than one indirect branch macro-instruction, call, and/or return.</p><p>For the illustrated embodiment, the trace segment terminating conditions further include the encountering of a branch misprediction notification, as well as an interrupt/exception.</p><p>For the illustrated embodiment, the trace segment terminating conditions further include the encountering of a long running trace segment <b>260</b> having a number of micro-ops that exceeds a predetermined maximum allowable trace segment length in terms of number of micro-ops per trace segment. In one embodiment, the predetermined maximum is 64 sets. However it will be appreciated by those skill in the art that the present invention may be practiced with or without a predetermined maximum, and if one is employed, the maximum value may be lesser than or greater than 64 sets.</p><p>FIG. 4 illustrates in further detail one embodiment of a tag entry <b>400</b> in the tag array <b>220</b> in accordance with the present invention. For the illustrated embodiment, the tag entry <b>400</b> includes a head bit <b>405</b> and a tail bit <b>410</b> for denoting whether the corresponding data line is a trace segment head <b>261</b> and/or a trace segment tail <b>263</b>. If neither bit is set, the corresponding data line is a trace segment body <b>262</b>. If both bits are set, the corresponding data line is also a trace segment body <b>262</b>, as well as the trace segment head <b>261</b> and tail <b>263</b>, i.e., the singular-member degenerate case described earlier. For the illustrated embodiment, the tag entry <b>400</b> further includes linear address bits (LA) <b>415</b> for storing a linear address in the event that the corresponding data line is a trace segment head, and a valid bit <b>420</b> for denoting whether the linear address bits <b>415</b> are valid.</p><p>For the illustrated embodiment, the tag entry <b>400</b> further comprises next way bits <b>425</b> and previous way bits <b>430</b> for facilitating sequential retrieval of the immediate successor trace segment member. More specifically, the next way bits <b>425</b> and previous way bits <b>430</b> specify the way location of the successor and predecessor data lines. For the illustrated embodiment, the tag entry <b>400</b> does not include any bits for denoting the set identifications for the successor and predecessor data lines. For the illustrated embodiment, the set identification of the successor and predecessor data lines are always X+1 modulo S and X\u22121 modulo S, respectively, where X is the set identification of the current data line, and S is number of sets of the data array <b>200</b>. In an alternate embodiment, additional bits may be employed to specify the set identifications of the successor and predecessor data lines. In other words, the successor and predecessor data lines may be located in any set.</p><p>For the illustrated embodiment, the tag entry <b>400</b> further comprises next micro-op IP bits (uIP) <b>435</b> for identifying the next micro-op IP, next macro-instruction linear IP bits (NLIP) <b>440</b> for identifying the next macro-instruction linear IP, and a uIP valid bit <b>445</b> for indicating whether the uIP <b>435</b> is valid. The uIP <b>435</b> is also used as an entry pointer into the microcode sequencer <b>115</b> for micro-ops of an encountered complex macro-instruction. The uIP valid bit <b>445</b>, when set, indicates that instruction caching a within the current data line was terminated in response to the encountering of a complex macro instruction. In one embodiment, the NLIP <b>440</b> is maintained for a trace segment tail only. In an alternate embodiment, the NLIP <b>440</b> is maintained for a trace segment head, a trace segment body, as well as a trace segment tail. Maintaining an NLIP <b>440</b> with each trace segment member has the advantage of not having to calculate it in real time, in the event it is needed while accessing the trace segment members, e.g., when the remaining trace segment member is replaced, as explained in more detail below.</p><p>Each tag entry <b>400</b> is constructed when the corresponding data line is built. More specifically, for the cache memory <b>105</b> illustrated in FIG. 1, each tag entry <b>400</b> is constructed in the fill buffers <b>250</b>, while the corresponding data line is constructed. The manner in which each tag entry <b>400</b> is constructed, and the usage of these fields are described below.</p><p>FIGS. 5 and 6 illustrate in further detail one embodiment of a data line in the data array <b>200</b>. As shown, for the illustrated embodiment, each data line <b>500</b> comprises six micro-ops (uOPs) <b>510</b>. As shown in FIG. 6, each uOP <b>510</b> comprises a valid bit <b>610</b> denoting whether the uOP <b>510</b> is valid, source register bits <b>620</b>, <b>630</b>, destination register bits <b>640</b>, and uOP code bits <b>650</b>. For the illustrated embodiment, each uOP <b>510</b> further comprises delta IP bits <b>660</b> denoting the delta increment for the macro-instruction IP, delta IP valid bit <b>670</b> denoting whether the delta IP bits <b>660</b> are valid, branch target bits <b>680</b> specifying a branch target address if the uOP <b>510</b> is a branch micro-op, and FOP Code bits <b>690</b> denoting a floating point opcode if the uOP <b>510</b> is a floating point operation. For the illustrated embodiment, the information stored with each uOP <b>510</b> may be provided by the decoder <b>140</b>.</p><p>It should be noted that some of the information described as being stored in tag entry <b>400</b> may be stored in the corresponding data line <b>500</b>, and vice versa. It should also be noted that the specific number of bit(s) used for each field can be selected according to various design considerations, and that the numbers specified herein are for ease of understanding of the present invention.</p><p>Referring now back to FIG. 2, as described earlier, for the illustrated embodiment, the cache memory <b>105</b> includes fill buffers <b>250</b>. The linear address <b>415</b> of a trace segment head (stored in the corresponding tag entry <b>400</b>) is routed to branch address calculation circuitry of the TBPU <b>110</b>. Besides the LA <b>415</b>, the NLIP <b>440</b> is routed to the next IP calculation circuitry of the TBPU <b>110</b> for calculating the next IP, whose input includes the output of the branch address calculation circuitry. The micro-op IP (uIP) <b>435</b> is routed to the microcode sequencer <b>115</b> for fetching the remaining uOPs of a complex macro-instruction, and to the multiplexer <b>120</b> for selecting between the uOPs output by the data array <b>200</b> and the microcode sequencer <b>115</b>, respectively.</p><p>The fill buffers <b>250</b> are used to build up the data lines along the predicted execution direction before they are transferred to the tag array <b>220</b> and the data array <b>200</b>, as the data width of the datapath from an external memory (not shown) to the decoder <b>140</b>, and therefore from the decoder <b>140</b> to the fill buffers <b>250</b>, is smaller than the size of a data line. For the illustrated embodiment, the fill buffers <b>250</b> include multiple buffers to facilitate multiple data lines to be constructed at the same time. The fill buffers <b>250</b> collect the address and control information as well as the decoded uOPs that are stored into the tag entries <b>400</b> of the tag array <b>220</b> and corresponding data lines of the data array <b>200</b>.</p><p>The control logic <b>210</b>, in addition to controlling the tag array <b>220</b> and the data array <b>200</b>, also controls the operation of the fill buffers <b>250</b>.</p><p>At some point in time the cache memory <b>105</b> will need to replace an existing data line to store a new trace segment, thereby replacing a trace segment member of an existing trace segment Candidates for replacement may be chosen by way prediction, least recently used (LRU), and the like. Replacing the line will cause the trace segment containing the original line to be disrupted. Any trace segment members included in cache lines following the replaced line would be cut off from the existing trace segment. To facilitate later retrieval, the replaced trace segment member is stored in the TVC <b>230</b>.</p><p>As illustrated in FIG. 9, a TVC entry <b>900</b> in the TVC <b>230</b> includes information from the tag array entry <b>400</b> and the cache line <b>500</b> of the replaced trace segment member and the linear instruction pointer (LIP) <b>910</b> of the first instruction of the replaced trace segment member. The LIP <b>910</b> may be determined from the NLIP bits <b>440</b> of the trace segment member preceding the replaced line. Alternatively, the LIP of the first instruction in each trace segment member may be stored in the tag entry <b>400</b> when the trace segment <b>260</b> is built. This facilitates quicker lookups as compared to querying the previous line for the NLIP <b>440</b>. The use of trace segment members stored in the TVC <b>230</b> is described in greater detail below. The control logic <b>210</b> comprises a plurality of state machines. FIGS. 7 and 8 illustrate the manner in which the control logic <b>210</b> operates the embodiment of the cache memory <b>105</b> illustrated in FIG. <b>2</b>. The control logic <b>210</b> operates the cache memory <b>105</b> basically in one of two complementary modes, an execution mode, which is illustrated in FIG. 7, and a trace segment building mode, which is illustrated in FIG. <b>8</b>. In one embodiment, the two complementary modes operate exclusive of one another, whereas in another embodiment, with the provision of arbitration circuitry for sharing resources, the two complementary modes may operate concurrently. In one embodiment, the two complementary modes are controlled by two corresponding state machines. It is contemplated that the present invention may be practiced with more or less state machines.</p><p>The execution mode state machine shown in FIG. 7 operates in one of seven states, an idle state <b>700</b>, a head lookup state <b>710</b>, a body lookup state <b>730</b>, a tail state <b>740</b>, a micro-sequencer (MS) state <b>750</b>, a body miss state <b>760</b>, and a trace build state <b>770</b>. As shown, the execution mode state machine starts off in the idle state <b>700</b>, upon reset or upon detection by the execution units <b>125</b> of a uOP branch misprediction condition. The execution mode state machine transitions from the idle state <b>700</b> to the head lookup state <b>710</b> when the control logic <b>210</b> is informed by the execution units <b>125</b> of a macro branch misprediction condition, or it detects either a fetch from a linear address or end of trace segment build condition.</p><p>While in the head lookup state <b>710</b>, the execution mode state machine causes a trace segment head to be looked up by address matching a next IP, provided by the next IP calculation circuitry of the TBPU <b>110</b>, against the memory addresses maintained for the trace segment heads. The execution mode state machine will cause the trace segment lookup process to be restarted with a new next IP, if a macro branch misprediction condition is detected by the execution units <b>125</b> prior to the completion of the current lookup. If the head lookup process proceeds to the end, the process will result in either a cache hit or cache miss.</p><p>If the head lookup process results in a cache hit, and the trace segment head is not also a trace segment tail, and the trace segment head data line did not end with a complex macro-instruction, the execution mode state machine causes the micro-ops of the trace segment head to be output to the execution units <b>125</b> and transitions to the body lookup state <b>730</b>. If the head lookup process results in a cache hit, and the trace segment head is also a trace segment tail, and the trace segment head data line did not end with a complex macro-instruction, the execution mode state machine causes the micro-ops of the trace segment head to be output to the execution units <b>125</b> and transitions to the tail state <b>740</b>. If the head lookup process results in a cache hit, and the trace segment head data line ends with a complex macro-instruction, the execution mode state machine causes the micro-ops of the trace segment head to be output to the execution units <b>125</b> and transitions to the MS state <b>750</b>. In any case, if the head lookup process results in a cache hit, the set register <b>235</b> is loaded with the set number of the trace segment head <b>261</b>.</p><p>If the head lookup process results in a cache miss, the execution mode state machine queries the TVC <b>230</b> with the NLIP <b>440</b> to determine if a corresponding TVC entry <b>900</b> is present by matching the LIP <b>910</b> of the TVC entry <b>900</b>. If a match is found, the head LA <b>415</b> of the TVC entry <b>415</b> is compared to the LIP <b>910</b> to verify that the TVC entry <b>900</b> is indeed the proper head segment, and a hit is generated if they match. In the case of a TVC <b>230</b> hit, the uOPs are supplied to the execution units <b>125</b>. The set register <b>235</b> is loaded with the set number that had been used to store the trace segment head <b>261</b> and incremented (X+1 modulo S). The set number is determined from the least significant bits of the head LA <b>415</b>, which are used for translating the LA <b>415</b> to the set number in the data array <b>200</b> when a trace segment is first built. The execution mode state machine then transitions to the body lookup state, using the information in the set register <b>235</b> and the TVC entry <b>900</b> to locate the next trace segment body <b>262</b>. Upon a TVC <b>230</b> miss, the execution mode state machine transitions to the trace build state <b>770</b>.</p><p>While in the body look up state <b>730</b>, the execution mode state machine causes the next trace segment body to be looked up. For the illustrated embodiment, as described earlier, the next trace segment body is located in the data line of set X+1 modulo S in way W indexed by next way bits <b>425</b> of the current tag entry <b>400</b>, where X is the current set, S is the number of sets of the data array <b>200</b>, and W is the indexed way. In an alternate embodiment, the next trace segment body is located in the data line of set Y (denoted by a set identifier bit) in way W indexed by next way bits <b>425</b> of the current tag entry <b>400</b>. Once located, the execution mode state machine causes the uOPs of the trace segment body to be output to the execution units <b>125</b>. The execution mode state machine remains in the body lookup state <b>730</b> and continues to cause the next trace segment bodies to be looked up, and their uOPs to be output, upon locating them, as long as it is getting cache hits, and has not reached the trace segment tail, nor encountered a data line ending with a complex macro-instruction, nor has been informed of a macro/micro branch misprediction condition by one of the execution units <b>125</b>. For the illustrated embodiment, decoded micro-ops of a macro-instruction may include one or more branch micro-ops.</p><p>While in the body lookup state <b>730</b>, if the control logic <b>210</b> is informed of the detection of a macro branch misprediction by one of the execution units <b>125</b>, the execution mode state machine aborts the body lookup process, and transitions back to the head lookup state <b>710</b>. If the body lookup process results in a cache hit, and the data line does not end with a complex macro-instruction, but the data line is a trace segment tail, the execution mode state machine transitions to the tail state <b>740</b> after the uOPs of the trace segment tail have been output. If the body lookup process results in a cache hit, and the data line ends with a complex macro-instruction, the execution mode state machine transitions to the MS state <b>750</b> after outputting the uOPs of the cache line. The set register <b>235</b> is incremented (X+1 modulo S) as each successive body segment is located. Alternatively, if the next trace segment body is located in the cache line of set Y (denoted by a set identifier bit) in way W indexed by next way bits <b>425</b> of the current tag entry <b>400</b>, the set register will be loaded with the value of set Y. In either case, the value in the set register corresponds to the set number of the current trace segment member. If the body lookup process results in a cache miss, the execution mode state machine transitions to the body miss state <b>760</b>.</p><p>At the tail state <b>740</b>, the execution mode state machine unconditionally returns to the head lookup state <b>710</b>.</p><p>At the body miss state <b>760</b>, the execution mode state machine queries the TVC <b>230</b> with the NLIP <b>440</b> to determine if a corresponding TVC entry <b>900</b> is present by matching the LIP <b>910</b> of the TVC entry <b>900</b>. If a match is found, the head LA <b>415</b> from the previous trace segment member is checked against the head LA <b>415</b> of the TVC entry <b>900</b>, and a hit is generated if they match. In the case of a TVC <b>230</b> hit, the uOPs are supplied to the execution units <b>125</b>. The set register <b>235</b> is incremented (X+1 modulo S) and the TVC <b>230</b> is again queried to determine if the next NLIP <b>440</b> matches the LIP <b>910</b> of an TVC entry <b>900</b>. This process continues until a TVC <b>230</b> miss occurs.</p><p>On a TVC <b>230</b> miss, the value in the set register <b>235</b> is incremented (X+1 modulo S). The incremented value stored in the set register <b>235</b> and the next way <b>425</b> information stored in the last executed TVC entry <b>900</b> are used to synchronize back to the tag array <b>220</b>. A lookup in the tag array <b>220</b> is conducted by matching the LA bits <b>415</b> of the last segment member executed from the TVC <b>230</b> to the LA bits <b>415</b> of the tag array entry <b>400</b> addressed by the incremented value in the set register <b>235</b>. If a match occurs execution continues from the tag array <b>220</b> as described above. If a match does not occur, the cache memory <b>105</b> transitions to the head lookup state <b>710</b>. In some embodiments, the information stored in the TVC <b>230</b> may be copied back into the tag and data arrays <b>220</b>, <b>200</b> before, after, or concurrent with the uOPs being provided to the execution units <b>125</b>. In other embodiments, the information stored in the TVC <b>230</b> may not be copied back into the tag and data arrays <b>220</b>, <b>200</b>.</p><p>The TBPU <b>110</b> may include a trace branch target buffer (TBTB) <b>112</b> for tracking branch history and facilitating branch prediction for a particular trace segment member. Typically, the TBTB <b>112</b> stores branch information based on the set number of the trace segment member. Because the value in the set register <b>235</b> corresponds to the set number of the current trace segment member, this value may be used to access the TBTB <b>112</b> for trace segment members executed from the TVC <b>230</b>.</p><p>At the MS state <b>750</b>, the execution mode state machine allows the microcode sequencer <b>115</b> to output the remaining uOPs of the data line ending with a complex macro-instruction. The execution mode state machine allows the microcode sequencer <b>115</b> to continue until all remaining uOPs have been output, as long as it is not informed of the detection of a macro/micro branch misprediction condition by the execution units <b>125</b>. The execution mode state machine aborts the allowance if it is informed of the detection of a macro/micro branch misprediction condition by the execution units <b>125</b>. The execution mode state machine transitions back to the head lookup state <b>710</b> if it is informed of the detection of a macro branch misprediction condition. The execution mode state machine transitions back to the idle state <b>700</b> if it is informed of the detection of a micro branch misprediction condition.</p><p>However, if the control logic <b>210</b> is informed by the microcode sequencer <b>115</b> that it has finished outputting the remaining uOPs of the data line ending with a complex macro-instruction, the execution mode state machine transitions to the body lookup state <b>730</b> if the data line is not a trace segment tail, and to the tail state <b>740</b> if the data line is a trace segment tail.</p><p>At the trace build state <b>770</b>, the execution mode state machine unconditionally transitions to the idle state <b>700</b> on detection of a trace segment ending condition (denoted by the complementary trace segment build mode state machine) In other words, the trace build state <b>770</b> of the execution mode is essentially a wait state.</p><p>The trace segment build mode state machine shown in FIG. 8 operates in one of seven states, an idle state <b>800</b>, a fetch request state <b>810</b>, a waiting for uOPs state <b>820</b>, a bypassing uOPs state <b>830</b>, a write to arrays state <b>840</b>, a microcode sequencer (MS) and write to arrays state <b>850</b>, and a head lookup state <b>860</b>. As shown, the trace segment build mode state machine starts off in the idle state <b>800</b>, upon reset or upon detection by the execution units <b>125</b> of a macro-micro branch misprediction condition. The trace segment build mode state machine transitions from the idle state <b>800</b> to the fetch request state <b>810</b> when the control logic <b>210</b> detects a need to issue an instruction fetch request, ie., an access to the cache memory <b>105</b> results in a tag array <b>220</b>.</p><p>At the fetch request state <b>810</b>, the trace segment build mode state machine causes an instruction fetch request to be issued to the ITLB <b>135</b>, and transitions to the waiting for uOPs state <b>820</b>. The trace segment build mode state machine remains in the waiting for uOPs state <b>820</b> until valid uOPs are provided to the fill buffers <b>250</b>. At such time, the trace segment build mode state machine transitions to the bypass uOPs state <b>830</b>. At the bypass uOPs state <b>830</b>, the trace segment build mode state machine bypasses the valid uOPs to the execution units <b>125</b> as it writes into the fill buffers <b>250</b> until a data line terminating condition is encountered. If the data line terminating condition is the encountering of a complex macro-instruction, the trace segment build mode state machine transitions to the MS and write to arrays state <b>850</b>. For other data line terminating conditions, if the bypassed uOPs built up in the fill buffers <b>250</b> are not cacheable, the trace segment build mode state machine returns to the waiting for uOPs state <b>820</b>. Otherwise, the trace segment build mode state machine transitions to the write to arrays state <b>840</b>.</p><p>At the write to arrays state <b>840</b>, the completed data line is transferred into corresponding locations in the tag and data arrays <b>220</b> and <b>200</b>. Recall that for the illustrated embodiment, the locations in data array <b>200</b> are the locations of one of the ways of set X+1 modulo S. Recall that for an alternate embodiment, the locations in data array <b>200</b> are the locations of one of the ways of an indexed set. In one embodiment, the way is selected by way prediction. Alternatively, an LRU approach may be used. Furthermore, when used in conjunction with the partial address matching approach for looking up a trace segment head, the LRU approach may be further qualified with the assurance that the tag matching subsets of the tag addresses for set X+1 module S (or an indexed set) will be unique. In other words, if a non-LRU way has a corresponding tag matching subset of its tag address that is the same as the tag matching subset of the tag address of the incoming data line, that non-LRU way is selected instead of the LRU way.</p><p>If a valid trace segment member is replaced, the replaced trace segment member is allocated into the TVC <b>230</b> as described above. The TVC <b>230</b> may employ a replacement method such as LRU if all entries in the TVC <b>230</b> have been previously allocated. Upon writing the data line into the tag and data arrays <b>220</b> and <b>200</b>, the trace segment build mode state machine transitions back to the waiting for uOPs state <b>820</b> if the data line that was just written into the data array <b>200</b> is not a trace segment tail. If the written data line is a trace segment tail, the trace segment build mode state machine transitions back to the idle state <b>800</b> if the NLIP is not known, otherwise, the trace segment build mode state machine transitions to the head lookup state <b>860</b>.</p><p>At the MS and write to arrays state <b>850</b>, the completed data line is written into the tag and data arrays <b>220</b> and <b>200</b>, as described earlier for the write to arrays state <b>840</b>. However, the trace segment build mode state machine does not transition out of the MS and write to arrays state <b>850</b> until it has been signaled by the microcode sequencer <b>115</b> that the remaining micro-ops of the complex macro-instruction have all been output to the execution units <b>125</b>. Upon completion of output by the microcode sequencer <b>115</b>, as in the write to arrays state <b>840</b>, the trace segment build mode state machine transitions to the waiting for uOPs state <b>820</b> if the written data line was not a trace segment tail. If the written data line is a trace segment tail, the trace segment build mode state machine transitions to the idle state <b>800</b> if the NLIP is unknown, and to the head lookup state <b>860</b> if the NLIP is known. Additionally, the trace segment build mode state machine will transition to the idle state <b>800</b> if the control logic <b>210</b> receives notification that a micro branch misprediction has been detected by the execution units <b>125</b>.</p><p>At the head lookup state <b>860</b>, the trace segment build mode state machine causes the trace segment head to be looked up based on the known NLIP (through the complementary execution mode state machine). The trace segment build mode state machine transitions to the idle state <b>800</b> if the lookup resulted in a hit (as informed by the complementary execution mode state machine). Otherwise, the trace segment build mode state machine transitions to the fetch request state <b>810</b>. From the fetch request state <b>810</b>, the cache memory <b>105</b> transitions to the other states as described earlier.</p><p>Thus, advantages of storing replaced trace segment members in the TVC <b>230</b> have been illustrated. By executing lines out of the TVC <b>230</b>, costly switches to build mode can be avoided and code redundancy can be reduced. Therefore, cache hit rate, and resultingly, processor performance are enhanced.</p><p>While the invention is susceptible to various modifications and alternative forms, specific embodiments have been shown by way of example in the drawings and have been described in detail herein. However, it should be understood that the invention is not intended to be limited to the particular forms disclosed. It will be appreciated by those of ordinary skill having the benefit of this disclosure that numerous variations from the foregoing illustrations will be possible without departing from the inventive concept described herein. Accordingly, it is the claims set forth below, and not merely the foregoing illustration, which are intended to define the exclusive rights claimed in this application.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Guy", "last_name": "Peled", "name": ""}, {"first_name": "Ilan", "last_name": "Spillinger", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTEL CORPORATION"}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMEP"}, {"label": "G06F   9/38        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711133"}, {"primary": false, "label": "711003"}, {"primary": false, "label": "712E09055"}, {"primary": false, "label": "712230"}, {"primary": false, "label": "711E1202"}], "ecla_classes": [{"label": "G06F   9/38B4"}, {"label": "G06F   9/38B"}, {"label": "G06F  12/08B14"}], "cpc_classes": [{"label": "G06F   9/3802"}, {"label": "G06F  12/0875"}, {"label": "G06F   9/3802"}, {"label": "G06F   9/3808"}, {"label": "G06F  12/0875"}, {"label": "G06F   9/3808"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1997-12-16", "application_date": "1997-12-16", "family_members": [{"ucid": "US-6216206-B1", "titles": [{"lang": "EN", "text": "Trace victim cache"}]}]}