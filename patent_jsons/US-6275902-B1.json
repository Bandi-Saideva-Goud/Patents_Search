{"patent_number": "US-6275902-B1", "publication_id": 72742300, "family_id": 26508524, "publication_date": "2001-08-14", "titles": [{"lang": "EN", "text": "Data processor with variable types of cache memories and a controller for selecting a cache memory to be access"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72598116\"><p>A data processor has a first cache memory with a large capacity and one port and a second cache memory with a small capacity and two ports disposed between a main memory and an instruction processing section. Data which is frequently used is stored in the first cache memory and data which is less frequently used is stored in the second cache memory under control of a controller responsive to prefetch instructions. One of the cache memories may be a set associative cache memory composed of a plurality of memory chips each having at least two memory banks and an output part to gain access to data sets consecutively and one at a time within the memory banks. On the basis of an address sent from the instruction processing section, a memory bank is selected, and a data set from the selected memory bank is supplied to the processing section.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6275902-B1-CLM-00001\" num=\"1\"><claim-text>1. A data processor comprising:</claim-text><claim-text>a main memory for storing data and instructions; </claim-text><claim-text>an instruction processor for processing said data in accordance with said instructions; </claim-text><claim-text>a cache memory part, connected between said main memory and said instruction processor, including a first cache memory and a second cache memory, said first cache memory having a large storage capacity and said second cache memory having a small storage capacity; and </claim-text><claim-text>a controller, included in said cache memory part, which in response to an address to be accessed, selects one of said first and second cache memories and stores data into the selected cache memory, </claim-text><claim-text>wherein said controller includes a storage having stored therein a plurality of addresses and information, each of said addresses being stored in corresponding relation to a portion of said information which indicates one of said first and second cache memories to be accessed, and </claim-text><claim-text>wherein said controller in response to said address to be accessed refers to said portion of said information stored in said storage of said controller in corresponding relation to said address to be accessed and selects one of said first and second cache memories indicated by said portion of said information. </claim-text></claim>"}, {"num": 2, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6275902-B1-CLM-00002\" num=\"2\"><claim-text>2. A data processor comprising:</claim-text><claim-text>a main memory for storing data and instructions; </claim-text><claim-text>an instruction processor for processing said data in accordance with said instructions; </claim-text><claim-text>a cache memory part, connected between said main memory and said instruction processor, including a first cache memory and a second cache memory, said first cache memory and said second cache memory having a different storage capacities; and </claim-text><claim-text>a controller, included in said cache memory part, which in response to an address to be accessed, selects one of said first and second cache memories and stores data into the selected cache memory, </claim-text><claim-text>wherein said controller includes a storage having stored therein a plurality of addresses and information, each of said addresses being stored in corresponding relation to a portion of said information which indicates one of said first and second cache memories to be accessed, and </claim-text><claim-text>wherein said controller in response to said address to be accessed refers to said portion of said information stored in said storage of said controller in corresponding relation to said address to be accessed and selects one of said first and second cache memories indicated by said portion of said information.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54708262\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><p>This is a continuation of application Ser. No. 08/281,002, filed Jul. 27, 1994 now U.S. Pat. No. 5,848,432.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>FIELD OF THE INVENTION</h4><p>The present invention relates to a data processor having a cache memory, and more particularly to a software prefetch for efficiently using two types of cache memories and set associative control for most favorably controlling the access of the set associative cache memories. Moreover, the present invention relates to a data processor having a controller for these operations.</p><h4>BACKGROUND OF THE INVENTION</h4><p>In general, a computer having a cache memory stores data to be frequently used in a small-capacity high-speed cache memory as a copy of part of the data stored in a large-capacity low-speed main memory, so that an instruction unit, such as a CPU, may make a high-speed data access to the cache memory for frequently used data and accesses to the main memory only when the desired data is not present in the cache memory.</p><p>However, because the machine cycle of the CPU is significantly shorter compared with that of the main memory, the penalty in the case of a cache miss (the time until requested data is obtained from the main memory) increases.</p><p>A method called software prefetch for solving the above problem is described in David Callhan et al., \u201cSoftware Prefetching\u201d Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, 1991, pp. 40-52. In the method described in this first publication, an address is computed by a prefetch instruction before an instruction unit requires data, the address is checked to see if data indicated by the address is present in the cache memory, and if not, the data is transferred from the main memory to the cache memory. Therefore, it is possible to improve the hit ratio of the cache memory and minimize the penalty because data is previously stored in the cache memory by the prefetch instruction whenever data is required.</p><p>A cache memory comprising two buffers with different purposes, which are properly used by hardware is disclosed in Japanese Patent Laid-Open No. 303248/1992</p><p>In this second publication, the cache memory has an S buffer and a P buffer. The S buffer stores data to be accessed frequently over time. The P buffer stores data of which the addresses to be referenced from now on by the program are close to the currently referenced address, i.e. the P buffer stores the array data to be accessed in the array computation. Either one of the two buffers may be used selectively depending on the addressing mode in effect and on the type of register being used for the address calculation.</p><p>In general, a computer stores instructions or data to be frequently called and processed by a processor in a high-speed small-capacity memory, called a cache memory, as a copy of part of the instructions or data stored in a comparatively low-speed large-capacity main memory. Thus, the computer operation speed is increased. A data access system for such a cache memory includes a direct-mapped memory and a set associative memory.</p><p>The direct mapping system is used for accessing a cache memory by directly outputting data or an instruction stored in an address designated by a processor or the like and storing it in the designated address.</p><p>The set associative memory is used for accessing a plurality of sets of data values or a plurality of instructions (called a data set) in a cache memory having a plurality of sets, each of which comprises a plurality of memories common in allocation of addresses. A plurality of accessed sets of data values or a plurality of accessed instructions required are selected and processed in the processor.</p><p>FIG. 17 shows a schematic view of a data processor having a two-set associative cache memory according to a third conventional arrangement. In FIG. 17, symbol <b>9201</b> represents a CPU, <b>9202</b> to <b>9217</b> represent 8-bit output universal memories, <b>9218</b> represents an address bus, <b>9219</b> represents a 64-bit data bus of a first set, and <b>9220</b> represents a 64-bit data bus of a second set. The universal memories are used as data arrays of the two-set associative cache memory. The memories <b>9202</b> to <b>9209</b> are used as the data array of the first set and the memories <b>9210</b> to <b>9217</b> are used as the data array of the second set.</p><p>When an address designated by the CPU is sent to memories through the address bus, two sets of data values each having a width of 64 bits are outputted to the CPU through a respective data bus.</p><p>To constitute a set associative cache memory having m sets of data values with the width of n bits by using k-bit output memories, \u201cn\u00d7m/k\u201d memory chips are necessary in general. In the case of the above-described third conventional arrangement, 16 memories are necessary because n equals 64, m equals 2, and k equals 8.</p><p>The method described in first publication has the problem that an expensive two-port cache memory must be used in order to process transfer of data from the main memory to the cache memory and a memory referencing instruction sent from the instruction unit at the same time. Unless simultaneous processing is carried out, it is possible to use a generally-used one-port cache memory. In this case, however, a lot of processing time is required and the feature of software prefetch cannot effectively be used.</p><p>Moreover, the method described in the first publication has the additional problem that, when data, which is read from a cache memory only once and is immediately expelled from the cache memory, is held in the cache memory, the cache memory is filled with useless data and the hit ratio decreases.</p><p>These problems frequently occur in a program for handling large-scale data exceeding the capacity of a cache memory.</p><p>The arrangement described in the second publication has the problem that, because a cache memory for storing data between two cache memories is determined by an address designation system and a register used for address computation, two cache memories must properly be used for considering data characteristics including data size.</p><p>It is the first object of the present invention to provide a data processor for solving the above problems, which is capable of quickly and efficiently processing small-capacity frequently accessed data stored in a cache memory and large-scale data exceeding the capacity of the cache memory, and which is also capable of lessening the contamination of the cache memory and improving the hit ratio.</p><p>The third conventional arrangement described with reference to FIG. 17 has a problem that, when the number of sets of set associative cache memories increases, or the data bit width increases and the number of memories for constituting the cache memories increases, the cache memory cost increases.</p><p>When the number of memories increases, problems occur in that the address bus fan-out, address bus length, and data bus length increase, the cache memory access time increases, and the machine cycle of the entire data processor cannot be shortened.</p><p>When the number of sets increases, problems occur in that a number of data buses equivalent to the number of sets is required and the number of pins of the CPU increases. That is, a problem occurs in that it is impossible to meet the restriction on the number of pins of a package in the case of one chip.</p><p>It is the second object of the present invention to provide a set associative cache memory comprising a smaller number of memories.</p><h4>SUMMARY OF THE INVENTION</h4><p>To achieve the above first object, the present invention involves the use of a first cache memory with a large capacity and one port and a second cache memory with a small capacity and two ports disposed between a main memory and an instruction processing section, and a control section controlled by a prefetch instruction to store data to be frequently accessed in the first cache memory and data to be less frequently accessed in the second cache memory.</p><p>Because data to be frequently accessed is stored in the first cache memory, the hit ratio is improved. Moreover, because data to be less frequently accessed is not stored in the first cache memory, the storing of useless data in the first cache memory can be lessened.</p><p>Because data to be less frequently used is stored in the second cache memory, the data can be removed from the second cache memory after it is processed. That is, because data to be always accessed is stored in the second cache memory, though the capacity of the second cache memory is small, the hit ratio can be improved.</p><p>Moreover, because the second cache memory has two ports, efficient processing is realized by simultaneously processing the transfer of large-scale data to be less frequently accessed from the main memory and the memory referencing instruction sent from the instruction unit.</p><p>Furthermore, because it is sufficient to provide only a small-capacity second cache memory with the function for simultaneously processing a data transfer from the main memory and the memory referencing instruction sent from the instruction unit, it is possible to decrease the hardware volume and the cost.</p><p>To achieve the above second object, the present invention provides a processor for processing instructions or data; a set associative cache memory comprising a plurality of memory chips each of which includes m (m is an integer equal to or larger than 2) sets of memory bank regions and an output section for sequentially accessing data sets one by one out of the above m sets of memory bank regions; a set judging section for generating a selection signal for selecting a memory bank region out of the above m sets of memory bank regions in accordance with an address sent from the processor; a set selecting section for outputting a data set selected by the selection signal out of the data sets to be sequentially accessed from the set associative cache memory to the processor; an address bus connected between the set associative cache memory and the processor to transfer an address for designating data from the processor; a first data bus connected between the set associative cache memory and the set selecting section to access the data sets; and a second data bus connected between the set selecting section and the processor to access the selected data set.</p><p>The above-described constitution makes it possible to decrease the number of memories to 1/m, as small as the existing number of memories, because m sets of memory bank regions are present in one memory chip.</p><p>Because the number of memories decreases, it is possible to decrease the loads on the address bus and the data bus, to access the cache memory at a high speed, and to shorten the machine cycle.</p><p>Moreover, because data sets are sequentially outputted from one memory chip one by one, only one data bus is required. Therefore, it is possible to decrease the number of pins and the load of the CPU.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>These and other objects, features, and advantages of the present invention will be understood more clearly from the following detailed description with reference to the accompanying drawings, wherein</p><p>FIG. 1 is a schematic block diagram of an embodiment of the present invention:</p><p>FIG. 2 is a schematic diagram of the memory unit <b>202</b> in FIG. 1;</p><p>FIG. 3 is a schematic block diagram of the instruction unit <b>201</b> in FIG. 2;</p><p>FIG. 4 is a diagrammatic illustration for explaining a pipeline;</p><p>FIG. 5 is a schematic block diagram of the prefetch queue in FIG. 2;</p><p>FIG. 6 is a schematic diagram of the cell <b>502</b> in FIG. <b>5</b>:</p><p>FIG. 7 is a schematic circuit diagram of the priority circuit <b>500</b> in FIG. 5;</p><p>FIG. 8 is a schematic circuit diagram of the judging circuit <b>501</b> in FIG. 5;</p><p>FIG. 9 is a schematic block diagram of the second cache memory <b>100</b> in FIG. 2;</p><p>FIG. 10 is a schematic diagram of the cell <b>901</b> in FIG. 9;</p><p>FIG. 11 is a schematic diagram of the first cache memory in FIG. 1;</p><p>FIG. 12 is a diagram for explaining an instruction format;</p><p>FIG. 13 is a table for explaining types of instructions;</p><p>FIG. 14 is a schematic circuit diagram of the control circuit <b>103</b> in FIG. 2;</p><p>FIG. 15 is a schematic diagram of a second embodiment of the memory unit <b>202</b> in FIG. 1;</p><p>FIG. 16 is a schematic block diagram of an embodiment of the present invention;</p><p>FIG. 17 is a schematic block diagram of a conventional processor;</p><p>FIG. 18 is a schematic block diagram of the processor <b>9101</b> in FIG. 16;</p><p>FIG. 19 is a diagram for explaining the pipeline operation of the processor <b>9101</b> in FIG. 16;</p><p>FIG. 20 is a timing diagram for memory operations for a data read operation;</p><p>FIG. 21 is a timing diagram for memory operations for a data write operation;</p><p>FIG. 22 is a block diagram of the memory <b>9107</b> in FIG. 16;</p><p>FIG. 23 is a schematic diagram of a first embodiment of the set selecting section <b>9103</b> in FIG. 16;</p><p>FIG. 24 is a schematic diagram of a second embodiment of the set selecting section <b>9103</b> in FIG. 16;</p><p>FIG. 25 is a schematic diagram of the set judging section <b>9102</b> in FIG. 16;</p><p>FIG. 26 is a schematic circuit diagram of the judging circuit <b>91007</b> in FIG. 25;</p><p>FIG. 27 is a schematic block diagram of a second embodiment of the processor <b>9101</b> in FIG. 16;</p><p>FIG. 28 is a diagram for explaining the pipeline operation of the processor <b>9101</b> in FIG. 27;</p><p>FIG. 29 is a timing diagram of memory operations for a data read operation;</p><p>FIG. 30 is a diagram for explaining the pipeline operation of the processor <b>9101</b> in FIG. 32;</p><p>FIG. 31 is a diagram for explaining an address constitution;</p><p>FIG. 32 is a schematic diagram of a third embodiment of the processor <b>9101</b> in FIG. <b>16</b>.</p><p>FIG. 33 is a schematic block diagram of a constitution including the first cache memory of FIG. 1 as a set associative type cache memory;</p><p>FIG. 34 is a schematic block diagram of another embodiment of the present invention;</p><p>FIG. 35 is a schematic diagram of the memory unit <b>3502</b> in FIG. 34;</p><p>FIG. 36 is a schematic diagram of the instruction unit <b>3501</b> in FIG. 34;</p><p>FIG. 37 is a diagram for explaining the pipeline operation in effect when the data processor in FIG. 34 executes instructions;</p><p>FIG. 38 is a schematic diagram of the second cache memory <b>3490</b> in FIG. 35;</p><p>FIG. 39 is a schematic diagram of the cell <b>3801</b> in FIG. 38;</p><p>FIG. 40 is a schematic diagram of the control circuit <b>3403</b> in FIG. 35;</p><p>FIG. 41 is a schematic diagram of a second embodiment of the first cache memory <b>101</b> in FIG. 2;</p><p>FIG. 42 is a schematic diagram of a second embodiment of the second cache memory <b>100</b> in FIG. 2;</p><p>FIG. 43 is a schematic block diagram of a third embodiment of the present invention;</p><p>FIG. 44 is a schematic diagram of the memory unit <b>4402</b> in FIG. 43;</p><p>FIGS. <b>45</b>(<i>a</i>), <b>45</b>(<i>b</i>), <b>45</b>(<i>c</i>) and <b>45</b>(<i>d</i>) are diagrams for explaining the pipeline operation in effect when the data processor in FIG. 43 executes instructions;</p><p>FIG. 46 is a schematic block diagram of the second cache memory <b>4390</b> in FIG. 44;</p><p>FIG. 47 is a schematic diagram of the cell <b>4601</b> in FIG. 46;</p><p>FIG. 48 is a schematic diagram of the control circuit <b>4303</b> in FIG. 44;</p><p>FIG. 49 is a schematic block diagram of a fourth embodiment of the present invention;</p><p>FIGS. <b>50</b>(<i>a</i>) and <b>50</b>(<i>b</i>) are diagrams for explaining the pipeline operation in effect when the data processor of in FIG. 49 executes instructions; and</p><p>FIG. 51 is a table for explaining the types of instructions to be processed by the data processor in FIG. <b>49</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DESCRIPTION OF THE PREFERRED EMBODIMENTS</h4><p>FIG. 1 shows a schematic view of the present invention.</p><p>The computer of the present invention comprises an instruction unit <b>201</b>, a memory unit <b>202</b>, and a main memory <b>203</b>.</p><p>The instruction unit <b>201</b> uses, for example, a CPU for performing operations and control.</p><p>The memory unit <b>202</b> comprises a control section comprising a first cache memory <b>101</b>, a second cache memory <b>100</b>, selectors <b>104</b> and <b>1605</b> for transferring data to and from these memories, and a control unit <b>1600</b>.</p><p>The main memory <b>203</b> is a memory for storing instructions and data.</p><p>The first cache memory <b>101</b> is a one-port cache memory having a capacity larger than that of the second cache memory <b>100</b>.</p><p>The second cache memory <b>100</b> is a two-port cache memory having a capacity smaller than that of the first cache memory <b>101</b>.</p><p>The instruction unit <b>201</b> is a unit for processing instructions, which transfers data to and from the first cache memory <b>101</b> and the second cache memory <b>100</b> through buses <b>210</b>, <b>211</b>, and <b>212</b>. That is, the unit <b>201</b> transmits an address, data, and a control signal to the memory unit <b>202</b> and main memory <b>203</b> through the address bus <b>210</b>, four-byte-width write data bus <b>211</b>, and control signal line <b>213</b>.</p><p>The memory unit <b>202</b> transmits data and a wait signal to the instruction unit <b>201</b> through the four-byte-width read data bus <b>212</b> and a wait signal line <b>214</b> and a request signal to the main memory <b>203</b> through a request signal line <b>218</b>.</p><p>The main memory <b>203</b> transmits data to the first cache memory <b>101</b> and the second cache memory <b>100</b> through buses <b>215</b> and <b>216</b>. That is, the main memory <b>203</b> transmits data, an address, and a response signal to the memory unit <b>202</b> through the transfer address bus <b>216</b> and a response signal line <b>217</b>.</p><p>FIG. 12 is an illustration for explaining a format of the operation code of an instruction processed by the instruction unit <b>201</b> in FIG. <b>1</b>. In FIG. 12, symbol OP represents an operation code, A and B represent fields for designating a source register, C represents a field for designating a target register, and d represents a field for showing immediate data.</p><p>FIG. 13 is an illustration showing types of instructions processed by the instruction unit <b>201</b> in FIG. <b>1</b>. Though the number of instructions is restricted to ten in this embodiment for easy understanding, this is not to be construed as a restriction on the present invention. The present invention can also be applied to a computer having several tens of instructions to more than one hundred instructions similar to a normal processor.</p><p>Instructions AND, OR, ADD, and SUB perform operations corresponding to the source registers A and B and store data in the target register C.</p><p>The instruction NOT stores the negation of bits in the source register A into the target register C.</p><p>The branch instruction BRA adds the immediate data d to the program counter PC and stores it in the program counter PC.</p><p>The load instruction LD stores read data in the register C by using the sum of the contents of the register A and those of the register B as an address.</p><p>The store instruction ST writes the contents of the register s by using the contents of the register A as an address.</p><p>A prefetch instruction is described below.</p><p>The prefetch instruction PF<b>1</b> checks if data corresponding to the first cache memory <b>101</b> and the second cache memory <b>100</b> is present by using the sum of the contents of the register A and those of the register B as an address. If not successful, the instruction PF<b>1</b> transfers data to the first cache memory <b>101</b> from the main memory <b>203</b>.</p><p>The prefetch instruction PF<b>2</b> has the same functions as PF<b>1</b> except that PP<b>2</b> writes transferred data in the second cache memory <b>100</b>.</p><p>Though described in detail later, the first cache memory <b>101</b> is a cache memory having a capacity of 1 M bits and a block size of 16 bytes using the direct map system.</p><p>The direct map system is a system in which a place for storing data in a cache memory is uniquely determined by an address of a memory.</p><p>The second cache memory <b>100</b> is a cache memory with a block size of 4 bytes and 64 entries using the full associative system.</p><p>The full associative system is a system for storing data of optional address of a memory in an optional storing place of a cache memory. The instruction PF<b>1</b> is used to prefetch data to be probably reused and the instruction PF<b>2</b> is used to prefetch data not to be reused.</p><p>A compiler judges whether to reuse the data when generating an object code. For example, when accessing large-scale data exceeding the capacity of a cache memory, the compiler uses the instruction PF<b>2</b> by judging that the data will not be reused even if the data to be stored in the cache memory.</p><p>Though the first cache memory <b>101</b> has a capacity of 1 M bits, which is larger than that of the second cache memory, the entire size of the cache memory <b>101</b> is not very large and the cache memory <b>101</b> operates at a high speed because it has one port.</p><p>The second cache memory <b>100</b> uses the full associative system and processes the memory referencing instruction sent from the instruction unit <b>1</b> and the transfer of the data sent from the main memory <b>203</b> at the same time. Therefore, though the cell structure is complicated, the entire size of the cache memory <b>100</b> is small, and moreover, the operation speed of it can be increased because the cache memory <b>100</b> has only sixty-four entries.</p><p>The second cache memory <b>100</b> is used to store data not to be reused by the instruction PF<b>2</b>. Therefore, because the cache memory <b>100</b> only temporarily stores data transferred from the main memory <b>203</b> by the instruction PF<b>2</b>, but not used yet by the instruction LD, it has a high hit ratio, though its capacity is small and the performance of it can be improved.</p><p>When executing a load instruction, the instruction unit <b>201</b> sends the address of data to be loaded to the address bus <b>210</b> and designates the load instruction by the control signal <b>213</b>. When data corresponding to a cache memory in the memory unit <b>202</b> is present, the memory unit <b>202</b> reads the data and sends it to the data bus <b>212</b>. Unless the data is present, the memory unit <b>202</b> transmits the wait signal <b>214</b> to the instruction unit <b>201</b> and sets the request signal <b>218</b>, for requesting the main memory <b>203</b> to transfer the data, to \u20181\u2019. When receiving the signal <b>218</b>, the main memory <b>203</b> reads the data, sends the data to the transfer data bus <b>215</b>, and returns the response signal <b>217</b> to the memory unit <b>202</b>. The memory unit <b>202</b> writes the data in a stored cache memory, reads the data to the instruction unit <b>201</b> to send it through the data bus <b>212</b>, and sets the wait signal <b>214</b> to \u20180\u2019.</p><p>When executing a store instruction, the instruction unit <b>201</b> sends a write address to the address bus <b>210</b> and data to be written to the write data bus <b>211</b> to send the data to the memory unit <b>202</b>, main memory <b>203</b>, and input/output unit <b>204</b>. In the case of this embodiment, data is written in both the cache memory <b>100</b> or <b>101</b> and the main memory <b>203</b> (write-through) for easy understanding. Even if the cache memory makes a mistake when writing the data, the data is not transferred from the main memory <b>203</b> to the cache memory. When data is written in a data space, the memory unit <b>202</b> writes the data sent from the write data <b>211</b> in the cache memory if the cache memory hits and the main memory <b>203</b> also writes the same data in the main memory.</p><p>Symbol <b>301</b> represents an instruction cache memory, <b>320</b> represents an arithmetic unit, and <b>302</b> represents a memory interface. The instruction cache memory <b>301</b> converts an instruction into a signal <b>307</b> and sends the signal <b>307</b> to the arithmetic unit <b>320</b> and memory interface <b>302</b>. When executing the instructions LD, ST, PF<b>1</b>, and PF<b>2</b>, the memory interface <b>302</b> sends the control signal <b>213</b> and receives the signal <b>214</b>. When the wait signal <b>214</b> is set to \u20181\u2019, the interface <b>302</b> transmits the signal <b>308</b> to the arithmetic unit <b>320</b> and stops the pipeline operation until the wait signal <b>214</b> comes to \u20180\u2019. Symbol <b>1600</b> represents a control unit and <b>1605</b> and <b>104</b> represent selectors. The control unit <b>1600</b> transfers the control signals <b>213</b>, <b>214</b>, <b>217</b>, and <b>218</b> to and from the memory interface <b>302</b> and main memory <b>203</b> and controls the selector <b>1605</b>, second cache memory <b>100</b>, and first cache memory <b>101</b> by the signals <b>111</b>, <b>113</b>, and <b>122</b> to <b>125</b>. The selector <b>104</b> selects correct data out of the data sent through the data bus <b>110</b> close to the second cache memory <b>100</b> and the data sent though the data bus <b>112</b> close to the first cache memory <b>101</b> and sends the selected data to the instruction unit <b>201</b> as the signal <b>212</b>. Because the first cache memory <b>101</b> has only one port, it is only able to sequentially process the access from the main memory <b>203</b> and the access from the instruction unit <b>201</b>. The control unit <b>1600</b> decides which one accesses the first cache memory <b>101</b> by way of the selector <b>1605</b>.</p><p>FIG. 3 shows a constitution of the instruction un it <b>201</b> in FIG. <b>1</b>. In FIG. 3, symbol <b>301</b> represents an instruction cache memory, <b>303</b> represents a decoder, <b>302</b> represents a memory interface, <b>305</b> represents a register, <b>306</b> represents an ALU, and <b>304</b> represents an address adder. The instruction cache memory <b>301</b> transmits an instruction to the decoder <b>303</b> and memory interface <b>302</b> through a bus <b>307</b>. The decoder <b>303</b> decodes the received instruction and controls the register <b>305</b>, ALU <b>306</b>, and address adder <b>304</b> by a signal <b>330</b>. The ALU <b>306</b> receives data from the register <b>305</b> through buses <b>312</b> and <b>313</b>, operates on the data, and writes the operation result in the register <b>305</b> through a bus <b>314</b>. The address adder <b>304</b> reads data from the register <b>305</b> through buses <b>310</b> and <b>311</b>, adds the read data values, and transmits the result to the bus <b>210</b> as an address to be loaded or stored. To store the result, data to be stored is read from the register <b>305</b> and transmitted to the bus <b>211</b>. To load the result, the adder <b>304</b> receives read data through the bus <b>212</b> and writes it in the register <b>305</b>.</p><p>The memory interface <b>302</b> outputs the control signal <b>213</b> when executing the instructions LD, ST, PF<b>1</b>, and PF<b>2</b> and receives the signal <b>214</b>. When the wait signal <b>214</b> is set to \u20181\u2019, the interface <b>302</b> transmits the signal <b>308</b> to the decoder <b>303</b> and stops the pipeline operation until the wait signal <b>214</b> comes to \u20180\u2019.</p><p>FIG. 4 shows an illustration for explaining the processing by the pipeline. In FIG. 4, symbol IF represents an instruction read stage, D represents a decode stage, E represents an operation and address addition stage, A represents a cache memory access stage, and W represents a register write stage. When a load instruction is executed, a cache memory is accessed at the stage A and data read at the stage W is written in the register <b>305</b>. When a store instruction is executed, a cache memory is checked at the stage A and, if it is hit, data is written in the cache memory at the stage A.</p><p>FIG. 2 shows a constitution of the memory unit <b>202</b> in FIG. <b>1</b>. In FIG. 2, symbol <b>100</b> represents a second cache memory with a capacity of 1 M bytes and a block size of 16 bytes using the direct map system, <b>101</b> represents a cache memory with a capacity of 256 bytes using the full associative system, <b>102</b> represents a four-entry prefetch queue,i<b>103</b> represents a control circuit, and <b>104</b> and <b>105</b> represent selectors.</p><p>The first cache memory <b>101</b> receives an address <b>130</b>, transfer data <b>215</b>, a select or control signal <b>123</b>, a write signal <b>122</b>, and write data <b>211</b>, and outputs read data <b>112</b> and a hit signal <b>113</b>. The second cache memory <b>100</b> receives an address <b>210</b>, a transfer address <b>216</b>, transfer data <b>215</b>, an entry signal <b>124</b>, a write signal <b>125</b>, and write data <b>211</b>, and outputs read data <b>110</b> and a hit signal <b>111</b>. The prefetch queue <b>102</b> receives a cache memory selection signal <b>213</b>-<b>1</b>, a transfer address <b>216</b>, an address <b>210</b>, a set signal <b>120</b>, and a reset signal <b>121</b>, and outputs a full signal <b>114</b>, a hit signal <b>115</b>, and a cache memory selection signal <b>116</b>.</p><p>The control circuit <b>103</b> receives a control signal <b>213</b>-<b>2</b> from the instruction unit <b>201</b>; the full signal <b>114</b>, the hit signal <b>115</b>, and the cache memory selection sign al <b>116</b> from the prefetch queue <b>102</b>; the response signal <b>217</b> from the main memory <b>203</b>; the hit signal <b>111</b> from the second cache memory <b>100</b>; and the hit signal <b>113</b> from the first cache memory <b>101</b>; and transmits the wait signal <b>214</b> to the instruction unit <b>201</b>; the set signal <b>120</b> and the reset signal <b>121</b> to the to the prefetch queue <b>102</b>; the transfer request signal <b>218</b> to the main memory <b>203</b>; the entry signal <b>124</b> and the write signal <b>125</b> to the second cache memory <b>100</b>; the write signal <b>122</b> and the selector control signal <b>123</b> to the first cache memory <b>101</b>; and the selector control signal <b>123</b> to the selector <b>105</b>.</p><p>The selector <b>104</b> receives the data <b>110</b> and the hit signal <b>111</b> from the second cache memory <b>100</b> and the data <b>112</b> and the hit signal <b>113</b> from the first cache memory <b>101</b>, and reads the data <b>110</b> as an output when the hit signal <b>111</b> is asserted and the data <b>110</b> as an output when the hit signal <b>113</b> is asserted to output the data to the data bus <b>212</b>. The selector <b>105</b> selects either of the address <b>210</b> and the transfer address <b>216</b> in accordance with the control by the selector control signal <b>123</b> and transmits it to the first cache memory <b>101</b> as an output <b>130</b>.</p><p>The first cache memory <b>101</b> reads data from the cache memory in accordance with the contents of the address <b>130</b> when the write signal <b>122</b> designates a data read operation and outputs the read data <b>112</b> and the hit signal <b>113</b>. When the write signal <b>122</b> designates a data write operation, the cache memory <b>101</b> writes the transfer data <b>215</b> if the selector control signal <b>123</b> is set to 1 and the contents of the write data <b>211</b> if the signal <b>123</b> is set to 0.</p><p>The second cache memory <b>100</b> checks the contents of the cache memory at the address <b>210</b> and outputs the read data <b>110</b> and the hit signal <b>111</b> when the write signal <b>125</b> is negated and designates a data read operation. When the write signal <b>125</b> is asserted and designates a data write operation, the cache memory <b>100</b> checks the contents of the cache memory and, if it is hit, the cache memory <b>100</b> writes the contents of the write data bus <b>211</b>. When the entry signal <b>124</b> is asserted simultaneously with the above operation, the cache memory <b>100</b> enters a set consisting of the transfer address <b>216</b> and the transfer data <b>215</b>.</p><p>The prefetch queue <b>102</b> is a queue for holding the address of the data being transferred from the main memory <b>203</b> up to four entries, and enters the contents of the address <b>210</b> and set selection signal <b>213</b>-<b>1</b> in the queue when the set signal <b>120</b> is asserted and outputs the cache memory selection signal <b>116</b> corresponding to the transfer address <b>216</b> when the reset signal <b>121</b> is asserted to negate the entry. Moreover, the queue <b>102</b> compares the address <b>210</b> with its holding address and asserts the hit signal <b>115</b> if the entry is currently transferred from the main memory <b>203</b>. Moreover, while an address valid for every entry is held, the queue <b>102</b> asserts the full signal <b>114</b> showing the address. Finally, the operation of the control circuit <b>103</b> is described below. FIG. 14 shows details of the control circuit <b>103</b>. The control circuit <b>103</b> decodes the control signal <b>213</b>-<b>2</b> and accepts the start of each of the instructions LD, ST, PF<b>1</b>, and PF<b>2</b>. When the instruction LD is under execution and both the hit signal <b>111</b> sent from the second cache memory <b>100</b> and the hit signal <b>113</b> sent from the first cache memory <b>101</b> are negated, the circuit <b>103</b> asserts the wait signal <b>214</b> to make the instruction unit <b>201</b> wait while transferring data from the main memory <b>203</b> because of errors of both cache memories. When the instructions LD, Pa<b>1</b>, and PF<b>2</b> are under execution, both the hit signal <b>111</b> sent from the second cache memory <b>100</b> and the hit signal <b>113</b> sent from the first cache memory <b>101</b> are negated, and the full signal <b>114</b> sent from the prefetch queue <b>102</b> is asserted; and, though the hit signal <b>115</b> sent from the prefetch queue <b>102</b> is also negated, the circuit <b>103</b> asserts the wait signal <b>214</b> in order to make the instruction unit <b>201</b> wait because the prefetch queue <b>102</b> is full and therefore no instruction can be loaded in the queue.</p><p>When the instruction LD, PF<b>1</b>, or PF<b>2</b> is under execution, the full signal <b>114</b> sent from the prefetch queue <b>102</b> is negated, and the hit signal <b>111</b> sent from the second cache memory <b>100</b> and the hit signal <b>113</b> sent from the first cache memory <b>101</b> are also negated. Thus, the circuit <b>103</b> asserts the transfer request signal <b>218</b> to be sent to the main memory <b>203</b> and also asserts the set signal <b>120</b> to be sent to the prefetch queue <b>102</b> to enter them in the prefetch queue <b>102</b>.</p><p>Moreover, when the response signal <b>217</b> sent from the main memory <b>203</b> is asserted, the circuit <b>103</b> asserts the reset signal <b>121</b> to be sent to the prefetch queue <b>102</b> in order to reset the entry from the prefetch queue <b>102</b>; and, in order to enter transfer data in a cache memory, the circuit <b>103</b> asserts the write signal <b>122</b> to be sent to the first cache memory <b>101</b> when the cache memory selection signal <b>116</b> designates the writing of data in the first cache memory <b>101</b> and asserts the entry signal <b>124</b> to be sent to the second cache memory <b>100</b> when the signal <b>116</b> designates the writing of data in the second cache memory <b>100</b>.</p><p>When the instruction ST is under execution and the hit signal <b>113</b> sent from the first cache memory <b>101</b> is asserted, the circuit <b>103</b> asserts the write signal <b>122</b> to be sent to the first cache memory <b>101</b> in order to write the data showing that the signal <b>113</b> is asserted in the first cache memory <b>101</b>. Similarly, when the instruction ST is under execution and the hit signal <b>111</b> sent from the second cache memory <b>100</b> is asserted, the circuit <b>103</b> asserts the write signal <b>125</b> to be sent to the second cache memory <b>100</b> in order to write the data showing that the signal <b>111</b> is asserted.</p><p>FIG. 5 shows details of the prefetch queue <b>102</b> in FIG. <b>2</b>. In FIG. 5, symbol <b>500</b> represents a priority circuit, <b>501</b> represents a judging circuit, and <b>502</b> to <b>505</b> represent cells. The cells <b>502</b> to <b>505</b> receive a read address <b>212</b>, a cache memory selection signal <b>213</b>-<b>1</b>, a transfer address <b>216</b>, and a reset signal <b>121</b>, and output valid signals <b>506</b>, <b>509</b>, <b>512</b>, and <b>515</b>, hit signals <b>507</b>, <b>510</b>, <b>513</b>, and <b>516</b>, and a selection signal <b>116</b>. Moreover, the cells receive set signals <b>508</b>, <b>511</b>, <b>514</b>, and <b>517</b>.</p><p>The priority circuit <b>500</b> receives valid signals <b>506</b>, <b>509</b>, <b>512</b>, and <b>515</b> from the cells <b>502</b> to <b>505</b> and the reset signal <b>120</b> from the control circuit <b>103</b>, and transmits the set signals <b>508</b>, <b>511</b>, <b>514</b>, and <b>517</b> to the cells <b>502</b> to <b>505</b>.</p><p>The judging circuit <b>501</b> receives the valid signals <b>506</b>, <b>509</b>, <b>512</b>, and <b>515</b> and the hit signals <b>507</b>, <b>510</b>, <b>513</b>, and <b>516</b> from the cells <b>502</b> to <b>505</b> and transmits the full signal <b>114</b> and hit signal <b>115</b> to the control circuit <b>103</b>.</p><p>Because the cells <b>502</b> to <b>505</b> all have the same function, the operation of only the cell <b>502</b> is described below. The cell <b>502</b> stores a register for holding addresses and a cache memory selection bit and its valid bit. When the set signal <b>508</b> is asserted, the cell <b>502</b> asserts the valid bit and incorporates the contents of the transfer address <b>216</b> and those of the cache memory selection signal <b>213</b>-<b>1</b> and compares the read address <b>212</b> with its holding valid address. When they coincide with each other, the cell <b>502</b> transmits a holding corresponding cache memory selection bit to the signal line <b>116</b>. When the transfer address <b>216</b> coincides with a holding address and the reset signal <b>121</b> is asserted, the cell <b>502</b> negates the valid bit. When the set signal <b>120</b> is asserted, the priority circuit <b>500</b> checks the valid signals <b>506</b>, <b>509</b>, <b>512</b>, and <b>515</b> and selects one of the valid cells to assert the corresponding signals <b>508</b>, <b>511</b>, <b>514</b>, and <b>517</b>. The highest priority is given to the cell <b>502</b> and the lowest priority is given to the cell <b>505</b> and the cells are set starting with the cell <b>502</b>.</p><p>The judging circuit <b>501</b> asserts the hit signal <b>115</b> if there is only one cell in which both the valid signal and hit signal are asserted. When valid signals <b>506</b>, <b>509</b>, <b>512</b>, and <b>515</b> are all asserted, the circuit <b>501</b> asserts the full signal <b>114</b>.</p><p>FIG. 6 shows details of the cell <b>502</b> in FIG. <b>5</b>. In FIG. 6, symbol <b>601</b> represents a register for holding a valid bit, <b>602</b> represents a register for holding addresses, <b>603</b> represents a register for holding cache memory selection bits, <b>604</b> and <b>605</b> represent comparators, <b>630</b> represents a tristate buffer, and <b>631</b> and <b>632</b> represent AND gales. The valid bit <b>601</b> is set when the set signal <b>508</b> is asserted and reset when the signal <b>608</b> is asserted. The set signal <b>508</b> is connected to the valid bit <b>601</b>, address register <b>602</b>, and cache memory selection bit <b>603</b>. When the set signal <b>508</b> is asserted, the valid bit <b>601</b> is set, the address register <b>602</b> incorporates the read address <b>212</b>, and the cache memory selection register <b>603</b> incorporates the cache memory selection signal <b>213</b>-<b>1</b>. The valid bit transmits its output as the valid signal <b>506</b>. The comparator <b>604</b> compares the address <b>212</b> with an output <b>606</b> of the address register <b>602</b>. When they coincide with each other and the valid bit <b>601</b> is asserted, the comparator <b>604</b> asserts the hit signal <b>507</b>. The comparator <b>605</b> compares the output <b>606</b> of the address register <b>602</b> with the transfer address <b>216</b>. When they coincide with each other, the comparator <b>605</b> opens the tristate buffer <b>630</b> and transmits the contents of the cache memory selection bit register <b>603</b> to the signal <b>116</b>. Moreover, when the reset signal <b>121</b> is asserted, the signal <b>608</b> is asserted and the valid bit <b>601</b> is reset.</p><p>FIG. 7 shows details of the priority circuit <b>500</b> in FIG. <b>5</b>. In FIG. 7, symbols <b>705</b> to <b>707</b> represent inverters and <b>701</b> to <b>704</b> represent AND gates. FIG. 8 shows a constitution of the judging circuit <b>501</b> in FIG. <b>5</b>. In FIG. 8, symbols <b>801</b> to <b>804</b> and <b>806</b> represent AND gates and <b>805</b> represents an OR gate. FIG. 9 shows details of the cache memory <b>100</b> in FIG. <b>2</b>. In FIG. 9, symbol <b>900</b> represents a judging circuit and <b>901</b> to <b>903</b> represent cells for holding a set consisting of a valid bit, address and data. The cells <b>901</b> to <b>903</b> receive the read address <b>210</b>, entry request <b>124</b>, write data <b>211</b>, and write request <b>125</b> as inputs and they output the data <b>110</b>. Moreover, the cells <b>901</b> to <b>903</b> transmit the hit signals <b>910</b> to <b>912</b> to the judging circuit <b>900</b>, respectively. The cell <b>901</b> receives the transfer address <b>216</b> and transfer data <b>215</b> and sends an address <b>913</b> and data <b>914</b> to the cell <b>902</b>. Similarly, the cell <b>902</b> sends addresses <b>915</b> and <b>916</b> to the next cell. The last cell <b>912</b> receives an address <b>917</b> and data <b>918</b>.</p><p>If any one of the hit signals <b>910</b> to <b>912</b> sent from the cells <b>901</b> to <b>903</b> is asserted, the judging circuit <b>900</b> asserts the hit signal <b>111</b> to be sent to the control circuit <b>103</b> and selector <b>104</b>. The cell <b>901</b> compares the address <b>210</b> with its holding address. When they coincide with each other and are valid, the cell <b>901</b> transmits the hit signal <b>910</b> and outputs the corresponding holding data to the bus <b>110</b>. When the write request <b>125</b> is asserted, the cell <b>901</b> compares its holding address with the write address <b>210</b>. When they coincide with each other and the valid bit is asserted, the cell <b>901</b> incorporates the contents of the write data <b>211</b>. When the entry request <b>124</b> is asserted simultaneously with the above operation, the cell <b>901</b> asserts the valid bit and incorporates the transfer address <b>216</b> and transfer data <b>215</b>. In this case, the cell <b>902</b> incorporates the address and data held by the cell <b>901</b> through the signals <b>913</b> and <b>914</b>. That is, the cells <b>901</b> to <b>903</b> follow a FIFO operation. FIG. 10 shows details of the cell <b>901</b> in FIG. <b>9</b>. In FIG. 10, symbols <b>1000</b>, <b>1001</b>, and <b>1002</b> represent registers for holding a valid bit, addresses, and data respectively. Symbol <b>1004</b> represents a comparator, <b>1005</b> and <b>1006</b> represent AND gates, and <b>1003</b> represents a tristate buffer. The entry request <b>124</b> is connected to the register <b>1000</b> for holding a valid bit, the register <b>1001</b> for holding addresses, and the register <b>1002</b> for holding data. When the entry request <b>124</b> is asserted, the register <b>1000</b> for holding a valid bit is set, the register <b>1001</b> for holding addresses incorporates the transfer address <b>216</b>, and the register <b>1002</b> for holding data incorporates the data <b>215</b>. The comparator <b>1004</b> compares an output <b>913</b> of the register for holding addresses with the address <b>210</b>. When the output of the comparator <b>1004</b> is asserted and also the valid bit is asserted, the AND gate <b>1006</b> asserts the hit signal <b>910</b> and opens the tristate buffer <b>1003</b> to transmit the contents of the register for holding data to the data bus <b>110</b>. Moreover, when the AND gate <b>1005</b> detects that the hit signal <b>910</b> and a write request are asserted, it asserts the signal <b>1008</b> to be sent to the register <b>1002</b> for holding data and incorporates the write data <b>211</b> into the register <b>1002</b> for holding data.</p><p>As described above, the second cache memory <b>100</b> uses the full associative system and processes a memory referencing instruction sent from the instruction unit <b>201</b> and transfer of the data sent from the main memory <b>203</b> at the same time. Therefore, the overall size of the cache memory <b>100</b> is small and the operation speed thereof can be increased because it has only 64 entries, though the cell structure is complicated.</p><p>Moreover, the second cache memory <b>100</b> has a high hit ratio, though the capacity of it is small, and the operation speed thereof can be increased, because it stores data which is not to be reused in accordance with the instruction PF<b>2</b>; and thereby, it only temporarily stores data transferred from the main memory <b>203</b> in accordance with the instruction PF<b>2</b>, but which has not been used yet by the instruction LD.</p><p>The cache memory in FIG. 9 has a block size of as small as 4 bytes. This means that the cache memory provides, given the same capacity, a greater number of entries than if the block size were the same as that of the first cache memory, i.e. 16 bytes. Thus, even when a large amount of array data is to be processed at one time, each array may be stored in a separate entry, whereby any drop in performance attributed conventionally to the lack of entries is prevented. Since data is transferred from the main memory in units of 4 bytes, data of discontinuous addresses may be processed without transferring unnecessary data. This ensures high-speed data processing.</p><p>FIG. 11 shows details of the first cache memory in FIG. <b>2</b>. In FIG. 11, symbol <b>1100</b> represents an address array, <b>1101</b> represents a valid bit, <b>1102</b> represents a data array, <b>1104</b> represents a comparator, and <b>1105</b> represents an AND gate, and <b>1103</b> represents a selector. The selector <b>1103</b> is controlled by the control signal <b>123</b>, which selects the transfer data <b>215</b> or write data <b>211</b> and transmits its output to the data array <b>1102</b>.</p><p>The address array <b>1100</b> and the valid bit <b>1101</b> are accessed by a low-order bit <b>130</b>-<b>1</b> of the address <b>130</b>. The comparator <b>1104</b> compares an address array output <b>1106</b> with a high-order bit <b>130</b>-<b>2</b> of the address <b>130</b>. The AND gate <b>1105</b> outputs the hit signal <b>112</b> when detecting that an output of the comparator is asserted and the valid bit <b>1107</b> is asserted. Moreover, when the write signal <b>122</b> is asserted, the AND gate <b>1105</b> incorporates the address <b>130</b>-<b>2</b> and sets a corresponding valid bit. The data array is accessed by the low-order bit <b>130</b>-<b>1</b> of the address <b>130</b>, which transmits read data to the bus <b>113</b>. When the write signal <b>122</b> is asserted, the data array writes an output of the selector <b>1103</b>.</p><p>Though the first cache memory <b>101</b> has a capacity of 1 M, bits which is larger than that of the second cache memory, the overall size thereof is not very large, because it has only one port, and so an increase in its operation speed can be expected.</p><p>FIG. 14 shows a constitution of the control circuit in FIG. <b>2</b>. In FIG. 14, symbols <b>1400</b>, <b>1406</b>, and <b>1410</b> represent OR gates and <b>1401</b> to <b>1405</b>, <b>1407</b> to <b>1409</b>, and <b>1411</b> represent AND gates. Symbol <b>1412</b> represents a decoder which has the function of decoding the control signal <b>213</b>-<b>2</b> by the instruction unit <b>201</b> to judge whether an instruction under execution is LD, ST, PF<b>1</b>, or PF<b>2</b>.</p><p>FIG. 15 shows details of the memory unit <b>202</b> in FIG. <b>1</b>. The constitution shown in FIG. 15 is almost the same as that shown in FIG. 2, except that an interface <b>130</b> is present between the first cache memory <b>101</b> and the second cache memory <b>100</b>.</p><p>A first problem with the arrangement shown in FIG. 2 is that the second cache memory is useless when a medium or small-scale program is run using the instruction PP<b>1</b>. A second problem is that the hit ratio is low compared with that of the same-capacity cache memory using the set associative system. The embodiment in FIG. 15 solves these problems.</p><p>In the case of the embodiment in FIG. 15, if the first cache memory <b>101</b> causes an error, the second cache memory <b>100</b> is searched. If it is hit, corresponding data is transferred from the second cache memory <b>100</b> to the first cache memory <b>101</b> through the interface <b>130</b>. To enter data in the first cache memory, overflow data is entered in the second cache memory <b>100</b> through the interface <b>130</b>. In the publication by Norman P. Jouppi, \u201cImproving Direct-Mapped Cache Performance by the Addition of a small Fully-Associative Cache and Prefetch Buffers,\u201d Proc. 17th Symp. on Camp. Arch., Settle, Wash., pp. 364-373, May, 1990, the above cache memory is called a victim cache memory which improves the hit ratio compared with a cache memory using the direct map system.</p><p>The embodiment in FIG. 15 makes it possible to improve the performance of a medium- or small-scale program by effectively using both the first cache memory <b>101</b> and the second cache memory <b>100</b>.</p><p>The present invention makes it possible to inexpensively improve the performance of a computer having a prefetch function for a cache memory about a medium- or small-scale program for reusing data stored in the cache memory and a large-scale program for not reusing data stored in the cache memory.</p><p>FIG. 41 shows details of the second embodiment of the first cache memory <b>101</b> in FIG. <b>2</b>. The cache memory in FIG. 41 is a two-way set associative type cache memory that has a capacity of 1 megabyte and a block size of 16 bytes. Reference numerals <b>4101</b> and <b>4103</b> are address arrays; <b>4102</b> and <b>4104</b> are valid bits; <b>4105</b> and <b>4106</b> are data arrays; <b>4107</b> and <b>4108</b> are comparators; <b>4109</b> is an array selection memory; <b>4110</b>, <b>4112</b>, <b>4113</b>, <b>4114</b> and <b>4115</b> are AND gates; <b>4111</b> and <b>4116</b> are OR gates; and <b>4120</b> and <b>4122</b> are selectors. In the description that follows, the address array <b>4101</b>, valid bit <b>4102</b> and data array <b>4105</b> are referred to collectively as an array <b>1</b>; likewise, the address array <b>4103</b>, valid bit <b>4104</b> and data array <b>4106</b> are referred to collectively as an array <b>2</b>.</p><p>Under control of a control signal <b>123</b>, the selector <b>4120</b> selects either transfer data <b>215</b> or write data <b>211</b> and sends its output <b>4130</b> to the data arrays <b>4105</b> and <b>4106</b>. The first address array <b>4101</b> and valid bit <b>4102</b> are accessed using the low-order bit <b>130</b>-<b>1</b> of address <b>130</b>. The comparator <b>4107</b> compares an address array output <b>4131</b> with the high-order bit <b>130</b>-<b>2</b> of address <b>130</b>. When the AND gate <b>4114</b> senses that the output of the comparator <b>4107</b> and the valid bit <b>4132</b> are both asserted, the AND gate <b>4114</b> outputs a hit signal <b>4135</b> indicating a hit in the array <b>1</b>. When a write signal <b>4137</b> to the array <b>1</b> is asserted, the first address array <b>4101</b> and valid bit <b>4102</b> fetch address <b>130</b>-<b>2</b> and set the corresponding valid bit. Similarly, the second address array <b>4103</b> and valid bit <b>4104</b> are accessed using the low-order bit <b>130</b>-<b>1</b> of address <b>130</b>. The comparator <b>4108</b> compares an address array output <b>4133</b> with the high-order bit <b>130</b>-<b>2</b> of address <b>130</b>. When the AND gate <b>4115</b> senses that the output of the comparator <b>4108</b> and the valid bit <b>4134</b> are both asserted, the AND gate <b>4115</b> outputs a hit signal <b>4136</b> indicating a hit in the array <b>2</b>. When a write signal <b>4138</b> to the array <b>2</b> is asserted, the second address array <b>4103</b> and valid bit <b>4104</b> fetch address <b>130</b>-<b>2</b> and set the corresponding valid bit. The OR gate <b>4116</b> outputs a hit signal <b>113</b> when either the hit signal <b>4135</b> of the array <b>1</b> or the hit signal <b>4136</b> of the array <b>2</b> is asserted. The first data array <b>4105</b> is accessed using the low-order bit <b>130</b>-<b>1</b> of address <b>130</b>. The data thus read out is placed onto a bus <b>4139</b>. When the write signal <b>4137</b> to the array <b>1</b> is asserted, the output <b>4130</b> of the selector <b>4120</b> is written to the array <b>1</b>. Likewise, the second data array <b>4106</b> is accessed using the low-order bit <b>130</b>-<b>1</b> of address <b>130</b>. The data thus read out is placed onto a bus <b>4140</b>. When the write signal <b>4138</b> to the array <b>2</b> is asserted, the output <b>4130</b> of the selector <b>4120</b> is written to the array <b>2</b>. When the hit signal <b>4135</b> of the array <b>1</b> is asserted, the selector <b>4122</b> selects the output <b>4139</b> of the first data array; otherwise, the selector <b>4122</b> selects the output <b>4140</b> of the second data array. The selected result is placed onto a data bus <b>112</b>. When a write signal <b>122</b> is asserted, the array selection memory <b>4109</b> retains information about which of the arrays <b>1</b> and <b>2</b> has data written thereto. The transfer data <b>215</b> from the main memory is written either to the array <b>2</b>, if the preceding data was written to the array <b>1</b>, or to the array <b>1</b>, if the preceding data was written to the array <b>2</b>. The write data <b>211</b> of the store instruction transferred from the instruction unit is written to either the array <b>1</b> or the array <b>2</b> in which a hit has been detected. In this case, the information retained in the array selection memory <b>4109</b> is ignored. What follows is a description of how the write signal <b>4137</b> to the array <b>1</b> and the write signal <b>4138</b> to the array <b>2</b> are generated. The array selection memory <b>4109</b> is accessed using the low-order bit <b>130</b>-<b>1</b> of address <b>130</b>. The data thus read out is sent to the AND gate <b>4110</b>. When the write signal <b>122</b> is asserted, the value of an array selection signal <b>4141</b> is written to the array selection memory <b>4109</b>. When neither the hit signal <b>113</b> nor the output of the array selection memory <b>4109</b> is asserted, the AND gate <b>4110</b> outputs a control signal <b>4142</b>. When either the hit signal <b>4135</b> of the array <b>1</b> or the control signal <b>4142</b> is asserted, the OR gate <b>4111</b> outputs the array selection signal <b>4141</b>. The array selection signal <b>4141</b> indicates that the array <b>1</b> is selected for writing data thereto when asserted; and, the array selection signal <b>4141</b> indicates that the array <b>2</b> is selected for writing data thereto when not asserted. When both the write signal <b>122</b> and the array selection signal <b>4141</b> are asserted, the AND gate <b>4112</b> outputs the write signal <b>4137</b> to the array <b>1</b>. Likewise, the AND gate <b>4113</b> outputs the write signal <b>4138</b> to the array <b>2</b> when the write signal <b>122</b> is asserted while the array selection signal <b>4141</b> is not asserted. The cache memory in FIG. 41, structured as a two-way set associative type, is more massive than the cache memory in FIG. 11 but prevents the occurrence of block conflict. Thus, the hit rate of the cache memory in FIG. 41 is higher than that of the cache memory in FIG. <b>11</b>.</p><p>FIG. 42 shows details of a second embodiment of the second cache memory <b>100</b> in FIG. <b>2</b>. The cache memory in FIG. 42 is a two-way set associative type cache memory that has a capacity of 2 kilobytes and a block size of 32 bytes. Reference numerals <b>4201</b> and <b>4203</b> are address arrays; <b>4202</b> and <b>4204</b> are valid bits; <b>4205</b> and <b>4206</b> are data arrays; <b>4207</b> and <b>4208</b> are comparators; <b>4209</b> is an array selection memory; <b>4210</b>, <b>4211</b>, <b>4212</b>, <b>4213</b>, <b>4214</b> and <b>4215</b> are AND gates; <b>4216</b> is an OR gate; <b>4217</b> is an inverting circuit; and <b>4222</b> is a selector. In the description that follows, the address array <b>4201</b>, valid bit <b>4202</b> and data array <b>4205</b> are referred to collectively as an array <b>1</b>; and, the address array <b>4203</b>, valid bit <b>4204</b> and data array <b>4206</b> are referred to collectively as an array <b>2</b>.</p><p>The first address array <b>4201</b> and valid bit <b>4202</b> output the value of the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>. The comparator <b>4207</b> compares an address array output <b>4231</b> with the high-order bit <b>210</b>-<b>2</b> of address <b>210</b>. When the AND gate <b>4214</b> senses that both the output of the comparator <b>4207</b> and a valid bit <b>4232</b> are asserted, the AND gate <b>4214</b> outputs a hit signal <b>4235</b> indicating a hit in the array <b>1</b>. When a first write signal <b>4237</b> to the array <b>1</b> is asserted, the first address array <b>4201</b> and valid bit <b>4202</b> set the high-order bit <b>210</b>-<b>2</b> of read address <b>210</b> to the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>, and set the corresponding valid bit. When a second write signal <b>4239</b> to the array <b>1</b> is asserted, the high-order bit <b>216</b>-<b>2</b> of transfer address <b>216</b> is set to the address designated by the low-order bit <b>216</b>-<b>1</b> of transfer address <b>216</b>, and the corresponding valid bit is set. Likewise, the second address array <b>4203</b> and valid bit <b>4204</b> output the value of the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>. The comparator <b>4208</b> compares an address array output <b>4233</b> with the high-order bit <b>210</b>-<b>2</b> of address <b>210</b>. When the AND gate <b>4215</b> senses that the output of the comparator <b>4208</b> and the valid bit <b>4234</b> are both asserted, the AND gate <b>4215</b> outputs a hit signal <b>4236</b> indicating a hit in the array <b>2</b>. When a first write signal <b>4238</b> to the array <b>2</b> is asserted, the second address array <b>4203</b> and valid bit <b>4204</b> set the high-order bit <b>210</b>-<b>2</b> of read address <b>210</b> to the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>, and set the corresponding valid bit. When a second write signal <b>4240</b> to the array <b>2</b> is asserted, the high-order bit <b>2162</b> of transfer address <b>216</b> is set to the address designated by the low-order bit <b>216</b>-<b>1</b> of transfer address <b>216</b>, and the corresponding valid bit is set. The OR gate <b>4216</b> outputs a hit signal <b>111</b> when either the hit signal <b>4235</b> of the array <b>1</b> or the hit signal <b>4236</b> of the array <b>2</b> is asserted. The first data array <b>4205</b> places onto a bus <b>4241</b> the data of the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>. When the first write signal <b>4237</b> to the array <b>1</b> is asserted, the write data <b>211</b> is written to the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>. When the second write signal <b>4239</b> to the array <b>1</b> is asserted, the transfer data <b>215</b> is written to the address designated by the low-order bit <b>216</b>-<b>1</b> of transfer address <b>216</b>. Likewise, the first data array <b>4206</b> places onto a bus <b>4242</b> the data of the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>. When the first write signal <b>4238</b> to the array <b>2</b> is asserted, the write data <b>211</b> is written to the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>. When the write signal <b>4240</b> to the array <b>2</b> is asserted, the transfer data <b>215</b> is written to the address designated by the low-order bit <b>216</b>-<b>1</b> of transfer address <b>216</b>. When the hit signal <b>4235</b> of the array <b>1</b> is asserted, the selector <b>4222</b> selects the output <b>4241</b> of the first data array; otherwise, the selector <b>4222</b> selects the output <b>4242</b> of the second data array. The selected result is placed onto a data bus <b>110</b>. When an entry request <b>124</b> or a write request <b>125</b> is asserted, the array selection memory <b>4209</b> retains information about which of the arrays <b>1</b> and <b>2</b> has the data written thereto. The transfer data <b>215</b> from the main memory is written either to the array <b>2</b>, if the preceding data was written to the array <b>1</b>, or to the array <b>1</b>, if the preceding data was written to the array <b>2</b>. The write data <b>211</b> of the store instruction transferred from the instruction unit is written to either the array <b>1</b> or the array <b>2</b> in which a hit has been detected. In this case, the information retained in the array selection memory <b>4209</b> is ignored. What follows is a description of how the write signals <b>4237</b> and <b>4239</b> to the array <b>1</b> and the write signals <b>4238</b> and <b>4240</b> to the array <b>2</b> are generated. The array selection memory <b>4209</b> supplies the inverting circuit <b>4217</b> with the data of the address designated by the low-order bit <b>2161</b> of transfer address <b>216</b>. When the write request <b>125</b> is asserted, the value of the hit signal <b>4235</b> for the array <b>1</b> is written to the address designated by the low-order bit <b>210</b>-<b>1</b> of read address <b>210</b>. When the entry request <b>124</b> is asserted, the value of an array selection signal <b>4243</b> is written to the address designated by the low-order bit <b>216</b>-<b>1</b> of transfer address <b>216</b>. The inverting circuit <b>4217</b> outputs the array selection signal <b>4243</b> when the output of the array selection memory <b>4209</b> is not asserted. The AND gate <b>4210</b> outputs the first write signal <b>4237</b> to the array <b>1</b> when both the write request <b>125</b> and the hit signal <b>4235</b> of the array <b>1</b> are asserted. The AND gate <b>4211</b> outputs the first write signal <b>4238</b> to the array <b>2</b> when the write request <b>125</b> is asserted while the hit signal <b>4235</b> of the array <b>1</b> is not asserted. Similarly, the AND gate <b>4212</b> outputs the second write signal <b>4239</b> to the array <b>1</b> when the entry request <b>124</b> and the array selection signal <b>4243</b> are both asserted. The AND gate <b>4213</b> outputs the second write signal <b>4240</b> to the array <b>2</b> when the entry request <b>124</b> is asserted while the array selection signal <b>4243</b> is not asserted. The cache memory in FIG. 42, being a two-way set associative type, is less massive than the full set associative type cache memory in FIG. 9, yet it provides a greater capacity. The block size of as many as 32 bytes allows a large amount of data to be transferred at one time from the main memory. Thus, when data of contiguous addresses are to be processed, an appreciably smaller number of prefetch instructions are needed to transfer a fixed quantity of data from the main memory to the second cache memory. This enhances the data processing performance.</p><p>FIG. 34 shows a general view of a second embodiment of the present invention. Of the components of the second embodiment in FIG. 34, those identical to their counterparts in the embodiment of FIG. 1 are given the same reference numerals. The second embodiment is characterized in that it has two address buses <b>3510</b> and <b>3513</b>, and four data buses <b>3511</b>, <b>3512</b>, <b>3514</b> and <b>3515</b>. This constitution allows two memory reference instructions to be processed in parallel.</p><p>The second embodiment in FIG. 34 comprises an instruction unit <b>3501</b>, a memory unit <b>3502</b> and a main memory <b>3503</b>.</p><p>The instruction unit <b>3501</b>, a unit for executing instructions, comprises an instruction cache memory <b>3601</b>, a memory interface <b>3602</b> and an arithmetic unit <b>3620</b>. The instruction unit <b>3501</b> exchanges data with a first and a second cache memory <b>101</b> and <b>3490</b> over the buses <b>3510</b> through <b>3512</b> and <b>3513</b> through <b>3515</b>. More specifically, the instruction unit <b>3501</b> sends addresses, data and control signals to the memory unit <b>3502</b> and main memory <b>3503</b> over the address buses <b>3510</b> and <b>3513</b>, four-byte-wide write data buses <b>3511</b> and <b>3514</b>, and a control signal line <b>3516</b>.</p><p>The memory unit <b>3502</b> is constituted by the first cache memory <b>101</b>, the second cache memory <b>3490</b>, selectors <b>104</b> and <b>3495</b> to input/output data, and a control section comprising a control unit <b>3492</b>. The first cache memory <b>101</b> is the same in constitution as the first cache memory of the first embodiment shown in FIG. 1; the first cache memory <b>101</b> is a one-port large-capacity cache memory. The second cache memory <b>3490</b> is a three-port small-capacity cache memory. The memory unit <b>3502</b> sends data and a wait signal to the instruction unit <b>3501</b> over the four-byte-wide read data buses <b>3512</b> and <b>3515</b> and via a wait signal line <b>3517</b>, and transmits a request signal to the main memory <b>3503</b> over request signal lines <b>3523</b> and <b>3524</b>.</p><p>The main memory <b>3503</b> stores instructions and data, and transfers data over buses <b>3520</b> and <b>3521</b> to the first cache memory <b>101</b> and the second cache memory <b>3490</b>. That is, the main memory <b>3503</b> sends data, addresses and a response signal to the memory unit <b>3502</b> over the transfer data bus <b>3520</b>, transfer address bus <b>3521</b> and a response signal line <b>3522</b>.</p><p>The operation code of the instructions processed by the instruction unit <b>3501</b> in FIG. 34 is the same in format as the operation code shown in FIG. <b>12</b>. The types of instructions to be processed are the same as those listed in FIG. <b>13</b>.</p><p>FIG. 36 shows details of the instruction unit <b>3501</b> in FIG. <b>34</b>. In FIG. 36, reference numeral <b>3601</b> is an instruction cache memory; <b>3603</b> is a decoder; <b>3602</b> is a memory interface; <b>3605</b> is a register; <b>3606</b> is an ALU; and <b>3641</b> and <b>3642</b> are address adders. The instruction cache memory <b>3601</b> sends an instruction to the decoder <b>3603</b> and memory interface <b>3602</b> over a bus <b>3607</b>. The decoder <b>3603</b> decodes the received instruction, and controls the register <b>3605</b>, ALU <b>3606</b> and address adders <b>3641</b> and <b>3642</b> using a signal <b>3630</b>. The ALU <b>3606</b> receives data from the register <b>3605</b> over buses <b>3612</b> and <b>3613</b>, operates on the data, and writes the result of the operation to the register <b>3605</b> over a bus <b>3614</b>. The first address adder <b>3641</b> receives data from the register <b>3605</b> over buses <b>3610</b> and <b>3611</b>, performs an add operation on the data, and places onto the bus <b>3513</b> the result of the operation as the address for a load or a store operation. For a store operation, the data to be stored is read from the register <b>3605</b> and placed onto the bus <b>3514</b>. For a load operation, the data that was read out is received via the bus <b>3515</b> and written to the register <b>3605</b>. Likewise, the second address adder <b>3642</b> reads data from the register <b>3605</b> over the buses <b>3614</b> and <b>3615</b>, performs an add operation on the data, and places onto the bus <b>3510</b> the result of the operation as the address for a load or a store operation. For a store operation, the data to be stored is read from the register <b>3605</b> and placed onto the bus <b>3511</b>. For a load operation, the data that was read out is received over the bus <b>3512</b> and written to the register <b>3605</b>.</p><p>Upon execution of instructions LD, ST, PF<b>1</b> and PF<b>2</b>, the memory interface <b>3602</b> outputs a control signal <b>3516</b> and receives a wait signal <b>3517</b>. When the wait signal <b>3517</b> is set to 1, a signal <b>3608</b> is output to the decoder <b>3603</b> to halt the pipeline operation until the wait signal <b>3517</b> is brought to 0.</p><p>FIG. 37 is an illustration for explaining the pipeline operation in effect when the data processor in FIG. 34 executes instructions. In FIG. 37, IF represents an instruction fetch stage; D is a decode stage; E is an operation and address add stage; A i<b>9</b> a cache access stage; W is a register write stage; R is a cache access retry stage; and X is a wait stage. When two load instructions (instructions <b>1</b> and <b>2</b>) are to be processed in parallel, the instruction <b>1</b> causes the first and the second cache memory to be accessed concurrently in stage A whereas the instruction <b>2</b> causes the second cache memory alone to be accessed in stage A. Following a hit in the second cache memory, the instruction <b>1</b> causes the data read from the second cache memory to be written to the register in stage W. When there occurs a hit in the second cache memory, the instruction <b>2</b> causes the data read from the second cache memory to be written to the register in stage W. The instruction <b>3</b> causes the first and the second cache memory to be accessed concurrently in stage A, and the instruction <b>4</b> causes only the second cache memory to be accessed in stage A. Following a hit in the second cache memory, the instruction <b>3</b> causes the data read from the second cache memory to be written to the register in stage W. When there occurs a miss in the second cache memory, the instruction <b>4</b> causes the first cache memory to be accessed in stage R so as to write the read-out data to the register in stage W. When instructions <b>5</b> and <b>6</b> are to be processed in parallel, the instruction <b>5</b> causes the first and the second cache memory to be accessed concurrently in stage A; whereas, the instruction <b>6</b> causes the second cache memory alone to be accessed in stage A. Following a hit in the first cache memory, the instruction <b>5</b> causes the data read from the first cache memory to be written to the register in stage W. When there occurs a hit in the second memory, the instruction <b>6</b> causes the data read from the second cache memory to be written to the register in stage W. Where instructions <b>7</b> and <b>8</b> are to be processed in parallel, the instruction <b>7</b> causes the first and the second cache memory to be accessed concurrently in stage A; whereas, the instruction <b>8</b> causes the second cache memory alone to be accessed. Following a hit in the first cache memory, the instruction <b>7</b> causes the data read from the first cache memory to be written to the register in stage W. When there occurs a miss in the second cache memory, the instruction <b>8</b> causes the first cache memory to be accessed in stage R so as to write the read-out data to the register in stage W.</p><p>The pipeline operation, upon execution of the store operation, is the same as that upon execution of the load instruction. That is, the cache memories are checked in stage A or R for a hit. In case of a hit, the data is written to the applicable cache memory in stage A or R.</p><p>As described, two memory reference instructions are processed in parallel when the second instruction attains a hit in the second cache memory. Thus, if the PF<b>2</b> instruction is used to transfer data to the second cache memory, two memory reference instructions are always carried out in parallel, whereby the processing performance is enhanced.</p><p>FIG. 35 shows details of the memory unit <b>3502</b> in FIG. <b>34</b>. In FIG. 35, reference numeral <b>101</b> is a first cache memory; <b>3490</b> is a second cache memory; <b>102</b> is a four-entry prefetch queue; <b>3403</b> is a control circuit; and <b>104</b>, <b>3540</b>, <b>3542</b>, <b>3531</b> and <b>3534</b> are selectors.</p><p>The first cache memory <b>101</b> receives as its input an address <b>3430</b>, transfer data <b>3520</b>, a selector control signal <b>3423</b>, a write signal <b>3422</b> and write data <b>3544</b>; and outputs read data <b>3412</b> and a hit signal <b>3413</b>. The second cache memory <b>3490</b> receives addresses <b>3510</b> and <b>3513</b>, a transfer address <b>3521</b>, transfer data <b>3520</b>, an entry signal <b>3424</b>, write signals <b>3425</b> and <b>3426</b>, and write data <b>3511</b> and <b>3514</b>; and outputs read data <b>3410</b> and <b>3512</b> and hit signals <b>3411</b> and <b>3481</b>. The prefetch queue <b>102</b> receives a cache selection signal <b>3533</b>, the transfer address <b>3521</b>, an address <b>3530</b>, a set signal <b>120</b> and a reset signal <b>121</b>; and outputs a full signal <b>114</b>, a hit signal <b>115</b> and a cache selection signal <b>116</b>.</p><p>The control circuit <b>3403</b> receives control signals <b>3516</b>-<b>3</b> and <b>3516</b>-<b>4</b> from the instruction unit; the full signal <b>114</b>, hit signal <b>115</b> and cache selection signal <b>116</b> from the prefetch queue <b>102</b>; the response signal <b>3522</b> from the main memory; the hit signals <b>3411</b> and <b>3481</b> from the second cache memory <b>3490</b>; and the hit signal <b>3413</b> from the first cache memory. In turn, the control circuit <b>3403</b> outputs the wait signal <b>3517</b> to the instruction unit; the set signal <b>120</b>, reset signal <b>121</b> and a selection signal <b>3532</b> to the prefetch queue <b>102</b>: the request signals <b>3523</b> and <b>3524</b> to the main memory; the entry signal <b>3424</b> and write signals <b>3425</b> and <b>3526</b> to the second cache memory <b>3490</b>; the write signal <b>3422</b> and selector control signal <b>3423</b> to the first cache memory <b>101</b>; and the selector control signals <b>3423</b> and <b>3427</b> to the selectors <b>3540</b> and <b>3542</b>.</p><p>The selector <b>104</b> receives the data <b>3410</b> and hit signal <b>3411</b> from the second cache memory <b>3490</b>, and the data <b>3412</b> and hit signal <b>3413</b> from the first cache memory <b>101</b>. When the hit signal <b>3411</b> is asserted, the selector <b>104</b> reads and outputs the data <b>3410</b> that is placed onto the data bus <b>3515</b>; and, when the hit signal <b>3413</b> is asserted, the selector <b>104</b> reads and outputs the data <b>3412</b> that is placed onto the data bus <b>3515</b>. Under control of the selector control signals <b>3423</b> and <b>3427</b>, the selector <b>3540</b> selects one of address <b>3513</b>, address <b>3510</b> and transfer address <b>3521</b>. The selected address is sent as the selector output <b>3430</b> to the first cache memory <b>101</b>. Under control of the selector control signal <b>3427</b>, the selector <b>3542</b> selects either the write data <b>3514</b> or the write data <b>3511</b>. The selected data is sent as the selector output <b>3544</b> to the first cache memory <b>101</b>. The selector <b>3531</b>, under control of the selection signal <b>3532</b>, selects either address <b>3513</b> or address <b>3510</b>. The selected address is sent as the selector output <b>3530</b> to the prefetch queue <b>102</b>. The selector <b>3534</b>, controlled by the selection signal <b>3532</b>, selects either a set selection signal <b>3516</b>-<b>1</b> or a set selection signal <b>3516</b>-<b>2</b>. The selected signal is sent as the selector output <b>3533</b> to the prefetch queue <b>102</b>.</p><p>Where the write signal <b>3422</b> designates a read operation from the first cache memory <b>101</b>, the content of address <b>3430</b> is read from the first cache memory <b>101</b>; and, the read data <b>3412</b> and the hit signal <b>3413</b> are output from the first cache memory <b>101</b>. Where the write signal <b>3422</b> designates a write operation to the first cache memory <b>101</b>, the transfer data <b>3520</b> is written to the first cache memory <b>101</b> if the selector control signal <b>3423</b> is 1, or the content of the write data <b>3544</b> is written to the first cache memory <b>101</b> if the selector control signal <b>3423</b> is 0.</p><p>Where the write signal <b>3425</b> is negated to designate a read operation from the second cache memory <b>3490</b>, the cache memory is searched for the content of address <b>3513</b>. The data <b>3410</b> read out accordingly and the hit signal <b>3411</b> are then output from the second cache memory <b>3490</b>. Where the write signal <b>3425</b> is asserted to designate a write operation to the second cache memory <b>3490</b>, the cache memory is searched for a hit. In case of a hit, the content of the write data bus <b>3514</b> is written to the second cache memory <b>3490</b>. Likewise, where the write signal <b>3426</b> is negated to designate a read operation from the second cache memory <b>3490</b>, the second cache memory is searched for the content of address <b>3510</b>. The data <b>3512</b> read out accordingly and the hit signal <b>3481</b> are then output from the second cache memory <b>3490</b>. Where the write signal <b>3426</b> is asserted to designate a write operation to the second cache memory <b>3490</b>, the second cache memory is searched for a hit. In case of a hit, the content of the write data bus <b>3511</b> is written to the second cache memory <b>3490</b>. If the entry signal <b>3424</b> is asserted concurrently with the above operation, the transfer address <b>3521</b> paired with the transfer data <b>3520</b> is entered.</p><p>The prefetch queue <b>102</b> is capable of retaining up to four entries of data addresses being transferred from the main memory. When the set signal <b>120</b> is asserted, address <b>3530</b> and the content of the cache selection signal <b>3533</b> are entered into the queue <b>102</b>. Where the reset signal <b>121</b> is asserted, the cache selection signal <b>116</b> corresponding to the transfer address <b>3521</b> is output from the queue and the corresponding entry is invalidated. If comparing address <b>3530</b> with the internally retained addresses reveals that the corresponding entry is being transferred from the main memory, the hit signal <b>115</b> is asserted. If the retained addresses are valid for all entries, the full signal <b>114</b> indicating that state is asserted.</p><p>FIG. 40 shows details of the control circuit <b>3403</b> in FIG. <b>35</b>. The control circuit <b>3403</b> decodes the control signal <b>3516</b>-<b>3</b> regarding the first instruction and the control signal <b>3516</b>-<b>4</b> regarding the second instruction, and accepts the start of any one of the instructions LD, ST, PF<b>1</b> and PF<b>2</b>. If the first instruction is LD and if the hit signal <b>3413</b> from the first cache memory and the first hit signal <b>3411</b> from the second cache memory are both negated, it means that a miss has occurred in both cache memories. In that case, the wait signal <b>4001</b> of the first instruction is asserted so that the instruction unit will wait while the data is being transferred from the main memory. If the first instruction is LD, PF<b>1</b> or PF<b>2</b>, if the hit signal <b>3413</b> from the first cache memory and the first hit signal <b>3411</b> from the second cache memory are both negated, and if the hit signal <b>115</b> from the prefetch queue is negated but the full signal <b>114</b> therefrom is asserted, that means the prefetch queue is full and no more instructions can be placed into the queue. In that case, the wait signal <b>4001</b> for the first instruction is asserted so that the instruction unit will wait until the prefetch queue is vacated. If the first instruction is LD, PF<b>1</b> or PF<b>2</b>, if the hit signal <b>3413</b> from the first cache memory and the first hit signal <b>3411</b> from the second cache memory are both negated, and if the hit signal <b>115</b> and full signal <b>114</b> from the prefetch queue are both negated, then the transfer request signal <b>3523</b> to the main memory is asserted. At the same time, the selection signal <b>3532</b> and set signal <b>120</b> to the prefetch queue are both asserted, and the first instruction is entered into the prefetch queue. If the first instruction is ST and if the hit signal <b>3413</b> from the first cache memory is asserted, then the write signal <b>3422</b> to the first cache memory is asserted so that the corresponding data will be written to the first cache memory. Likewise, if the first instruction is ST and if the first hit signal <b>3411</b> from the second cache memory is asserted, then the first write signal <b>3425</b> to the second cache memory is asserted so that the corresponding data will be written to the second cache memory.</p><p>If the second instruction is LD, ST, PF<b>1</b> or PF<b>2</b> and if the second hit signal <b>3481</b> from the second cache memory is negated, it is necessary to access the first cache memory in the next cycle. Thus, the wait signal <b>4002</b> of the second instruction is asserted. Access to the first cache memory by the second instruction is accomplished after access to the cache memory by the first instruction has ended with the wait signal <b>4001</b> of the first instruction being negated. An AND gate <b>4011</b> asserts a control signal <b>4003</b> when the wait signal <b>4001</b> of the first instruction is negated and the wait signal <b>4002</b> of the second instruction is asserted. A register <b>4012</b> asserts the selection signal <b>3427</b> to the first cache memory one cycle after the control signal <b>4003</b> is asserted. When the selection signal <b>3427</b> is 1, the first cache memory is accessed by the second instruction and the first instruction is kept from accessing any cache memory. If the second instruction is LD, if the selection signal <b>3427</b> to the first cache memory is asserted, and if the hit signal <b>3413</b> from the first cache memory is negated, that means a miss has occurred in both cache memories. In that case, the wait signal <b>4002</b> of the second instruction is asserted so that the instruction unit will wait while the data is being transferred from the main memory. If the second instruction is LD, PF<b>1</b> or PF<b>2</b>, if the selection signal <b>3427</b> to the first cache memory is asserted, if the hit signal <b>3413</b> from the first cache memory is negated, and if the hit signal <b>115</b> from the prefetch queue is negated but the full signal <b>114</b> therefrom is asserted, that means the prefetch queue is full and no more instructions can be placed into the queue. In that case, the wait signal <b>4002</b> of the second instruction is asserted so that the instruction unit will wait until the prefetch queue is vacated. If the second instruction is LD, PF<b>1</b> or PF<b>2</b>, if the selection signal <b>3427</b> to the first cache memory is asserted, if the hit signal <b>3413</b> from the first cache memory is negated, and the hit signal <b>115</b> and the full signal <b>114</b> from the prefetch queue are negated, then the transfer request signal <b>3523</b> to the main memory is asserted. At the same time, the set signal <b>120</b> to the prefetch queue is asserted and the second instruction is entered into the prefetch queue. If the second instruction is ST, if the selection signal <b>3427</b> to the first cache memory is asserted, and if the hit signal <b>3413</b> from the first cache memory is asserted, then the write signal <b>3422</b> to the first cache memory is asserted so that the applicable data will be written thereto. If the second instruction is ST and if the second hit signal <b>3481</b> from the second cache memory is asserted, then the second write signal <b>3426</b> to the second cache memory is asserted so that the applicable data will be written thereto.</p><p>An OR gate <b>4013</b> asserts the wait signal <b>3517</b> to the instruction unit when either the wait signal <b>4001</b> of the first instruction or the wait signal <b>4002</b> of the second instruction is asserted.</p><p>When the response signal <b>3522</b> from the main memory is asserted, the reset signal <b>121</b> to the prefetch queue is asserted so that the applicable entry will be reset from the prefetch queue <b>102</b>. At the same time, a check is made of the cache selection signal <b>116</b> to see if the signal designates a write operation to the first cache memory. If the cache selection signal <b>116</b> is found to designate a write operation to the first cache memory, the write signal <b>3422</b> and selection signal <b>3423</b> to the first cache memory are asserted. If the cache selection signal <b>116</b> is found to designate a write operation to the second cache memory, the entry signal <b>3424</b> to the second cache memory is asserted.</p><p>FIG. 38 shows details of the second cache memory <b>3490</b> in FIG. <b>35</b>. The cache memory of FIG. 38 is a full associative type cache memory having a block size of 4 bytes and a capacity of 256 bytes. In FIG. 38, reference numeral <b>3800</b> is a judging circuit, and <b>3801</b> through <b>3803</b> are cells that hold combinations of valid bits, addresses and data. The cells <b>3801</b> through <b>3803</b> receive the read addresses <b>3513</b> and <b>3510</b>, the entry request <b>3424</b>, the write data <b>3514</b> and <b>3511</b>, and the write requests <b>3425</b> and <b>3426</b>; and, in turn, the cells output the data <b>3410</b> and <b>3512</b>. The cells <b>3801</b> through <b>3803</b> also output hit signals <b>3810</b> through <b>3812</b> and <b>3820</b> through <b>3822</b> to the judging circuit <b>3800</b>. The cell <b>3801</b> receives the transfer address <b>3521</b> and transfer data <b>3520</b>, and forwards address <b>3813</b> and data <b>3814</b> to the cell <b>3802</b>. Likewise, the cell <b>3802</b> forwards address <b>3815</b> and data <b>3816</b>. The last cell <b>3803</b> receives address <b>3817</b> and data <b>3818</b>.</p><p>The judging circuit <b>3800</b> asserts the hit signal <b>3411</b> if any one of the hit signals <b>3810</b> through <b>3812</b> from the cells <b>3801</b> through <b>3803</b> is asserted. Similarly, the judging circuit <b>3800</b> asserts the hit signal <b>3481</b> if any one of the hit signals <b>3820</b> through <b>3822</b> from the cells <b>3801</b> through <b>3803</b> is asserted. The cell <b>3801</b> compares read address <b>3513</b> with the internally retained address. If the two addresses match and are found valid, the cell <b>3801</b> outputs the hit signal <b>3810</b> and places the internally retained applicable data onto a bus <b>3410</b>. If the write request <b>3425</b> is asserted, the cell <b>3801</b> compares the internally retained address with address <b>3513</b>. If the two addresses match and the valid bit is asserted, the cell <b>3801</b> fetches the content of the write data <b>3514</b>. Likewise, the cell <b>3801</b> compares read address <b>3510</b> with the internally retained address. If the two addresses match and are found valid, the cell <b>3801</b> outputs the hit signal <b>3820</b> and places the internally retained applicable data onto a bus <b>3512</b>. When the write request <b>3426</b> is asserted, the cell <b>3801</b> compares the internally retained address with address <b>3510</b>. If the two addresses match and the valid bit is asserted, the cell <b>3801</b> fetches the content of the write data <b>3511</b>. If the entry request <b>3424</b> is asserted in parallel with the above operation, the cell <b>3801</b> asserts its valid bit and fetches the transfer address <b>3521</b> and transfer data <b>3520</b>. At this point, the cell <b>3802</b> fetches via the signals <b>3813</b> and <b>3814</b> the address and data that were retained by the cell <b>3801</b>. That is, the cells <b>3801</b> through <b>3803</b> constitute an FIFO structure.</p><p>FIG. 39 shows details of the cell <b>3801</b> in FIG. <b>38</b>. In FIG. 39, reference numerals <b>3900</b>, <b>3901</b> and <b>3902</b> are registers that hold a valid bit, an address and data, respectively; <b>3904</b> and <b>3914</b> are comparators; <b>3905</b>, <b>3906</b>, <b>3915</b> and <b>3916</b> are AND gates; and <b>3903</b> and <b>3913</b> are tri-state buffers. The entry request <b>3424</b> is connected to the register <b>3900</b> that holds a valid bit, to the register <b>3901</b> that holds an address, and to the register <b>3902</b> that holds data. When the entry request <b>3424</b> is asserted, the valid bit <b>3900</b> is set, the register <b>3901</b> fetches the transfer address <b>3521</b>, and the register <b>3902</b> fetches the transfer data <b>3520</b>. The comparator <b>3904</b> compares address <b>3513</b> with the output <b>3813</b> of the address-holding register. When the output of the comparator <b>3904</b> and the valid bit are both asserted, the AND gate <b>3906</b> asserts the hit signal <b>3810</b> and opens the tri-state buffer <b>3903</b> to place the content of the data-holding register onto the data bus <b>3410</b>. When the AND gate <b>3905</b> senses that the hit signal <b>3810</b> and the write request <b>3425</b> are both asserted, the AND gate <b>3905</b> asserts a signal <b>3908</b> to the data-holding register <b>3902</b> and causes the register <b>3902</b> to fetch the write data <b>3514</b>. Likewise, the comparator <b>3914</b> compares address <b>3510</b> with the output <b>3813</b> of the address-holding register. When the output of the comparator <b>3914</b> and the valid bit are both asserted, the AND gate <b>3916</b> asserts the hit signal <b>3820</b> and opens the tri-state buffer <b>3913</b> to place the content of the data-holding register onto the data bus <b>3512</b>. When the AND gate <b>3915</b> senses that the hit signal <b>3820</b> and the write request <b>3426</b> are both asserted, the AND gate <b>3915</b> asserts the signal <b>3918</b> to the data-holding register <b>3902</b> and causes the register <b>3902</b> to fetch the write data <b>3511</b>.</p><p>As described, the cache memory of FIG. 38 is a full associative type cache memory that processes in parallel an access by two memory reference instructions and the write operation of transfer data from the main memory. Although complicated structurally so as to implement such functions, the cache memory of FIG. 38 is reduced in overall size because its capacity is as small as 256 bytes. This means that the cache memory can operate at high speed.</p><p>FIG. 43 shows a general view of a third embodiment of the present invention. Of the components of the third embodiment shown in FIG. 43, those identical to their counterparts in the embodiment of FIG. 1 are given the same reference numerals. The third embodiment is characterized in that its memory unit <b>4402</b> has a register <b>4380</b> for holding information about the ST instruction. The arrangement allows a cache hit judgment on the ST instruction and a data write operation to be carried out in different machine cycles. This reduces the time required to process the ST instruction per machine cycle and boosts the operating frequency correspondingly.</p><p>The third embodiment shown in FIG. 43 comprises an instruction unit <b>201</b>, the memory unit <b>4402</b> and a main memory <b>203</b>.</p><p>The instruction unit <b>201</b> is the same in constitution as that of the embodiment shown in FIG. <b>1</b>.</p><p>The memory unit <b>4402</b> comprises a first cache memory <b>101</b>, a second cache memory <b>4390</b>, and a control section including selectors <b>104</b> and <b>4395</b>, as well as a control unit <b>4392</b> for exchanging data with the first and the second cache memory. The first cache memory <b>101</b> is a single-port large-capacity cache memory which is the same in constitution as the first cache memory of the embodiment in FIG. <b>1</b>. The second cache memory <b>4390</b> has three ports for parallel processing of access by a memory reference instruction, the writing of data by the ST instruction, and the writing of transfer data from the main memory. The memory unit <b>4402</b> sends data and a wait signal to the instruction unit <b>201</b> over a four-byte-wide read data bus <b>212</b> and a wait signal line <b>214</b>, and transmits a request signal to the main memory <b>203</b> over a request signal line <b>218</b>.</p><p>The main memory <b>203</b> is the same in structure as the main memory of the embodiment in FIG. <b>1</b>.</p><p>The operation code of the instructions processed by the instruction unit <b>201</b> in FIG. 43 is the same in format as the operation code shown in FIG. <b>12</b>. The types of the instructions to be processed are the same as those listed in FIG. <b>13</b>.</p><p>FIGS. <b>45</b>(<i>a</i>), <b>45</b>(<i>b</i>), <b>45</b>(<i>c</i>) and <b>45</b>(<i>d</i>) are illustrations for explaining the pipeline operation in effect when the data processor of FIG. 43 executes instructions. In FIGS. <b>45</b>(<i>a</i>) through <b>45</b>(<i>d</i>), IF represents an instruction fetch stage; D is a decode stage: E is an operation and address add stage; A is a cache access stage; W is a register write stage; R is a cache access retry stage; X is a wait stage; and S is an ST instruction data write stage. Unlike the pipeline operation shown in FIG. 4, the pipeline operation depicted in FIGS. <b>45</b>(<i>a</i>) through <b>45</b>(<i>d</i>) has the writing of data by the ST instruction carried out not in the stage A, but in stage S. Referring now to FIG. <b>45</b>(<i>a</i>), instruction <b>1</b> gains access to both the first and the second cache memory simultaneously in stage A. Following a hit in the second cache memory, instruction <b>1</b> causes the applicable data to be written to the second cache memory in stage S. Instruction <b>2</b> accesses both the first and the second cache memory simultaneously in stage A. The reading of data from the second cache memory by instruction <b>2</b> is accomplished in the same cycle as that in which data is written to the second cache memory by instruction <b>1</b>, whereas the second cache memory allows the reading of data by the LD instruction and the writing of data by the ST instruction to be processed in a single machine cycle. That is, the processing of instruction <b>2</b> is carried out without extra penalty. Following a hit in the second cache memory, instruction <b>2</b> causes the data read from the second cache memory to be written to the register in stage W. Referring to FIG. <b>45</b>(<i>b</i>), instruction <b>1</b> gains access to both the first and the second cache memory simultaneously in stage A. Following a hit in the second cache memory, instruction <b>1</b> causes the applicable data to be written to the second cache memory in stage S. Instruction <b>2</b> accesses the first and the second cache memory simultaneously in stage A. The reading of data from the second cache memory by instruction <b>2</b> is performed in the same cycle as that in which data is written to the second cache memory by instruction <b>1</b>, whereas the second cache memory allows the reading of data by the LD instruction and the writing of data by the ST instruction to be processed in a single machine cycle. That is, the processing of instruction <b>2</b> is carried out without extra penalty. Following a hit in the first cache memory, instruction <b>2</b> causes the data read from the first cache memory to be written to the register in stage W. Referring now to FIG. <b>45</b>(<i>c</i>), instruction <b>1</b> gains access to the first and the second cache memory simultaneously in stage A. Following a hit in the first cache memory, instruction <b>1</b> causes the applicable data to be written to the first cache memory in stage S. Instruction <b>2</b> accesses the second cache memory alone in stage A. Because the reading of data from the first cache memory by instruction <b>2</b> cannot be performed in the same cycle as that in which data is written to the first cache memory by instruction <b>1</b>, the first cache memory is not accessed in stage A. Following a hit in the second cache memory, instruction <b>2</b> causes the data read from the second cache memory to be written to the register in stage W without gaining access to the first cache memory. Referring to FIG. <b>45</b>(<i>d</i>), instruction <b>1</b> accesses the first and the second cache memory simultaneously in stage A. Following a hit in the first cache memory, instruction <b>1</b> causes the applicable data to be written to the first cache memory in stage S. Instruction <b>2</b> gains access only to the second cache memory in stage A. Because the reading of data from the first cache memory by instruction <b>2</b> cannot be performed in the same cycle as that in which data is written to the first cache memory by instruction <b>1</b>, the first cache memory is not accessed in stage A. Following a miss in the second cache memory, instruction <b>2</b> accesses the first cache memory in stage R. With a hit taking place in the first cache memory as a result of access thereto in stage R. the data read from the first cache memory is written to the register in stage W.</p><p>When the hit check of the ST instruction and the writing of data thereby are carried out in different stages, the amount of processing per stage is reduced and the processing speed is enhanced. When the ST instruction attains a hit in the second cache memory, the next LD instruction is executed without extra penalty. This means that if the PF<b>2</b> instruction is used to transfer data to the second cache memory in advance, the processing is always carried out without extra penalty, whereby the performance is enhanced.</p><p>FIG. 44 shows details of the memory unit <b>4402</b> in FIG. <b>43</b>. In FIG. 44, reference numeral <b>101</b> is a first cache memory, <b>4390</b> is a second cache memory, <b>102</b> is a four-entry prefetch queue, <b>4303</b> is a control circuit, <b>104</b> and <b>4440</b> are selectors, and <b>4431</b> and <b>4432</b> are registers.</p><p>The first cache memory <b>101</b> receives address <b>4330</b>, transfer data <b>215</b>, a selector control signal <b>4323</b>, a write signal <b>4322</b> and write data <b>4444</b>; and outputs read data <b>3212</b> and a hit signal <b>4313</b>. The second cache memory <b>4390</b> receives read address <b>210</b>, a write address <b>4413</b>, transfer address <b>216</b>, transfer data <b>215</b>, an entry signal <b>4324</b>, a write signal <b>4325</b> and the write data <b>4444</b>; and outputs a read data <b>4310</b> and a hit signal <b>4311</b>. The prefetch queue <b>102</b> receives a cache selection signal <b>213</b>-<b>1</b>, transfer address <b>216</b>, address <b>210</b>, a set signal <b>120</b> and a reset signal <b>121</b>; and outputs a full signal <b>114</b>, a hit signal <b>115</b> and a cache selection signal <b>116</b>.</p><p>The control circuit <b>4303</b> receives a control signal <b>213</b>-<b>2</b> from the instruction unit; the full signal <b>114</b>, hit signal <b>115</b> and cache selection signal <b>116</b> from the prefetch queue <b>102</b>; a response signal <b>217</b> from the main memory; the hit signal <b>4311</b> from the second cache memory <b>4390</b>; and the hit signal <b>4313</b> from the first cache memory. In turn, the control circuit <b>4303</b> outputs a wait signal <b>214</b> to the instruction unit; the set signal <b>120</b> and reset signal <b>121</b> to the prefetch queue <b>102</b>; a transfer request signal <b>218</b> to the main memory; the entry signal <b>4324</b> and write signal <b>4325</b> to the second cache memory <b>4390</b>; the write signal <b>4322</b> and selector control signal <b>4323</b> to the first cache memory <b>101</b>; and the selector control signals <b>4323</b> and <b>4327</b> to the selector <b>4440</b> respectively.</p><p>The selector <b>104</b> receives the data <b>4310</b> and hit signal <b>4311</b> from the second cache memory, and the data <b>4312</b> and hit signal <b>4313</b> from the first cache memory <b>101</b>. When the hit signal <b>4311</b> is asserted, the selector <b>104</b> reads and outputs the data <b>4310</b> that is placed onto a read data bus <b>212</b>; and, when the hit signal <b>4313</b> is asserted, the selector <b>104</b> reads and outputs the data <b>4312</b> that is placed onto the read data bus <b>212</b>. The selector <b>4440</b>, under control of the selector control signals <b>4323</b> and <b>4327</b>, selects one of address <b>210</b>, address <b>4413</b> and transfer address <b>216</b>. The selected address is output as the selector output <b>4330</b> to the first cache memory <b>101</b>.</p><p>Where the write signal <b>4322</b> designates a read operation from the first cache memory <b>101</b>, the content of address <b>4330</b> is read from the first cache memory <b>101</b>. The read data <b>4312</b> is output along with the hit signal <b>4313</b>. Where the write signal <b>4322</b> designates a write operation to the first cache memory <b>101</b>, either the transfer data <b>215</b> is written thereto if the selector control signal <b>4323</b> is 1, or the content of the write data <b>4444</b> is written if the selector control signal <b>4323</b> is 0.</p><p>The second cache memory <b>4390</b> is checked for the content of address <b>210</b>. The data <b>4310</b> read out accordingly and the hit signal <b>4311</b> are then output from the second cache memory <b>4390</b>. If the write signal <b>4325</b> is asserted to designate a write operation, the second cache memory <b>4390</b> is checked for the content of address <b>4413</b>. In case of a hit, the content of the data bus <b>4444</b> is written to the second cache memory <b>4390</b>. If the entry signal <b>4324</b> is asserted in parallel with the above operation, transfer address <b>216</b> paired with the transfer data <b>215</b> is entered into the second cache memory <b>4390</b>.</p><p>The operation of the prefetch queue <b>102</b> shown in FIG. 44 is the same as that of the prefetch queue <b>102</b> shown in FIG. <b>2</b>.</p><p>The register <b>4431</b> receives the write data <b>211</b> and places it onto the data bus <b>4444</b> in the next cycle. The register <b>4432</b> receives address <b>210</b> and places it onto the bus <b>4413</b> in the next cycle.</p><p>FIG. 48 shows details of the control circuit <b>4303</b> in FIG. <b>44</b>. The control circuit <b>4303</b> decodes the control signal <b>213</b>-<b>2</b> to accept the start of any one of the instructions LD, ST, PF<b>1</b> and PF<b>2</b>. The control signal <b>4327</b> designates the writing of store data to the first cache memory. When the control signal <b>4327</b> is set to 1, the first cache memory cannot be accessed by any other instruction. If the control signal <b>4327</b> is set to 1, if the LD, ST, PF<b>1</b> or PF<b>2</b> instruction is being executed, and if the hit signal <b>4311</b> from the second cache memory is negated, then the wait signal <b>214</b> is asserted because of the need to access the first cache memory in the next cycle. If the control signal <b>4327</b> is set to 0, if the LD instruction is being executed, and if the hit signal <b>4313</b> from the first cache memory and the hit signal <b>4311</b> from the second cache memory are both negated, that means a miss has occurred in both cache memories. Thus, the wait signal <b>214</b> is asserted so that the instruction unit will wait while data is being transferred from the main memory. If the control signal <b>4327</b> is set to 0, if the LD, PF<b>1</b> or PF<b>2</b> instruction is being executed, if the hit signal <b>4313</b> from the first cache memory and the hit signal <b>4311</b> from the second cache memory are both negated, and if the hit signal <b>115</b> from the prefetch queue is negated but the full signal <b>114</b> therefrom is asserted, that means the prefetch queue is full and no more instructions can be placed into the queue. In that case, the wait signal <b>214</b> is asserted so that the instruction unit will wait until the prefetch queue is vacated. If the control signal <b>4327</b> is set to 0, if the LD, PF<b>1</b> or PF<b>2</b> instruction is being executed, if the hit signal <b>4313</b> from the first cache memory and the hit signal <b>4311</b> from the second cache memory are both negated, and if the hit signal <b>115</b> and full signal <b>114</b> from the prefetch queue are both negated, then the transfer request signal <b>218</b> to the main memory is asserted. At the same time, the set signal <b>120</b> to the prefetch queue is asserted and an entry is made into the prefetch queue. If the control signal <b>4327</b> is set to 0, if the ST instruction is being executed, and if the hit signal <b>4313</b> from the first cache memory is asserted, then a control signal <b>4801</b> is asserted. When the control signal <b>4801</b> is asserted, a register <b>4811</b> asserts the control signal <b>4327</b> in the next cycle. When the control signal <b>4327</b> is asserted, an OR gate <b>4813</b> asserts the write signal <b>4322</b> to the first cache memory. This causes store data to be written to the first cache memory. Likewise, if the hit signal <b>4311</b> from the second cache memory is asserted during execution of the ST instruction, a control signal <b>4802</b> is asserted. With the control signal <b>4802</b> asserted, the register <b>4812</b> asserts the write signal <b>4325</b> to the second cache memory in the next cycle. This causes store data to be written to the second cache memory.</p><p>When the response signal <b>217</b> from the main memory is asserted, the reset signal <b>121</b> to the prefetch queue <b>102</b> is asserted so that the applicable entry will be reset from the queue. At the same time, a check is made on the cache selection signal <b>116</b> to see if it designates a write operation to the first cache memory. If the cache selection signal <b>116</b> is found to designate a write operation to the first cache memory, then the write signal <b>4322</b> and selection signal <b>4323</b> to the first cache memory are asserted. If the cache selection signal <b>116</b> is found to designate a write operation to the second cache memory, then the entry signal <b>4324</b> to the second cache memory is asserted. The transfer data is then entered into the selected cache memory.</p><p>FIG. 46 shows details of the second cache memory <b>4390</b> in FIG. <b>44</b>. The cache memory shown in FIG. 46 is a full associative type cache memory that has a block size of 4 bytes and a capacity of 256 bytes. In FIG. 46, reference numeral <b>4600</b> is a judging circuit, and <b>4601</b> through <b>4603</b> are cells that hold combinations of valid bits, addresses and data. The cells <b>4601</b> through <b>4603</b> receive read address <b>210</b>, write address <b>4413</b>, the entry request <b>4324</b>, the write data <b>4444</b> and write request <b>4325</b>; and outputs the data <b>4310</b>. In addition, the cells <b>4601</b> through <b>4603</b> send hit signals <b>4610</b> through <b>4612</b> respectively to the judging circuit <b>4600</b>. The cell <b>4601</b> receives transfer address <b>216</b> and the transfer data <b>215</b>, and outputs address <b>4613</b> and data <b>4614</b> to the cell <b>4602</b>. Likewise, the cell <b>4602</b> sends address <b>4615</b> and data <b>4616</b> to the next cell. The last cell <b>4612</b> receives address <b>4617</b> and data <b>4618</b>.</p><p>When any one of the hit signals <b>4610</b> through <b>4612</b> is asserted, the judging circuit <b>4600</b> asserts the hit signal <b>4311</b>. The cell <b>4601</b> compares read address <b>210</b> with the internally retained address. If the two addresses match and are found valid, the cell <b>4601</b> outputs the hit signal <b>4610</b> and places the internally retained corresponding data onto a bus <b>4310</b>. If the write request <b>4325</b> is asserted, the cell <b>4601</b> compares write address <b>4413</b> with the internally retained address. If the two addresses match and the valid bit is asserted, the cell <b>4601</b> fetches the content of the write data <b>4444</b>. If the entry request <b>4324</b> is asserted in parallel with the above operation, the cell <b>4601</b> asserts its valid bit and fetches transfer address <b>216</b> and the transfer data <b>215</b>. At this point, the cell <b>4602</b> fetches via the signals <b>4613</b> and <b>4614</b> the address and data which are retained in the cell <b>4601</b>. That is, the cells <b>4601</b> through <b>4603</b> constitute an FIFO structure.</p><p>FIG. 47 shows details of the cell <b>4601</b> in FIG. <b>46</b>. In FIG. 47, reference numerals <b>4700</b>, <b>4701</b> and <b>4702</b> are registers that hold a valid bit, an address and data, respectively; <b>4704</b> and <b>4714</b> are comparators; <b>4706</b>, <b>4715</b> and <b>4716</b> are AND gates; and <b>4703</b> is a tri-state buffer. The entry request <b>4324</b> is connected to the register <b>4700</b> that holds a valid bit, to the register <b>4701</b> that holds an address and to the register <b>4702</b> that retains data. When the entry request <b>4324</b> is asserted, the valid bit <b>4700</b> is set, the address-holding register <b>4701</b> fetches transfer address <b>216</b>, and the data-holding register <b>4702</b> fetches transfer data <b>215</b>. The comparator <b>4704</b> compares read address <b>210</b> with the output <b>4613</b> of the address-holding register. If the output of the comparator <b>4704</b> and the valid bit are both asserted, then the AND gate <b>4706</b> asserts the hit signal <b>4610</b> and opens the tri-state buffer <b>4703</b> to place the content of the data-holding register onto the data bus <b>4310</b>. Meanwhile, the comparator <b>4714</b> compares write address <b>4413</b> with the output <b>4613</b> of the address-holding register. If the output of the comparator <b>4714</b> and the valid bit are both asserted, the AND gate <b>4716</b> asserts a hit signal <b>4720</b>. When the hit signal <b>4720</b> and write request <b>4325</b> are both asserted, the AND gate <b>4715</b> asserts a signal <b>4718</b> to the data-holding register <b>4702</b> to place the write data <b>4444</b> into the data-holding register <b>4702</b>.</p><p>As described, the cache memory of FIG. 46 is a full associative type cache memory that processes in parallel the access by memory reference instructions, the writing of data by the ST instruction and the writing of transfer data from the main memory. Although complicated structurally so as to implement such functions, the cache memory of FIG. 46 is reduced in overall size because its capacity is as small as 256 bytes. This means that the cache memory can operate at high speed.</p><p>FIG. 49 shows a general view of a fourth embodiment of the present invention. Of the components of the fourth embodiment in FIG. 49, those identical to their counterparts in the embodiment of FIG. 34 are given the same reference numerals. The fourth embodiment is characterized in that the first and second cache memories are each a single-port cache memory and that references to the first cache memory and the second cache memory are processed in parallel. Because the second cache memory of the embodiment in FIG. 34 is small in capacity, the hit rate of that embodiment using the cache memory tends to drop with respect to data that are likely to be used repeatedly. By contrast, the embodiment shown in FIG. 49 has a second cache memory which provides a large capacity, but is relatively small physically. Thus, the hit rate of the fourth embodiment does not drop when it utilizes a second cache memory in accommodating data that are likely to be used repeatedly. With the repeatedly usable data placed in both the first and the second cache memory, the fourth embodiment can process memory reference instructions in parallel regarding such repeatedly usable data.</p><p>The operation code of the instructions processed by the instruction unit <b>4951</b> in FIG. 49 is the same in format as the operation code shown in FIG. <b>12</b>.</p><p>FIG. 51 is an illustration for explaining the types of instructions to be processed by the data processor of FIG. <b>49</b>. In FIG. 51, the AND, OR, NOT, ADD, SUB and BRA instructions are the same as those explained with reference FIG. <b>13</b>.</p><p>The load instruction LD<b>1</b> adds the contents of registers A and B. takes the result of the addition as an address, reads data from that address, and loads the read data in register C. This instruction is used when the first cache memory is highly likely to contain the applicable data. Thus, the first cache memory is accessed preferentially when the LD<b>1</b> instruction is processed.</p><p>The load instruction LD<b>2</b> also adds the contents of registers A and B. takes the result of the addition as an address, reads data from that address, and loads the read data in register C. This instruction is used when the second cache memory is highly likely to contain the applicable data. Thus, the second cache memory is accessed preferentially when the LD<b>2</b> instruction is processed.</p><p>The store instruction ST<b>1</b> takes the content of register B as an address and writes the content of register A to that address. This instruction is used when the first cache memory is highly likely to contain the applicable data. Thus, the first cache memory is accessed preferentially when the ST<b>1</b> instruction is processed.</p><p>The store instruction ST<b>2</b> also takes the content of register B as an address and writes the content of register A to that address. This instruction is used when the second cache memory is highly likely to contain the applicable data. Thus, the second cache memory is accessed preferentially when the ST<b>2</b> instruction is processed.</p><p>The PF<b>1</b> and PF<b>2</b> instructions are the same as those explained with reference to FIG. <b>13</b>.</p><p>FIGS. <b>50</b>(<i>a</i>) and <b>50</b>(<i>a</i>) are illustrations for explaining the pipeline operation in effect when the data processor of FIG. 49 executes instructions. In FIGS. <b>50</b>(<i>a</i>) and <b>50</b>(<i>b</i>), IF represents an instruction fetch stage; D is a decode stage; E is an operation and address add stage; A is a cache access stage; W is a register write stage; R is a cache access retry stage; and X is a wait stage. For execution of the LD<b>1</b> or ST<b>1</b> instruction, the first cache memory is accessed in stage A. In case of a miss, the second cache memory is accessed in stage R. For execution of the LD<b>2</b> or ST<b>2</b> instruction, the second cache memory is accessed in stage A. With a miss detected, the first cache memory is accessed in stage R. The pipeline operation of FIG. <b>50</b>(<i>a</i>) will now be described. When two load instructions (instructions <b>1</b> and <b>2</b>) are to be processed in parallel, instruction <b>1</b> gains access to the first cache memory in stage A, while instruction <b>2</b> accesses the second cache memory also in stage A. Following a hit in the first cache memory, instruction <b>1</b> reads the data from the first cache memory and writes the read data to the register in stage W. Following a hit in the second cache memory, instruction <b>2</b> reads the data from the second cache memory and writes the read data to the register in stage W. Where instructions <b>3</b> and <b>4</b> are to be processed in parallel, instructions <b>3</b> and <b>4</b> gain access, respectively, to the first and the second cache memory in stage A. Following a hit in the first cache memory, instruction <b>3</b> reads the data from the first cache memory and writes the read data to the register in stage W. Following a miss in the second cache memory, instruction <b>4</b> accesses the first cache memory in stage R. reads the data therefrom and writes the read data to the register in stage W. Where instructions <b>5</b> and <b>6</b> are to be processed in parallel, instructions <b>5</b> and <b>6</b> gain access respectively to the first and the second cache memory in stage A. Following a miss in the first cache memory, instruction <b>5</b> accesses the second cache memory in stage R, reads the data therefrom and writes the read data to the register in stage W. Following a hit in the second cache memory, instruction <b>6</b> reads the data from the second cache memory and writes the read data to the register in stage W. Where instructions <b>7</b> and <b>8</b> are to be processed in parallel, instructions <b>7</b> and <b>8</b> gain access respectively to the first and the second cache memory in stage A. Following a miss in the first cache memory, instruction <b>7</b> accesses the second cache memory in stage R. reads the data therefrom and writes the read data to the register in stage W. Following a miss in the second cache memory, instruction <b>8</b> accesses the first cache memory in stage R. reads the data therefrom and writes the read data to the register in stage W. The pipeline operation of FIG. <b>50</b>(<i>b</i>) will now be described. In this case, instructions <b>1</b>, <b>3</b>, <b>5</b> and <b>7</b> are each the LD<b>2</b> instruction; and instructions <b>2</b>, <b>4</b>, <b>6</b> and <b>8</b> are each the LD<b>1</b> instruction. In this case, instructions <b>1</b>, <b>3</b>, <b>5</b> and <b>7</b> gain access to the second cache memory in stage A, whereas instructions <b>2</b>, <b>4</b>, <b>6</b> and <b>8</b> access the first cache memory in stage A. Other details of the operation are the same as in the pipeline operation of FIG. <b>50</b>(<i>a</i>).</p><p>The pipeline operation in executing the store instruction is similar to that in executing the load instruction. That is, the cache memories are checked in stage A or in stage R. In case of a hit, the data is written to the applicable cache memory in stage A or in stage R.</p><p>As described, when the LD<b>1</b> or ST<b>1</b> instruction attains a hit in the first cache memory or when the LD<b>2</b> or ST<b>2</b> instruction gains a hit in the second cache memory, the memory reference instructions may be processed in parallel. Thus, the LD<b>1</b> and ST<b>1</b> instructions are used to access the data that was transferred to the first cache memory by the PF<b>1</b> instruction; and the LD<b>2</b> and ST<b>2</b> instructions are used to access the data that was transferred to the second cache memory by the PF<b>2</b> instruction. This makes it possible to process the memory reference instructions in parallel, whereby the processing performance is boosted.</p><p>The fourth embodiment shown in FIG. 49 will now be described. The data processor of FIG. 49 comprises the instruction unit <b>4951</b>, a memory unit <b>4952</b> and a main memory <b>3503</b>.</p><p>The instruction unit <b>4951</b> is substantially the same in constitution as that described with reference to FIG. 36, except for small differences in the decoder and memory interface structures. These differences are attributable to the different types of instructions to be processed, i.e. the instructions in FIG. 13 now being replaced by those in FIG. 51 so that the decoder and the memory interface need to be slightly modified to deal with the different instruction types. The instruction unit <b>4951</b> exchanges data with a first cache memory <b>4991</b> and a second cache memory <b>4990</b> over buses <b>5010</b> through <b>5012</b> and <b>5013</b> through <b>5015</b>. That is, the instruction unit <b>4951</b> sends addresses, data and control signals to the memory unit <b>4952</b> and main memory <b>3503</b> over the address buses <b>5010</b> and <b>5013</b>, four-byte-wide write data buses <b>5011</b> and <b>5014</b>, and a control signal line <b>5016</b>.</p><p>The memory unit <b>4952</b> is composed of the first cache memory <b>4991</b>, the second cache memory <b>4990</b>, and a control section including selectors <b>4981</b> through <b>4984</b> and a control unit <b>4992</b> for exchanging data with the two cache memories. The first and second cache memories <b>4991</b> and <b>4990</b> are a direct map type cache memory each having a capacity of 512 kilobytes and a block size of 16 bytes. Except for a difference in capacity, each of these cache memories is the same in constitution as the cache memory described with reference to FIG. <b>11</b>. The memory unit <b>4952</b> sends data and a wait signal to the instruction unit <b>4951</b> over the four-byte-wide data buses <b>5012</b> and <b>5015</b> and a wait signal line <b>5017</b>, and outputs transfer request signals <b>3523</b> and <b>3524</b> to the main memory <b>3503</b>.</p><p>The main memory <b>3503</b>, which stores instructions and data, transfers data to the first cache memory <b>4991</b> and second cache memory <b>4990</b> over buses <b>3520</b> and <b>3521</b>. That is, the main memory <b>3503</b> outputs data, an address and a response signal to the memory unit <b>4952</b> over the transfer data bus <b>3520</b>, transfer address bus <b>3521</b> and a response signal line <b>3522</b>.</p><p>Where the first instruction is the LD<b>1</b> instruction, the instruction unit <b>4951</b> places onto the address bus <b>5013</b> the address of the data to be loaded, and uses a control signal <b>5016</b> to indicate that the LD<b>1</b> instruction is now in effect. The memory unit <b>4952</b> first selects address <b>5013</b> using the selector <b>4981</b> and performs a read operation on the first cache memory <b>4991</b>. In case of a hit in the first cache memory <b>4991</b>, the memory unit <b>4952</b> causes the selector <b>4983</b> to select the data read from the first cache memory <b>4991</b> and places the selected data onto the data bus <b>5015</b>. In case of a miss in the first cache memory <b>4991</b>, the memory unit <b>4952</b> sets to 1 the wait signal <b>5017</b> to the instruction unit <b>4951</b>, causes the selector <b>4982</b> to select address <b>5013</b> in the next cycle, and performs a read operation on the second cache memory <b>4990</b>. In case of a hit in the second cache memory <b>4990</b>, the memory unit <b>4952</b> causes the selector <b>4983</b> to select the data read from the second cache memory <b>4990</b>, and places the selected data onto the data bus <b>5015</b>. At the same time, the wait signal <b>5017</b> is set to 0. In case of a miss in the second cache memory <b>4990</b>, the data transfer request signal <b>3523</b> to the main memory <b>3503</b> is set to 1. Upon receipt of the transfer request signal <b>3523</b>, the main memory <b>3503</b> reads the applicable data, places the read data onto the transfer data bus <b>3520</b>, and returns the response signal <b>3522</b> to the memory unit <b>4952</b>. In turn, the memory unit <b>4952</b> writes the transferred data to the first cache memory <b>4991</b>, simultaneously transfers the data to the instruction unit <b>4951</b> over the data bus <b>5015</b>, and sets the wait signal <b>5017</b> to 0.</p><p>Where the first instruction is the LD<b>2</b> instruction, the instruction unit <b>4951</b> places onto the address bus <b>5013</b> the address of the data to be loaded, and uses the control signal <b>5016</b> to indicate that the LD<b>2</b> instruction is now in effect. The memory unit <b>4952</b> first causes the selector <b>4982</b> to select address <b>5013</b> and performs a read operation on the second cache memory <b>4990</b>. In case of a hit in the second cache memory <b>4990</b>, the memory unit <b>4952</b> causes the selector <b>4983</b> to select the data read from the second cache memory <b>4990</b>, and places the selected data onto the data bus <b>5015</b>. In case of a miss in the second cache memory <b>4990</b>, the memory unit <b>4952</b> sets to 1 the wait signal <b>5017</b> to the instruction unit <b>4951</b>, causes the selector <b>4981</b> to select address <b>5013</b> in the next cycle, and performs a read operation on the first cache memory <b>4991</b>. In case of a hit in the first cache memory <b>4991</b>, the memory unit <b>4952</b> causes the selector <b>4983</b> to select the data read from the first cache memory <b>4991</b>, and places the selected data onto the data bus <b>5015</b>. At the same time, the wait signal <b>5017</b> is set to 0. In case of a miss in the first cache memory <b>4991</b>, the data transfer request signal <b>3523</b> to the main memory <b>3503</b> is set to 1. Upon receipt of the transfer request signal <b>3523</b>, the main memory <b>3503</b> reads the applicable data, places the read data onto the transfer data bus <b>3520</b>, and returns the response signal <b>3522</b> to the memory unit <b>4952</b>. In turn, the memory unit <b>4952</b> writes the transferred data to the second cache memory <b>4990</b>, simultaneously transfers the data to the instruction unit <b>4951</b> over the data bus <b>5015</b>, and sets the wait signal <b>5017</b> to 0.</p><p>Where the first instruction is the ST<b>1</b> instruction, the instruction unit <b>4951</b> places the write address onto the address bus <b>5013</b>, puts onto the data bus <b>5014</b> the data to be written, and uses the control signal <b>5016</b> to indicate that the ST<b>1</b> instruction is now in effect. The memory unit <b>4952</b> first causes the selector <b>4981</b> to select address <b>5013</b> and performs a read operation on the first cache memory <b>4991</b>. In case of a hit in the first cache memory <b>4991</b>, the memory unit <b>4952</b> causes the selector <b>4981</b> to select write data <b>5014</b>, and writes the selected data to the first cache memory <b>4991</b>. In case of a miss in the first cache memory <b>4991</b>, the memory unit <b>4952</b> sets to 1 the wait signal <b>5017</b> to the instruction unit <b>4951</b>, causes the selector <b>4982</b> to select address <b>5013</b> in the next cycle, and performs a read operation on the second cache memory <b>4990</b>. In case of a hit in the second cache memory <b>4990</b>, the memory unit <b>4952</b> causes the selector <b>4982</b> to select the write data <b>5014</b>, and writes the selected data to the second cache memory <b>4990</b>. In case of a miss in the second cache memory <b>4990</b>, the memory unit <b>4952</b> sets the wait signal <b>5017</b> to 0 without transferring data from the main memory <b>3503</b>. In parallel with the above operation, the main memory <b>3503</b> has the same data written thereto.</p><p>Where the first instruction is the ST<b>2</b> instruction, the instruction unit <b>4951</b> places the write address onto the address bus <b>5013</b>, puts onto the data bus <b>5014</b> the data to be written, and uses the control signal <b>5016</b> to indicate that the ST<b>2</b> instruction is now in effect. The memory unit <b>4952</b> first causes the selector <b>4982</b> to select address <b>5013</b> and performs a read operation on the second cache memory <b>4990</b>. In case of a hit in the second cache memory <b>4990</b>, the memory unit <b>4952</b> causes the selector <b>4982</b> to select the write data <b>5014</b> and writes the selected data to the second cache memory <b>4990</b>. In case of a miss in the second cache memory <b>4990</b>, the memory unit <b>4952</b> sets to 1 the wait signal <b>5017</b> to the instruction unit <b>4951</b>, causes the selector <b>4981</b> to select address <b>5013</b> in the next cycle, and performs a read operation on the first cache memory <b>4991</b>. In case of a hit in the first cache memory <b>4991</b>, the memory unit <b>4952</b> causes the selector <b>4981</b> to select the write data <b>5014</b> and writes the selected data to the first cache memory <b>4991</b>. In case of a miss in the first cache memory <b>4991</b>, the memory unit <b>4952</b> sets the wait signal <b>5017</b> to 0 without transferring data from the main memory <b>3503</b>. In parallel with the above operation, the main memory <b>3503</b> has the same data written thereto.</p><p>Where the first instruction is the PF<b>1</b> instruction, the instruction unit <b>4951</b> places onto the address bus <b>5013</b> the data to be prefetched, and uses the control signal <b>5016</b> to indicate that the PF<b>1</b> instruction is now in effect. The memory unit <b>4952</b> causes the selectors <b>4981</b> and <b>4982</b> to select address <b>5013</b>, and performs read operations simultaneously on the first cache memory <b>4991</b> and on the second cache memory <b>4990</b>. In case of a hit in the first or second cache memory <b>4991</b> or <b>4990</b>, the memory unit <b>4952</b> terminates its processing without transferring data from the main memory <b>3503</b>. In case of a miss in both the first and the second cache memory <b>4991</b> and <b>4990</b>, the memory unit <b>4952</b> sets to 1 the data transfer request signal <b>3523</b> to the main memory <b>3503</b>. Upon receipt of the transfer request signal <b>3523</b>, the main memory <b>3503</b> reads the applicable data, places the read data onto the transfer data bus <b>3520</b>, and returns the response signal <b>3522</b> to the memory unit <b>4952</b>. In turn, the memory unit <b>4952</b> writes the transferred data to the first cache memory <b>4991</b>. Where the first instruction is the PF<b>2</b> instruction, the processing is approximately the same except that the data transferred from the main memory <b>3503</b> is written to the second cache memory <b>4990</b>.</p><p>The processing of the second instruction is substantially the same as that of the first instruction. Data exchanges are conducted over the address bus <b>5010</b>, read data bus <b>5012</b> and write data bus <b>5011</b>.</p><p>FIG. 16 shows a further embodiment of the present invention. In FIG. 16, symbol <b>9101</b> represents a processor, <b>9102</b> represents a set judging section storing an address array, <b>9103</b> represents a set selecting section, <b>9107</b> to <b>9114</b> represent memories having a capacity of 1 M bits and a width of 8 bits used for a data array, <b>9106</b> represents a CPU, <b>9104</b> represents an input/output unit, and <b>9105</b> represents a main memory. The set judging section <b>9102</b>, set selecting section <b>9103</b>, and memories <b>9107</b> to <b>9114</b> constitute a two-set associative cache memory (the capacity per set is 0.5 M bytes) for data with a total capacity of 1 M bytes.</p><p>The processor <b>9101</b> transmits an address <b>9124</b> and a control signal <b>9125</b> for reading 8-byte data to the memories <b>9107</b> to <b>9114</b> and to the set judging section, and receives 8-byte data from the set selecting section. The memories <b>9107</b> to <b>9114</b> are connected to the data bus <b>9127</b>. The bus <b>9127</b> includes one-byte buses <b>9127</b>-<b>1</b> to <b>9127</b>-<b>8</b>. The memories <b>9107</b> to <b>9114</b> are connected to the buses <b>9127</b>-<b>1</b> to <b>9127</b>-<b>8</b>, respectively. The memories <b>9107</b> to <b>9114</b>, as described later, hold data for two sets and thereby transmit corresponding 8-byte data in the first set and corresponding 8-byte data in the second set to the set selecting section <b>9103</b> through the bus <b>9127</b> by dividing the overall data into two blocks. The set judging section <b>9102</b> receives the address <b>9124</b> from the processor <b>9101</b> and transmits a signal <b>9126</b> indicating which set to select to the set selecting section <b>9103</b> and a signal <b>9122</b> indicating whether a cache memory is hit to the processor <b>9101</b>. The set selecting section <b>9103</b> selects the two-block data received through the bus <b>9127</b> in accordance with the signal <b>9126</b> sent from the set judging section <b>9102</b> and sends selected data to the processor <b>9101</b> through the bus <b>9121</b>.</p><p>When writing 8-byte data, the processor <b>9101</b> outputs an address through the bus <b>9124</b> and sends data to the set selecting section <b>9103</b> through the bus <b>9121</b>. The set selecting section <b>9103</b> sends received data to the memories <b>9107</b> to <b>9114</b> through the bus <b>9127</b>. Thus, data is written in the memories <b>9107</b> to <b>9114</b> in accordance with the control signal <b>9125</b>.</p><p>Moreover, the processor <b>9101</b> transfers data to and from the input/output unit <b>9104</b> and the main memory <b>9105</b> through the bus <b>9120</b>. In the case of a cache memory error, the processor <b>9101</b> reads a desired block from the main memory <b>9105</b> through the bus <b>9120</b> and transfers it to the memories <b>9107</b> to <b>9114</b> through the buses <b>9121</b> and <b>9127</b>.</p><p>FIG. 18 shows details of a first embodiment of the processor <b>9101</b> in FIG. <b>16</b>. In FIG. 18, symbol <b>9301</b> represents an instruction cache memory, <b>9302</b> represents a decoder, <b>9303</b> represents a cache memory controller, <b>9305</b> represents a register, <b>9306</b> represents an ALU, <b>9304</b> represents an address adder, and <b>9303</b> represents a buffer. An instruction is transferred from the instruction cache memory <b>9301</b> to the decoder <b>9302</b> through a signal line <b>9310</b>. The decoder <b>9302</b> controls the cache memory controller <b>9303</b> through a signal line <b>9311</b> and also controls the ALU <b>9306</b>, register <b>9305</b>, and address adder <b>9904</b>. The ALU <b>9306</b> processes the data transferred from the buses <b>9312</b> and <b>9313</b> and writes the data in the register <b>9305</b> through the bus <b>9316</b>. The address adder <b>9304</b> reads data from the register <b>9305</b> through the buses <b>9314</b> and <b>9315</b>, computes an address to be loaded or stored, and outputs the result to the bus <b>9124</b>. When loading the address, the adder <b>9304</b> incorporates data into the register <b>9305</b> from the bus <b>9121</b>. When storing the address, the adder <b>9304</b> outputs data to the bus <b>9121</b> from the register <b>9305</b>. When transferring data from a memory to a cache memory, the adder <b>9304</b> incorporates the data from the memory into the buffer <b>9330</b> and outputs the data to the bus <b>9121</b>. The cache memory controller <b>9303</b> is started by the decoder <b>9302</b> and outputs the cache memory control signal <b>9125</b> to be loaded or stored. Moreover, the controller <b>9303</b> receives the cache memory hit signal <b>9122</b> and controls transfer of data from the main memory <b>9105</b> to the memories <b>9107</b> to <b>9114</b> in the case of a cache memory error. In this case, the controller <b>9303</b> enters necessary data in the set judging section <b>9102</b> through the bus <b>9123</b>.</p><p>FIG. 19 is an illustration for explaining pipeline operations. In FIG. 19, an instruction <b>1</b> is a load instruction and instructions <b>2</b> and <b>3</b> are inter-register operation instructions. Symbol IF represents a instruction cache memory read stage, D represents a decode stage, A represents a register-read and address-computation stage, C represents a cache memory read stage, and W represents a register write stage. Symbol R represents a register read stage and E represents an operation stage in the ALU.</p><p>For the instruction <b>2</b>, it is impossible to use the contents of a register loaded by the instruction <b>1</b>. For the instruction <b>3</b>, however, it is possible to use the contents written in a register at the stage W of the instruction <b>1</b> by reading the contents by the register at the stage R of the instruction <b>3</b>.</p><p>FIG. 20 shows a timing chart for continuously executing the load instruction. The address <b>9124</b> changes in the sequence of \u201cn\u22121\u201d, \u201cn\u201d, and \u201cn+1\u201d every cycle and data n and data n\u2032 are sent to the data bus <b>9127</b> for the address n. The data is transferred twice every machine cycle. The control signal <b>9125</b> in FIG. 16 includes a clock <b>9125</b>-<b>1</b> and a read/write selection signal <b>9125</b>-<b>2</b> shown in FIG. <b>20</b>. The data n is latched at the leading edge of the clock and the data n\u2032 is latched at the trailing edge of the clock.</p><p>FIG. 21 shows a timing chart when a store instruction is executed. The address n is the address of the store instruction while the data n is transmitted to the memory from the CPU through the data bus <b>9127</b>. The read/write selection signal <b>9125</b>-<b>2</b> goes high for one cycle in order to indicate a data write operation.</p><p>FIG. 22 shows details of the memory <b>9107</b>. Though the constitution of only the memory <b>9107</b> is shown, the constitutions of the other memories <b>9108</b> to <b>9114</b> are the same. In FIG. 22, symbol <b>9700</b> represents a first memory bank, <b>9701</b> represents a second memory bank, <b>9703</b> represents a third memory bank, and <b>9703</b> represents a fourth memory bank. Symbol <b>9704</b> represents a first write register, <b>9705</b> represents a second write register, <b>9706</b> represents a first read register, and <b>9707</b> represents a second read operation. Symbols <b>9709</b>, <b>9710</b>, and <b>9711</b> represents selectors and <b>9712</b> represents a tri-state buffer. Symbol <b>9708</b> represents a timing generation circuit. The first memory bank <b>9700</b> and the third memory bank <b>9702</b> constitute a first set and the second memory bank <b>9701</b> and the fourth memory bank <b>9703</b> constitute a second set.</p><p>The signal <b>9124</b> serves as an address input. FIG. 31 is an illustration for explaining an address constitution. An address is given for each byte and the block size is 16 bytes. Therefore, bits <b>0</b> to <b>3</b> serve as an in-block address and bits <b>4</b> to <b>19</b> serve as a block address. A signal <b>9124</b>-<b>1</b> in FIG. 32 corresponds to the bits <b>4</b> to <b>19</b>, which is used as an address input of the memory banks <b>9700</b> to <b>9703</b>. A signal <b>9124</b>-<b>2</b> corresponds to the bit <b>3</b>, which indicates which eight bytes to read/write among 16 bytes of one block.</p><p>The following is a description of the read operation as performed by the memory <b>9107</b> in FIG. <b>22</b>. Outputs of the first memory bank <b>9700</b> and the third memory bank <b>9702</b> are transmitted to the selector <b>9710</b> through the signals <b>9715</b> and <b>9717</b>, respectively. The selector <b>9710</b> selects the signal <b>9715</b> when the signal <b>9124</b>-<b>2</b> is set to 0 and the signal <b>9717</b> when the signal <b>9124</b>-<b>2</b> is set to 1. Selected data is set to the first read register <b>9706</b> by the data read from the first set. Similarly, outputs of the second memory bank <b>9701</b> and the fourth memory bank <b>9703</b> are transmitted to the selector <b>9709</b> through signals <b>9716</b> and <b>9718</b>, respectively. The selector <b>9709</b> selects the signal <b>9716</b> when the signal <b>9124</b>-<b>2</b> is set to 0 and the signal <b>9718</b> when the signal <b>9124</b>-<b>2</b> is set to 1. The selected data is set to the second read register <b>9707</b> by the data read from the second set. The contents of the first read register <b>9706</b> and those of the second read register <b>9707</b> are transmitted to the selector <b>9711</b> through signal lines <b>9719</b> and <b>9720</b>. An output of the selector <b>9711</b> is transmitted to the tri-state buffer <b>9712</b>, and the tri-state buffer <b>9712</b> drives the 8-bit bus <b>9127</b>.</p><p>The set timing for the first read register <b>9706</b> and the second read register <b>9707</b>, change timing of the selector <b>9711</b>, and drive timing of the driver <b>9712</b> are controlled by the timing generation circuit <b>9708</b> through signals <b>9728</b>, <b>9729</b>, <b>9730</b>, and <b>9731</b>, respectively, as shown in FIG. <b>20</b>. The signal <b>9730</b> selects the first read register <b>9706</b> when it is high and the second read register <b>9707</b> when it is low, which serves as a reverse signal to the clock, as shown in FIG. <b>20</b>. The timing generation circuit <b>9708</b> generates a timing signal in accordance with the clock <b>9125</b>-<b>1</b> and read/write selection signal <b>9125</b>-<b>2</b>. The following is a description of the write operation. Because data is driven through the bus <b>9127</b>-<b>1</b> in the case of a write operation, the data is set to the first write register <b>9704</b> or second write register <b>9705</b>. A bank is selected by the timing generation circuit <b>9708</b> that transmits the set signal <b>9722</b> to the first write register <b>9704</b> or transmits the set signal <b>9727</b> to the second write register <b>9705</b> depending on the signal <b>9124</b>-<b>2</b>. The data is set to the first write register <b>9704</b> when the signal <b>9124</b>-<b>2</b> is set to 0 and to the second write register <b>9705</b> when the signal <b>9124</b>-<b>2</b> is set to 1. An output of the first write register <b>9704</b> is transferred to the first memory bank <b>9700</b> or the second memory bank <b>9701</b> through the signal line <b>9713</b>. An output of the second write register <b>9705</b> is transferred to the third memory bank <b>9702</b> or the fourth memory bank <b>9703</b> through the signal line <b>9714</b>. The timing generation circuit <b>9708</b> generates write signals <b>9723</b> to <b>9726</b> for the memory banks <b>9700</b> to <b>9703</b>. The timing generation circuit <b>9708</b>, as shown in FIG. 21, controls the above timing in accordance with the clock <b>9125</b>-<b>1</b>, read/write selection signal <b>9125</b>-<b>2</b>, set selection signal <b>9126</b>, and address <b>9124</b>-<b>2</b>. The set selection signal represents the writing of data in the first set when it is high and writing of data in the second set when it is low. That is, the following expressions are logically obtained.</p><p>Signal <b>9723</b>=Set selection signal*NOT(<b>91242</b>)*Read/write selection signal</p><p>Signal <b>9725</b>=Set selection signal*<b>9124</b>-<b>2</b>*Read/write selection signal</p><p>Signal <b>9724</b>=NOT (Set selection signal)*NOT (<b>9124</b>-<b>2</b>)*Read/write selection signal</p><p>Signal <b>9723</b>=NOT (Set selection signal)*<b>91242</b>*Read/write selection signal</p><p>FIG. 23 shows a first embodiment of the set selecting section <b>9103</b> in FIG. <b>16</b>. In FIG. 23, symbol <b>9801</b> represents a first register, <b>9802</b> represents a second register, and <b>9806</b> represents a tri-state driver. Symbol <b>9803</b> represents a selector. In the case of a read operation, data of the first set, which is first sent through the bus <b>9127</b>, is set to the first register <b>9801</b>, and data of the second set, which is next sent through the bus <b>9127</b>, is set to the second register <b>9802</b>. The selector <b>9803</b> selects the output signal <b>9804</b> of the first register when the first set selection signal <b>9126</b> is set to 1 and the output signal <b>9805</b> of the second register when the signal <b>9126</b> is set to 0, and transmits either of the output signals to the processor <b>9101</b> through the signal <b>9121</b>. In the case of a write operation, the selector <b>9803</b> transmits the data sent from the processor <b>9101</b> through the signal line <b>9121</b> to the bus <b>9127</b> by using the tri-state buffer <b>9806</b>.</p><p>FIG. 24 shows a second embodiment of the set selecting section <b>9103</b> in FIG. 16. A part which is the same as that in FIG. 16 is provided with the same symbol. In FIG. 24, the second register is not used, though it is used in FIG. 23, and the selector <b>9803</b> directly inputs the data sent from the second set through the bus <b>9127</b>. Thus, one register can be saved.</p><p>FIG. 25 shows details of the set judging section <b>9102</b> in FIG. <b>16</b>. In FIG. 25, symbol <b>91001</b> represents a tag section of the first set, <b>91002</b> represents a valid bit section of the first set, <b>91003</b> represents a tag section of the second set, and <b>91004</b> represents a valid bit section of the second set. Symbols <b>91005</b> and <b>91006</b> represent comparators and <b>91007</b> represents a judging circuit. The first tag <b>91001</b>, first valid bit <b>91002</b>, second tag <b>91003</b>, and second valid bit <b>91004</b> are read with an address <b>9124</b>-<b>1</b>. The first comparator <b>91005</b> compares a signal <b>91014</b> sent from the first tag with an address <b>9124</b>-<b>3</b> and transmits a coincidence signal <b>91010</b> indicating whether they coincide to the judging circuit <b>91007</b>. The hit position of the address <b>9124</b>-<b>3</b> is described in FIG. <b>31</b>. Similarly, the second comparator <b>91006</b> compares a signal <b>91015</b> sent from the second tag with the address <b>9124</b>-<b>3</b> and transmits a coincidence signal indicating whether they coincide to the judging circuit <b>91007</b>.</p><p>The judging circuit <b>91007</b> receives a coincidence signal <b>91010</b> from the first comparator <b>91005</b>, a valid signal <b>91011</b> from the first valid bit section <b>91002</b>, coincidence signal <b>91012</b> from the second comparator <b>91006</b>, and a valid signal <b>91013</b> from the second valid bit section <b>91004</b>, and selects the cache memory hit signal <b>9122</b> and the first set selection signal <b>9126</b>. The circuit <b>91007</b> asserts the cache memory hit signal <b>9122</b> when either set is valid and a coincidence signal is asserted and asserts the first set selection signal <b>9126</b>, when the signal <b>91010</b> is asserted and the signal <b>91011</b> is valid.</p><p>FIG. 26 shows details of the judging circuit in FIG. <b>25</b>. In FIG. 26, symbol <b>91102</b> represents an AND gate and <b>91101</b> represents an AND-OR gate.</p><p>FIG. 27 shows a second embodiment of the processor <b>9101</b> in FIG. 16. A part which is the same as that in FIG. 18 showing the first embodiment of the processor <b>9101</b> is provided with the same symbol. The constitution in FIG. 27 is different from that in FIG. 18 in the fact that selectors <b>9330</b> and <b>9340</b> are used and data can be bypassed to the input of the ALU <b>9306</b> through the bus <b>9121</b>. The decoder <b>9302</b> controls the selectors <b>9330</b> and <b>9340</b> by using signals <b>9331</b> and <b>9341</b>.</p><p>FIG. 28 is an illustration for explaining the pipeline operation of the processor shown in FIG. <b>27</b>. Description of the pipeline operation is omitted because it is the same as that shown in FIG. <b>19</b>. The pipeline operation shown in FIG. 28 is different from that shown in FIG. 19 in the fact that data loaded by the instruction <b>1</b> can be used for the instruction <b>2</b> by using the selectors <b>9330</b> and <b>9340</b> in FIG. <b>27</b>.</p><p>FIG. 29 shows a timing chart of a memory for realizing the pipeline operation shown in FIG. <b>28</b>. For this embodiment, the timing is more critical than that in FIG. 20 because the data n and the data n\u2032 must be returned in the cycle in which the address n appears.</p><p>In the case of the above-described second embodiment, the selectors <b>9330</b> and <b>9340</b> and their control are necessary and the memory access timing gets more critical. However, there is an advantage that loaded data can immediately be used by the next instruction.</p><p>FIG. 32 shows a third embodiment of the processor <b>9101</b> in FIG. <b>16</b>. The constitution shown in FIG. 32 is almost the same as that shown in FIG. <b>27</b> and the same part is provided with the same number. Therefore, the description thereof is omitted. The constitution of FIG. 32 is different from that shown in FIG. 27 in the fact that the set selection signal <b>9126</b> sent from the set judging section <b>9102</b> is also inputted to the decoder <b>9302</b>.</p><p>FIG. 30 shows the pipeline operation of the processor shown in FIG. <b>32</b>. The memory timing in this embodiment is the same as that shown in FIG. <b>20</b>. For the pipeline shown in FIG. 30, data is transferred to the ALU <b>9306</b> by the selector <b>9330</b> or <b>9340</b> for use as shown by the arrow A in FIG. 30 when the instruction <b>1</b> issues a load instruction and the first set is hit by the instruction <b>1</b>. However, when the set <b>2</b> is hit by the instruction <b>1</b>, the data cannot be used by the instruction <b>2</b>, but it can be used by the instruction <b>3</b>, as shown by the arrow B in FIG. <b>30</b>. In this case, the data written at the stage W of the instruction <b>1</b> is used by reading it from a register at the stage R of the instruction <b>3</b>. The third embodiment has an advantage that the data of the first set can immediately be used by the next instruction at the timing shown in FIG. 20, which is less severe than that in FIG. 29, by using the set selection signal <b>9126</b> and thereby controlling bypass control signals <b>9331</b> and <b>9341</b> by the decoder <b>9302</b>.</p><p>The present invention makes it possible to decrease the number of memories necessary for a computer having m sets of associative cache memories up to 1/m smaller than the existing number of memories and therefore to decrease the price.</p><p>The present invention makes it possible to decrease the number of memories necessary for a computer having m sets of associative cache memories up to 1/m smaller than the existing number of memories and therefore to decrease the number of machine cycles. The present invention makes it possible to decrease the number of memories necessary for a computer having m sets of associative cache memories up to 1/m smaller than the existing number of memories and therefore to decrease the number of pins of a CPU.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Takashi", "last_name": "Hotta", "name": ""}, {"first_name": "Toshihiko", "last_name": "Kurihara", "name": ""}, {"first_name": "Shigeya", "last_name": "Tanaka", "name": ""}, {"first_name": "Hideo", "last_name": "Sawamoto", "name": ""}, {"first_name": "Akiyoshi", "last_name": "Osumi", "name": ""}, {"first_name": "Koji", "last_name": "Saito", "name": ""}, {"first_name": "Kotaro", "last_name": "Shimamura", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "HITACHI, LTD."}], "ipc_classes": [{"primary": true, "label": "G06F  12/08"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/0897      20160101A I20201006RMEP"}, {"label": "G06F  12/0846      20160101A I20201006RMEP"}, {"label": "G06F  12/0864      20160101A N20201006RMEP"}, {"label": "G06F  12/0862      20160101A I20201006RMEP"}, {"label": "G06F  12/08        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711129"}, {"primary": false, "label": "711E12045"}, {"primary": false, "label": "711120"}], "ecla_classes": [{"label": "G06F  12/08B8"}, {"label": "G06F  12/08B22L"}, {"label": "S06F12:08B10"}, {"label": "S06F212:6028"}, {"label": "G06F  12/08B6M"}], "cpc_classes": [{"label": "G06F  12/0864"}, {"label": "G06F  12/0897"}, {"label": "G06F  12/0862"}, {"label": "G06F  12/0846"}, {"label": "G06F2212/6028"}, {"label": "G06F  12/0897"}, {"label": "G06F  12/0864"}, {"label": "G06F  12/0862"}, {"label": "G06F  12/0846"}, {"label": "G06F2212/6028"}], "f_term_classes": [], "legal_status": "Expired - Fee Related", "priority_date": "1993-08-05", "application_date": "1998-11-10", "family_members": [{"ucid": "US-20070233959-A1", "titles": [{"lang": "EN", "text": "Data processor having cache memory"}]}, {"ucid": "US-5848432-A", "titles": [{"lang": "EN", "text": "Data processor with variable types of cache memories"}]}, {"ucid": "EP-1901170-A1", "titles": [{"lang": "FR", "text": "Processeur de donn\u00e9es ayant une m\u00e9moire cache"}, {"lang": "EN", "text": "Data processor having cache memory"}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher"}]}, {"ucid": "DE-69432133-D1", "titles": [{"lang": "EN", "text": "Data processor with cache memory"}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher"}]}, {"ucid": "EP-1256879-A2", "titles": [{"lang": "FR", "text": "Processeur de donn\u00e9es avec ant\u00e9m\u00e9moire"}, {"lang": "EN", "text": "Data processor having cache memory"}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher"}]}, {"ucid": "US-6848027-B2", "titles": [{"lang": "EN", "text": "Data processor having cache memory"}]}, {"ucid": "US-20050102472-A1", "titles": [{"lang": "EN", "text": "Data processor having cache memory"}]}, {"ucid": "US-20030204676-A1", "titles": [{"lang": "EN", "text": "Data processor having cache memory"}]}, {"ucid": "EP-0637800-B1", "titles": [{"lang": "FR", "text": "Processeur de donn\u00e9es avec ant\u00e9m\u00e9moire"}, {"lang": "EN", "text": "Data processor having cache memory"}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher"}]}, {"ucid": "US-20010037432-A1", "titles": [{"lang": "EN", "text": "Data processor having cache memory"}]}, {"ucid": "EP-0637800-A3", "titles": [{"lang": "FR", "text": "Processeur de donn\u00e9es avec ant\u00e9m\u00e9moire."}, {"lang": "EN", "text": "Data processor having cache memory."}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher."}]}, {"ucid": "EP-1256879-A3", "titles": [{"lang": "FR", "text": "Processeur de donn\u00e9es avec ant\u00e9m\u00e9moire"}, {"lang": "EN", "text": "Data processor having cache memory"}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher"}]}, {"ucid": "US-6275902-B1", "titles": [{"lang": "EN", "text": "Data processor with variable types of cache memories and a controller for selecting a cache memory to be access"}]}, {"ucid": "US-6587927-B2", "titles": [{"lang": "EN", "text": "Data processor having cache memory"}]}, {"ucid": "DE-69432133-T2", "titles": [{"lang": "EN", "text": "Data processor with cache memory"}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher"}]}, {"ucid": "EP-0637800-A2", "titles": [{"lang": "FR", "text": "Processeur de donn\u00e9es avec ant\u00e9m\u00e9moire"}, {"lang": "EN", "text": "Data processor having cache memory"}, {"lang": "DE", "text": "Datenprozessor mit Cache-Speicher"}]}, {"ucid": "US-7240159-B2", "titles": [{"lang": "EN", "text": "Data processor having cache memory"}]}]}