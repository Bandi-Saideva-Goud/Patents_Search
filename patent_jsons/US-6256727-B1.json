{"patent_number": "US-6256727-B1", "publication_id": 72726662, "family_id": 22133020, "publication_date": "2001-07-03", "titles": [{"lang": "EN", "text": "Method and system for fetching noncontiguous instructions in a single clock cycle"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72580583\"><p>A system and method for fetching noncontiguous blocks of instructions in a data processing system is disclosed. The system comprises an instruction cache means for providing a first plurality of instructions and branch logic means for receiving the first plurality of instructions and for providing branch history information about the first plurality of instructions. The system further includes an auxiliary cache means for receiving a second plurality of instructions based upon the branch history information. The auxiliary cache means overlays at least one of the second plurality of instructions if there is a branch in the first plurality of instructions and the branch is to the second plurality of instructions.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00001\" num=\"1\"><claim-text>1. A system for fetching noncontiguous blocks of instructions in a data processing system; the system comprising:</claim-text><claim-text>an instruction cache means for providing a first plurality of instructions; </claim-text><claim-text>a branch logic means for receiving the first plurality of instructions and for providing branch history information about the first plurality of instructions; </claim-text><claim-text>a branch target address cache coupled to the branch logic means; and </claim-text><claim-text>an auxiliary cache means comprising an auxiliary cache and an auxiliary directory, the auxiliary cache means having multiple entries including one of a plurality of instructions and an associated address; the auxiliary cache means for receiving a second plurality of instructions based upon the branch history information; the auxiliary cache means for fetching noncontiguous instructions in a single cycle, and overlaying at least one of the second plurality of instructions if there is a branch in the first plurality of instructions and the branch is to the second plurality of instructions. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00002\" num=\"2\"><claim-text>2. The system of claim <b>1</b> in which the auxiliary cache means comprises an auxiliary cache and an auxiliary directory.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00003\" num=\"3\"><claim-text>3. The system of claim <b>1</b> in which the first plurality of instructions comprises two blocks of instructions.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00004\" num=\"4\"><claim-text>4. The system of claim <b>1</b> in which the second plurality of instructions comprises one block of instructions.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00005\" num=\"5\"><claim-text>5. The system of claim <b>1</b> which further comprises a branch address target cache coupled to the branch logic.</claim-text></claim>"}, {"num": 6, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00006\" num=\"6\"><claim-text>6. A method for obtaining non-contiguous blocks of instruction in a data processing system; the method comprising the steps of:</claim-text><claim-text>(a) storing a first plurality of instructions in a first cache; </claim-text><claim-text>(b) utilizing an auxiliary cache means for fetching noncontiguous instructions in a single cycle, the auxiliary cache means comprising an auxiliary cache and an auxiliary directory, the auxiliary cache means having multiple entries including one of a plurality of instructions and an associated address; </claim-text><claim-text>(c) fetching the first plurality of instructions in parallel with a fetch of a second plurality of instructions within a second cache, the number of the second plurality of instructions being greater than the number of the first plurality of instructions; and </claim-text><claim-text>(d) replacing a portion of the second plurality of instructions with at least one of the first plurality of instructions based upon a branch history information of the data processing system. </claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00007\" num=\"7\"><claim-text>7. The method of claim <b>6</b> wherein the first cache comprises an auxiliary cache a and the second cache comprises an instruction cache.</claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00008\" num=\"8\"><claim-text>8. The method of claim <b>7</b> in which the auxiliary cache includes an auxiliary directory.</claim-text></claim>"}, {"num": 9, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00009\" num=\"9\"><claim-text>9. The method of claim <b>6</b> in which the second plurality of instructions comprises two blocks of instructions.</claim-text></claim>"}, {"num": 10, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00010\" num=\"10\"><claim-text>10. The method of claim <b>6</b> in which the first plurality of instructions comprises one block of instructions.</claim-text></claim>"}, {"num": 11, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00011\" num=\"11\"><claim-text>11. A system for obtaining non-contiguous blocks of instructions in a data processing system; the system comprising:</claim-text><claim-text>means for storing a first plurality of instructions in a first cache; </claim-text><claim-text>means for utilizing an auxiliary cache means, the auxiliary cache means for fetching noncontiguous instructions in a single cycle, the auxiliary cache means comprising an auxiliary cache and an auxiliary directory, the auxiliary cache means having multiple entries including one of a plurality of instructions and an associated address; </claim-text><claim-text>means for fetching the first plurality of instructions in parallel with a fetch of a second plurality of instructions within a second cache, the number of the second plurality of instructions being greater than the number of the first plurality of instructions; and </claim-text><claim-text>means for replacing a portion of the second plurality of instructions with at least one of the first plurality of instructions based upon a branch history information of the data processing system. </claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00012\" num=\"12\"><claim-text>12. The system of claim <b>11</b> wherein the first cache comprises an auxiliary cache and the second cache comprises an instruction cache.</claim-text></claim>"}, {"num": 13, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00013\" num=\"13\"><claim-text>13. The system of claim <b>12</b> in which the auxiliary cache includes an auxiliary directory.</claim-text></claim>"}, {"num": 14, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00014\" num=\"14\"><claim-text>14. The system of claim <b>11</b> in which the second plurality of instructions comprises two blocks of instructions.</claim-text></claim>"}, {"num": 15, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6256727-B1-CLM-00015\" num=\"15\"><claim-text>15. The system of claim <b>11</b> in which the first plurality of instructions comprises one block of instructions.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54596669\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>FIELD OF THE INVENTION</h4><p>The present invention relates generally to a superscalar processor and more particularly to a system and method for fetching noncontiguous instructions in such a processor.</p><h4>BACKGROUND OF THE INVENTION</h4><p>Processors having this organization employ aggressive techniques to exploit instruction-level parallelism. Wide dispatch and issue paths place an upper bound on peak instruction throughput. Large issue buffers are used to maintain a window of instructions necessary for detecting parallelism, and a large pool of physical registers provides destinations for all of the in-flight instructions issued from the window. To enable concurrent execution of instructions, the execution engine is composed of many parallel functional units. The fetch engine speculates past multiple branches in order to supply a continuous instruction stream to the window.</p><p>The trend in superscalar design is to scale these techniques: wider dispatch/issue, larger windows, more physical registers, more functional units, and deeper speculation. To maintain this trend, it is important to balance all parts of the processor-any bottlenecks diminish the benefit of aggressive techniques.</p><p>Instruction fetch performance depends on a number of factors. Instruction cache hit rate and branch prediction accuracy have been long recognized as important problems in fetch performance and are well-researched areas.</p><p>Because of branches and jumps, instructions to be fetched during any given cycle may not be in contiguous cache locations. Hence, there must be adequate paths and logic available to fetch and align noncontiguous basic blocks and pass them down the pipelines. That is, it is not enough for the instructions to be present in the cache, it must also be possible to access them in parallel.</p><p>Modem microprocessors routinely use Branch History Tables and Branch Target Address Caches to improve their ability to efficiently fetch past branch instructions. Branch History Tables and other prediction mechanisms allow a processor to fetch beyond a branch instruction before the outcome of the branch is known. Branch Target Address Caches allow a processor to speculatively fetch beyond a branch before the branch's target address has been computed. Both of these techniques use run-time history to speculatively predict which instructions should be fetched and eliminate \u201cdead\u201d cycles that might normally be wasted. Even with these techniques, current microprocessors are limited to fetching only contiguous instructions during a single clock cycle.</p><p>As superscalar processors become more aggressive and attempt to execute many more instructions per cycle, they must also be able to fetch many more instructions per cycle. Frequent branch instructions can severely limit a processor's effective fetch bandwidth. Statistically, one of every four instructions is a branch instruction and over half of these branches are taken. A processor with a wide fetch bandwidth, say 8 contiguous instructions per cycle, could end up throwing away half of the instructions that it fetches as much as half of the time.</p><p>High performance superscalar processor organizations divide naturally into an instruction fetch mechanism and an instruction execution mechanism. The fetch and execution mechanisms are separated by instruction issue buffer(s), for example, queues, reservation stations, etc. Conceptually, the instruction fetch mechanism acts as a \u201cproducer\u201d which fetches, decodes, and places instructions into the buffer. The instruction execution engine is the \u201cconsumer\u201d which removes instructions from the buffer and executes them, subject to data dependence and resource constraints. Control dependences (branches and jumps) provide a feedback mechanism between the producer and consumer.</p><p>Previous designs use a conventional instruction cache, containing a static form of the program, to work with. Every cycle, instructions from noncontiguous locations must be fetched from the instruction cache and assembled into the predicted dynamic sequence. There are problems with this approach:</p><p>Pointers to all of the noncontiguous instruction blocks must be generated before fetching can begin. This implies a level of indirection, through some form of branch target table (branch target buffer, branch address cache, etc.), which translates into an additional pipeline stage before the instruction cache.</p><p>The instruction cache must support simultaneous access to multiple, noncontiguous cache lines. This forces the cache to be multiported: if multiporting is done through interleaving, bank conflicts are suffered.</p><p>After fetching the noncontiguous instructions from the cache, they must be assembled into the dynamic sequence. Instructions must be shifted and aligned to make them appear contiguous to the decoder. This most likely translates into an additional pipeline stage after the instruction cache.</p><p>A trace cache approach avoids these problems by caching dynamic sequences themselves, ready for the decoder. If the predicted dynamic sequence exists in the trace cache, it does not have to be recreated on the fly from the instruction cache's static representation. In particular, no additional stages before or after the instruction cache are needed for fetching noncontiguous instructions. The stages do exist, but not on the critical path of the fetch unit-rather, on the fill side of the trace cache. The cost of this approach is redundant instruction storage: the same instructions must reside in both the primary cache and the trace cache, and there even might be redundancy among lines in the trace cache. Accordingly, utilizing a trace cache approach several instructions are grouped together based upon a most likely path. They are then stored together in the trace cache. This system requires a complex mechanism to pack and cache instruction segments.</p><p>Accordingly, what is needed is a method and system for improving the overall throughput of a superscalar processor. More particularly, what is needed is a system and method for efficiently fetching noncontiguous instructions in such a processor. The present invention addresses such a need.</p><h4>SUMMARY OF THE INVENTION</h4><p>A method and system for obtaining non-contiguous blocks of instruction in a data processing system is disclosed. In a first aspect, a system for fetching noncontiguous blocks of instructions in a data processing system is disclosed. The system comprises an instruction cache means for providing a first plurality of instructions and branch logic means for receiving the first plurality of instructions and for providing branch history information about the first plurality of instructions. The system further includes an auxiliary cache means for receiving a second plurality of instructions based upon the branch history information. The auxiliary cache means overlays at least a one of the second plurality of instructions if there is a branch in the first plurality of instructions and the branch is to the second plurality of instructions.</p><p>In a second aspect, a method for obtaining noncontiguous blocks of instruction comprises storing a first plurality of instructions in a first cache and fetching the first plurality of instructions in parallel with a fetch of a second plurality of instructions within a second cache. In the present invention, the number of the second plurality of instructions being greater than the number of first plurality of instructions. This second aspect includes replacing a portion of the second plurality of instructions with at least one of the first plurality of instructions based upon a branch history information of the data processing system.</p><p>The above-described present invention allows a processor to use branch history information and an auxiliary cache to fetch multiple noncontiguous groups of instructions in a single cycle. Furthermore, the technique allows noncontiguous fetching to be performed without requiring multiple levels of nested branch prediction logic to be evaluated in a single cycle.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1 is a block diagram of a superscalar processor.</p><p>FIG. 2A is a block diagram of a conventional mechanism within a processor for fetching noncontiguous instructions.</p><p>FIG. 2B is a block diagram of an instruction cache and BTAC entry.</p><p>FIG. 3 is a flow chart of a branch prediction algorithm for the conventional mechanism of FIG. <b>2</b>A.</p><p>FIG. 4 is a block diagram of a mechanism within a processor for fetching noncontiguous instructions in a single cycle in accordance with the present invention.</p><p>FIG. 5 is a flow chart of the branch prediction algorithm for the noncontiguous instruction fetch mechanism of FIG. <b>4</b>.</p><p>FIG. 6 is a table that illustrates the flow of instructions when utilizing the branch prediction algorithm of FIG. <b>5</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DESCRIPTION OF THE INVENTION</h4><p>The present invention relates generally to a superscalar processor and more particularly to a system and method for fetching noncontiguous instructions in such a processor. The following description is presented to enable one of ordinary skill in the art to make and use the invention and is provided in the context of a patent application and its requirements. Various modifications to the preferred embodiment will be readily apparent to those skilled in the art and the generic principles herein may be applied to other embodiments. Thus, the present invention is not intended to be limited to the embodiment shown but is to be accorded the widest scope consistent with the principles and features described herein.</p><p>FIG. 1 is a block diagram of a superscalar processor <b>10</b>. As shown, the superscalar processor <b>10</b> typically include a system bus <b>11</b> connected to a bus interface unit (\u201cBIU\u201d) <b>12</b>.</p><p>BIU <b>12</b> controls the transfer of information between processor <b>10</b> and system bus <b>11</b>. BIU <b>12</b> is connected to an instruction cache <b>14</b> and to a data cache <b>16</b> of processor <b>10</b>. Instruction cache <b>14</b> outputs instructions to a sequencer unit <b>18</b>. In response to such instructions from instruction cache <b>14</b>, sequencer unit <b>18</b> selectively outputs instructions to other execution circuitry of processor <b>10</b>.</p><p>In addition to sequencer unit <b>18</b> which includes execution units of a dispatch unit <b>46</b> and a completion unit <b>48</b>, in the preferred embodiment the execution circuitry of processor <b>10</b> includes multiple execution units, namely a branch unit <b>20</b>, a fixed point unit A (\u201cFXUA\u201d) <b>22</b>, a fixed point unit B (\u201cFXUB\u201d) <b>24</b>, a complex fixed point unit (\u201cCFXU\u201d) <b>26</b>, a load/store unit (\u201cLSU\u201d) <b>28</b> and a floating point unit (\u201cFPU\u201d) <b>30</b>. FXUA <b>22</b>, FXUB <b>24</b>, CFXU <b>26</b> and LSU <b>28</b> input their source operand information from general purpose architectural registers (\u201cGPRs\u201d) <b>32</b> and fixed point rename buffers <b>34</b>. Moreover, FXUA <b>22</b> and FXUB <b>24</b> input a \u201ccarry bit\u201d from a carry bit (\u201cCA\u201d) register <b>42</b>. FXUA <b>22</b>, FXUB <b>24</b>, CFXU <b>26</b> and LSU <b>28</b> output results (destination operand information) of their operations for storage at selected entries in fixed point rename buffers <b>34</b>. Also, CFXU <b>26</b> inputs and outputs source operand information and destination operand information to and from special purpose registers (\u201cSPRs\u201d) <b>40</b>.</p><p>FPU <b>30</b> inputs its source operand information from floating point architectural registers (\u201cFPRs\u201d) <b>36</b> and floating point rename buffers <b>38</b>. FPU <b>30</b> outputs results (destination operand information) of its operation for storage at selected entries in floating point rename buffers <b>38</b>.</p><p>Processes</p><p>The processor <b>10</b> is usually implemented with a large number of state machines that control relatively independent processes. It may be thought of as a complex parallel algorithm involving multiple concurrent processes.</p><p>Instruction Fetch</p><p>This process provides a continuous stream of instructions from the instruction cache and utilizes the branch target address cache (BTAC) as a fetch prediction mechanism.</p><p>Branch Prediction</p><p>This process identifies and predicts branches, verifies that the appropriate instructions were fetched, updates information, and places information about speculative branches into a Branch Queue.</p><p>Branch Resolution</p><p>This process checks that the prediction matched the actual branch result and makes corrections if a misprediction occurred.</p><p>Branch Completion</p><p>This process writes information for completed branches into the BHT and removes entries from the Branch Queue.</p><p>The present invention relates generally to the fetch cycle and the ability to fetch noncontiguous instructions. FIG. 2A shows in system <b>100</b> the hardware mechanisms for the conventional technique for fetching groups of instructions. In this embodiment, eight instructions are shown being fetched at a time. In addition, the present invention is discussed with reference to instruction being four bytes length. However, one of ordinary skill in the art, readily recognizes that any number of instructions can be fetched at a time and can be of any length and that number and length would be within the spirit and scope of the present invention.</p><p>Referring back to FIG. 2A, as is seen there is a fetch address signal <b>102</b> which is provided to a branch history table (BHT) <b>104</b>, an instruction cache <b>106</b>, a branch target address cache (BTAC) <b>108</b>, a directory for the instruction cache (INST Dir) <b>110</b>, +32 counter <b>111</b>. To provide a fuller understanding of the operation of the above-identified mechanism, particularly as it relates to the instruction cache <b>106</b>, a conventional instruction cache entry is described below.</p><p>FIG. 2B shows a simple organization for the instruction cache and BTAC entry <b>200</b> of the instruction required by an instruction fetcher (this entry may include other information that is not important for this discussion). FIG. 2B shows a fetch information <b>201</b> which includes a sample address tag <b>202</b>, successor index <b>204</b>, and branch block index entries <b>206</b> for a code sequence, assuming a 64-Kbyte, direct-mapped cache and the indicated instruction addresses. For this example, the cache entry holds four instructions <b>208</b>, <b>210</b>, <b>212</b> and <b>214</b>. The entry also contains instruction-fetch information. The fetch information also includes two additional fields (not shown) used by the instruction fetcher.</p><p>The successor index field <b>204</b> indicates both the next cache block predicted to be fetched and the first instruction within this next block predicted to be executed. The successor index field <b>204</b> does not specify a full instruction address, but is of sufficient size to select any instruction within the cache. For example, a 64-Kbyte, direct-mapped cache requires a 14-bit successor index if all instructions are 32 bits in length (12 bits to address the cache block and 2 bits to address the instruction in the block if the block size is four words).</p><p>In a preferred embodiment, the branch block index field <b>206</b> indicates the location of a branch point within the corresponding instruction block. Instructions beyond the branch point are predicted not to be executed.</p><p>Referring back to FIG. 2A, the BHT <b>104</b> also receives a BHT update signal and outputs a read signal. The read signal from the BHT <b>104</b> is provided to branch logic <b>116</b>. The instruction cache <b>106</b> receives write signal from an outside source, such as an L2 cache. The instruction cache <b>106</b> outputs eight instructions (instruction group 0) to the branch logic <b>116</b>. An address 0 signal is provided directly to the branch logic <b>116</b>. The branch logic <b>116</b> provides an override address signal to multiplexer <b>120</b>. Multiplexer <b>120</b> also receives signals <b>32</b>, counter <b>111</b> and the output of BTAC <b>108</b>. An address 1 signal is provided from BTAC <b>108</b> to branch logic <b>116</b>. The instruction directory <b>110</b> provides a hit signal to the branch logic <b>116</b>. The branch logic <b>116</b> also receives the branch outcome signal, provides branch information to a branch queue <b>126</b>, and outputs a BTAC address <b>128</b> and provides valid instructions <b>124</b>. This type of mechanism is capable of fetching eight contiguous instructions per cycle, but would only use instructions up to the first predicted taken branch in the group. To explain this in more detail refer to the following discussion in combination with the accompanying figures.</p><p>As before described, there are several processes associated with the fetching of groups of instructions. The present invention is related to an improvement in the branch prediction algorithm and an associated modification to the conventional fetch mechanism of FIG. <b>2</b>A.</p><p>To further illustrate the problems associated with the fetching of non-contiguous instructions with regard to the conventional mechanisms of FIG. 2A, refer now to FIG. <b>3</b>.</p><p>FIG. 3 is a flow chart of a branch prediction algorithm for the conventional mechanism of FIG. <b>2</b>A. Referring to FIGS. 2A and 3 together, first it is determined whether valid instructions are found in the instruction cache, via step <b>302</b>. If there are no valid instructions found in the instruction cache, then all fetched instructions are invalidated and the miss handler is initiated, via step <b>304</b>. However, if there are valid instructions found in the instruction cache, then branches are identified, target addresses are computed, and predicted taken or not taken based on the branch logic <b>116</b> and the branch history tables <b>104</b>, via step <b>306</b>. Thereafter it is determined whether there is a predicted taken branch in instruction group 0 (the first group of instructions), via step <b>308</b>. If there is a predicted branch taken, then all subsequent instructions are invalidated, via step <b>310</b>. Then it is determined if the address 1 (address of the second group of instructions) from BTAC <b>108</b> is equal to target 0 of the instruction directory, via step <b>312</b>. If the answer is yes, then the branch addresses are stored and prediction information for all branches are provided into the branch queue <b>126</b>, via step <b>314</b>. If, on the other hand, address 1 is not equal to target 0, then the instructions that have been fetched in the next cycle are invalidated and the override address is equal to target 0, via step <b>316</b>. Thereafter, the BTAC address is updated to equal target 0, via step <b>318</b>, and then the branch addresses and predicted information is stored into the branch queue via step <b>314</b>. If, on the other hand, at step <b>308</b> there are no predicted branches taken in group 0, then it is determined if address 1 is equal to address 0 plus <b>32</b>. If the answer is yes, then return to step <b>314</b>. If, on the other hand, the answer is no, then all instruction groups fetched for the next cycle are invalidated and the override address equals address 0+32, via step <b>322</b>. Thereafter, the BTAC address is updated to equal invalid, via step <b>324</b> and then return to step <b>314</b>.</p><p>This algorithm of FIG. 3 does not allow for fetching non-contiguous instructions in a single cycle. This prediction algorithm always requires that when a branch instruction is encountered only the instructions up to the branch can be utilized. As has been before-mentioned, there are mechanisms, i.e., trace cache, etc., to retrieve noncontiguous instructions in a single cycle but they add complexity and cost to the system.</p><p>The present invention overcomes this problem by providing an auxiliary cache and an overlaying technique that utilizes the auxiliary cache to fetch noncontiguous instructions in a single cycle.</p><p>Three major hardware mechanisms are required for this technique:</p><p>(1) a Standard Instruction Cache (or other memory source),</p><p>(2) a Branch Target Address Cache, and</p><p>(3) an auxiliary cache.</p><p>A Standard Instruction Cache and a Branch Target Address Cache are commonly used in most microprocessors and may be used without modification for this technique. The auxiliary cache is a new hardware mechanism that contains multiple entries with one or more instructions and an associated address. The auxiliary cache may be highly associative and relatively small compared to the main instruction cache.</p><p>The present invention operates generally in the following manner:</p><p>1. If a branch instruction in the first instruction group is considered strongly taken (based on branch history or other information) and no instructions were provided from the auxiliary cache, use the fetch index to add the branch's target address and one or more instructions at that address to the auxiliary cache. Also, an appropriate sequential address is provided as needed (e.g., branch target plus 16 bytes) to the BTAC.</p><p>2. Else, if a branch instruction in the second instruction group is considered strongly taken, use the fetch index to add the branch's target address to the BTAC.</p><p>3. Else, if no branch instructions in either instruction group is considered strongly taken, use the fetch index to clear the BTAC and default to an appropriate sequential address.</p><p>To more particularly describe the features and operation of the present invention, refer now to the following discussion in conjunction with the accompanying figures.</p><p>FIG. 4 is a block diagram of a mechanism <b>400</b> within a processor for fetching noncontiguous instructions in a single cycle in accordance with the present invention. The elements of the mechanism <b>400</b> are similar to many of the elements presently in mechanism <b>100</b>. Those elements that are similar have been given similar reference numerals. As has been before mentioned, the key element that is different is the addition of the auxiliary cache <b>415</b> and its directory <b>417</b>.</p><p>In addition, as is seen, there are instruction groups 0 and 1 and as is seen, there are four multiplexers <b>425</b> which allow for the overlaying of the instructions from the auxiliary cache <b>415</b> in the instruction group 1 from the instruction cache <b>106</b>\u2032 based on branch history information derived from BHT <b>104</b>\u2032 and branch logic <b>116</b>\u2032. Similarly, the auxiliary directory also overlays its address over the address 1 signal of the +16 counter <b>421</b> based upon the branch history information. In addition, BTAC <b>414</b> also provides an address 2 signal rather than the address 1 signal provided by the BTAC <b>108</b>\u2032 of FIG. <b>2</b>A. Accordingly, as has been before mentioned, through the addition of the auxiliary cache <b>415</b> and the use of it and the auxiliary directory <b>417</b>, it is possible now to accumulate information to allow for fetching of noncontiguous instructions. To further describe this feature in a more detailed manner, refer now to FIG. <b>5</b>.</p><p>FIG. 5 is a flow chart of the branch prediction algorithm for the noncontiguous instruction fetch mechanism of FIG. <b>4</b>. Referring now to FIGS. 4 and 5 together, first it is determined whether there are valid instructions stored in the instruction cache <b>106</b>\u2032, via step <b>502</b>. If there were no valid instructions found in the instruction cache <b>106</b>\u2032, then all instructions are invalidated and a miss handler is initiated, via step <b>504</b>. If, on the other hand, there are valid instructions in the instruction cache <b>106</b>\u2032, it is next determined whether there were valid instructions found in the auxiliary cache <b>415</b>, via step <b>506</b>. If there were valid instructions found in the auxiliary cache <b>415</b>, then the instructions from the auxiliary cache <b>415</b> are overlaid on the instruction group from the instruction cache <b>106</b>\u2032, via step <b>508</b>. If, on the other hand, there were no valid instructions found in the auxiliary cache, then all the instructions from the instruction cache are retained, via step <b>510</b>.</p><p>From either of the steps <b>508</b> and <b>510</b>, next branches are identified, target addresses are computed, and they are predicted taken or not taken, via step <b>512</b> based upon the branch logic <b>106</b>\u2032 and the BHT <b>104</b>\u2032 operating in a conventional manner. Thereafter, it is then determined if there is a predicted branch taken in the instruction group 0, via step <b>514</b>. If there is a predicted taken branch in instruction group 0, then the subsequent instructions are invalidated, via step <b>516</b>.</p><p>Next, it is determined whether address 1 is equal to the target address 0 of the branch, via step <b>518</b>. If the answer is yes, then it is determined whether there is a predicted taken branch in group 1 or in the next group of instructions, via step <b>520</b>. If the answer to that question is yes, then the subsequent instructions in instruction group 1 are invalidated, via step <b>522</b>. Then it is determined whether address 2 is equal to target 1 of the branch, via step <b>524</b>. If the answer to that is yes, then the branch queue stores the branch addresses and prediction information for all the branches, via step <b>526</b>. If the answer is no, then the next cycle group is invalidated and the override address equals target 1, via step <b>528</b>. Thereafter, the BTAC address is updated to equal target 1, via <b>530</b>, and return to step <b>526</b>.</p><p>If address 1 is not equal to target 0 via step <b>518</b>, then all the instructions in group 1 and the next cycle groups are invalidated and the override address equals target 0 and prepare to save next group in auxiliary cache, via step <b>521</b>. Thereafter, the auxiliary address is updated to equal target 0 and the BTAC address equals target 0+16, via step <b>523</b>.</p><p>If, on the other hand, there is no predicted branch taken in group 1, via step <b>520</b>, then it is then determined if address 2 is equal to address 1 plus 16, via step <b>532</b>. If the answer is yes, then return to step <b>526</b>. If the answer is no, then all the next cycle groups are invalidated and the override address set to equal address 1+16, via step <b>534</b>. Thereafter the FTAC address is updated to equal address 1+16, via step <b>536</b>, and then return to step <b>526</b>.</p><p>Returning now to step <b>514</b>, if there is no predicted branches taken in group 0, then it is determined if address 1 equals address 0+16. If address 1 is equal to address 0+16, then return to step <b>520</b> and proceed through the steps based on that decision chain. If, on the other hand, the answer is no, that address 1 does not equal address 0+16, then all instructions in group 1 and the next cycle groups are invalidated and the override address equals address 0+16, via step <b>540</b>. Thereafter, the auxiliary address is updated to equal invalid and the BTAC address is updated to equal invalid, via step <b>542</b>. Then return to step <b>526</b>. Accordingly, through this branch prediction process, the system can accumulate branch history information in a manner to allow for the overlay instruction of auxiliary cache to efficiently fetch a noncontiguous instructions. To more clearly describe the operation in the context of a particular example, refer now to FIG. <b>6</b>.</p><p>FIG. 6 is an example <b>600</b> that illustrates the flow of instructions when utilizing the branch prediction algorithm of FIG. <b>5</b>. The example <b>600</b> shown in FIG. 6 illustrates a sequence of fetches <b>602</b> performed on consecutive cycles in accordance with the present invention for a program segment <b>604</b>. Note that all the addresses are described using a hexadecimal format (base <b>16</b>). Asterisks in the example <b>600</b> indicate fetched instructions that were invalidated from the instruction stream.</p><p>As is seen, the program segment comprises a plurality of basic blocks <b>606</b>, <b>608</b>, <b>610</b> and <b>612</b>. Each of the basic blocks <b>606</b>-<b>612</b> begin with a load instruction and end with a branch instruction. The basic blocks are used in conjunction with the present invention to allow for non-contiguous instructions to be obtained in a single cycle.</p><p>Through the use of the branch prediction algorithm of FIG. 5 in conjunction with the hardware mechanisms of FIG. 4, to accumulation branch history information, noncontiguous instructions of FIG. 6 can be obtained in a single cycle.</p><p>To illustrate the method for obtaining instructions in the single cycle, refer to FIGS. 4, <b>5</b> and <b>6</b>. As has been indicated, at cycle 000 there are eight instructions being provided. It is assumed that the auxiliary cache <b>415</b> initially contains no instructions, and so at this time there are invalid instructions found in the information cache <b>502</b>, then it is determined whether valid instructions are found in the auxiliary cache <b>506</b>, and the answer would be no. In that event, then all the instructions from the instruction cache would be retained. At that point, branches are identified, target addresses are computed, and predicted taken or not taken, via step <b>512</b>. It is known that the target for the branch in the first set of instructions is at 0x100. It is now determined whether there is a predicted branch taken in group 0, and the answer to that is yes. That is the third instruction in address 000. Through the branch prediction process the instruction at address 100 is provided to the auxiliary and the address is stored in the auxiliary directory. Also, through the branch prediction process address 110 would be stored in the BTAC <b>108</b> (step <b>530</b>).</p><p>Then the next basic block <b>608</b> is used at cycle 003 to load the instructions at the target address 0x100. The last instructions at basic block <b>608</b> is a branch to address 200. Then address 100, as before mentioned, is then fetched and similar information is accumulated for it in the auxiliary cache, auxiliary directory and BTAC. Accordingly, information is accumulated in cycles 003-007 until, as is seen in cycle 008, two non-contiguous instructions (0X000 and 0X100) are retrieved in a single cycle.</p><p>This branch prediction process is repeated again, via basic blocks <b>610</b> and <b>612</b>, wherein non-contiguous instructions are fetched in cycles 020 through 024.</p><p>Accordingly, as is seen in this example, after branch history information is accumulated in a sufficient manner, then noncontiguous instructions can be obtained in a single cycle. This process can be repeated, particularly in those instances where instructions recur, such that a majority of noncontiguous instructions can be retrieved in a single cycle. This is accomplished through the use of the auxiliary cache and the miscellaneous branch logic cooperating with the branch history tables while utilizing the branch prediction process in accordance with the present invention.</p><p>Several other techniques, such as trace caching and multi-level branch predictors; have been proposed for allowing a processor to fetch noncontiguous instructions in a single cycle. The auxiliary cache and instruction overlay technique described in accordance with the present invention is simpler than other techniques, but as effective.</p><p>Although the present invention has been described in accordance with the embodiments shown, one of ordinary skill in the art will readily recognize that there could be variations to the embodiments and those variations would be within the spirit and scope of the present invention. Accordingly, many modifications may be made by one of ordinary skill in the art without departing from the spirit and scope of the appended claims.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Robert Greg", "last_name": "McDonald", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTERNATIONAL BUSINESS MACHINES CORPORATION"}, {"first_name": "", "last_name": "INTERNATIONAL BUSINESS MACHINES CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F   9/38"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101ALI20051220RMJP"}, {"label": "G06F   9/38        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "712235"}, {"primary": false, "label": "712E09057"}, {"primary": false, "label": "712E09056"}, {"primary": false, "label": "712237"}, {"primary": false, "label": "712205"}], "ecla_classes": [{"label": "G06F   9/38B2B"}, {"label": "G06F   9/38B2"}], "cpc_classes": [{"label": "G06F   9/3857"}, {"label": "G06F   9/34"}, {"label": "G06F   9/3804"}, {"label": "G06F   9/3806"}, {"label": "G06F   9/3836"}, {"label": "G06F   9/3806"}, {"label": "G06F   9/3836"}, {"label": "G06F   9/3804"}], "f_term_classes": [], "legal_status": "Expired - Fee Related", "priority_date": "1998-05-12", "application_date": "1998-05-12", "family_members": [{"ucid": "EP-0957428-A3", "titles": [{"lang": "FR", "text": "M\u00e9thode et dispositif d'extraction d'instructions non-contigues dans un syst\u00e8me de traitement de donn\u00e9es"}, {"lang": "EN", "text": "Method and apparatus for fetching noncontiguous instructions in a data processing system"}, {"lang": "DE", "text": "Verfahren und Vorrichtung zum Abrufen von nicht-angrenzenden Befehlen in einem Datenverarbeitungssystem"}]}, {"ucid": "DE-69929936-T2", "titles": [{"lang": "EN", "text": "Method and apparatus for retrieving non-contiguous instructions in a data processing system"}, {"lang": "DE", "text": "Verfahren und Vorrichtung zum Abrufen von nicht-angrenzenden Befehlen in einem Datenverarbeitungssystem"}]}, {"ucid": "JP-2000029701-A", "titles": [{"lang": "JA", "text": "\u5358\u4e00\u30af\u30ed\u30c3\u30af\u30fb\u30b5\u30a4\u30af\u30eb\u306b\u975e\u9023\u7d9a\u547d\u4ee4\u3092\u53d6\u308a\u51fa\u3059\u305f\u3081\u306e\u65b9\u6cd5\u304a\u3088\u3073\u30b7\u30b9\u30c6\u30e0\u3002"}, {"lang": "EN", "text": "METHOD AND SYSTEM FOR FETCHING DISCONTINUOUS INSTRUCTION IN SINGLE CLOCK CYCLE"}]}, {"ucid": "KR-100431168-B1", "titles": [{"lang": "EN", "text": "A METHOD AND SYSTEM FOR FETCHING NONCONTIGUOUS INSTRUCTIONS IN A SINGLE CLOCK CYCLE"}, {"lang": "KO", "text": "\ub2e8\uc77c \ud074\ub7ed \uc0ac\uc774\ud074 \ub0b4\uc5d0 \ubd88\uc5f0\uc18d \uba85\ub839\uc744 \ud398\uce58\ud558\uae30 \uc704\ud55c \ubc29\ubc95 \ubc0f \uc2dc\uc2a4\ud15c"}]}, {"ucid": "KR-19990087940-A", "titles": [{"lang": "EN", "text": "A METHOD AND SYSTEM FOR FETCHING NONCONTIGUOUS INSTRUCTIONS IN A SINGLE CLOCK CYCLE"}, {"lang": "KO", "text": "\ub2e8\uc77c\ud074\ub7ed\uc0ac\uc774\ud074\ub0b4\uc5d0\ubd88\uc5f0\uc18d\uba85\ub839\uc744\ud398\uce58\ud558\uae30\uc704\ud55c\ubc29\ubc95\ubc0f\uc2dc\uc2a4\ud15c"}]}, {"ucid": "EP-0957428-B1", "titles": [{"lang": "FR", "text": "M\u00e9thode et dispositif d'extraction d'instructions non-contigu\u00ebs dans un syst\u00e8me de traitement de donn\u00e9es"}, {"lang": "EN", "text": "Method and apparatus for fetching non-contiguous instructions in a data processing system"}, {"lang": "DE", "text": "Verfahren und Vorrichtung zum Abrufen von nicht-angrenzenden Befehlen in einem Datenverarbeitungssystem"}]}, {"ucid": "US-6256727-B1", "titles": [{"lang": "EN", "text": "Method and system for fetching noncontiguous instructions in a single clock cycle"}]}, {"ucid": "DE-69929936-D1", "titles": [{"lang": "EN", "text": "Method and apparatus for retrieving non-contiguous instructions in a data processing system"}, {"lang": "DE", "text": "Verfahren und Vorrichtung zum Abrufen von nicht-angrenzenden Befehlen in einem Datenverarbeitungssystem"}]}, {"ucid": "EP-0957428-A2", "titles": [{"lang": "FR", "text": "M\u00e9thode et dispositif d'extraction d'instructions non-contigues dans un syst\u00e8me de traitement de donn\u00e9es"}, {"lang": "EN", "text": "Method and apparatus for fetching noncontiguous instructions in a data processing system"}, {"lang": "DE", "text": "Verfahren und Vorrichtung zum Abrufen von nicht-angrenzenden Befehlen in einem Datenverarbeitungssystem"}]}, {"ucid": "JP-3182740-B2", "titles": [{"lang": "JA", "text": "\u5358\u4e00\u30af\u30ed\u30c3\u30af\u30fb\u30b5\u30a4\u30af\u30eb\u306b\u975e\u9023\u7d9a\u547d\u4ee4\u3092\u53d6\u308a\u51fa\u3059\u305f\u3081\u306e\u65b9\u6cd5\u304a\u3088\u3073\u30b7\u30b9\u30c6\u30e0\u3002"}, {"lang": "EN", "text": "A method and system for fetching non-consecutive instructions in a single clock cycle."}]}]}