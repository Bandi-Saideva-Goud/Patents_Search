{"patent_number": "US-6463522-B1", "publication_id": 73185729, "family_id": 25537506, "publication_date": "2002-10-08", "titles": [{"lang": "EN", "text": "Memory system for ordering load and store instructions in a processor that performs multithread execution"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50392064\"><p>In one embodiment of the invention, a processor includes a memory order buffer (MOB) including load buffers and store buffers, wherein the MOB orders load and store instructions so as to maintain data coherency between load and store instructions in different threads, wherein at least one of the threads is dependent on at least another one of the threads. In another embodiment of the invention, a processor includes an execution pipeline to concurrently execute at least portions of threads, wherein at least one of the threads is dependent on at least another one of the threads, the execution pipeline including a memory order buffer that orders load and store instructions. The processor also includes detection circuitry to detect speculation errors associated with load instructions in a load buffer.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00001\" num=\"1\"><claim-text>1. A processor comprising:</claim-text><claim-text>a memory order buffer (MOB) including a plurality of load buffers to each hold multiple load instructions of one of a group of threads and store buffers to each hold multiple store instructions of one of the threads wherein at times there are dependencies between at least some of the threads, wherein within each of the load buffers load instructions are held in program order and within each of the store buffers store instructions are held in program order, and wherein the MOB orders the load and store instructions so as to maintain data coherency between the load and store instructions in the threads, and wherein the MOB includes match determining logic and replay triggering logic; </claim-text><claim-text>wherein the match determining logic determines whether there are matches between addresses of certain of the load and store instructions; and </claim-text><claim-text>wherein under selected conditions when there are matches between the addresses of the load and store instructions, the replay determining logic controls re-execution of selected ones of the load and store instructions without there being a re-execution of entire threads containing the re-executed load and store instructions. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00002\" num=\"2\"><claim-text>2. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, further comprising thread management logic to control dynamic creation of the threads.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00003\" num=\"3\"><claim-text>3. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, further comprising thread management logic to provide an indication of program order and retirement order.</claim-text></claim>"}, {"num": 4, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00004\" num=\"4\"><claim-text>4. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00003\">claim 3</claim-ref>, wherein threads are retired from the MOB in retirement order in a final retirement.</claim-text></claim>"}, {"num": 5, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00005\" num=\"5\"><claim-text>5. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00003\">claim 3</claim-ref>, wherein threads are retired from the MOB in retirement order in a final retirement after it is assured that all instructions have been executed without speculation error or have been part of a reset thread.</claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00006\" num=\"6\"><claim-text>6. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein the store buffer includes a field to hold data to be stored to memory.</claim-text></claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00007\" num=\"7\"><claim-text>7. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein load buffers include status fields including indications as to whether a corresponding one of the load instructions had previously received data from memory or data in the store buffer.</claim-text></claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00008\" num=\"8\"><claim-text>8. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein load buffers include status fields including a store buffer identification number (SBID) of a store buffer entry from which a corresponding one of the load instructions previously received data.</claim-text></claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00009\" num=\"9\"><claim-text>9. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein load buffers include status fields including a thread identification number of a store instruction from which the load instruction previously received data.</claim-text></claim>"}, {"num": 10, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00010\" num=\"10\"><claim-text>10. A processor, comprising:</claim-text><claim-text>an execution pipeline to concurrently execute at least portions of threads, the execution pipeline including a memory order buffer that orders load and store instructions, wherein the memory order buffer includes load buffers and store buffers with different ones of the load buffers holding load instructions from different ones of the threads and different ones of the store buffers holding store instructions from different ones of the threads wherein at times there are dependencies between at least some of the threads, and wherein within the load buffers load instructions are held in program order and within the store buffers store instructions are held in program order; </claim-text><claim-text>detection circuitry to detect speculation errors associated with at least some of the thread dependencies and load instructions in a load buffer; and </claim-text><claim-text>triggering logic to identify at least some of the load instructions as being dependent on at least one of the speculation errors and to trigger re-execution of at least some of the identified load instructions. </claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00011\" num=\"11\"><claim-text>11. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00010\">claim 10</claim-ref>, wherein the triggering logic includes replay triggering circuitry to trigger replay of at least some of the load instructions.</claim-text></claim>"}, {"num": 12, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00012\" num=\"12\"><claim-text>12. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00010\">claim 10</claim-ref>, further including trace buffers outside the execution pipeline to hold the load and store instructions following execution until a final retirement.</claim-text></claim>"}, {"num": 13, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00013\" num=\"13\"><claim-text>13. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00010\">claim 10</claim-ref>, wherein at least part of the detection circuitry is included in the execution pipeline.</claim-text></claim>"}, {"num": 14, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00014\" num=\"14\"><claim-text>14. A processor comprising:</claim-text><claim-text>a memory order buffer including: </claim-text><claim-text>load buffers to each hold load instructions of one of a group of threads, wherein within the load buffers the load instructions are held in program order; </claim-text><claim-text>store buffers to each hold store instructions of one of the threads, wherein within the store buffers the store instructions are held in program order, wherein at times there are dependencies between at least some of the threads; </claim-text><claim-text>comparison circuitry to compare an address of one of the load instructions to be executed with addresses of at least one of the store instructions in the store buffers; and </claim-text><claim-text>data path control logic to determine whether the load instruction reads data from memory or from one of the store buffers. </claim-text></claim>"}, {"num": 15, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00015\" num=\"15\"><claim-text>15. A processor comprising:</claim-text><claim-text>a memory order buffer including: </claim-text><claim-text>load buffers to each hold load instructions of one of a group of threads, wherein within the load buffers the load instructions are held in program order; </claim-text><claim-text>store buffers to each hold store instructions of one of the threads, wherein within the store buffers the store instructions are held in program order, wherein at times there are dependencies between at least some of the threads; </claim-text><claim-text>comparison circuitry to compare an address and at least one status bit of one of the store instructions to be executed with an address and at least one status bit of at least one of the load instructions; and </claim-text><claim-text>detection logic to determine whether to re-execute one or more of the load instructions based on the comparison. </claim-text></claim>"}, {"num": 16, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00016\" num=\"16\"><claim-text>16. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein the match determining logic includes matching circuitry to perform address matching of a load instruction with older store instructions.</claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00017\" num=\"17\"><claim-text>17. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00016\">claim 16</claim-ref>, wherein the address matching is made to identify a closest earlier matching store instruction.</claim-text></claim>"}, {"num": 18, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00018\" num=\"18\"><claim-text>18. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein the match determining logic includes matching circuitry to perform address matching of a store instruction with younger load instructions.</claim-text></claim>"}, {"num": 19, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00019\" num=\"19\"><claim-text>19. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00018\">claim 18</claim-ref>, wherein the address matching is made to identify a closest later load instruction.</claim-text></claim>"}, {"num": 20, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00020\" num=\"20\"><claim-text>20. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00010\">claim 10</claim-ref>, wherein at least part of the detection circuitry is included in the memory order buffer.</claim-text></claim>"}, {"num": 21, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00021\" num=\"21\"><claim-text>21. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00011\">claim 11</claim-ref>, wherein the replay triggering circuitry triggers replay of all instructions following a load.</claim-text></claim>"}, {"num": 22, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00022\" num=\"22\"><claim-text>22. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein the processor is in a computer system.</claim-text></claim>"}, {"num": 23, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00023\" num=\"23\"><claim-text>23. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00001\">claim 1</claim-ref>, wherein each load buffer holds load instructions for only one of the threads at a time and each store buffer holds store instructions for only one of the threads at a time.</claim-text></claim>"}, {"num": 24, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00024\" num=\"24\"><claim-text>24. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00011\">claim 11</claim-ref>, wherein each load buffer holds load instructions for only one of the threads at a time and each store buffer holds store instructions for only one of the threads at a time.</claim-text></claim>"}, {"num": 25, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00025\" num=\"25\"><claim-text>25. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00014\">claim 14</claim-ref>, wherein each load buffer holds load instructions for only one of the threads at a time and each store buffer holds store instructions for only one of the threads at a time.</claim-text></claim>"}, {"num": 26, "parent": 15, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00026\" num=\"26\"><claim-text>26. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00015\">claim 15</claim-ref>, wherein each load buffer holds load instructions for only one of the threads at a time and each store buffer holds store instructions for only one of the threads at a time.</claim-text></claim>"}, {"num": 27, "parent": 15, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00027\" num=\"27\"><claim-text>27. The processor of <claim-ref idref=\"US-6463522-B1-CLM-00015\">claim 15</claim-ref>, wherein the detection logic determines whether to replay one or more of the load instructions based on the comparison.</claim-text></claim>"}, {"num": 28, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00028\" num=\"28\"><claim-text>28. A chip comprising:</claim-text><claim-text>a memory order buffer (MOB) including load buffers and store buffers to each hold store instructions of one of a group of threads wherein at times there are dependencies between at least some of the threads, wherein within the load buffers load instructions are held in program order and within the store buffers store instructions are held in program order, and wherein the MOB orders the load and store instructions so as to maintain data coherency between the threads, and wherein the MOB includes match determining logic to compare addresses of at least some of the load instructions to be executed with addresses of at least some of the store instructions to determine which, if any, of the store instructions are closest earlier matching store instructions. </claim-text></claim>"}, {"num": 29, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00029\" num=\"29\"><claim-text>29. A chip comprising:</claim-text><claim-text>a memory order buffer (MOB) including load buffers to each hold load instructions of one of a group of threads and store buffers to each hold store instructions of one of the threads wherein at times there are dependencies between at least some of the threads, wherein the MOB orders the load and store instructions so as to maintain data coherency between the threads, and wherein the MOB includes match determining logic to compare addresses of at least some of the store instructions with addresses of load instructions to determine which, if any, at least some of the load instructions that are later in program order have the same address as the compared store instructions. </claim-text></claim>"}, {"num": 30, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00030\" num=\"30\"><claim-text>30. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, wherein the chip is a processor and within the load buffers load instructions are held in program order and within the store buffers store instructions are held in program order.</claim-text></claim>"}, {"num": 31, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00031\" num=\"31\"><claim-text>31. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, wherein threads are retired from the MOB in retirement order in a final retirement after it is assured that all instructions have been executed without speculation error or have been part of a reset thread.</claim-text></claim>"}, {"num": 32, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00032\" num=\"32\"><claim-text>32. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, further comprising thread management logic to provide an indication of program order and retirement order.</claim-text></claim>"}, {"num": 33, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00033\" num=\"33\"><claim-text>33. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, wherein threads are retired from the MOB in retirement order in a final retirement.</claim-text></claim>"}, {"num": 34, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00034\" num=\"34\"><claim-text>34. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, wherein threads are retired from the MOB in retirement order in a final retirement after it is assured that all instructions have been executed without speculation error or have been part of a reset thread.</claim-text></claim>"}, {"num": 35, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00035\" num=\"35\"><claim-text>35. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, wherein load buffers include status fields including indications as to whether a corresponding one of the load instructions had previously received data from memory or data in the store buffer.</claim-text></claim>"}, {"num": 36, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00036\" num=\"36\"><claim-text>36. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, wherein load buffers include status fields including a store buffer identification number (SBID) of a store buffer entry from which a corresponding one of the load instructions previously received data.</claim-text></claim>"}, {"num": 37, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6463522-B1-CLM-00037\" num=\"37\"><claim-text>37. The chip of <claim-ref idref=\"US-6463522-B1-CLM-00029\">claim 29</claim-ref>, wherein load buffers include status fields including a thread identification number of a store instruction from which the load instruction previously received data.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53648382\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><h4>RELATED APPLICATIONS</h4><p>The present application and Appl. Ser. No. 08/992,375 entitled \u201cProcessor Having Multiple Program Counters and Trace Buffers Outside an Execution Pipeline\u201d and Appl. Ser. No. 08/991,269 entitled \u201cOut-of-Pipeline Trace Buffer For Instruction Replay Following Misspeculation\u201d, filed concurrently herewith, have essentially common specifications.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. Technical Field of the Invention</p><p>The present invention relates to processors and, more particularly, to processors having a memory order buffer.</p><p>2. Background Art</p><p>Current superscaler processors, such as microprocessors, perform techniques such as branch prediction and out-of-order execution to enhance performance. Processors having out-of-order execution pipelines execute certain instructions in a different order than the order in which the instructions were fetched and decoded. Instructions may be executed out of order with respect to instructions for which there are not dependencies. Out-of-order execution increases processor performance by preventing execution units from being idle merely because of program instruction order. Instruction results are reordered after execution.</p><p>The task of handling data dependencies is simplified by restricting instruction decode to being in-order. The processors may then identify how data flows from one instruction to subsequent instructions through registers. To ensure program correctness, registers are renamed and instructions wait in reservation stations until their input operands are generated, at which time they are issued to the appropriate functional units for execution. The register renamer, reservation stations, and related mechanisms link instructions having dependencies together so that a dependent instruction is not executed before the instruction on which it depends. Accordingly, such processors are limited by in-order fetch and decode.</p><p>When the instruction from the instruction cache misses or a branch is mis-predicted, the processors have either to wait until the instruction block is fetched from the higher level cache or memory, or until the mis-predicted branch is resolved, and the execution of the false path is reset. The result of such behavior is that independent instructions before and after instruction cache misses and mis-predicted branches cannot be executed in parallel, although it may be correct to do so.</p><p>A memory order buffer has been used to order loads and stores. There is a need for improved mechanisms in a processor that allow the processor to recover from speculation errors.</p><h4>SUMMARY OF THE INVENTION</h4><p>In one embodiment of the invention, a processor includes a memory order buffer (MOB) including load buffers and store buffers, wherein the MOB orders load and store instructions so as to maintain data coherency between load and store instructions in different threads, wherein at least one of the threads is dependent on at least another one of the threads. In another embodiment of the invention, a processor includes an execution pipeline to concurrently execute at least portions of threads, wherein at least one of the threads is dependent on at least another one of the threads, the execution pipeline including a memory order buffer that orders load and store instructions. The processor also includes detection circuitry to detect speculation errors associated with load instructions in a load buffer.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>The invention will be understood more fully from the detailed description given below and from the accompanying drawings of embodiments of the invention which, however, should not be taken to limit the invention to the specific embodiments described, but are for explanation and understanding only.</p><p>FIG. 1 is a high level block diagram representation of certain components in one embodiment of a processor.</p><p>FIG. 2 is a block diagram of a processor according to one embodiment of the invention.</p><p>FIG. 3 is a block diagram of a processor according to another embodiment of the invention.</p><p>FIG. 4 is a flow diagram of an example of two threads.</p><p>FIG. 5 is a flow diagram of another example of two threads.</p><p>FIG. 6 is a flow diagram of an example of four threads.</p><p>FIG. 7 is a graph showing overlapping execution of the threads of FIG. <b>6</b>.</p><p>FIG. 8 is a block diagram illustrating individual trace buffers according to one embodiment of the invention.</p><p>FIG. 9 illustrates an array indicating program and retirement orders at two times.</p><p>FIG. 10 is a block diagram representation of certain components in one embodiment of a trace buffer of FIG. <b>8</b>.</p><p>FIG. 11 is a block diagram representation of certain components in another embodiment of a trace buffer of FIG. <b>8</b>.</p><p>FIG. 12 is a graphical representation of portions of one embodiment of an instruction queue array of the trace buffer of FIG. <b>10</b>.</p><p>FIG. 13 is a graphical representation of portions of one embodiment of a data and dependency array of the trace buffer of FIG. <b>10</b>.</p><p>FIG. 14 illustrates one embodiment of modifier registers and a modified register used in creating the dependency field of the array of FIG. <b>10</b>.</p><p>FIG. 15 is a logical OR gate used in creating the dependency field of the array of FIG. <b>13</b>.</p><p>FIG. 16 is a flow chart illustrating one embodiment of operations used to create the dependency field of the array of FIG. <b>13</b>.</p><p>FIG. 17 is a graphical representation of a particular register and locations in a trace buffer that has dependencies thereon according to one embodiment of the invention.</p><p>FIG. 18 is a graphical representation of portions of one embodiment of an output register file of the trace buffer of FIG. <b>10</b>.</p><p>FIG. 19 is a graphical representation of portions of one embodiment of an input register file of the trace buffer of FIG. <b>10</b>.</p><p>FIG. 20 is a block diagram of a comparator and replay triggering logic used in connection with the output register file of FIG. <b>18</b> and the input register file of FIG. 19 according to one embodiment of the invention.</p><p>FIG. 21 is a flow diagram illustrating points at which the contents of the output register file may be utilized.</p><p>FIG. 22 is a block diagram illustrating individual memory order buffers (MOBs) within the MOB of FIG. 2 according to one embodiment of the invention.</p><p>FIG. 23 is a graphical representation of portions of one embodiment of a store buffer of one of the MOBs of FIG. <b>22</b>.</p><p>FIG. 24 is a graphical representation of portions of one embodiment of a load buffer of one of the MOBs of FIG. <b>22</b>.</p><p>FIG. 25 illustrates a comparator comparing addresses of load and store instructions.</p><p>FIG. 26 illustrates a comparator comparing addresses of store and load instructions.</p><p>FIG. 27 is a block diagram representation of MOB control circuitry and store buffers according to one embodiment of the invention.</p><p>FIG. 28 is a block diagram representation of MOB control circuitry and load buffers according to one embodiment of the invention.</p><p>FIG. 29 is a flow diagram of an example of six threads.</p><p>FIG. 30 is a tree illustrating a relationship in the threads of FIG. 29 at a time t<b>1</b>.</p><p>FIG. 31 is a tree illustrating a relationship in the threads of FIG. 29 at a time t<b>2</b> assuming thread T<b>4</b> is reset before thread T<b>1</b> retires.</p><p>FIG. 32 is a tree illustrating a relationship in the threads of FIG. 29 at a time t<b>2</b> assuming thread T<b>1</b> retires before thread T<b>4</b> is reset.</p><p>FIG. 33 is a tree illustrating a relationship in the threads of FIG. 29 at a time t<b>3</b>.</p><p>FIG. 34 is a flow diagram illustrating an example with five threads.</p><p>FIG. 35 is a tree illustrating a relationship in the threads of FIG. 34 at a time t<b>1</b>.</p><p>FIG. 36 is a tree illustrating a relationship in the threads of FIG. 34 at a time t<b>2</b>.</p><p>FIG. 37 is a block diagram presentation of a processor according to an alternative embodiment to that of FIG. <b>2</b>.</p><p>FIG. 38 is a computer system including the processor of FIG. <b>2</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</h4><h4>A. Creation of Threads and Overview of Pipeline <b>108</b></h4><h4>B. Details Regarding Trace Buffers <b>114</b></h4><p>1. Trace Buffer <b>114</b>A</p><p>a. Instruction Queue Array <b>202</b>A</p><p>b. DAD Array <b>206</b>A and Dependency Generation Circuitry <b>212</b>A</p><p>c. Output Register File <b>210</b>A and Input Register File <b>208</b>A</p><p>2. Trace Buffer <b>114</b>\u2032</p><h4>C. A Replay Sequence Algorithm</h4><h4>D. Second Level or Final Retirement</h4><h4>E. Memory System</h4><p>1. Store Buffers and Load Buffers</p><p>2. Comparisons of Load and Store Addresses</p><p>a. Execution of Load Instructions</p><p>b. Execution of Store Instructions</p><p>c. Reset</p><p>3. Replay of Store Instructions</p><p>4. Replays of Multiple Load Instructions</p><p>5. Final Retirement of Load and Store Instructions</p><h4>F. Additional Information Regarding Thread Management Logic and Final Retirement Logic</h4><h4>G. An Embodiment Without Multithreading</h4><h4>H. Additional Information and Embodiments</h4><p>FIG. 1 illustrates certain components of a processor <b>10</b>. Processor <b>10</b> includes an execution pipeline <b>12</b> and a trace buffer <b>14</b>, which is outside execution pipeline <b>12</b>. Execution pipeline <b>12</b> may include a memory order buffer. Instructions on conductors <b>18</b> are provided to execution pipeline <b>12</b> for execution. The instructions are also provided through conductors <b>22</b> to trace buffer <b>14</b>. The instructions may be executed speculatively in execution pipeline <b>12</b>. Examples of the speculation include data speculation and dependency speculation. Any of a wide variety of speculations may be involved. Processor <b>10</b> includes mechanisms, including in trace buffer <b>14</b>, to detect speculation errors (misspeculations) and to recover from them.</p><p>When a misspeculation is detected, the misspeculated instruction is provided to execution pipeline <b>12</b> from trace buffer <b>14</b> through conductors <b>24</b> and is replayed in execution pipeline <b>12</b>. If an instruction is \u201creplayed,\u201d the instruction and all instructions dependent on the instruction are re-executed, although not necessarily simultaneously. If an instruction is \u201creplayed in full,\u201d the instruction and all instructions following the instruction in program order are re-executed. The program order is the order the instructions would be executed in an in order processor. Instructions may pass through conductors <b>18</b> entirely in program order or in something other than program order. Processor <b>10</b> may be an in order or out-of-order processor. The re-execution of a dependent instruction may result in instructions which are dependent on the dependent instruction being replayed. The number of re-executions of instructions can be controlled by controlling the events which trigger replays. In general, the term execute may include original execution and re-execution. Results of at least part of the instructions are provided to trace buffer through conductors <b>26</b>. Final retirement logic <b>34</b> finally retires instructions in trace buffer <b>14</b> after it is assured that the instructions were correctly executed either originally or in re-execution.</p><p>Execution pipeline <b>12</b> may be any of a wide variety execution pipelines and may be a section of a larger pipeline. Execution pipeline <b>12</b> may be used in connection with a wide variety of processors. Examples are provided in FIG. 2 which illustrates components of a processor <b>50</b> having an execution pipeline <b>108</b>, and in FIG. 3 which illustrates a processor <b>100</b> having an execution pipeline <b>308</b>. In the embodiment of the invention in FIG. 2, execution pipeline <b>108</b> includes register renaming. In other embodiments, the execution pipeline does not include register renaming. The processor may concurrently process multiple threads (as in the case of processor <b>50</b> in FIG. <b>2</b>), or not concurrently process multiple threads (as in the case of processor <b>100</b> in FIG. <b>3</b>). Processor <b>50</b> will be discussed first.</p><p>Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification are not necessarily all referring to the same embodiment.</p><h4>A. Creation of Threads and Overview of Pipeline <b>108</b></h4><p>Instructions are provided through conductors <b>102</b> to an instruction cache (I-cache) <b>104</b>. A decoder <b>106</b> is illustrated as receiving instructions from I-cache <b>104</b>, but alternatively could decode instructions before they reach I-cache <b>104</b>. Depending on the context and implementation chosen, the term \u201cinstructions\u201d may include macro-operations (macro-op), micro-operations (uops), or some other form of instructions. Any of a variety of instruction sets may be used including, but not limited to, reduced instruction set computing (RISC) or complex instruction set computing (CISC) instructions. Further, decoder <b>106</b> may decode CISC instructions to RISC instructions. Instructions from I-cache <b>104</b> are provided to pipeline <b>108</b> through MUX <b>110</b> and to trace buffers <b>114</b> through conductors <b>118</b>.</p><p>A trace is a set of instructions. A thread includes the trace and related signals such as register values and program counter values.</p><p>Thread management logic <b>124</b> creates different threads from a program or process in I-cache <b>104</b> by providing starting counts to program counters <b>112</b>A, <b>112</b>B, . . . , <b>112</b>X, through conductors <b>130</b> (where X represents the number of program counters). As an example, X may be 4 or more or less. Thread management logic <b>124</b> also ends threads by stopping the associated program counter. Thread management logic <b>124</b> may cause the program counter to then begin another thread. Portions of different threads are concurrently read from I-cache <b>104</b>.</p><p>To determine where in a program or process to create a thread, thread management logic <b>124</b> may read instructions from decoder <b>106</b> through conductors <b>128</b>. The threads may include instructions inserted by a programmer or compiler that expressly demarcate the beginning and ending of threads. Alternatively, thread management logic <b>124</b> may analyze instructions of the program or process to break up a program or process supplied to I-cache <b>104</b> into different threads. For example, branches, loops, backward branches, returns, jumps, procedure calls, and function calls may be good points to separate threads. Thread management logic <b>124</b> may consider the length of a potential thread, how many variables are involved, the number of variables that are common between successive threads, and other factors in considering where to start a thread. Thread management logic <b>124</b> may consider the program order in determining the boundaries of threads. The program order is the order the threads and the instructions within the threads would be executed on an in order processor. The instructions within the threads may be executed out of order (contrary to program order). The threads may be treated essentially independently by pipeline <b>108</b>. Thread management logic <b>124</b> may include a prediction mechanism including a history table to avoid making less than optimal choices. For example, thread management logic <b>124</b> may create a thread and then later determine that the thread was not actually part of the program order. In that case, if the same code is encountered again, the prediction mechanism could be used to determine whether to create that same thread again.</p><p>Dynamically creating threads is creating threads from a program that was not especially written or compiled for multithreading, wherein at least one of the threads is dependent on another of the threads. The program may originate from off a chip that includes execution pipeline <b>108</b> and thread management logic <b>124</b>. Dynamically creating the threads, executing the threads, and detecting and correcting speculation errors in the execution is referred to as dynamic multithreading.</p><p>FIG. 4 illustrates a thread T<b>1</b> that includes a conditional backward branch instruction. In program order, thread T<b>2</b> is executed following the conditional branch instruction. In time order, thread T<b>2</b> is executed speculatively beginning at the time thread T<b>1</b> first reaches the conditional branch instruction. Therefore, portions of thread T<b>1</b> and T<b>2</b> are executed concurrently. If thread T<b>2</b> involves misspeculations, the effected instructions of thread T<b>2</b> are replayed.</p><p>Thread management logic <b>124</b> may monitor the count of the program counters through conductors <b>130</b>. A purpose of monitoring the count is to determine when a thread should end. For example, when the condition of the conditional branch is not met, if the program counter of thread T<b>1</b> were allowed to continue, it would advance to the first instruction of thread T<b>2</b>. Therefore, thread management logic <b>124</b> stops the program counter of thread T<b>1</b> when the condition is not met.</p><p>FIG. 5 illustrates a thread T<b>1</b> that includes a function call instruction. In program order, when the call instruction is reached, the program counter jumps to the location of the function and execute until a return instruction, at which time the program counter returns to the instruction after the call. In program order, thread T<b>2</b> begins at the instruction following the return. In time order, thread T<b>2</b> is executed speculatively beginning at the time thread T<b>1</b> first reaches the call. If thread T<b>2</b> involves misspeculations, the effected instructions of thread T<b>2</b> are replayed. Thread T<b>1</b> ends when its program counter reaches the first instruction of thread T<b>2</b>. The Load MX and Store MX instructions in FIG. 5 will be discussed below.</p><p>FIG. 6 illustrates threads T<b>1</b>, T<b>2</b>, T<b>3</b>, and T<b>4</b> which are part of a section of a program. Different program counters produce threads T<b>1</b>, T<b>2</b>, T<b>3</b>, and T<b>4</b>. Thread T<b>1</b> includes instructions to point A (function call instruction) and then from point B, to point C (conditional backward branch instruction), to point D and to point C again (the loop may be repeated several times). Tread T<b>2</b> begins at the instruction that in program order is immediately after the return instruction of the function that is called at point A. Thread T<b>3</b> begins at the instruction that in program order is immediately after the conditional backward branch of point C and continues to point E, to point F, to point G, to point H, and to point I, which is a return instruction to the instruction immediately following point A where thread T<b>2</b> begins. Thread T<b>4</b> begins at the instruction that in program order is immediately after the conditional backward branch at point E.</p><p>As illustrated in FIG. 7, portions of threads T<b>1</b>, T<b>2</b>, T<b>3</b>, and T<b>4</b> are fetched, decoded, and executed concurrently. The threads are fetched, decoded, and executed out of order because the program order is not followed. In time order, execution of threads T<b>2</b>, T<b>3</b>, and T<b>4</b> begins immediately following instructions at points A, C, and E, respectively. The vertical dashed lines show a parent child relationship. Threads T<b>2</b>, T<b>3</b>, and T<b>4</b> are executed speculatively by relying on data in registers and/or memory locations before it is certain that the data is correct. Processor <b>100</b> has mechanisms to detect misspeculation and cause misspeculated instructions to be replayed. It turns out that thread T<b>4</b> is not part of the program order. Thread T<b>4</b> may be executed until thread management logic <b>124</b> determines that thread T<b>4</b> is not part of the program order. At that time, thread T<b>4</b> may be reset and the resources that held or process thread T<b>4</b> in processor <b>100</b> may be deallocated and then allocated for another thread. In program order, threads T<b>1</b>, T<b>2</b>, and T<b>3</b> would be executed as follows: first thread T<b>1</b>, then thread T<b>3</b>, and then thread T<b>2</b>.</p><p>Referring to FIG. 2, instructions from MUX <b>110</b> are received by rename/allocate unit <b>150</b> which provides a physical register identification (PRID) of the renamed physical register in register file <b>152</b>. The PRID is provided to trace buffer <b>114</b> through bypass conductors <b>126</b>. Allocation involves assigning registers to the instructions and assigning entries of the reservation stations of schedule/issue unit <b>156</b>. Once the operands are ready for a particular instruction in the reservation stations, the instruction is issued to one of the execution units (e.g., integer, floating point) of execution units <b>158</b> or a memory execution pipeline which includes address generation unit (AGU) <b>172</b>, memory order buffer (MOB) <b>178</b>, and data cache <b>176</b>. Depending on the instructions, operands may be provided from register file <b>152</b> through conductors <b>168</b>. Under one embodiment of the invention, dependent instructions within a thread may be so linked that they are not executed out-of-order. However, dependent instructions from different threads may be concurrently fetched, decoded, and executed out-of-order. The execution of certain of the threads may be speculative.</p><p>For high performance, reservation stations and related mechanisms are designed to have both low latency and high bandwidth issue of instructions. The latency and bandwidth requirements place restrictions on the number of instructions that can be waiting in the reservation stations. By positioning trace buffers <b>114</b> outside pipeline <b>108</b>, a large number of instructions can be available for execution/replay without significantly decreasing throughput of pipeline <b>108</b>. The effect of latency between execution pipeline <b>108</b> and trace buffers <b>114</b> can be reduced through pipelining.</p><p>The result of an execution and related information are written from writeback unit <b>162</b> through conductors <b>122</b> (in the case of registers) and through MUX <b>192</b> and conductors <b>196</b> to trace buffers <b>114</b>. The results and related information may also be written to register file <b>152</b> and associated re-order buffer (ROB) <b>164</b>. Once the result and information of an instruction are written to register file <b>152</b> and ROB <b>164</b>, the instruction is retired in order as far as pipeline <b>108</b> is concerned. This retirement is called a first level or initial retirement. At or before the first level retirement, resources for the retired instruction in schedule/issue unit <b>156</b> including the reservation stations, register file <b>152</b>, and ROB <b>164</b> are deallocated. However, all needed details regarding the instruction are maintained in trace buffers <b>114</b> and MOB <b>178</b> until a final retirement, described below.</p><p>A dependency exists between a later thread and an earlier thread when in program order, data used in the later thread is produced in the earlier thread. The data may have been produced in the earlier thread through a memory or non-memory instruction. For example, the later thread may be dependent on the earlier thread if a load instruction in the later thread has the same address as a store instruction in the earlier thread. The later thread may also be dependent on the earlier thread if an instruction in the later thread involves a register that was modified in the earlier thread. Likewise, a later instruction is dependent on an earlier instruction when in program order the later instruction uses data produced by the earlier instruction. The word \u201cdependency\u201d is also used in the phrase \u201cdependency speculation.\u201d An example of a dependency speculation is speculating that there is no dependency between a load instruction and an earlier store instruction. Address matching is an example of a technique for checking for dependency speculation errors. An example of data speculation is speculating that the data in a register is the correct data. Register matching is an example of a technique for checking for data speculation errors.</p><h4>B. Details Regarding Trace Buffers <b>114</b></h4><p>Referring to FIG. 8, trace buffers <b>114</b> include trace buffers <b>114</b>A, <b>114</b>B, <b>114</b>C, . . . , <b>114</b>Y, where Y presents the number of trace buffers. For example, if Y=4 (i.e., Y=D), there are 4 trace buffers. If Y is less than 3, trace buffers <b>114</b> does not include all the trace buffers shown in FIG. 8. Y may be the same as or different than X (the number of program counters). Trace buffers <b>114</b> may be a single memory divided into individual trace buffers, or physically separate trace buffers, or some combination of the two.</p><p>Referring to FIG. 9, in one embodiment, thread management logic <b>124</b> includes an array <b>198</b> that specifies the program order (which is also the retirement order) of thread IDs. In the example, each trace buffer has a unique thread ID or a one-to-one mapping to a thread ID. For example, trace buffer <b>114</b>A is assigned thread ID <b>1</b>, trace buffer <b>114</b>B is assigned thread ID <b>2</b>, etc. The thread IDs may be hardwired or programmed. In one embodiment, each program counter is associated with a particular thread ID and trace buffer. (Alternatively, there is not such a restricted relationship.)</p><p>FIG. 9 shows an example of the retirement order of threads at time t<b>1</b> and time t<b>2</b>. In the example, there are only four trace buffers and four thread IDs. The associated thread numbers are shown in parenthesis. Depending on the implementation, the thread number in parenthesis is not actually included in array <b>198</b>. At time t<b>1</b>, the program and retirement order is thread T<b>1</b>, T<b>3</b>, T<b>2</b>, and T<b>4</b>, as in the example of FIG. <b>6</b>. Between time t<b>1</b> and time t<b>2</b>, it is determined that thread T<b>4</b> is not in the program order. Therefore, thread T<b>4</b> is reset, making room for thread T<b>5</b> (not shown in FIG. 5) in trace buffer <b>114</b>D. Thread T<b>5</b> is associated with thread ID <b>4</b>. Thread T<b>1</b> retires, making room for thread T<b>6</b> in trace buffer <b>114</b>A. Thread T<b>6</b> is associated with thread ID <b>1</b>. At time t<b>2</b>, the program and retirement order is thread T<b>3</b>, T<b>2</b>, T<b>5</b>, and T<b>6</b>. (If thread T<b>1</b> retired before thread T<b>4</b> was reset, then threads T<b>5</b> and T<b>6</b> would have had different thread IDs, but program and retirement order would not be changed). Depending on the algorithm used, it may have been that thread T<b>2</b> was initially before thread T<b>3</b> in array <b>198</b>, but the program and retirement order would be corrected, as array <b>198</b> at time t<b>1</b>.</p><p>As mentioned, the program order of threads is the order the threads would be executed on an in order processor. The program order of instructions is the order the instructions would be executed on an in order processor. Thread management logic <b>124</b> does not necessarily initially determine the true program order for the threads. However, thread management logic <b>124</b> does eventually determines the true program order.</p><p>Referring to FIG. 8, trace buffers <b>114</b>A, <b>114</b>B, . . . , <b>114</b>Y receive instructions through conductors <b>118</b>A, <b>118</b>B, . . . <b>118</b>Y, which are connected to conductors <b>118</b>. There may be demultiplexing circuitry between conductors <b>118</b>A, <b>118</b>B, . . . , <b>118</b>Y and conductors <b>118</b>. Alternatively, enable signals may control which trace buffer is activated. Still alternatively, there may be enough parallel conductors to handle parallel transactions. Trace buffers <b>114</b>A, <b>114</b>B, . . . , <b>114</b>Y supply instructions and related information for replay to pipeline <b>108</b> through conductors <b>120</b>A, <b>120</b>B, . . . <b>120</b>Y, which are connected to conductors <b>120</b>. It is noted that multiple instructions from trace buffers <b>114</b> may concurrently pass through conductors <b>120</b> and MUX <b>110</b> for re-execution. At the same time, multiple instructions from decoder <b>106</b> may also pass through MUX <b>110</b> for the first time. A thread ID and instruction ID (instr ID) accompany each instruction through the pipeline. A replay count may also accompany the instruction. In the case of load and store instructions, a load buffer ID (LBID) and a store buffer ID (SBID) may also accompany the instruction. In one embodiment, the LBID and SBID accompany every instruction, although the LBID and SBID values may be meaningless in the case of instructions which are not loads or stores. As described below, a PRID or value may also accompany an instruction being re-executed.</p><p>Trace buffers <b>114</b>A, <b>114</b>B, . . . , <b>114</b>Y receive PRID, LBID, and SBID values from rename/allocate unit <b>150</b> through bypass conductors <b>126</b>A, <b>126</b>B, . . . <b>126</b>Y, which are connected to conductors <b>126</b>. Trace buffers <b>114</b>A, <b>114</b>B, . . . , <b>114</b>Y receive writeback result information and related signals through conductors <b>122</b>A, <b>122</b>B, . . . , <b>122</b>Y, which are connected to conductors <b>122</b>, and through conductors <b>196</b>A, <b>196</b>B, . . . , <b>196</b>Y, which are connected to conductors <b>196</b>. Replay signals are provided through conductors <b>194</b>A, <b>194</b>B, . . . , <b>194</b>Y, which are connected to conductors <b>194</b>. Multiplexing and/or enable circuitry and/or a substantial number of parallel conductors may be used in conductors <b>120</b>, <b>126</b>, <b>122</b>, <b>194</b>, and <b>196</b>. The trace buffers may be identical or somewhat different.</p><p>In FIG. 10, trace buffer <b>114</b>A illustrates a first embodiment of a trace buffer. In FIG. 11, trace buffer <b>114</b>A\u2032 illustrates a second embodiment of a trace buffer. Other embodiments of trace buffers could include variations of trace buffer <b>114</b>A and <b>114</b>A\u2032 or quite different architecture.</p><p>1. Trace Buffer <b>114</b>A</p><p>Referring to FIG. 10, trace buffer <b>114</b>A includes an instruction queue array <b>202</b>A, a data and dependency (DAD) array <b>206</b>A, an input register file <b>208</b>A, an output register file <b>210</b>A, dependency generation circuitry <b>212</b>A, and control circuitry <b>224</b>A. The term \u201carray\u201d is intended in a broad sense to include information in multiple directions, without restriction to particular form.</p><p>a. Instruction Queue Array <b>202</b>A</p><p>With reference to FIG. 12, the following describes the structure of an instruction queue array <b>202</b>A and its interaction with other components according to one embodiment of the invention. Instruction queue array <b>202</b>A receives instructions fetched from I-cache <b>104</b> that are part of a particular thread. The instructions within a thread are fetched and written into instruction queue array <b>202</b>A in order. Instructions that are part of another thread are written into an instruction queue of a different trace buffer or into instruction queue array <b>202</b>A at a different time. Instruction queue array <b>202</b>A includes various fields of information for each instruction identifier (instr ID). Different embodiments could include somewhat different fields and a different numbers of rows. In the embodiment of instruction queue array <b>202</b>A, the program counter value is not considered, but could be in other embodiments. Instruction queue array <b>202</b>A and all other components illustrated in the drawings may include various fields, signals, and structure that is not illustrated. Such fields, signals, and structure are not illustrated because they vary depending on the implementation, are understood by those skilled in the art, and would greatly complicate this specification and tend to obscure the invention.</p><p>Instructions wait in trace buffer <b>114</b>A until they are finally retired or discarded (because, for example, it is determined that the thread is not part of an in order execution of the program). If instruction queue array <b>202</b>A fills up while there are still instructions in the trace that have not yet been executed, the instructions are not received by trace buffer <b>114</b> or rename/allocate unit <b>150</b> until an instruction is finally retired from instruction queue array <b>202</b>A and a row is deallocated. Entries of the various arrays in system <b>100</b> may be allocated and deallocated by movement of head and tail pointers.</p><p>Instruction queue array <b>202</b>A is described in connection with the following lines of code:</p><p>I<b>0</b>: mul R<b>1</b>, R<b>2</b>\u2192R<b>1</b></p><p>I<b>1</b>: mul R<b>3</b>, R<b>4</b>\u2192R<b>2</b></p><p>I<b>2</b>: add R<b>1</b>, R<b>2</b>\u2192R<b>1</b></p><p>I<b>3</b>: add <b>10</b>, R<b>1</b>\u2192R<b>4</b></p><p>I<b>4</b>: store R<b>2</b>\u2192Mx</p><p>I<b>5</b>: store R<b>1</b>\u2192My,</p><p>which are the first six instructions within a thread. It will be apparent that a trace buffer other than trace buffer <b>114</b>A is earlier in program order than is trace buffer <b>114</b>A.</p><p>The \u201cOp Code\u201d field contains the operation code associated with the particular instruction. \u201cDest,\u201d \u201cSource <b>1</b>,\u201d and \u201cSource <b>2</b>\u201d fields identify the destination, source <b>1</b>, and source <b>2</b> of the instructions. The \u201cIndex for Source <b>1</b>\u201d field, identifies instruction entries within the trace buffer <b>114</b>A that contain the source. For example, the destination of instr ID <b>0</b> is used for source <b>1</b> for instr ID <b>2</b>. Therefore, a 0 is placed in the \u201cIndex for Source <b>1</b>\u201d field of instr ID <b>2</b>. The destination of instr ID <b>2</b> is used for source <b>2</b> for instr ID <b>3</b>. Therefore, a 2 is placed in the \u201cIndex for Source <b>2</b>\u201d field of instr ID <b>3</b>. An X indicates a don't care.</p><p>The \u201cValid <b>1</b>\u201d and \u201cValid <b>2</b>\u201d field are bits that are set to a first value (e.g., a logic 0) when a corresponding source operand of an instr ID has been previously produced by an instruction from outside the thread in trace buffer <b>114</b>A, and a second value (e.g., a logic 1) when the source operand for an instr ID has been previously produced by an instruction within the thread. Source <b>1</b> (R<b>1</b>) of instr ID <b>0</b> is produced outside the trace in instruction queue array <b>202</b>A. Accordingly, valid <b>1</b> of instr ID <b>0</b> is a logic 0. Source <b>2</b> for instr ID <b>3</b> is from the destination of instr ID <b>2</b>. Accordingly, valid <b>2</b> of instr ID <b>3</b> is a logic 1.</p><p>Instruction <b>13</b> involves adding R<b>1</b> to a constant \u201c<b>10</b>.\u201d The constant may be stored with the instruction, in a special register (not shown), in the source <b>1</b> field, or through some other mechanism. In FIG. 12, an X (don't care) is shown in the Source <b>1</b> field for instr ID <b>3</b>. Alternatively, some indicator could be placed in the Source <b>1</b> field.</p><p>A store buffer ID (SBID) field holds an SBID associated with a store instruction in a store buffer, described below. A load buffer (LBID) field hold an LBID entry associated with a load instruction in a load buffer, described below. The SBID and LBID values are assigned by rename/allocate unit <b>150</b> and are written to the instruction queue array through bypass conductors <b>126</b>. A thread ID number field could be included in instruction queue array <b>202</b>A, but it is not needed because it is implicit.</p><p>b. DAD Array <b>206</b>A and Dependency Generation Circuitry <b>212</b>A</p><p>Referring to FIG. 13, one embodiment of DAD array <b>206</b>A includes \u201cinstr ID\u201d entries (rows) that correspond to the instr ID entries of Instruction Queue Array <b>202</b>A in a one-to-one fashion. Indeed, instruction queue array <b>202</b>A and DAD array <b>206</b>A could be different portions of the same array. However, in some embodiments, there are different read ports associated with instruction queue array <b>202</b>A and DAD array <b>206</b>A.</p><p>DAD array <b>206</b>A includes a \u201cValue or PRID\u201d field that contains either the value produced by an instruction or the PRID in register file <b>152</b>. The value is written back from the execution units to trace buffer <b>114</b>A through write back unit <b>162</b> and write back buses <b>122</b> and <b>196</b>. A \u201cStatus\u201d field, which may be two bits, indicates whether the \u201cValue or PRID\u201d field contains a \u201cValue\u201d or a \u201cPRID.\u201d In one embodiment, it is possible that the \u201cValue or PRID\u201d does not hold either a valid \u201cValue\u201d or a valid \u201cPRID.\u201d A \u201cReplay Count\u201d field, which uniquely identifies an instruction dispatch, is incremented each time the instruction of the same instr ID is replayed in pipeline <b>108</b>. Under one embodiment, it is possible that an instruction may be concurrently replayed more than one time within pipeline <b>108</b>. In this case, under one embodiment, only the information associated with the highest \u201creplay count\u201d is written back to DAD array <b>206</b>A.</p><p>The \u201cDependency Field\u201d includes a bit for each logical register. In FIG. 13, for simplicity, only four logical registers (R<b>1</b>, R<b>2</b>, R<b>3</b>, and R<b>4</b>) are represented. However, the number could be far larger. In the example, the dependency field entries are set to 1 to indicate that a data dependency chain exists between an input value to the trace and the instruction entry, and a 0 if there is no dependency. The dependency field entries identify which instructions in the trace would need to be executed if an input value is received (such as when value misspeculation is detected).</p><p>As the instructions are fetched, decoded, and written into trace buffer <b>114</b>A, the dependency bits are computed sequentially, and are written into the DAD array <b>206</b>A. The dependency bits may be generated before it is determined whether to replay an instruction. The dependency bits in FIG. 13 are for the six instructions I<b>0</b>-I<b>5</b>, recited above in section B.<b>1</b>.a.</p><p>The dependency field can be created through a mechanical approach. Before describing one such approach, the creation will be explained on a more intuitive level.</p><p>i. Intuitive Level</p><p>The result of instruction I<b>0</b> is dependent on only registers R<b>1</b> and R<b>2</b>. Therefore, a 1 is placed in the R<b>1</b> and R<b>2</b> columns and a 0 remains in the R<b>3</b> and R<b>4</b> columns of instr ID <b>0</b> (which holds information related to instruction I<b>0</b>).</p><p>The result of instruction I<b>1</b> is dependent on only registers R<b>3</b> and R<b>4</b>. Therefore, a 0 is placed in the R<b>1</b> and R<b>2</b> columns and a 1 in the R<b>3</b> and R<b>4</b> columns of instr ID <b>1</b>.</p><p>The result of instruction I<b>2</b> is directly dependent on registers R<b>1</b> and R<b>2</b>, produced in instructions I<b>0</b> and I<b>1</b>, respectively. In instruction I<b>0</b>, R<b>1</b> is dependent on the R<b>1</b> and R<b>2</b> values at the beginning of the trace. In instruction I<b>2</b>, R<b>2</b> is dependent on the R<b>3</b> and R<b>4</b> values at the beginning of the trace. Therefore, instruction I<b>2</b> is indirectly dependent on the R<b>1</b>-R<b>4</b> values at the beginning of the trace and a 1 is placed in the R<b>1</b>-R<b>4</b> columns of instr ID <b>2</b>.</p><p>The result of instruction <b>13</b> is directly dependent on register R<b>1</b> produced in instruction I<b>2</b>. Therefore, instruction I<b>3</b> indirectly depends on R<b>1</b>-R<b>4</b> values at the beginning of the trace because instruction I<b>2</b> depends on these values and a 1 is placed in the R<b>1</b>-R<b>4</b> columns of instr ID <b>3</b>.</p><p>The result of instruction I<b>4</b> is directly dependent on register R<b>2</b>, which is produced in instruction I<b>1</b>. R<b>2</b> depends on registers R<b>3</b> and R<b>4</b> values at the beginning of the trace. Therefore, a 0 is placed in the R<b>1</b> and R<b>2</b> columns and a 1 is placed in the R<b>3</b> and R<b>4</b> columns of instr ID <b>4</b>.</p><p>The result of instruction I<b>5</b> is directly dependent register R<b>1</b>, which is produced in instruction I<b>2</b>, which depends on registers R<b>1</b>-R<b>4</b> at the beginning of the trace. Therefore, a 1 is placed in the R<b>1</b>-R<b>4</b> columns of instr ID <b>5</b>.</p><p>ii. A Mechanical Approach</p><p>The following are registers and an algorithm that may be used to generate the dependency field according to one embodiment of the invention. Referring to FIG. 14, dependency generation circuitry <b>212</b>A contains temporary registers <b>230</b>, <b>232</b>, <b>234</b>, and <b>236</b>, one for each logical register, plus an additional temporary register <b>240</b>. Temporary registers <b>230</b>, <b>232</b>, <b>234</b>, and <b>236</b> contain modifiers for logical registers R<b>1</b>, R<b>2</b>, R<b>3</b>, and R<b>4</b>. Modified registers <b>240</b> contains a set of bits which indicate which logical registers are to be modified by instructions within a trace. Registers <b>230</b>, <b>232</b>, <b>234</b>, <b>236</b>, and <b>240</b> are updated every time a new instruction is written into the trace buffer. The boundaries between registers is somewhat arbitrary. For example, they may all be in one combined register.</p><p>For each logical register, a trace buffer address register is provided, which points to the last instruction in trace buffer <b>114</b>A to modify the logical register. The modified bits, and the last modifiers addresses are used to compute the dependency bits for the next instruction to be written into trace buffer <b>114</b>A.</p><p>Note that as used herein, modifying a register merely means a value is written into the register. It does not necessary mean that the contents of the register are different as a result of the instruction. For example, if the contents of R<b>1</b> and R<b>2</b> are multiplied (as they are in instruction I<b>0</b>) and the result is written into register R<b>1</b>, the contents of R<b>1</b> is not necessarily different as a result of instruction I<b>0</b>. For example, the contents of R<b>1</b> after the instruction would not be different if the contents of R<b>1</b> is \u201c0\u201d or R<b>2</b> is \u201c1\u201d before the instruction.</p><p>In FIG. 16, a flow chart <b>250</b> represents an algorithm which is performed for each source operand of an instruction (e.g., source <b>1</b> and source <b>2</b>) to create the dependency field of DAD array <b>206</b>A. In step <b>252</b> it is determined whether the associated bit is set in register <b>240</b>. As described in step <b>254</b>, if the bit in register <b>240</b> is not set, then the bit in the dependency field associated with the register is set to a logical 1. As stated in step <b>258</b>, if the bit in register <b>240</b> is set, the source dependency field is read using the index created from the modifier register (<b>230</b>, <b>232</b>, <b>234</b>, or <b>236</b>) for the relevant register. Next, as stated in step <b>262</b>, the source dependency bits are merged with the current instruction dependency bits using a logical OR operation. Such a logical OR operation is illustrated by OR-gate <b>244</b> in FIG. 15 (in which multiple bits are represented at the inputs). In performing the algorithm of FIG. 16, the modified registers and modifiers referred to are those that existed immediately before an instruction is performed.</p><p>With respect to I<b>0</b>, prior to instruction I<b>0</b>, register <b>240</b> has logical 0s for R<b>1</b>, R<b>2</b>, R<b>3</b>, and R<b>4</b>, and the values of registers <b>230</b>, <b>232</b>, <b>234</b>, and <b>236</b> are X (don't care). Under step <b>252</b>, the modified bits in register <b>240</b> for R<b>1</b> and R<b>2</b> are each 0. Therefore, under step <b>254</b>, the dependency field bits for R<b>1</b> and R<b>2</b> are each set to 1 in row instr ID <b>0</b> of DAD array <b>206</b>A. Registers R<b>3</b> and R<b>4</b> are not involved and remain a 0 in the row of instr ID <b>0</b>. Instruction I<b>0</b> modifies register R<b>1</b>. Therefore, a 0 is placed in register <b>230</b>, indicating that instruction I<b>0</b> is the most recent instruction to modify register R<b>1</b>. The values in registers <b>232</b>, <b>234</b>, and <b>236</b> remain X (don't care). The R<b>1</b> bit of register <b>240</b> is set to a 1 indicating that R<b>1</b> has been modified by an instruction within the trace.</p><p>The dependency field for instruction I<b>1</b> is generated in a similar manner to that of instruction I<b>0</b>. The R<b>1</b> logical register column of modified register <b>240</b> remains set to a 1. A logical 1 is placed in the R<b>2</b> column of modified register <b>240</b>. The 1 in register <b>232</b> represents instruction I<b>1</b>.</p><p>With respect to instruction I<b>2</b>, prior to instruction I<b>2</b>, under step <b>252</b>, the modified bits in register <b>240</b> for R<b>1</b> and R<b>2</b> are each a logical 1 (i.e., set). Under step <b>258</b>, the modifier registers for R<b>1</b> (<b>230</b>) and R<b>2</b> (<b>232</b>), immediately prior to instruction I<b>2</b>, are used as an index. Register <b>230</b> contains a 0 for instruction I<b>0</b>. The dependency field for instruction I<b>0</b> in instr ID <b>0</b> of DAD array <b>206</b>A is 0011. Register <b>232</b> contains a <b>1</b> for instruction I<b>1</b>. The dependency field for instruction I<b>1</b> in instr ID <b>1</b> is 1100. Under step <b>262</b>, the logical OR of 0011 and 1100 is 1111. Therefore, 1111 is placed in the dependency field of DAD array <b>206</b>A for instr ID <b>2</b>. R<b>1</b> is modified by instruction I<b>2</b>. However, a 1 is already in register <b>240</b> for register R<b>1</b>. A <b>2</b> is placed in register <b>230</b>, indicating that instruction I<b>2</b> is the most recent instruction to modify instruction R<b>1</b>.</p><p>The dependency field for instruction I<b>3</b> is generated in a similar manner to that of instruction I<b>2</b>. A logical 1 is added to the R<b>4</b> column of modified register <b>240</b> and a 3 representing instruction I<b>3</b> is placed in register <b>236</b>. The logical OR produces 1111.</p><p>With respect to instruction I<b>4</b>, prior to instruction I<b>4</b>, under step <b>252</b>, the modified bit in register <b>240</b> for R<b>2</b> is set to a 1. Under step <b>258</b>, the modifier register for R<b>2</b> (<b>232</b>), immediately prior to instruction I<b>4</b>, is used as an index. Register <b>232</b> contains a 1 for instruction I<b>1</b>. The dependency field for instruction I<b>1</b> in instr ID <b>1</b> of DAD array <b>206</b>A is 1100. Under step <b>262</b>, the logical OR of 1100 (source <b>1</b> from instr ID <b>1</b>) and 0000 (there is no source <b>2</b>) is 1100. Therefore, 1100 is placed in the dependency field of DAD array <b>206</b>A for row instr ID <b>4</b>.</p><p>The dependency field of instruction I<b>5</b> is generated in a manner similar to that of instruction I<b>4</b>. Instructions I<b>5</b> and I<b>6</b> modify an external memory location and do not cause a change in registers <b>230</b>, <b>232</b>, <b>234</b>, <b>236</b>, or <b>240</b>.</p><p>The dependency information may be used by schedule/issue unit <b>156</b>, or schedule/issue unit <b>156</b> may merely derive its own dependency information.</p><p>There are different ways in which a sequence or string of instructions can be issued out of trace buffer <b>114</b>A in replay. One way is to sequentially read the trace buffer and extract those instructions that have the dependency bits set and send them for replay. However, zeros may have the effect of creating bubbles in the pipeline. Another approach is to have bubbles removed by packing logic before sending instructions for execution/replay. Referring to FIG. 17, another approach involves some additional hardware including an array <b>268</b> for each logical register. Array <b>268</b> includes instr ID values of instructions that are dependent on register R<b>1</b>. The values in array <b>268</b> act as pointers to the entire instr ID entries in instruction queue array <b>202</b>A. This allows very fast reading from the instruction buffer. A block of instructions (perhaps 2 or 4) are read at a time. Trace buffer <b>114</b>A could be multi-ported and have four decoders and pass each one of these indices that were obtained from the register array into the decoders and instructions I<b>0</b>, I<b>2</b>, I<b>3</b>, and I<b>5</b> can be read in one cycle. The register R<b>1</b> array could be assembled at the time the dependency field is created, before replay begins. The level of indirection facilitates high bandwidth replay.</p><p>C. Output Register File <b>210</b>A and Input Register File <b>208</b>A</p><p>Trace buffers <b>114</b> include detection circuitry to detect certain speculation errors. According to one embodiment of the invention, each trace buffer has an output register file that holds the register context of the associated thread and an input register file to receive the register context of the immediately preceding thread in program order. The register context is the contents or state of the logical registers. The contents of the output register file is updated often, perhaps each time there is a change in a register. The contents of the input register file is updated only after a comparison, described below.</p><p>FIGS. 18 and 19 illustrate embodiments of an output register file <b>208</b>A (in trace buffer <b>114</b>A) and an input register file <b>208</b>B (in trace buffer <b>114</b>B), although other embodiments could be used. Output register file <b>208</b>A and input register file <b>210</b>B include a Value or PRID field and a status field. The status field indicates whether a valid value or a valid PRID is held in the Value or PRID field. In one embodiment, there is either a valid value or a valid PRID. In another embodiment, there could be neither, in which case an instruction that depends on an input register file could wait for one.</p><p>Note that instruction I<b>0</b> in the example described above involved registers R<b>1</b> and R<b>2</b>, neither of which were previously the destination of an instruction within the thread that includes instruction I<b>0</b>. However, the value or PRID for registers R<b>1</b> and R<b>2</b> would be available from input register file <b>208</b>A to be used in execution of instruction I<b>0</b>.</p><p>Referring to FIG. 20, a comparator <b>280</b>B compares the contents of input register file <b>208</b>B (in trace buffer <b>114</b>B) for a current thread with the contents of output register file <b>210</b>A (in trace buffer <b>114</b>A) for an immediately preceding thread in program order. The comparison can be made at the end of the execution of the immediately preceding thread or during the original execution of the preceding thread. The comparison is also made at the end of the retirement of the preceding thread. In one embodiment, the comparison is only made at the end of the retirement of the preceding thread.</p><p>Various events could trigger a comparison by comparator <b>280</b>B. The comparison is made to detect speculation errors. If there is a difference between the input and output register files, then values of one or more of the output registers of the immediately preceding thread had changed. In response, input register file <b>208</b>B is updated and replay triggering logic <b>284</b>B causes the effected instructions to be replayed with the changed register values. The dependency field may be used by replay triggering logic <b>284</b>B. There is no guarantee that the changed values are the ultimately correct values (i.e., the register values that would have been produced in a purely in order processor). The instructions may need to be replayed again, perhaps several times.</p><p>In one embodiment, the detection circuitry for a thread includes an output register file, an input register file, a comparator and associated control circuitry to detect certain speculation errors in instructions held in the trace buffer that includes the input register file. In other embodiments, the detection circuitry could include somewhat different circuitry.</p><p>As an example, referring to FIG. 21, thread T<b>2</b> is a current thread and is associated with trace buffer <b>114</b>B. Thread T<b>1</b> is the immediately preceding thread to thread T<b>2</b> and is associated with trace buffer <b>114</b>A. Thread T<b>1</b> includes a function call, the function, and a return from the function call. Execution of thread T<b>2</b> begins immediately after the function call. The contents of output register <b>210</b>A as it existed at the function call are copied into input register file <b>208</b>B. The instructions of thread T<b>2</b> are executed speculatively based on the register context in input register file <b>208</b>B. At the time of the return instruction, the contents of input register file <b>208</b>B are compared by comparator <b>280</b>B with the contents of output register file <b>210</b>A. If there is a difference, input register file <b>208</b>B is updated and the effected instructions in thread T<b>2</b> are replayed. The comparison may also be made at one or more intermediate times. This may help prevent bottlenecks by more evenly distributing replay of instructions, but may cause additional replays if, for example, the output register file contents changes more than once during the function. In that the output register file is constantly changing, it may be desirable to have an intermediate buffer that receives the contents of output register file <b>210</b>A. The comparison then may be between the contents of intermediate buffer and input register file <b>208</b>B.</p><p>As illustrated in FIGS. 8 and 10, register contexts are passed between output register files and input register files over conductors <b>216</b>. Conductors <b>216</b> connect each input register file with the output register file of each trace buffer that could hold the trace for the immediately preceding thread. If it can be guaranteed that program order will always follow particular trace buffer order, then the layout for conductors <b>216</b> could be fairly simple. The output and input register files may be controlled by control circuitry <b>224</b>A shown in FIGS. 10 and 11.</p><p>Because output and input register files will provide either a value or a PRID, there may be a very small latency between receiving contents in an input register file and being able to execute instructions using a register from the input register file as a source operand. If a value is not available, the PRID to register file <b>152</b> may be used for execution in pipeline <b>108</b>.</p><p>It is expected that many instructions will be replayed several times as correct source operands work their way through the register files of the various threads. However, it is also expected that for many programs, a great deal of instructions will need to be replayed either not at all or a relatively small number of times, leading to a substantial increase in instructions correctly executed per unit of time, and a decrease in the total time required to run a program.</p><p>2. Trace Buffer <b>114</b>\u2032</p><p>Referring to FIG. 11, trace buffer <b>114</b>A\u2032 is similar to trace buffer <b>114</b> (in FIG. <b>10</b>). However, in trace buffer <b>114</b>A\u2032 the dependency field is generated in dependency generation and decoding circuitry <b>218</b>A after it has been decided that an instruction is to be replayed. While this may cause some initial latency in replay, if the issuance of instructions for replay and determining of dependencies is performed in a pipelined fashion, there may be little additional latency once the process has begun.</p><p>In one embodiment, dependency generation and decoding circuitry <b>218</b>A holds only one field for dependency information. (In FIG. 13, there are four fields.) That same field could be reused. For example, during replay of instructions dependent on register R<b>1</b>, the field could be used to list instructions dependent on register R<b>1</b>. During replay of instructions dependent on register R<b>2</b>, the same field could be used to list instructions dependent on register R<b>2</b>, etc. Dependency generation and decoding circuitry <b>218</b>A could include only one modifier field and one modifier register. (In FIG. 14, there are four.) Alternatively, dependency generation and decoding circuitry <b>218</b>A could include multiple dependency fields and registers. Dependency generation and decoding circuitry <b>218</b>A may determine dependencies for only a few instructions at a time.</p><p>Data array <b>214</b>A includes a Value or PRID field, a Status bit field, and replay count field for each instr ID entry (as in DAD array <b>206</b>A of FIGS. <b>10</b> and <b>13</b>). Alternatively, the contents of data array <b>214</b>A could be put in dependency generation and decoding circuitry <b>218</b>A making data array <b>214</b>A unnecessary. There are two reasons why it may be advantageous to keep data array <b>214</b>A and dependency generation and decoding circuitry <b>218</b>A separate. First, they may involve different read ports. Second, in one embodiment, dependency generation and decoding circuitry <b>218</b>A does not have as many rows as do instruction queue array <b>202</b>A and data array <b>214</b>A. In other words, in one embodiment, dependency generation and decoding circuitry <b>218</b>A reuses rows, just like it may reuse dependency fields. There are, of course, many possibilities.</p><p>As will be described in greater detail below, MOB <b>178</b> signals when load instructions are to be replayed through conductors <b>194</b>. An array having a dependency field (like that for R<b>1</b> in FIG. 13) may be generated to list the instructions dependent on the load instruction to be replayed. However, for a load instruction, the list of dependent instructions begins with the load instruction, rather than with the first instruction in the trace as in the case of registers. The dependency field for load instructions may be in dependency generation and decoding circuitry <b>218</b>A (in FIG. <b>11</b>). (Of course, load instructions for other traces would be replayed from other trace buffers.) In one embodiment, dependency generation and decoding circuitry <b>218</b>A is used for dependency fields for both load instructions and registers. The same field can be used for both. In another embodiment, the dependency fields for registers is in DAD array <b>206</b>A and the dependency field for loads is in dependency generation and decoding circuitry <b>218</b>A.</p><p>In still another embodiment, the load instruction is replayed in full (i.e., all instructions following the load are re-executed) so that the dependency field is not needed.</p><h4>C. A Replay Sequence Algorithm</h4><p>When replay triggering logic (such as replay triggering logic <b>284</b>B) determines that a source operand (or other input value) has been mispredicted, it triggers the corresponding trace buffer (such as trace buffer <b>114</b>B) to dispatch those instructions that are directly or indirectly dependent on the mispredicted source operand to be replayed in pipeline <b>108</b>. The instructions that are directly or indirectly dependent may be identified from the dependency field of the DAD array in the trace buffer or through another array as in FIG. <b>11</b>.</p><p>The identified instructions are dispatched from the trace buffer for execution in the order the instructions exist in the trace buffer (which is the program order). For example, the instruction in instr ID<b>0</b> entry is dispatched at prior to or at the same time as an instruction in the instr ID<b>1</b> entry. However, the instructions may be executed out of order under the control of schedule/issue unit <b>156</b>, as in any out-of-order processor. Control bits are appended to the instruction dispatched from the trace buffer to indicate to rename/allocate unit <b>150</b> whether to (1) do register renaming, (2) bypass the rename alias table lookup in rename/allocate unit <b>150</b> and instead use the PRID from the corresponding trace buffer, or (3) bypass renaming completely and use the value from the DAD array as if it where a constant operand in the instruction.</p><p>As explained in connection with FIG. 12, the \u201cValid <b>1</b>\u201d and \u201cValid <b>2</b>\u201d field are bits that are set to a first value (e.g., a logic 0) when a corresponding source operand of an instr ID has been produced by (e.g., the destination of) an instruction from outside the thread in trace buffer <b>114</b>A, and a second value (e.g., a logic 1) when the source operand for an instr ID has been produced by an instruction within the thread. A replayed instruction dispatched from trace buffer <b>114</b>A may have its source operands determined as follows:</p><p>(1) Valid Bit <b>1</b></p><p>If the valid bit in instruction queue array <b>202</b>A is set to a logical 1, the index for the source operand is used to read the corresponding value or PRID in DAD array <b>206</b>A. If neither the value bit nor PRID bit of the DAD array status field is valid, it means the source operand register has not been renamed yet. In this case, the instruction is dispatched with the value and PRID status bits having logical zero values through conductor <b>120</b> and MUX <b>110</b>, allowing rename/allocate unit <b>150</b> to perform alias table lookup (register renaming) as it normally does. If the PRID or value is valid, it is passed along with the instruction through conductor <b>120</b> and MUX <b>110</b> to rename/allocate unit <b>150</b>, which in response thereto bypasses the renaming stage.</p><p>(2) Valid Bit <b>0</b></p><p>If the valid bit for a source operand is set to a logical 0, the input operand comes from outside the trace. The source register name is used to access input register file <b>208</b>A. The value or PRID from input register file <b>208</b>A is passed along with the instruction to rename/allocate unit <b>150</b>, which in response thereto bypasses the renaming stage.</p><p>Whether the valid bit is 0 or 1, for each dispatched instruction, the value and PRID status field bits in DAD array <b>206</b>A are reset to or remain at a logical 0. This achieves two purposes. First, it ensures that a later dependent instruction dispatched before the PRID is copied into the entry from the rename stage would be allowed to be renamed from the rename alias table, avoiding the use of a stale PRID from trace buffer <b>114</b>A. Second, it also ensures that an instruction will not retire until the last execution instance is written back, therefore allowing an instruction to retire only when all data mispredictions have been corrected.</p><h4>D. Second Level or Final Retirement</h4><p>An instruction is finally retired from trace buffer <b>114</b> when all the instructions for all previous threads have retired and all replay events that belong to the instruction have been serviced. Stated another way, an instruction is finally retired when it can be assured that the instruction has been executed with the correct source operand(s). Threads are retired in order. For example, an instruction in thread X cannot be retired until all the previous threads have been retired (i.e., the instructions of all the previous threads have been retired). The instructions within a thread are retired in order, although instructions that are all ready for retirement may be retired simultaneously.</p><p>Final retirement is controlled by final retirement logic <b>134</b>. In one embodiment of the invention, final retirement includes (1) commitment of results to in order register file, (2) service interrupts, exceptions, and/or branch mispredictions; (3) deallocation of trace buffer and MOB <b>178</b> resource entries; and (4) signaling the MOB to mark stores as retired and to issue them to memory. Deallocating entries may involve moving a head pointer. As described below, store instructions in MOB <b>178</b> are not deallocated until after it is certain that associated data is copied to data cache <b>176</b> or other memory. Details regarding final retirement of loads and stores instructions in MOB <b>178</b> are described below.</p><h4>E. Memory System</h4><p>FIG. 22 illustrates that one embodiment of MOB <b>178</b> of FIG. 2 includes MOBs <b>178</b>A, <b>178</b>B, . . . , <b>178</b>Y, where Y represents the number of MOBs and matches the number of trace buffers <b>114</b>. MOBs <b>178</b>A, <b>178</b>B, . . . , <b>178</b>Y hold copies of load and store instructions of the traces in trace buffers <b>114</b>A, <b>114</b>B, . . . , <b>114</b>Y, respectively. Load instructions are held in load buffers <b>182</b>A, <b>182</b>B, <b>182</b>Y. Store instructions are held in store buffers <b>184</b>A, <b>184</b>B, . . . , <b>184</b>Y. Conductors <b>292</b> represent various conductors that carry signals to and from MOB <b>178</b>. Replay conductors <b>194</b> provide signals from MOB <b>178</b> to trace buffers <b>114</b> alerting trace buffers <b>114</b> that a load instruction should be replayed. Control circuitry <b>302</b> performs a variety of control functions.</p><p>1. Store Buffers and Load Buffers</p><p>FIG. 23 illustrates one embodiment of a store buffer <b>184</b>A, which is representative of store buffers <b>184</b>B, . . . , <b>184</b>Y. Various other embodiments could be used. Store buffer <b>184</b>A includes various fields for rows of store buffer entries. Each entry is identified by a store buffer ID (SBID). Rename/allocate unit <b>150</b> allocates an SBID entry to each store instruction when it is first fetched and executed, but not on replay. The store instruction has the same SBID value until final retirement. For example, in FIG. 23, entry SBID <b>0</b> is allocated for instruction store <b>0</b>. Entry SBID <b>1</b> is allocated for instruction store <b>1</b>, etc. An LBID field holding a \u201cstore LBID\u201d value described below, is illustrated in FIG. <b>23</b>. In one embodiment, when an entry of instruction queue array <b>202</b>A (in FIG. 12) holds a store instruction, the SBID field of instruction queue array <b>202</b>A holds the SBID that identifies the entry in store buffer <b>184</b>A that holds the store instruction, and the LBID field holds the store LBID, if there is one, for that the store instruction. The SBID and store LBID accompany the store instruction through pipeline <b>108</b>. In that embodiment, the LBID field might not be also included in store buffer <b>184</b>A.</p><p>An instr ID field holds the instruction ID of the store instruction in instruction queue array <b>202</b>A. The thread buffer ID is implicit in both store buffer <b>184</b>A and the trace buffer <b>114</b>A. An op code field holds the op code of the store instruction. A store address field holds the address to which the store instruction is directed. In the illustrated embodiment, the address is generated by AGU <b>172</b>. An SB address valid field includes a bit indicating whether the store address is a valid address. A data field holds the data to be stored. A data valid field includes a bit indicating whether the data is valid. Separate address and data valid bits may be used because the valid address may arrive at a different time than the valid data. Both the address and data arrive before the store instruction is executed. Under one embodiment, the data is included as part of the instruction. A retired field includes a bit that is set when final retirement logic <b>134</b> indicates the store instruction should retire and is reset when confirmation is received from memory that the store to memory has been complete. Retirement of loads and stores is discussed below. A replay count field includes a replay count number (and is similar to the replay count field of DAD array <b>206</b>A in FIG. <b>13</b>). The replay count field is not necessary. Under one embodiment, a store instruction can be replayed only once at a time and there is no replay count field.</p><p>FIG. 24 illustrates one embodiment of a load buffer <b>182</b>A, which is representative of load buffers <b>182</b>B, . . . , <b>182</b>Y. Various other embodiments could be used. Load buffer <b>182</b>A includes various fields for rows of load buffer entries. Each entry is identified by a load buffer ID (LBID). Rename/allocate unit <b>150</b> allocates an LBID entry to each load instruction when it is first fetched and executed, but not on replay. The load instruction has the same LBID value until final retirement. For example, in FIG. 24, entry LBID <b>0</b> is allocated for instruction load <b>0</b>. Entry LBID <b>1</b> is allocated for instruction load <b>1</b>, etc. (The LBID entry number and the SBID field may be called a MOB ID). An SBID field holding a \u201cload SBID\u201d value described below, is illustrated in FIG. <b>24</b>. In one embodiment, when an entry of instruction queue array <b>202</b>A (in FIG. 12) holds a load instruction, the LBID field of instruction queue array <b>202</b>A holds the LBID that identifies the entry in load buffer <b>182</b>A that holds the load instruction, and the SBID field holds the load SBID, if there is one, for that store instruction. The LBID and load SBID accompany the load instruction through pipeline <b>108</b>. In that embodiment, the SBID field might not be also included in load buffer <b>182</b>A.</p><p>An instr ID field holds the instruction ID of the load instruction in instruction queue array <b>202</b>A. The thread buffer ID is implicit in both load buffer <b>182</b>A and the trace buffer <b>114</b>A. An op code field holds the op code of the load instruction. A load address field holds the address from which the load instruction loads. An entry valid field includes a bit indicating the entry is occupied by a valid load instruction. In the illustrated embodiment, an address valid field is not included because the address has already been generated by AGU <b>172</b>. A PRID field holds a PRID from rename/allocate unit <b>152</b> which indicates the destination of load instructions in the register file <b>152</b>. SB Hit, SBID, Thread ID, and replay count field (if there is one) may be considered part of a status field and are described below in connection with execution of store instructions.</p><p>At the time store and load instructions are first received by rename/allocate unit <b>150</b>, entries for store and load instructions are allocated in store buffers <b>184</b> and load buffers <b>182</b>, and entries for registers to receive loaded values are allocated in register file <b>150</b> and ROB <b>164</b>. These store and load entries are not subject to a first level retirement, but like entries in trace buffers <b>114</b>, remain allocated until a final retirement. Accordingly, entries are not reallocated on replay. If a store or load buffer is full, a store or load instruction, respectively, from I-cache <b>104</b> will not pass through rename/allocate unit <b>150</b> until an entry is freed up. However, a load or store instruction that is being re-executed from a trace buffer will pass through rename/allocate unit <b>150</b>.</p><p>2. Comparisons of Load and Store Addresses</p><p>Referring to FIG. 5, in program order, store MX in thread T<b>1</b> is executed before load MX is executed in thread T<b>2</b>. However, because of concurrent execution, in time order, store MX may be executed before or after load MX. If store MX is executed before load MX in time order, then the speculative execution of load MX will be in the correct order with respect to store MX. If all instructions before store MX in program order have been retired, then it is certain that load MX will load the correct value from memory location MX. The correct value is the value that would have been loaded if the threads were run by an in order processor. If not all instructions before store MX in program order have been retired, then there is always a chance that the data for store MX is incorrect.</p><p>By contrast, if store MX is executed after load MX in time order, then the speculative execution of load MX will not be in the correct order with respect to store MX and there is no certainty load MX will load the correct value. It would only be by coincidence that the correct value happened to be in memory location MX (or the data field of the store buffer entry holding store MX until store MX is finally retired). To ensure ultimate correctness of execution, MOB <b>178</b> includes various mechanisms to ensure memory data coherency between threads.</p><p>a. Execution of Load Instructions</p><p>Before a load instruction is executed, its address is compared with the addresses of store instructions to determine which, if any, store instruction is the closest earlier matching store instruction (CEMSI). \u201cMatching\u201d means having the same address as the load instruction. \u201cEarlier\u201d means the CEMSI is earlier in program order than the load instruction. \u201cClosest\u201d means there is no other matching store instruction between the CEMSI and the load instruction to be executed. If there is only one earlier matching store instruction, it is the CEMSI.</p><p>If there is a CEMSI, the load instruction reads its data from the data field of the CEMSI. If there is no CEMSI, the load instruction takes its data from memory, such as data cache <b>176</b>, an L<b>2</b> cache, or main memory. Data from a store buffer <b>184</b> or memory is passed through MUX <b>192</b> and written to the entry in trace buffers <b>114</b> designated by the thread ID and instr ID. The data may also be written to the register in register file <b>152</b> designated by the PRID. The data may also be stored in data cache <b>176</b> depending on the caching rules (e.g., write back, write through, etc.). MUX <b>192</b> is a bypass because it can bypass memory, such as data cache <b>176</b>, an L<b>2</b> cache, or main memory.</p><p>In one embodiment, a different comparator is associated with each entry of each of store buffers <b>184</b> to make comparisons between the address of the load to be executed and the address of store instructions. Comparator <b>320</b> in FIG. 25 is an example and receives the load instruction address and the store address of entry SBID <b>1</b> in store buffer <b>184</b>A. Conductor <b>322</b> as well as output conductors from other comparators are connected to MOB control circuitry <b>302</b>.</p><p>The load SBID points to the SBID of a closest earlier store instruction (CESI) with respect to the load instruction to be executed. The CESI is in the store buffer that has the same thread ID as the load instruction. If there is a CEMSI, it is either the CESI or earlier than the CESI in program order. Rename/allocate unit <b>150</b> keeps track of the order of store and load instructions in the program and provides the SBID and the LBID values. They may be written through conductors <b>126</b> to trace buffers <b>114</b>. Under one embodiment, if there is no CESI with respect to a load instruction, then there is no load SBID associated with that instruction. This happens when the first memory instruction in a trace is a load. Various techniques may be used to handle this situation including rename/allocate unit <b>150</b> sending certain signals to indicate there is no valid load SBID. The array wrap around bit, described below, may be used for this purpose.</p><p>Consider store and load instructions in the following program order:</p><p>store <b>0</b></p><p>store <b>1</b></p><p>load <b>0</b></p><p>store <b>2</b></p><p>load <b>1</b></p><p>store <b>3</b></p><p>store <b>4</b></p><p>load <b>2</b>.</p><p>The store LBID values in the LBID field are illustrated in store buffer <b>184</b>A. The load SBID values in the SBID field are illustrated in load buffer <b>182</b>A. For example, the 2 in the SBID field of LBID entry <b>1</b> indicates that the store instruction at entry SBID <b>2</b> in store buffer <b>184</b>A holds the CESI with respect to the load instruction in LBID entry <b>1</b>. Instructions store <b>0</b>, store <b>1</b>, store <b>2</b>, and load <b>0</b> are older or earlier than load <b>1</b>. Instructions store <b>3</b>, store <b>4</b>, and load <b>2</b> are younger or later than load <b>1</b>.</p><p>There are various ways in which control circuitry <b>302</b> may determine which if any store instruction is the CEMSI. Examples of the ways are discussed in connection with FIG. 27, wherein store buffers <b>184</b>A, <b>184</b>B, <b>184</b>C, and <b>184</b>D are the only store buffers in MOB <b>178</b> and are associated with threads A, B, C, and D, respectively. Assume that the program order is thread A, then thread B, then thread C, then thread D. In the example, the load instruction to be executed is in load buffer <b>182</b>C. There is a CESI, which is in store buffer <b>184</b>C.</p><p>Conductors <b>342</b>, <b>344</b>, <b>346</b>, and <b>348</b> are the output conductors of the various comparators. Conductors <b>362</b>, <b>364</b>, <b>366</b>, and <b>368</b> provide control signals that enable the comparators to perform the comparisons. In different embodiments, control circuitry <b>302</b> enables (1) the comparators for all entries in each store buffer, (2) only those comparators that are in a store buffer having a thread ID that is the same as or earlier in program order than the load instruction's thread ID, or (3) only those comparators associated with entries that are earlier in program order than the load instruction.</p><p>Match determining logic <b>356</b> determines which, if any, of the store instructions is the CEMSI. In FIG. 27, the store MX instruction in the upper portion of store buffer <b>184</b>C is the CEMSI. If that store MX instruction were not in store buffer <b>184</b>C, then the CEMSI would be the store MX instruction in store buffer <b>184</b>B. While comparators and match determining logic <b>356</b> are determining whether there is a CEMSI, a lookup may be occurring in data cache <b>176</b> (and other memory) to be ready if there is no CEMSI. Match determining logic <b>356</b> includes data path control logic <b>390</b>, which provides a signal on conductor <b>370</b> to control whether MUX <b>192</b> passes data from memory or a store buffer.</p><p>Under one approach, there are two priority determinations made by MOB control circuitry <b>302</b>. One may be to determine the priority of store instructions within store buffers. Another may be to determine the priority of the store buffers. The determinations may be in either order. A carry chain structure may be used in the determination of the priority within the store buffer. For example, in one embodiment, for each store buffer other than the one having the same thread ID as the load instruction, it is determined which, if any, matching store instruction is the youngest in program order. For the store buffer having the same thread ID as the load instruction, it is determined which, if any, matching instruction is the closest in program order to (including equal to) the CESI. Then, it is determined which of those store buffers that have a matching instruction have a thread ID that is closest in program order to the thread ID of the load instruction.</p><p>Store buffers <b>184</b> may be circular arrays each having a head and a tail. Initially, store instructions with the greater SBID value are younger. However, as store entries are deallocated and allocated, the tail will eventually wrap around so that the head points to a higher SBID entry than does the tail. In one embodiment, a wrap around bit is toggled when the tail goes from the highest to the lowest SBID value, and is provided to closest match determining logic <b>356</b>.</p><p>b. Execution of Store Instructions</p><p>When a store instruction is executed, its address is compared with the addresses of load instructions to determine which, if any, load instructions that are later in program order (from the same or a younger thread) have the same address as the store instruction. A closest later load instruction (CLLI) pointed to by the store SBID designates the earliest load instruction that may be considered.</p><p>In one embodiment, a different comparator is associated with each entry of each of load buffers <b>182</b> to make those comparisons. One of the comparators is comparator <b>324</b>, illustrated in FIG. <b>26</b>. Merely as an example, comparator <b>324</b> is associated with the entry LBID <b>1</b> of load buffer <b>182</b>A. Comparator <b>324</b> receives the address of a store instruction at one input and the address in the load address field of entry LBID <b>1</b> in load buffer <b>182</b>A at another input. A signal on output conductor <b>326</b> signifies whether the addresses are the same. Conductor <b>326</b> as well as output conductors from other comparators are connected to MOB control circuitry <b>302</b>. Comparators (such as comparator <b>324</b>) may also compare status bits of the store instruction with status bits in the load buffer as described below.</p><p>FIG. 28 is similar to FIG. <b>27</b>. However, in FIG. 28 load instruction addresses in load buffers <b>182</b>A-<b>182</b>D are compared with the address of a store instruction to be executed, and match determining logic <b>356</b> determines whether to replay load instructions. In one embodiment, match determining logic includes replay triggering logic <b>394</b> that provides signals on conductors <b>194</b> to indicate to the trace buffers which load instructions are to be replayed. In one embodiment, match determining logic <b>356</b> considers matches of load instructions with the store instruction beginning with the CLLI. Different algorithms may be used. Thread management logic <b>124</b> indicates those thread IDs that are later in program order than the thread ID of the store instruction being executed. In one embodiment, all comparators are enabled. In another embodiment, only the conductors in the load buffers having thread IDs equal to or later in program order than the thread ID of the load instruction are enabled. In still another embodiment, only the conductors in the load buffers associated with the CLLI and later instructions are enabled. The threads to consider can be determined before, after, or during the determination as to which load instructions within the load buffers come later in program order than the store instruction.</p><p>Under one embodiment, detection circuitry to detect certain speculation errors in execution of load instructions includes the comparators associated with the load buffers, portions of match determining logic <b>356</b>, and associated control circuitry. In other embodiments, the detection circuitry could include somewhat different circuitry. It is not required that the detection circuitry to detect speculation errors be in the execution pipeline. Different match determining logic could be used in connection with data path control logic and replay triggering logic.</p><p>i. Cases in Which There is an Address Match</p><p>The status field (SB hit, SBID, Thread ID, Replay Count (if used)) for those younger instructions for which there is an address match is considered in determining whether to replay. The status field indicates whether the load instruction got its data from memory (e.g., data cache <b>176</b>) or the data field of a store buffer. The SB hit field has, for example, a 0 if the data came from memory and a 1 if the data came from the store buffer. The SBID and thread ID fields hold the SBID and thread ID of the store instruction from which the data came from. The thread ID of the store instruction is not necessarily the thread ID of the load instruction for which there is an address match. The thread ID of the load instruction is implicit in the load buffer. The replay count field (if used) indicates which replay is involved. (If the SB Hit is 0, the data in the SBID, thread ID, and replay count fields is meaningless.)</p><p>If SB Hit=0 (previous data from memory), a replay event is signaled from the load buffer over conductors <b>194</b> to the trace buffer identified by the load instruction thread ID and that load instruction and all dependent instructions are replayed from the trace buffer. The instr ID and thread ID are passed over conductors <b>194</b> to indicate which instruction is replayed.</p><p>If SB Hit=1 (previous data from store buffer), the values in the SBID field, thread ID field, and replay count field (if used) control whether a replay is triggered. In a first case, the thread ID of the status field for the particular load instruction equals the thread ID of the store instruction, and the SBID in the status field of the particular load instruction matches the SBID of the store instruction. In the first case, the load instruction is replayed if the replay count of the store instruction is larger than the replay count in the status field. If there is not a replay count (because a store instruction can only be replayed once at a time), then the load instruction is replayed.</p><p>In a second case, the thread ID in the status field equals the thread ID of the store instruction, but the SBID in the status field does not match the SBID of the store instruction. In the second case, the load instruction is replayed if the SBID in the status field is less then the SBID of the store instruction, but not replayed if the SBID in the status field is greater then the SBID of the store instruction.</p><p>In a third case, the thread IDs of the status field and store instruction do not match. It is expected that this is an infrequent case. For simplicity, under one embodiment, the load instruction is replayed (even though it may be contrary to program order). It may be a false replay. The load instruction when replayed will receive the correct store data. Other approaches could be used but they may be far more complex that is justified for such an infrequent case.</p><p>ii. Cases in Which There is Not an Address Match</p><p>If the addresses do not match, then no replay is triggered except in the following infrequent case. If SB Hit=1, the thread ID of the status field matches the thread ID of the store instruction, and the SBID of the status field matches the SBID of the store instruction. In this case, there is a replay and the replayed load instruction receives its data from a new entry or memory.</p><p>c. Reset</p><p>A thread is reset when it is determined that the thread is not in the program order. However, loads from other threads could have taken data from the data field associated with store instructions in that thread. Thread management logic <b>124</b> sends a signal to control circuitry <b>302</b>. In one embodiment, when a thread is reset, the thread ID of the reset thread is compared with every load in every load buffer (except perhaps the load buffer corresponding to the reset thread). A replay is triggered for load instructions where the thread ID in the status field matches the thread ID of the reset thread. The load instructions are replayed from the appropriate trace buffers.</p><p>3. Replay of Store Instructions</p><p>As described above, load instructions are replayed in response to execution of store instructions. In one embodiment, store instructions are replayed in response to register comparisons in the trace buffers that indicate a register value has changed. For example, referring to FIGS. 12 and 13, instr IDs <b>4</b> and <b>5</b> in trace buffer <b>114</b>A, which are store instructions, are shown to be dependent on registers R<b>1</b>-R<b>4</b>.</p><p>4. Replays of Multiple Load Instructions</p><p>It is possible that more than one load instruction in a load buffer will have status field match with a store instruction. In order to avoid complicated logic, one approach is for control circuitry <b>302</b> to detect when there are multiple load address matches and cause all instructions after the earliest load in the trace to be re-executed.</p><p>5. Final Retirement of Load and Store Instructions</p><p>When a load or store instruction is to be finally retired, final retirement logic <b>134</b> provides signals to trace buffers <b>114</b> and MOB <b>184</b> indicating that an instruction is to be finally retired. The entry in the trace buffer (identified by the instr ID and thread ID) is deallocated. In the case of load instructions, the entry in the load buffer (identified by the thread ID and LBID, is deallocated. In the case of load instructions, final retirement is complete. In the case of store instructions, prior to deallocation, the data in the data field must be committed to memory. Deallocation of the entry in the store buffer and hence final retirement does not occur until confirmation is received that the store is complete. Alternatively, the entry may be finally retired before confirmation, but reallocation of the entry cannot occur until confirmation is received. Signals on conductors <b>200</b> can indicate to thread management logic <b>124</b> when the final retirement of stores is complete and the next thread can begin.</p><p>SB Retired indicates that an instruction has been retired. At the time final retirement logic <b>134</b> indicates that an instruction should be retired, a bit in the SB Retired field is asserted. Once the SB Retired field is asserted, the associated instruction is written to memory in order. As soon as MOB <b>184</b>A learns that the instruction has been written to memory, the SB Retired field is deasserted and the instruction is deallocated.</p><p>Load buffer <b>182</b>A and store buffer <b>184</b>A may be queues with a head and a tail. The head is moved when an instruction is deallocated. In load buffer <b>184</b>A, and trace buffers <b>114</b>, retirement and deallocation may occur simultaneously. Final retirement logic <b>134</b> provides signals through conductors <b>136</b> and <b>140</b>. Demux <b>188</b> selects whether one of load buffers <b>182</b> or store buffers <b>184</b> will receive a retirement signals. Demux <b>188</b> is optional and could be replaced by enable ports in load buffers <b>182</b> and store buffers <b>184</b>.</p><h4>F. Additional Information Regarding Thread Management Logic and Final Retirement Logic</h4><p>In one embodiment, thread management logic <b>124</b> uses a tree structure to keep track of thread order. Under the tree structure, the program order (which is also the retirement order) flows from top to bottom, and a node on the right is earlier in program order than a node on the left. A root is the first in program order. A tree is an abstract idea, whereas a tree structure is circuitry that implements the tree.</p><p>Threads begin at the instruction following a backward branch or a function call. That is, threads begin at the next instruction assuming the backward branch were not taken or the function was not called (as illustrated by threads T<b>2</b> in FIGS. <b>4</b> and <b>5</b>). In so doing, from the perspective of a thread (node), the program order of children nodes of the thread are in the reverse of the order in which the threads were started (created). For example, in FIG. 6, in time order, execution of thread T<b>2</b> begins before execution of thread T<b>3</b>, but in program order, thread T<b>3</b> occurs before thread T<b>2</b>.</p><p>In one embodiment, three events may cause a thread to be removed from the tree: (1) A thread at the root of the tree is removed when the thread is retired. When the thread at the root is retired, the thread (node) that is next in program order becomes the root and nodes are reassigned accordingly. (2) A thread that is last in program order is removed from the tree to make room for a thread higher in program order to be added to the tree. In this respect, the tree acts as a last-in-first-out (LIFO) stack. (3) A thread may be reset and thereby removed from the tree when it is discovered that the program counter of its parent thread is outside a range between a start count and an end count. In the case where a child thread is created at a backward branch (e.g., thread T<b>4</b> in FIGS. <b>6</b> and <b>29</b>), the start count is the target of the backward branch and the end count is the program counter value at the backward branch instruction. A thread started after a function call can also be reset because there is no return from the function, although it is quite rare for this to happen. One approach for dealing with the possibility of there being no return from a function is to ignore the possibility and let the system eventually remove the thread from the tree when it becomes the lowest in program order, as in event (2). When a thread is removed from the tree, the resources allocated for that thread (such as a trace buffer, store buffer, and load buffer) are deallocated.</p><p>Events (1) and (3) are illustrated in FIG. 29, which includes the threads of the example of FIG. 6, with the addition of threads T<b>5</b> and T<b>6</b>. Thread T<b>5</b> starts following a backward branch instruction at point J and thread T<b>6</b> starts following a function call at point K. It is assumed that there are only four trace buffers. FIG. 30 illustrates the tree structure at time t<b>1</b>. Thread T<b>2</b> is added to the tree before thread T<b>3</b> is added to the tree. Thread T<b>4</b> is added to the tree after thread T<b>3</b> is added to the tree. Threads T<b>2</b> and T<b>3</b> are children of thread T<b>1</b>. Thread T<b>4</b> is a child of thread T<b>3</b>. Following the rules of top to bottom and right to left, the program and retirement orders are thread T<b>1</b>, T<b>3</b>, T<b>4</b>, and T<b>2</b>. FIG. 31 illustrates the tree structure at time t<b>2</b> assuming that thread T<b>4</b> is reset before thread T<b>1</b> retires. The program and retirement orders are thread T<b>1</b>, T<b>3</b>, T<b>2</b>, and T<b>5</b>. FIG. 32 illustrates the tree structure at time t<b>2</b> assuming that thread T<b>1</b> retires before thread T<b>4</b> is reset. The program and retirement orders are thread T<b>3</b>, T<b>4</b>, T<b>2</b>, and T<b>5</b>. FIG. 33 illustrates the tree structure at time t<b>3</b>, which is after the time thread T<b>1</b> retires and thread T<b>4</b> is reset. The program and retirement orders are T<b>3</b>, T<b>2</b>, T<b>5</b> and T<b>6</b>.</p><p>Event (2) is illustrated in FIG. 34, which includes nested functions. In time order, the threads are created (started) in the order T<b>1</b>, T<b>2</b>, T<b>3</b>, T<b>4</b>, and T<b>5</b>. However, the program order is T<b>1</b>, T<b>5</b>, T<b>4</b>, T<b>3</b>, and T<b>2</b>. In the example, there are only four trace buffers. Therefore, not all five threads exist at the same time. FIG. 35 illustrates the tree structure at time t<b>1</b>, which is before thread T<b>5</b> has started. Program and retirement order are T<b>1</b>, T<b>4</b>, T<b>3</b>, and T<b>2</b>. Thread T<b>5</b> is not yet part of the tree structure. FIG. 36 illustrates the tree structure at time t<b>2</b>, which is after thread T<b>5</b> has started. Thread T<b>2</b>, which is lowest is program order, is removed from the tree structure to make room for thread T<b>5</b>. A thread that is removed from the tree may be restarted at a later time. Alternatively, another thread may execute all or part of the instructions of the thread removed from the tree. In one embodiment, in the case of reset, a thread may seek to join the next following thread rather than the reset thread. Alternatively, the thread may just continue until otherwise ended. The functions of array <b>198</b> may be performed in the nodes of the tree.</p><p>The thread IDs of the children threads are properly positioned according to program order in the tree structure. (Although the program order as determined by thread management logic <b>124</b> might change.) A thread is finished when it joins or matches the program count of the next thread in the tree in program order. If there is only one child of the thread, then that is the next thread in program order. For example, in FIG. 33, thread T<b>2</b> is the next thread in the tree in program order.</p><p>Final retirement logic <b>134</b> gains information from the tree structure to assemble array <b>198</b> or straight from the circuitry of the tree structure. There may be decoding circuitry between the tree structure and other logic of thread management logic <b>124</b> and logic of final retirement logic <b>134</b>. Array <b>198</b> may not be required.</p><p>In summary, the tree structure provides information for at least the following purposes: (1) the tree specifies retirement order; (2) the tree specifies program order, which is used by, for example, MOB <b>178</b> as described above; (3) the tree specifies an end point of a thread by indicating the starting instruction of another thread; (4) the tree is used in thread resource allocation by indicating which resources are available and which resources get deallocated.</p><h4>G. An Embodiment Without Multithreading</h4><p>FIG. 3 illustrates a processor <b>100</b> including a pipeline <b>308</b>. Processor <b>100</b> is similar to processor <b>50</b>. However, a trace buffer <b>300</b> is the only trace buffer and a MOB <b>310</b> is the only MOB. Processor <b>50</b> is not designed to process multiple threads. Therefore, thread management logic is not required for processor <b>100</b>. Trace buffer <b>300</b> may be similar to trace buffer <b>114</b>A, for example, except that multithread specific components are not required. For example, conductors <b>216</b> and output register file <b>210</b> would not be needed. Various circuitry may be used to detect speculation errors, including well known circuitry. MOB <b>310</b> may be similar to MOB <b>178</b>A, for example, except that multithread specific features are not required. For example, a thread ID field would not be needed in the load buffer. Other components of processor <b>100</b> may be modified somewhat with respect to their configuration in processor <b>50</b> to remove multi-threading related features. Trace buffer <b>300</b> and MOB <b>310</b> may be used in connection with various speculations and recovery from errors therein. The trace buffer allows a large number of instructions to be held outside the pipeline for possible replay before final retirement.</p><p>Processor <b>50</b> could be used in connection with a non-multithread program. In that case, thread management logic <b>124</b> could always keep the same thread ID in program order. Alternatively, thread management logic <b>124</b> could be disabled. In the non-multithread case, only one of trace buffers <b>114</b> and only one of the MOBs <b>178</b> are used. Alternatively, trace buffers could be combined to make a larger trace buffer and MOBs could be combined to make a larger MOB.</p><h4>H. Additional Information and Embodiments</h4><p>Referring to FIG. 37, a processor <b>400</b> is a multi-processor (MP) chip including multipipeline unit <b>402</b>. Multi-pipeline unit <b>400</b> differs from shared resource pipeline <b>108</b> of FIG. 2 in that an entire pipeline (e.g., separate rename/allocate unit for each pipeline) is included with each of pipelines <b>0</b>, <b>1</b>, . . . W of multi-pipeline unit <b>402</b>. (W may equal to or more or less than X.) Otherwise, processor <b>400</b> may be essential the same as or very different than processor <b>50</b>. Other processors may include some features of multi-pipeline unit <b>402</b> and some features of pipeline <b>108</b>.</p><p>Each of the processors mentioned herein, may be included in a part of a variety of computer systems. Referring to FIG. 38, merely as an example, processor <b>50</b> may be part of a computer system <b>430</b>. System <b>430</b> may also include a second processor <b>434</b>. An on-chip second level (L<b>2</b>) cache may be including within processor <b>50</b>. Processor <b>50</b> may communicate with a memory controller <b>440</b> through a processor bus <b>442</b>. Memory controller <b>440</b> may communicate with main memory <b>446</b> and peripherals <b>448</b> through buses <b>452</b> and <b>454</b>.</p><p>A pipeline similar to pipeline <b>108</b> or <b>308</b> (in FIGS. 2 and 3) could be used in a processor that does not use register renaming. In such a case, the components that are involved in register renaming (e.g., rename/allocate unit <b>150</b>) could be modified to remove renaming related features.</p><p>The circuits and details that are described and illustrated are only exemplary. Various other circuits and details could be used in their place. Further, there may be various design tradeoffs in size, latency, etc. For example, the maximum operating clock frequency may have to be reduced if buffers in the execution path (e.g., in the reservation station, register file, ROB) are too large. The components illustrated herein may be designed and constructed accordingly to various techniques.</p><p>There may be intermediate structure (such as a buffer) or signals between two illustrated structures. Some conductors may not be continuous as illustrated, but rather be broken up by intermediate structure. The borders of the boxes in the figures are for illustrative purposes. An actual device would not have to include components with such defined boundaries. The relative size of the illustrated components is not to suggest actual relative sizes. Arrows shown certain data flow in certain embodiments, but not every signal, such as data requests. Where a logical high signal is described above, it could be replaced by a logical low signal and vice versa.</p><p>The components illustrated in a processor may all be on the same processor chip. Alternatively, for example, the trace buffers could be on a different chip than the execution pipeline.</p><p>The terms \u201cconnected,\u201d \u201ccoupled,\u201d and related terms are not limited to a direct connection or a direct coupling, but may include indirect connection or indirect coupling. The term \u201cresponsive\u201d and related terms mean that one signal or event is influenced to some extent by another signal or event, but not necessarily completely or directly. If the specification states a component \u201cmay\u201d, \u201ccould\u201d, or is \u201cpreferred\u201d to be included, that particular component is not required to be included.</p><p>A MOB could use data matching rather than address matching to detect misspeculation.</p><p>Those skilled in the art having the benefit of this disclosure will appreciate that many other variations from the foregoing description and drawings may be made within the scope of the present invention. Accordingly, it is the following claims including any amendments thereto that define the scope of the invention.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Haitham", "last_name": "Akkary", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTEL CORPORATION"}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F   9/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F   9/38        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "712216"}, {"primary": false, "label": "712E09048"}, {"primary": false, "label": "712225"}, {"primary": false, "label": "712E09053"}], "ecla_classes": [{"label": "G06F   9/38D4"}, {"label": "G06F   9/38E4"}], "cpc_classes": [{"label": "G06F   9/3834"}, {"label": "G06F   9/3851"}, {"label": "G06F   9/3834"}, {"label": "G06F   9/3851"}, {"label": "G06F  12/10"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1997-12-16", "application_date": "1997-12-16", "family_members": [{"ucid": "KR-20010024751-A", "titles": [{"lang": "KO", "text": "\ube44\uc21c\uc11c\uc801 \uba40\ud2f0\uc2a4\ub808\ub4dc \uc2e4\ud589\uc744 \uc218\ud589\ud558\ub294 \uc801\uc7ac \ubc0f \uc800\uc7a5\uba85\ub839\uc5b4\ub97c \ubc30\uc5f4\ud558\uae30 \uc704\ud55c \uc2dc\uc2a4\ud15c"}, {"lang": "EN", "text": "SYSTEM FOR ORDERING LOAD AND STORE INSTRUCTIONS THAT PERFORMS OUT-OF-ORDER MULTITHREAD EXECUTION"}]}, {"ucid": "WO-1999031594-A1", "titles": [{"lang": "FR", "text": "SYSTEME DE CLASSEMENT D'INSTRUCTIONS DE CHARGEMENT ET DE MEMORISATION PERMETTANT D'EFFECTUER UNE EXECUTION MULTIFILE HORS CLASSEMENT"}, {"lang": "EN", "text": "SYSTEM FOR ORDERING LOAD AND STORE INSTRUCTIONS THAT PERFORMS OUT-OF-ORDER MULTITHREAD EXECUTION"}]}, {"ucid": "KR-100388952-B1", "titles": [{"lang": "EN", "text": "SYSTEM FOR ORDERING LOAD AND STORE INSTRUCTIONS THAT PERFORMS OUT-OF-ORDER MULTITHREAD EXECUTION"}, {"lang": "KO", "text": "\ube44\uc21c\uc11c\uc801 \uba40\ud2f0\uc2a4\ub808\ub4dc \uc2e4\ud589\uc744 \uc218\ud589\ud558\ub294 \uc801\uc7ac \ubc0f \uc800\uc7a5\uba85\ub839\uc5b4\ub97c \ubc30\uc5f4\ud558\uae30 \uc704\ud55c \uc2dc\uc2a4\ud15c"}]}, {"ucid": "CN-1285064-A", "titles": [{"lang": "EN", "text": "System for ordering load and store instructions that performs out-of-order multithread execution"}, {"lang": "ZH", "text": "\u8fdb\u884c\u65e0\u5e8f\u591a\u7ebf\u7a0b\u6267\u884c\u7684\u52a0\u8f7d\u548c\u5b58\u50a8\u6307\u4ee4\u6392\u5e8f\u7cfb\u7edf"}]}, {"ucid": "US-6463522-B1", "titles": [{"lang": "EN", "text": "Memory system for ordering load and store instructions in a processor that performs multithread execution"}]}, {"ucid": "BR-9813653-A", "titles": [{"lang": "PT", "text": "Sistema para ordena\u00e7\u00e3o de instru\u00e7\u00f5es de carga e armazenamento que realiza uma execu\u00e7\u00e3o de multilinha fora de ordem"}, {"lang": "EN", "text": "System for ordering loading and storage instructions that performs an out-of-order multiline execution"}]}, {"ucid": "CN-100392622-C", "titles": [{"lang": "ZH", "text": "\u5177\u6709\u5b58\u50a8\u5668\u987a\u5e8f\u7f13\u51b2\u5668\u7684\u5904\u7406\u5668"}, {"lang": "EN", "text": "System for ordering load and store instructions that performs out-of-order multithread execution"}]}, {"ucid": "US-20020194457-A1", "titles": [{"lang": "EN", "text": "Memory system for ordering load and store instructions in a processor that performs out-of-order multithread execution"}]}, {"ucid": "AU-1911199-A", "titles": [{"lang": "EN", "text": "System for ordering load and store instructions that performs out-of-order multithread execution"}]}, {"ucid": "EP-1040423-A4", "titles": [{"lang": "DE", "text": "ORDNUNGSSYSTEM F\u00dcR LADE/SPEICHERBEFEHLE ZUM DURCHF\u00dcHREN VON NICHT SEQUENTIELLEN MEHRFACHEN PROGRAMMBEFEHLEN"}, {"lang": "FR", "text": "SYSTEME DE CLASSEMENT D'INSTRUCTIONS DE CHARGEMENT ET DE MEMORISATION PERMETTANT D'EFFECTUER UNE EXECUTION MULTIFILE HORS CLASSEMENT"}, {"lang": "EN", "text": "SYSTEM FOR ORDERING LOAD AND STORE INSTRUCTIONS THAT PERFORMS OUT-OF-ORDER MULTITHREAD EXECUTION"}]}, {"ucid": "EP-1040423-A1", "titles": [{"lang": "FR", "text": "SYSTEME DE CLASSEMENT D'INSTRUCTIONS DE CHARGEMENT ET DE MEMORISATION PERMETTANT D'EFFECTUER UNE EXECUTION MULTIFILE HORS CLASSEMENT"}, {"lang": "EN", "text": "SYSTEM FOR ORDERING LOAD AND STORE INSTRUCTIONS THAT PERFORMS OUT-OF-ORDER MULTITHREAD EXECUTION"}, {"lang": "DE", "text": "ORDNUNGSSYSTEM F\u00dcR LADE/SPEICHERBEFEHLE ZUM DURCHF\u00dcHREN VON NICHT SEQUENTIELLEN MEHRFACHEN PROGRAMMBEFEHLEN"}]}, {"ucid": "JP-2002508568-A", "titles": [{"lang": "JA", "text": "\u4e0d\u9069\u6b63\u9806\u5e8f\u30de\u30eb\u30c1\u30b9\u30ec\u30c3\u30c9\u5b9f\u884c\u3092\u5b9f\u884c\u3059\u308b\u30ed\u30fc\u30c9\u547d\u4ee4\u304a\u3088\u3073\u30b9\u30c8\u30a2\u547d\u4ee4\u3092\u9806\u5e8f\u4ed8\u3051\u308b\u30b7\u30b9\u30c6\u30e0"}, {"lang": "EN", "text": "System for ordering load and store instructions that perform out-of-order multithreaded execution"}]}, {"ucid": "JP-3957456-B2", "titles": [{"lang": "JA", "text": "\u4e0d\u9069\u6b63\u9806\u5e8f\u30de\u30eb\u30c1\u30b9\u30ec\u30c3\u30c9\u5b9f\u884c\u3092\u5b9f\u884c\u3059\u308b\u30ed\u30fc\u30c9\u547d\u4ee4\u304a\u3088\u3073\u30b9\u30c8\u30a2\u547d\u4ee4\u3092\u9806\u5e8f\u4ed8\u3051\u308b\u30b7\u30b9\u30c6\u30e0"}, {"lang": "EN", "text": "System for ordering load and store instructions that perform improperly ordered multithreaded execution"}]}, {"ucid": "TW-425528-B", "titles": [{"lang": "EN", "text": "Memory system for ordering load and store instructions in a processor that performs out-of-order multithread execution"}]}]}