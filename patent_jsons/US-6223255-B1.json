{"patent_number": "US-6223255-B1", "publication_id": 72656190, "family_id": 27010020, "publication_date": "2001-04-24", "titles": [{"lang": "EN", "text": "Microprocessor with an instruction level reconfigurable n-way cache"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11180221\" source=\"national office\"><p>A microprocessor includes a multiply-accumulate unit (MAU) for performing high-speed signal processing operations. First and second caches provide first and second operands (x, y) directly to the MAU when a multiply-accumulate (MAC) instruction is executed. In addition, a multiplexer is included to select data from either the first and second caches when a normal instruction is executed. A translation look-aside buffer may be included that has page table entries that include additional \"reconfigure\" and \"way\" bits to control writing data into the caches. In this manner, the microprocessor may use a conventional n-way set-associative cache to simultaneously access two or more operands.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72547274\"><p>A microprocessor includes a multiply-accumulate unit (MAU) for performing high-speed signal processing operations. First and second caches provide first and second operands (x, y) directly to the MAU when a multiply-accumulate (MAC) instruction is executed. In addition, a multiplexer is included to select data from either the first and second caches when a normal instruction is executed. A translation look-aside buffer may be included that has page table entries that include additional \u201creconfigure\u201d and \u201cway\u201d bits to control writing data into the caches. In this manner, the microprocessor may use a conventional n-way set-associative cache to simultaneously access two or more operands.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00001\" num=\"1\"><claim-text>1. A data processor comprising:</claim-text><claim-text>an instruction register; </claim-text><claim-text>an n-way set-associative cache, comprising n subcaches, where n is an integer greater than 1; </claim-text><claim-text>a functional unit that operates on a first operand and a second operand when an instruction is executed; </claim-text><claim-text>a first signal path from a first subcache of the said n subcaches to supply the first operand to the functional unit; </claim-text><claim-text>a second signal path from a second subcache of the said n subcaches to supply the second operand to the functional unit simultaneously with the first operand when certain instructions are executed; and </claim-text><claim-text>a multiplexer for selecting data from one of the subcaches when other instructions are executed. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00002\" num=\"2\"><claim-text>2. The data processor of claim <b>1</b>, further comprising a translation look-aside buffer having page table entries which include a reconfigure field that controls whether a regular cache line replacement algorithm is to be used or a special cache line replacement scheme is to be used.</claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00003\" num=\"3\"><claim-text>3. The data processor of claim <b>2</b>, wherein the page table entries further include a way field that provides that a first set of data is written into an even-way subcache, and a second set of data is written into an odd-way subcache.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00004\" num=\"4\"><claim-text>4. The data processor of claim <b>1</b>, wherein the instruction register includes at least one control bit to control writing of data into the n-way set-associate cache.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00005\" num=\"5\"><claim-text>5. The data processor of claim <b>1</b>, wherein the certain instructions include a multiply-accumulate instruction.</claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00006\" num=\"6\"><claim-text>6. The data processor of claim <b>1</b>, wherein the functional unit is an arithmetic logic unit.</claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00007\" num=\"7\"><claim-text>7. The data processor of claim <b>6</b>, wherein the arithmetic logic unit is a multiply-accumulate unit.</claim-text></claim>"}, {"num": 8, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00008\" num=\"8\"><claim-text>8. A data processor comprising:</claim-text><claim-text>a data memory having a first cache and a second cache; </claim-text><claim-text>a multiply-accumulate unit that operates on a first operand and a second operand simultaneously when a multiply-accumulate instruction is executed; </claim-text><claim-text>a first signal path from the first cache for supplying the first operand to the multiply-accumulate unit; </claim-text><claim-text>a second signal path from the second cache for supplying the second operand to the multiply-accumulate unit; and </claim-text><claim-text>a multiplexer for selecting data from either the first cache or the second cache when other instructions are executed. </claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00009\" num=\"9\"><claim-text>9. The data processor of claim <b>8</b>, further comprising a translation look-aside buffer having page table entries, wherein a reconfigure field of the page table entries controls how the data is written into the first and second caches.</claim-text></claim>"}, {"num": 10, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00010\" num=\"10\"><claim-text>10. The data processor of claim <b>9</b>, wherein the page table entries further comprise a way field that indicates whether a first set of data is written into the first cache as an even-way direct-mapped cache, and a second set of data is written into the second cache as an odd-way direct mapped cache.</claim-text></claim>"}, {"num": 11, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00011\" num=\"11\"><claim-text>11. A data processing system including a data processor, comprising:</claim-text><claim-text>an instruction register; </claim-text><claim-text>an n-way set-associative cache where n is an integer greater than 1 and which includes a first cache and a second cache; </claim-text><claim-text>a functional unit that operates on a first operand and a second operand when an instruction is executed; </claim-text><claim-text>a first signal path from the first cache for supplying the first operand to the functional unit; </claim-text><claim-text>a second signal path from the second cache for supplying the second operand to the functional unit simultaneously with the first operand when a special type of instruction is executed; </claim-text><claim-text>a multiplexer for selecting data from either the first cache or the second cache when another type of instruction is executed; </claim-text><claim-text>a translation look-aside buffer having page table entries which include a reconfigure field that controls how the data is written into the n-way set-associative cache, and a way field that provides that a first set of data is written to an even-way cache, and a second set of data is written into an odd-way cache; and </claim-text><claim-text>an operating system which sets the reconfigure bit and the way bit. </claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00012\" num=\"12\"><claim-text>12. The data processor of claim <b>11</b>, wherein the special type of instruction includes a multiply-accumulate instruction.</claim-text></claim>"}, {"num": 13, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00013\" num=\"13\"><claim-text>13. The data processor of claim <b>11</b>, wherein the functional unit is an arithmetic logic unit.</claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6223255-B1-CLM-00014\" num=\"14\"><claim-text>14. The data processor of claim <b>13</b>, wherein the arithmetic logic unit is a multiply-accumulate unit.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54535041\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><p>This is a Continuation-In-Part of application Ser. No. 08/870,013 filed Feb. 3, 1997 now abandoned which in turn is a continuation of application Ser. No. 08/383,037 filed Feb. 3, 1995, now abandoned. The entire disclosure of the prior applications is hereby incorporated by reference herein in its entirety.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. Field of Invention</p><p>This invention relates to a microprocessor having a reconfigurable n-way cache to provide increased bandwidth for signal processing as well as general purpose applications.</p><p>2. Description of Related Art</p><p>There is a fundamental difference in the way microprocessor and digital signal processors (DSP) are designed and used in system realization. Whereas microprocessors are designed to execute general purpose applications as efficiently as possible, digital signal processors (DSPs) are designed to execute only specific applications (such as speech processing) as efficiently as possible. Systems based on microprocessors are designed to run any general application. Some of these applications may not be run on the system until years after the system was shipped. On the other hand, systems based on a DSP are designed to run, in general, only a small set of specific applications, e.g., a telephone answering machine runs only a specific application throughout its lifetime. Once a system based on a DSP is shipped, typically, no new applications are run on it.</p><p>Due to this difference in the way microprocessors and DSPs are used, the design styles for these two types of processors have evolved quite differently. However, both processors are designed to provide high performance cost effectively.</p><p>Many conventional processors have multi-ported register files, and are therefore capable of providing two or more operands contained in registers to the execution unit (EU) every cycle. The register files are contained on the same integrated circuit as the arithmetic logic unit (ALU), and are very fast devices for providing the desired data. For example, referring to FIG. 1, a typical prior-art microprocessor <b>100</b> includes an instruction register <b>101</b> that supplies a first address (ADDR<b>0</b>) to a first register file <b>102</b>, and a second address (ADDR<b>1</b>) to a second register file <b>103</b>. The register files <b>102</b> and <b>103</b> illustratively have 32 entries of 32 bits each. The first register file <b>102</b> supplies a first operand to a first operand register <b>104</b>. The second register file <b>103</b> supplies a second operand to a second operand register <b>105</b>. The registers <b>104</b> and <b>105</b> supply the first and second operands to the arithmetic logic unit (ALU) <b>106</b>, which may perform various arithmetic operations, illustratively including a multiply-accumulate (MAC) operation. The result is stored in the result register <b>107</b>, and may be written back into the register files via a signal line <b>108</b>. In an alternate embodiment, a single dual-ported register file (not shown)is used in lieu of the two register files <b>102</b> and <b>103</b>. In that case, two read ports allow simultaneous access to any two entries in the register file.</p><p>Although a register file provides efficient temporary storage, memory organization plays a critical role in determining the performance of microprocessors and DSPs. This is because the performance is determined by how efficiently instructions and data are accessed from the memory. Since speed of discrete memories has not kept pace with the processor speeds, typically, on-chip storage is provided for both instructions and data. Microprocessors and DSPs differ in the way in which this on-chip memory is organized.</p><p>There are many instances where it is necessary to supply two operands, contained in memory, that are not already in the on-chip registers. An example is a multiply-accumulated instruction which is one of the basis primitives of signal processing. A typical instruction is</p><p><maths><formula-text>MAC x, y, a<b>0</b></formula-text></maths></p><p>where MAC is the mnemonic for the instruction \u201cmultiply accumulate\u201d and the operation specified is:</p><p><maths><formula-text><i>a</i>0=<i>a</i>0+(<i>x*y</i>)</formula-text></maths></p><p>Typically, x and y belong to specific arrays in the memory. For example, x may be located in a coefficient array and y may be located in a data array.</p><p>The two memory operands x and y are typically contained in an on-chip data memory, if available, or in a memory external to the microprocessor chip. In either case, supplying two operands to the ALU every cycle implies dual-porting the data memory.</p><p>FIG. 2 shows an example of a DSP <b>200</b> having two banks of on-chip memory. An instruction register <b>201</b> supplies first and second addresses (ADDR<b>0</b>, ADDR<b>1</b>) to a first bank <b>202</b> and a second bank <b>203</b> of the RAM, where each bank <b>202</b> and <b>203</b> is illustratively 1 kilobyte in size. The data is written to the RAM via a write line <b>213</b>. The first operand is read from the bank <b>202</b> and output to a multiplexer <b>204</b>. Similarly, the second operand is read from the second bank <b>203</b> and output to a multiplexer <b>206</b>. Assuming the multiplexers <b>204</b> and <b>206</b> select the outputs of the RAM banks <b>202</b> and <b>203</b>, the first operand is then latched into a first operand register <b>205</b>, while the second operand is then latched into a second operand register <b>207</b>. Alternatively, the operands may be selected by the multiplexers <b>204</b> and <b>206</b> from an external memory bus <b>212</b>.</p><p>The operands are then provided from the operand registers <b>205</b> and <b>207</b> to the ALU/MAC unit <b>208</b>, where they are multiplied together and added to the previous result accessed from an accumulator file <b>210</b> via a second line <b>214</b>. The result is provided to the result register <b>209</b> and stored in the accumulator file <b>210</b>.</p><p>Although this technique provides for the multiply/accumulate function within a conventional DSP architecture, there are disadvantages of this approach. For example, since the on-chip memory is configured as RAM rather than as a cache memory, only selected applications can utilize it. All the data addresses in the memory have to be determined when the application program is developed. Thus, conventional microprocessor applications cannot make flexible use of this memory. Furthermore, it is difficult to run applications from different vendors that are installed in the field.</p><p>Since any application may be run on a microprocessor-based system, its characteristics are not known in advance. On-chip caches are conventionally used in microprocessors to improve performance. The cache works based on temporal locality and spatial locality. Temporal locality means that once a given memory location is used, it is likely that it may be used in the near future. Spatial locality means that once a memory location is used, it is likely that locations in the vicinity of that location may be used in the near future.</p><p>FIG. 3 shows a schematic diagram of a 2-way set-associative cache and how it is addressed, as described in <i>Computer Architecture: A Quantitative Approach</i>, J. L. Hennessy and D. A. Patterson, Morgan Kaufmann Publishers, Inc. pp. 408-414, 1990 (<i>Computer Architecture</i>) . The cache includes data portions <b>305</b> and <b>306</b> and tag portions <b>307</b> and <b>308</b>. The cache has n blocks or lines. A block typically includes more than one byte of storage. A byte within a block is addressed by the block offset field <b>304</b> of the address <b>301</b>. For example, if the block size is 8 bytes, block offset field is 3 bits. The index field <b>303</b> of the address <b>301</b> is used to select the set in the cache. Each set in a 2-way associative cache has two blocks. The block frame address <b>302</b> is stored in the tag portion associated with the data portion where the block is stored. When a cache block is first written, a set is specified by the index <b>303</b> portion of the address. The block within the set is determined by a selection algorithm, such as, random replacement or least recently used (LRU). Once a block is selected, the block frame address <b>302</b> is written in the tag portion <b>307</b> or <b>308</b> and the block from memory is written in the data portion <b>305</b> or <b>306</b> corresponding to the selected block. A special bit is provided in the tag portions <b>307</b> and <b>308</b> to indicate that a given entry in the cache contains valid data. In general, there are other control bits in the tag portions <b>307</b> and <b>308</b> to store other information, such as privilege level, etc.</p><p>At a later time, the processor may request data at a specified memory address <b>301</b>. In order to check whether a specific data address \u201chits\u201d in (i.e., is in) the cache, the index <b>303</b> portion of the address is used to select the set. For a 2-way associative cache, there are two sets of tags <b>307</b> and <b>308</b> and data <b>305</b> and <b>306</b>, which are accessed simultaneously using the index <b>303</b>. The two output tags <b>307</b> and <b>308</b> are compared with the block frame address <b>302</b> using the comparators <b>309</b> and <b>310</b>. If neither tag <b>307</b> or <b>308</b> equals the block frame address <b>302</b>, a cache miss has occurred. On the other hand, if one of the tags <b>307</b> or <b>308</b> is equal to the block frame address <b>302</b> and the valid bit is set, a cache hit has occurred, and the data corresponding to the matching tag is correct data that is selected by a multiplexer <b>311</b> using the hit signals. The appropriate byte(s) within the data <b>312</b> are then accessed using the block offset field <b>304</b>.</p><p>A cache that has only one block per set is referred to as a direct mapped cache. Furthermore, a cache that has n blocks per set is referred to as a n-way set-associative cache.</p><p>Conventionally, virtual memory is used to appear to the application as much more memory than is physically available. This is achieved through secondary storage, such as a disk drive. Thus, an application generates virtual instruction and data addresses. These addresses are translated using page directory and page table entries and hardware table walk. For faster translation, virtual address-to-physical address translations are cached in an on-chip memory called a Translation Look-aside Buffer (TLB), as described in <i>Computer Architecture</i>, pp. 432-449.</p><p>A major advantage of caches is that they adapt to the dynamics of the application being run, based on temporal and spatial locality. A major disadvantage of caches is that there is some uncertainty about whether a given location is guaranteed to be in the cache. Events, such as an interrupt, may change the execution flow and \u201cpollute\u201d the cache. If required memory locations are not guaranteed to be on-chip, the computation may not be completed in the time allocated. This may not be acceptable for DSP applications.</p><p>Accordingly, DSPs conventionally do not use on-chip cache for instruction and data storage. Since a small set of applications run on a DSP, the instructions are typically contained in an on-chip ROM. Furthermore, since the data storage requirements for DSP applications are known in advance, the data is allocated in on-chip memory banks. On-chip cache differs from on-chip memory banks in that on-chip cache can store data at any absolute memory location, whereas an on-chip memory bank stores data only at specified memory locations.</p><p>Recently, a new class of devices, called Personal Communicators, are becoming available. These devices integrate communications capabilities, such as voice, data, and fax communications using a cellular phone, with personal organizers. These devices currently use a separate DSP for communications tasks and a general purpose microprocessor for the other tasks.</p><h4>SUMMARY OF THE INVENTION</h4><p>This invention provides a data processor having a cache with an n-way associativity, wherein a first operand is located in a first portion of the cache and a second operand is located in a second portion of the cache. The outputs of the first and second portions of the cache are provided to a functional unit when a given instruction type is executed. The functional unit is, for example, a multiply-accumulate unit. The instruction type is, for example, a multiply-accumulate unit instruction. A multiplexer is connected to the outputs of the first and second portions of the cache. Therefore, operands can be retrieved from either portion when the cache is to be accessed as a conventional set-associative cache for executing other types of instructions. For controlling writing into the cache, a translation look-aside buffer may include a page table entry having a reconfigure field. Alternatively, other methods may be used.</p><p>This invention enables a two (or more)-way set associative cache to be used in a conventional way for general purpose computing applications. Furthermore, the same cache, with modest additional hardware, can be used to provide two memory operands simultaneously.</p><p>These and other features and advantages of this invention are described in or are apparent from the following detailed description of the preferred embodiment.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>The preferred embodiments of this invention will be described in detail, with reference to the following figures, wherein:</p><p>FIG. 1 shows a conventional microprocessor having two register files for storing operands;</p><p>FIG. 2 shows a conventional digital signal processor having an on-chip random access memory comprising multiple banks for storing operands;</p><p>FIG. 3 shows a conventional 2-way set associative cache;</p><p>FIG. 4 shows an illustrative embodiment of a microprocessor according to this invention;</p><p>FIG. 5 shows an illustrative page table entry according to this invention; and</p><p>FIG. 6 shows an illustrative translation lookaside buffer usable in implementing this invention.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</h4><p>FIG. 4 shows an illustrative embodiment of a microprocessor using the reconfigurable set-associative cache of this invention. In particular, the cache is a 2-way set-associative cache. The microprocessor also has a dual port register file. In a first configuration, the cache provides one operand. In a second configuration, the cache provides two or more operands simultaneously to an arithmetic processor when an instruction that requires high data bandwidth is performed. As used herein, \u201csimultaneously\u201d means in the same \u201cmachine\u201d cycle, which may comprise one or more \u201cclock\u201d cycles. One such instruction is the \u201cmultiply-accumulate\u201d instruction. In this manner, fast multiply-accumulate operations may be implemented in a general-purpose microprocessor. The cache of this invention is preferably an n-way set-associative cache, and techniques of this invention allow the n-way set-associative cache to be used as two or more direct-mapped caches. Reconfiguring the cache from the n-way set-associative cache to the plurality of direct-mapped caches, and vice-versa, may be accomplished on a per-instruction basis. As used herein, the cache portions are also referred to as \u201ccache way 0\u201d , \u201ccache way 1\u201d, or more generally as \u201ccache way n\u201d, wherein n is a positive integer.</p><p>The instruction register <b>414</b> illustratively contains a machine instruction <b>413</b> for the processor. ADDR<b>0</b> and ADDR<b>1</b> provide two addresses and the opcode indicates the operation to be performed (e.g. add, subtract, etc.). If ADDR<b>0</b> and ADDR<b>1</b> refer to data from the register files <b>428</b> and <b>429</b>, the corresponding data is accessed from the register files <b>428</b> and <b>429</b> via the data output lines <b>432</b> and <b>433</b>. A multiplexer <b>410</b> passes the data on the signal line <b>432</b> or the data on a signal line <b>425</b> to a first input of a multiplier <b>406</b> of an ALU <b>405</b>, via a signal line <b>403</b>. At the same time, a multiplexer <b>411</b> passes data on the signal lines <b>425</b> or <b>427</b> to a multiplexer <b>430</b> on a signal line <b>404</b>. The multiplexer <b>430</b> passes data on the signal line <b>433</b> or the signal line <b>404</b> to a second input of the multiplier <b>406</b> via a signal line <b>431</b>. The operation indicated by the opcode of the instruction <b>413</b> is carried out in the ALU <b>405</b>. The result output from the multiplier <b>406</b> and/or the accumulator <b>407</b> is written to the result register <b>498</b>, and may be mapped in the register files <b>428</b> and <b>429</b> (via paths not shown). The result may also be written to the external memory via an external memory bus <b>434</b>. As indicated above, the register files <b>428</b> and <b>429</b> together may form a dual ported register file.</p><p>The instruction register <b>414</b> may store an instruction such that ADDR<b>1</b> refers to a memory operand, and ADDR<b>0</b> may be a memory or a register operand. In this case, as described above with respect to FIG. 2, the index portion of ADDR<b>1</b> is used to access tag and data within the same set from a cache <b>401</b> and a cache <b>402</b>. Assuming ADDR<b>1</b> is a virtual address, corresponding upper address bits are translated by the TLB <b>418</b>. These upper address bits form the block frame address. This address is compared to the tag from cache <b>401</b> and cache <b>402</b> via equality comparators <b>420</b> and <b>421</b>. If the comparison is valid, the corresponding cache <b>401</b> or <b>402</b> has valid data. The left hit (LHIT) and right hit (RHIT) signals on the signal lines <b>496</b> and <b>497</b>, respectively, are used to control the multiplexer <b>411</b> to select one of the data signal lines <b>425</b> and <b>427</b> and to control the multiplexer <b>410</b> to select one of the data signal lines <b>432</b> and <b>425</b> via the Access Control <b>424</b>. The multiplexer <b>430</b> outputs the data on the signal line <b>404</b> to the second input of the multiplier <b>406</b> via the signal line <b>431</b>. It should be appreciated that, in contrast, in a conventional cache, only one memory operand is fetched at a time.</p><p>The data is stored into the cache <b>401</b> and the cache <b>402</b> via a signal line <b>435</b> after the multiplexer <b>436</b> selects as an input either the external memory bus <b>499</b> or the output from the result register <b>498</b> via a signal line <b>434</b>.</p><p>Signal processing requires accessing two operands simultaneously, e.g., for a multiply accumulate instruction, from memory, as described above. One of the operands may be the coefficient and the other operand may be data, e.g., for dot product computation. In this invention, the cache is used by both general purpose applications as well as signal processing applications as described below.</p><p>It is assumed that the processor runs either a general purpose application or a signal processing application at any given instant. If a general purpose application is being run, the cache functions as a conventional 2-way set associative cache as described above. If, on the other hand, a signal processing application is being run, the cache is used as two direct mapped caches.</p><p>The data output from the cache <b>401</b> and the cache <b>402</b> is provided to the ALU <b>405</b> via the data lines <b>403</b> and <b>431</b>, respectively. In addition to the data input via the signal lines <b>403</b> and <b>431</b> to the multiplier <b>406</b>, the ALU <b>405</b> also receives accumulator data via a signal line <b>408</b> from the accumulator file <b>412</b>, which is input directly to the accumulator <b>407</b>. The ALU <b>405</b> is a multiply-accumulate unit and comprises the multiplier <b>406</b> and the accumulator <b>407</b> for illustrative purposes only. However, the ALU <b>405</b> may be of various designs, including those known in the art. When a multiply-accumulate instruction is executed, the ALU <b>405</b> is instructed to perform the multiply-accumulate function on the operand x accessed from the cache <b>401</b> via the multiplexer <b>410</b>, and the operand y accessed from the cache <b>402</b> via the multiplexer <b>411</b> and the multiplexer <b>430</b>. However, when another type of instruction is being executed that does not require simultaneous operands from the cache <b>401</b> and the cache <b>402</b>, the multiplexer <b>411</b> selects the cache <b>401</b> or the cache <b>402</b>, if there is a cache hit. In this case, the cache is access as a conventional 2-way set-associative cache.</p><p>The instruction register <b>414</b> may encode an instruction that refers to two memory operands referred to by addresses ADDR<b>0</b> and ADDR<b>1</b>. This instruction indicates that the 2-way set-associative cache is to be treated as two direct mapped caches. ADDR<b>0</b> and ADDR<b>1</b> refer to elements of two arrays X and Y and the operation being performed may be a \u201cdot product\u201d of these two arrays. As will be described below, the two arrays will be loaded such that all the elements of the x array will be guaranteed to be in cache <b>401</b> and those of the y array will be guaranteed to be in cache <b>402</b>.</p><p>An index portion of ADDR<b>1</b> is used to access the corresponding cache <b>402</b> and, as described above, the data and tag portion is accessed. The block frame address part of ADDR<b>1</b> is translated from a virtual address to a physical address by the TLB <b>418</b> and is then compared to the tag from the cache <b>402</b> via the comparator <b>421</b>. If there is a match, and the valid bit is set, the RHIT signal is output from the comparator <b>421</b> via signal line <b>497</b>, and indicates the availability of the data. The special nature of the instruction forces the multiplexer <b>411</b> to select the data output from the cache <b>402</b> via the signal line <b>427</b>, which is then supplied as the operand y via the signal line <b>431</b> through the multiplexer <b>430</b>. The index portion of ADDR<b>0</b> is selected by the multiplexer <b>416</b> and forwarded to the cache <b>401</b> to access the data and tag portion. The TLB <b>417</b> is used to translate the block frame address from a virtual address to a physical address. This physical tag is then compared to the tag from the cache <b>401</b> via the comparator <b>420</b>. If there is a match, and the valid bit is set, the LHIT signal is output from the comparator <b>420</b> via the signal line <b>496</b>, and indicates the availability of the data on the signal line <b>425</b>. This data is supplied as the operand x by the multiplexer <b>410</b> selecting the data on the signal line <b>425</b> and supplying the data via the signal line <b>403</b>.</p><p>It should be appreciated that the illustrative embodiment is for a 2-way set-associative cache. However, this invention may be implemented for any n-way set-associative cache, where n is any positive integer. n is illustratively an even integer in the following discussion (and illustratively n=2), but n may be an odd integer. In general, this may be accomplished using a multiplexer having n-inputs, one from each cache portion. When n is greater than 2, the distribution of the n ways for accessing the two operands is determined by the specific implementation, any of which may be used with this invention. In addition, when the cache is configured as a conventional n-way set associative cache, the replacement algorithm for the cache may be accomplished using any technique insofar as this invention is concerned.</p><p>How the data for the x array is guaranteed to be in the cache <b>401</b> and that for the y array is guaranteed to be in the cache <b>402</b> is now described. As is known in the art, memory management page translations are used to translate virtual addresses to physical addresses, and also to control cache operation. The page tables are cached in the translation look-aside buffer (TLB), which converts virtual memory addresses into physical memory addresses. The TLB also provides control information for memory pages, and determines whether a given page is cacheable. FIG. 5 shows an illustrative page table entry of the TLBs <b>417</b> and <b>418</b>. The page table entry includes a page frame address in a field <b>41</b> (bits <b>12</b> to <b>31</b>). Bits <b>12</b>-<b>31</b> are the most significant bits of the address. The page frame address is used to determine whether the desired address is located within the cache, in which case a cache \u201chit\u201d is indicated by the LHIT signal via the signal line <b>496</b>, or the RHIT signal via the signal line <b>497</b>, as shown in FIG. <b>4</b>. The field <b>42</b> may include unused bits. The field <b>45</b> typically includes \u201cpermission\u201d bits that control whether the data in the memory page is writable, valid, cacheable, and/or user-accessible. These fields may be in any order insofar as this invention is concerned.</p><p>FIG. 6 shows a TLB which includes the illustrative page frame address as a physical tag <b>602</b> and control bits <b>603</b>, along with the virtual tag <b>601</b>. In this manner, the virtual address <b>601</b> is translated into a physical address <b>602</b> according to principles known in the art.</p><p>To implement the inventive technique as described above, one or more additional control bits may be included in the memory management page tables, as shown in FIG. <b>5</b>. For example, the field <b>43</b> may include an even/odd \u201cway\u201d bit that indicates how data is to be written into the caches <b>401</b> and <b>402</b>. The field <b>44</b> may include a \u201creconfigure\u201d bit. When the reconfigure bit is \u201c0\u201d, the cache is treated as a conventional 2-way set-associative cache. That is, the data is written into the cache <b>401</b> and the cache <b>402</b> using the chosen cache entry replacement scheme. On the other hand, when the reconfigure bit is \u201c1\u201d, the 2-way set-associative cache is treated as two direct-mapped caches. In this case, data is written to even-way cache portions if the way bit in field <b>43</b> is \u201c0\u201d, and is written to odd-way cache portions if the way bit in field <b>43</b> is \u201c1\u201d. In this manner, the data is placed into the appropriate cache portions to serve as the x and y operands for executing a multiply-accumulate instruction, or other special type of instruction, by the ALU <b>405</b>. In the presence of an operating system (OS), a user program may direct the OS to set the \u201creconfigure bit\u201d and \u201cway bit\u201d via a special function call. In this manner, a data processing system including both a data processor and the operating system may advantageously utilize this inventive technique.</p><p>By convention, the left operand (i.e., the operand x in the above example) is fetched from the cache <b>401</b>, and the right operand (i.e., the operand y in the above example) is fetched from the cache <b>402</b>. However, other conventions are possible. Furthermore, still other techniques for controllably writing data into the cache <b>401</b> and the cache <b>402</b> are usable with this invention. For example, an instruction which loads the cache could explicitly specify which portion of the cache the data should be written into. To accomplish this, one or more \u201cway\u201d bits may be included in the instruction register <b>413</b> of FIG. <b>4</b>. In that case, a memory management unit and the TLBs <b>417</b> and <b>418</b> may not be necessary. Also, the distribution of the x and y data need not be separated into even and odd way caches, but could be distributed among the caches in any convenient manner. Finally, more than two operands may be fetched simultaneously from the caches for various operations performed by the functional unit, as will be apparent to persons of skill in the art.</p><p>While the data processor of this invention is typically of the type conventionally referred to as a \u201cmicroprocessor\u201d, still other designations and types are possible. For example, a special purpose computer, a programmable microprocessor, a micro-controller and peripheral integrated circuit elements, an ASIC or other integrated circuit, a hardware electronic or logic circuit such as a discrete element circuit, a programmable logic device such as a PLD, PLA or PAL, or the like may be used.</p><p>While this invention has been described in conjunction with the specific embodiments outlined above, it is evident that many alternatives, modifications and variations will be apparent to those skilled in the art. Accordingly, the preferred embodiments of the invention as set forth above are intended to be illustrative, not limiting. Various changes may be made without departing from the spirit and scope of the invention as defined in the following claims.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Pramod V.", "last_name": "Argade", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "LUCENT TECHNOLOGIES"}, {"first_name": "", "last_name": "AGERE SYSTEMS LLC", "name": ""}, {"first_name": "", "last_name": "LSI CORPORATION", "name": ""}, {"first_name": "", "last_name": "AVAGO TECHNOLOGIES GENERAL IP (SINGAPORE) PTE. LTD.", "name": ""}, {"first_name": "", "last_name": "DEUTSCHE BANK AG NEW YORK BRANCH, AS COLLATERAL AGENT", "name": ""}, {"first_name": "", "last_name": "LUCENT TECHNOLOGIES, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/08"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMUS"}, {"label": "G06F   9/38        20060101A I20051008RMEP"}, {"label": "G06F  12/10        20060101A N20051008RMEP"}, {"label": "G06F   9/302       20060101A I20051008RMEP"}, {"label": "G06F   9/345       20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711129"}, {"primary": false, "label": "711173"}, {"primary": false, "label": "711120"}, {"primary": false, "label": "712E09046"}, {"primary": false, "label": "711170"}, {"primary": false, "label": "711E12018"}, {"primary": false, "label": "712E09017"}, {"primary": false, "label": "711128"}, {"primary": false, "label": "712E09039"}, {"primary": false, "label": "711E12045"}], "ecla_classes": [{"label": "G06F   9/30A1A"}, {"label": "G06F   9/345"}, {"label": "G06F  12/08B10"}, {"label": "S06F12:10L4P"}, {"label": "G06F   9/38D"}, {"label": "G06F  12/08B6M"}], "cpc_classes": [{"label": "G06F  12/0864"}, {"label": "G06F  12/1054"}, {"label": "G06F  12/1054"}, {"label": "G06F   9/345"}, {"label": "G06F   9/3001"}, {"label": "G06F  12/0846"}, {"label": "G06F   9/3824"}, {"label": "G06F   9/3001"}, {"label": "G06F   9/3824"}, {"label": "G06F  12/0864"}, {"label": "G06F  12/0846"}, {"label": "G06F   9/345"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1995-02-03", "application_date": "1998-01-05", "family_members": [{"ucid": "US-6223255-B1", "titles": [{"lang": "EN", "text": "Microprocessor with an instruction level reconfigurable n-way cache"}]}]}