{"patent_number": "US-6516386-B1", "publication_id": 73307798, "family_id": 21699498, "publication_date": "2003-02-04", "titles": [{"lang": "EN", "text": "Method and apparatus for indexing a cache"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50445719\"><p>A method for indexing a cache includes searching on a cache index using a partial physical address, the partial physical address including any bits of the virtual address which are untranslated between the virtual address and the physical address. The partial physical address is used to identify a block of the cache index sets that might contain an address of requested data. The identification is performed prior to translation of the virtual address to the physical address. Once identified, the block is read out into an auxiliary memory structure. After the full physical address becomes available, the block is multiplexed down to one set, and a compare is performed on the ways of the set to determine if the requested data is in the cache and, if so, which way the data is in. A device for achieving the method includes a cache index organized into two arrays, each having a number of sets and a number of ways. One of the arrays may used to store micro-tags for way prediction. In addition, the device includes an auxiliary memory structure for receiving and storing intermediate search results.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00001\" num=\"1\"><claim-text>1. A cache, comprising:</claim-text><claim-text>a data array; </claim-text><claim-text>a cache index coupled to said data array, said cache index comprising: </claim-text><claim-text>a first array, wherein the first array is organized into a plurality of first-array sets, the plurality of first-array sets is organized into a plurality of blocks, each of the plurality of blocks contains a subset of the plurality of first-array sets, each of the plurality of first-array sets contains a plurality of ways, and each of the plurality of ways of the first-array sets contains a first partial address tag; and </claim-text><claim-text>a second array coupled to the first array. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00002\" num=\"2\"><claim-text>2. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00001\">claim 1</claim-ref>, wherein the first array is coupled to an auxiliary memory structure.</claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00003\" num=\"3\"><claim-text>3. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00002\">claim 2</claim-ref>, wherein the auxiliary memory structure is coupled to a comparator and wherein the second array is coupled to a comparator.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00004\" num=\"4\"><claim-text>4. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00001\">claim 1</claim-ref>, wherein the second array is organized into a plurality of second-array sets, each of the second-array sets contains a plurality of ways, each of the plurality of ways of the second-array sets contains a second partial address tag.</claim-text></claim>"}, {"num": 5, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00005\" num=\"5\"><claim-text>5. A method for searching a cache index, the cache index having a first array, the first array organized into a plurality of first-array sets, the first-array sets organized into a plurality of blocks, comprising:</claim-text><claim-text>receiving a virtual address of a requested data element, said virtual address including a common bit that is a partial physical address for the data element; </claim-text><claim-text>selecting a block of sets in a first array of the cache index, using the common bit before the virtual address is completely translated; and </claim-text><claim-text>reading out the selected block into an auxiliary data location. </claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00006\" num=\"6\"><claim-text>6. The method of <claim-ref idref=\"US-6516386-B1-CLM-00005\">claim 5</claim-ref>, wherein each of the first-array sets contains ways, the ways of the first-array sets containing micro address tags, and wherein the method further comprises:</claim-text><claim-text>receiving a first string of translated bits and a second string of translated bits, wherein the first string of translated bits and second string of translated bits each represent part of the physical address of the requested data item; </claim-text><claim-text>multiplexing the selected first-array block using the first string of translated bits to select a potential first-array set; and </claim-text><claim-text>comparing the second string of translated bits on the ways contained within the selected potential first-array set, a hit being predicted when the second string of translated bits matches one of the micro address tags contained within the selected potential first-array set. </claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00007\" num=\"7\"><claim-text>7. The method of <claim-ref idref=\"US-6516386-B1-CLM-00006\">claim 6</claim-ref>, wherein the cache index has a second array and a cache data array, the second array being organized into second-array sets, and wherein the method further comprises:</claim-text><claim-text>sending an identity of a predicted way to the second array and the cache data array when a hit is predicted; and </claim-text><claim-text>identifying in the second array a potential second-array set corresponding to the selected potential first-array set while said multiplexing the selected first-array block, comparing the second string, and sending an identity are performed. </claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00008\" num=\"8\"><claim-text>8. The method of <claim-ref idref=\"US-6516386-B1-CLM-00007\">claim 7</claim-ref>, wherein the cache data array is organized into a plurality of sets, and wherein the method further comprises:</claim-text><claim-text>identifying a data set in the cache data array corresponding to the selected potential first-array set while said multiplexing the selected block, comparing the second string, and sending an identity are performed; and </claim-text><claim-text>reading out predicted data from the cache data array, the predicted data being contained in the predicted way of the identified cache data array set. </claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00009\" num=\"9\"><claim-text>9. The method of <claim-ref idref=\"US-6516386-B1-CLM-00008\">claim 8</claim-ref>, wherein each of the second-array sets contains ways, each of the ways containing confirmation address tags, and wherein the method further comprises:</claim-text><claim-text>receiving a third string of translated bits concurrently with reading out predicted data from the cache data array; and </claim-text><claim-text>comparing the third string of translated bits on the ways of the potential second-array set concurrently with said reading out predicted data from the cache data array, a hit being confirmed when the third string of translated bits matches one of the confirmation address tags contained within the potential second-array set. </claim-text></claim>"}, {"num": 10, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00010\" num=\"10\"><claim-text>10. The method of <claim-ref idref=\"US-6516386-B1-CLM-00009\">claim 9</claim-ref>, wherein translating a remainder of the virtual address to generate a remainder of the physical address is performed concurrently with said searching on the first array and said reading out the selected first-array block into an auxiliary data location.</claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00011\" num=\"11\"><claim-text>11. The method of <claim-ref idref=\"US-6516386-B1-CLM-00010\">claim 10</claim-ref>, wherein the physical address includes at least 35 bits, and wherein the first string of translated bits includes bits <b>12</b>-<b>14</b> of the physical address, the second string of translated bits includes bits <b>15</b>-<b>23</b> of the physical address, and the third string of translated bits includes bits <b>24</b>-<b>35</b> of the physical address.</claim-text></claim>"}, {"num": 12, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00012\" num=\"12\"><claim-text>12. A method of searching a cache index, comprising:</claim-text><claim-text>receiving a first partial virtual memory address and a second partial virtual memory address, wherein the first partial virtual memory address is the same as a first partial physical memory address; </claim-text><claim-text>translating the second partial virtual memory address into a second partial physical memory address; </claim-text><claim-text>selecting a block of sets from a first array using the first partial virtual memory address, said selecting being initiated prior to completion of said translating the second partial virtual memory address; </claim-text><claim-text>selecting a single first-array set in the block of sets using the second partial physical memory address; and </claim-text><claim-text>determining whether a desired data element is in the cache using information in the selected set. </claim-text></claim>"}, {"num": 13, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00013\" num=\"13\"><claim-text>13. The method of <claim-ref idref=\"US-6516386-B1-CLM-00012\">claim 12</claim-ref>, wherein said selecting a block of sets and said translating the second partial virtual memory address are performed concurrently.</claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00014\" num=\"14\"><claim-text>14. The method of <claim-ref idref=\"US-6516386-B1-CLM-00013\">claim 13</claim-ref>, wherein said determining further comprises:</claim-text><claim-text>receiving a third partial virtual memory address; </claim-text><claim-text>translating the third virtual memory partial address into a third partial physical memory address, concurrently with said translating the third partial virtual memory address; and </claim-text><claim-text>selecting a first-array potential way within the single selected first-array set using the translated third partial physical memory address. </claim-text></claim>"}, {"num": 15, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00015\" num=\"15\"><claim-text>15. The method of <claim-ref idref=\"US-6516386-B1-CLM-00014\">claim 14</claim-ref>, further comprising:</claim-text><claim-text>receiving a fourth partial virtual memory address; </claim-text><claim-text>translating the fourth partial virtual memory address into a fourth partial physical memory address while said selecting a block of sets is performed; </claim-text><claim-text>selecting a set and way within a second array that corresponds to the selected first-array set and selected first-array potential way; and </claim-text><claim-text>determining that a cache hit is present when the selected set and way within the second array contain a confirmation tag that matches the fourth partial physical memory address. </claim-text></claim>"}, {"num": 16, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00016\" num=\"16\"><claim-text>16. A cache, comprising:</claim-text><claim-text>a data array; </claim-text><claim-text>a first index array coupled to the data array; and </claim-text><claim-text>a control block programed to: </claim-text><claim-text>receive a first string of bits and a second string of bits, the first string of bits being untranslated between a virtual address and a physical address, the second string of bits being a partial physical address that was translated from a partial virtual address; and </claim-text><claim-text>use the first string of bits to select a block of sets in the first index array and to use the second string of bits to multiplex the selected block down to a selected first-array set. </claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00017\" num=\"17\"><claim-text>17. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00016\">claim 16</claim-ref>, wherein the control block is further programed to select a block of sets in the first index array before receiving the second string of bits.</claim-text></claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00018\" num=\"18\"><claim-text>18. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00017\">claim 17</claim-ref>, wherein the control block is further programed to:</claim-text><claim-text>receive a third string of bits which is a partial physical address that was translated from a partial virtual address; </claim-text><claim-text>compare the third string of bits on each of a plurality of ways contained in the selected first-array set; and </claim-text><claim-text>predict a hit when the third string of bits matches a partial address tag contained in the selected first-array set. </claim-text></claim>"}, {"num": 19, "parent": 18, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00019\" num=\"19\"><claim-text>19. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00018\">claim 18</claim-ref>, further comprising a second index array, and wherein the control block is further programmed to identify a set in the second index array using the first and second strings of bits.</claim-text></claim>"}, {"num": 20, "parent": 19, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00020\" num=\"20\"><claim-text>20. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00019\">claim 19</claim-ref>, wherein the control block is further programmed to:</claim-text><claim-text>receive a fourth string of bits, the fourth string of bits being a partial physical address that was translated from a partial virtual address; and </claim-text><claim-text>compare the fourth string of bits on each of a plurality of ways contained in the identified second-array set, a hit being confirmed when the fourth string of bits matches a partial address tag contained in the identified second-array set. </claim-text></claim>"}, {"num": 21, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00021\" num=\"21\"><claim-text>21. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00020\">claim 20</claim-ref>, wherein the first string of bits has at least 5 bits.</claim-text></claim>"}, {"num": 22, "parent": 21, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00022\" num=\"22\"><claim-text>22. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00021\">claim 21</claim-ref>, wherein the first string of bits has at least 11 bits and includes bits <b>7</b>-<b>11</b> of the virtual address.</claim-text></claim>"}, {"num": 23, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00023\" num=\"23\"><claim-text>23. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00022\">claim 22</claim-ref>, wherein the partial address tag in the first-array set is a 9-bit string and the partial address tag in the second-array set is a 12-bit string.</claim-text></claim>"}, {"num": 24, "parent": 23, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00024\" num=\"24\"><claim-text>24. The cache of <claim-ref idref=\"US-6516386-B1-CLM-00023\">claim 23</claim-ref>, wherein the physical address has at least 14 bits, and the second string of bits includes bits <b>12</b>-<b>14</b> of the physical address.</claim-text></claim>"}, {"num": 25, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00025\" num=\"25\"><claim-text>25. A cache index, the cache index having a first array, the first array organized into a plurality of first-array sets, the first-array sets organized into a plurality of blocks, the cache index comprising:</claim-text><claim-text>an input port to receive a virtual address of a requested data element, said virtual address including a common bit that is a partial physical address for the data element; </claim-text><claim-text>a selector to select a block of sets in a first array of the cache index using the common bit before the virtual address is completely translated; and </claim-text><claim-text>a connection to an auxiliary memory structure to read out the selected block into an auxiliary data location. </claim-text></claim>"}, {"num": 26, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00026\" num=\"26\"><claim-text>26. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00025\">claim 25</claim-ref>, wherein each of the first-array sets contains ways, the ways of the first-array sets containing micro address tags, wherein the input port receives a first string of translated bits and a second string of translated bits, wherein the first string of translated bits and second string of translated bits each represent part of the physical address of the requested data item, and wherein the cache index further comprises:</claim-text><claim-text>a multiplexor to multiplex the selected first-array block using the first string of translated bits to select a potential first-array set; and </claim-text><claim-text>a comparator to compare the second string of translated bits on the ways contained within the selected potential first-array set, a hit being predicted when the second string of translated bits matches one of the micro address tags contained within the selected potential first-array set. </claim-text></claim>"}, {"num": 27, "parent": 26, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00027\" num=\"27\"><claim-text>27. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00026\">claim 26</claim-ref>, wherein the cache index has a second array and a cache data array, the second array being organized into second-array sets, and wherein the cache index further comprises:</claim-text><claim-text>a means to send an identity of a predicted way to the second array and the cache data array when a hit is predicted; and </claim-text><claim-text>a means to identify in the second array a potential second-array set corresponding to the selected potential first-array set while said multiplexing the selected first-array block, comparing the second string, and sending an identity are performed. </claim-text></claim>"}, {"num": 28, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00028\" num=\"28\"><claim-text>28. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00027\">claim 27</claim-ref>, wherein the cache data array is organized into a plurality of sets, and wherein the cache index further comprises:</claim-text><claim-text>a means to identify a data set in the cache data array corresponding to the selected potential first-array set while said multiplexing the selected block, comparing the second string, and sending an identity are performed; and </claim-text><claim-text>a means to read out predicted data from the cache data array, the predicted data being contained in the predicted way of the identified cache data array set. </claim-text></claim>"}, {"num": 29, "parent": 28, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00029\" num=\"29\"><claim-text>29. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00028\">claim 28</claim-ref>, wherein each of the second-array sets contains ways, each of the ways containing confirmation address tags, and wherein the input port receives a third string of translated bits concurrently with said reading out predicted data from the cache data array, and wherein the comparator compares the third string of translated bits on the ways of the potential second-array set concurrently with said reading out predicted data from the cache data array, a hit being confirmed when the third string of translated bits matches one of the confirmation address tags contained within the potential second-array set.</claim-text></claim>"}, {"num": 30, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00030\" num=\"30\"><claim-text>30. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00029\">claim 29</claim-ref>, wherein translating a remainder of the virtual address to generate a remainder of the physical address is performed concurrently with said searching on the first array and said reading out the selected first-array block into an auxiliary data location.</claim-text></claim>"}, {"num": 31, "parent": 30, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00031\" num=\"31\"><claim-text>31. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00030\">claim 30</claim-ref>, wherein the physical address includes at least 35 bits, and wherein the first string of translated bits includes bits <b>12</b>-<b>14</b> of the physical address, the second string of translated bits includes bits <b>15</b>-<b>23</b> of the physical address, and the third string of translated bits includes bits <b>24</b>-<b>35</b> of the physical address.</claim-text></claim>"}, {"num": 32, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00032\" num=\"32\"><claim-text>32. A cache index, comprising:</claim-text><claim-text>an input port to receive a first partial virtual memory address and a second partial virtual memory address, wherein the first partial virtual memory address is the same as a first partial physical memory address; </claim-text><claim-text>translator to translate the second partial virtual memory address into a second partial physical memory address; </claim-text><claim-text>a selector to select a block of sets from a first array using the first partial virtual memory address, said selecting being initiated prior to completion of said translating the second partial virtual memory address and to select a single first-array set in the block of sets using the second partial physical memory address; and </claim-text><claim-text>a comparator to determine whether a desired data element is in the cache using information in the selected set. </claim-text></claim>"}, {"num": 33, "parent": 32, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00033\" num=\"33\"><claim-text>33. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00032\">claim 32</claim-ref>, wherein said selection of a block of sets and said translation of the second partial virtual memory address are performed concurrently.</claim-text></claim>"}, {"num": 34, "parent": 33, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00034\" num=\"34\"><claim-text>34. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00033\">claim 33</claim-ref>, wherein:</claim-text><claim-text>said input port is to receive a third partial virtual memory address; </claim-text><claim-text>said translator is to translate the third virtual memory partial address into a third partial physical memory address, concurrently with said translating the third partial virtual memory address; and </claim-text><claim-text>said selector is to select a first-array potential way within the single selected first-array set using the translated third partial physical memory address. </claim-text></claim>"}, {"num": 35, "parent": 34, "type": "dependent", "paragraph_markup": "<claim id=\"US-6516386-B1-CLM-00035\" num=\"35\"><claim-text>35. The cache index of <claim-ref idref=\"US-6516386-B1-CLM-00034\">claim 34</claim-ref>, wherein:</claim-text><claim-text>said input port receives a fourth partial virtual memory address; </claim-text><claim-text>said translator translates the fourth partial virtual memory address into a fourth partial physical memory address, while said selecting a block of sets is performed; </claim-text><claim-text>said selector is to select a set and way within a second array that corresponds to the selected first-array set and selected first-array potential way; and </claim-text><claim-text>said comparator is to determine that a cache hit is present when the selected set and way within the second array contain a confirmation tag that matches the fourth partial physical memory address.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53872192\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>FIELD OF THE INVENTION</h4><p>The present invention relates to address searching within a cache index. In particular, the present invention relates to address searching within a cache index using a partial physical address.</p><h4>BACKGROUND OF THE INVENTION</h4><p>Data is stored in memory according to a physical address scheme. Software programmers, however, write program code that requires the retrieval of data using a virtual or linear address scheme (referred to herein as the \u201cvirtual address\u201d). Therefore, it becomes necessary for a system to translate a virtual address for a piece of data to a physical address before the data can be read from physical memory.</p><p>Many conventional searching techniques require that the fall physical address be translated from the virtual address of the requested data prior to initiating a search. This significantly slows down the process of actually retrieving the data from memory, especially if the data is stored in high speed cache memory. Since a physical address is necessary before identifying and/or retrieving data from a cache, many conventional cache systems must wait until the translation from the virtual to the physical address is complete. This process can delay a search by a clock cycle or more.</p><p>In an attempt to solve this problem, other known cache systems have implemented a technique for searching an index for cache data based upon a partial physical address. This technique is based upon the recognition that a virtual address and a physical address share some address bits in common, so that these bits are available to the system immediately.</p><p>Generally, caches and cache indexes are organized into a number of sets, with each set containing one or more entry locations, or ways. In order to begin a partial-address search using the above-mentioned techniques, the available string of bits (i.e. those bits common to the virtual and physical address) must be of sufficient length to uniquely identify the individual set which might contain the requested data. According to known systems, only then may the system read out an individual set whose ways may be later searched to determine the location of requested data.</p><p>For example, for some systems, address bits <b>0</b>-<b>11</b> for a virtual and physical address are the same. In this example, bits <b>0</b>-<b>6</b> are used for addressing data within each entry of the cache, and therefore are not used to index the entries themselves.</p><p>For smaller caches, for example 16 kilobyte caches, it is possible to begin searching a cache index using bits <b>7</b>-<b>11</b> as many such caches are organized into 32 or fewer sets. This is possible because bits <b>7</b>-<b>11</b> can identify 32 individual sets (the five bits forming 2<sup>5</sup>, or 32, unique binary numerals). Thus for caches with 32 or fewer sets, if bits <b>7</b>-<b>11</b> are available they may be immediately used to uniquely identify the individual set which might contain the requested data.</p><p>Larger caches, however, for example 256 kilobyte caches, typically contain more than 32 sets. A 256 kilobyte cache containing, for example, 256 sets requires an 8-bit string (e.g. bits <b>7</b>-<b>14</b>) to effectively begin a search of the cache index. Known cache systems, therefore, have not initiated a search of a cache index for large caches using bits <b>0</b>-<b>11</b>, since these systems require bits <b>12</b>-<b>14</b> to initiate the search anyway. These systems must wait until the translation process is complete, and the full physical address is available, before initiating a search of the cache index. The problem with this method, however, is that one or more clock cycles are wasted waiting for the translation process to finish prior to beginning the search for cache data.</p><h4>SUMMARY OF THE INVENTION</h4><p>The method for searching a cache index includes the steps of receiving a virtual address of a requested data element which has at least one common bit which is untranslated between the virtual address and a physical address and searching the cache index using the at least one common bit, before the virtual address is completely translated, to identify a selected block. The cache index may be organized into blocks, each block containing a plurality of sets. Each of the plurality of sets may contain at least one way, each of the ways containing an address tag.</p><p>An embodiment of a device according to the present invention includes a cache index organized into a number of sets and ways, and an auxiliary memory structure for receiving and storing intermediate search results.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1A shows a schematic view of a cache unit including an embodiment of a cache index according to the present invention.</p><p>FIG. 1B shows a schematic view of the cache unit of FIG. 1 connected to a processor.</p><p>FIG. 1C shows a schematic view of an embodiment of a cache index according to the present invention.</p><p>FIG. 2A shows a schematic view of an array of the cache index of FIG. <b>1</b>C.</p><p>FIG. 2B shows a schematic view of a second array of the cache index of FIG. <b>1</b>C.</p><p>FIG. 3 shows a schematic view of an embodiment of an array of a cache index according to the present invention with an identified block of sets.</p><p>FIG. 4 shows a schematic view of the array of FIG. 2 with an identified block of sets read out to an auxiliary memory structure.</p><p>FIGS. 5A, <b>5</b>B, and <b>6</b> show a flow diagram of a method according to the present invention.</p><p>FIG. 7 shows a schematic view of another embodiment of an array of a cache index according to the present invention.</p><p>FIGS. 8A and 8B show a flow diagram of a method for searching the data array of FIG. <b>7</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION</h4><p>FIG. 1A shows a cache unit <b>10</b> including an embodiment of a cache index according to the present invention. This system includes a cache index <b>30</b> connected to a cache data array <b>40</b>. The functions of the cache index <b>30</b> are controlled by control block <b>20</b>. The control block <b>20</b> may be any type of controlling circuit or processor. As shown in FIG. 1B, the cache unit <b>10</b> may be connected, for example, to a processor <b>50</b>.</p><p>FIG. 1C shows an exemplary structure of a cache index <b>30</b> according to the present invention. In this embodiment, the cache index <b>30</b> includes two arrays A<b>1</b> and A<b>2</b>. The cache index <b>30</b> also includes, for example, an auxiliary memory structure B<b>1</b> which may store intermediate search results from array A<b>1</b>. Comparitors <b>31</b> and <b>32</b> are also provided, for example, in the cache index <b>30</b>. These may be used by the control block <b>20</b> to perform comparisons between partial address strings of a requested piece of data and partial address strings contained in the arrays A<b>1</b> and A<b>2</b>.</p><p>FIGS. 2A and 2B show this exemplary cache index <b>30</b> in greater detail. The cache index <b>30</b> stores address tags or simply \u201ctags\u201d for the actual data stored in the cache data array <b>40</b>. As noted above, the cache index is organized into, for example, two separate arrays A<b>1</b> and A<b>2</b>. Each of the two arrays is further organized into, for example, 256 sets, each of the sets containing, for example, 8 ways (other particular configurations being possible).</p><p>The number of ways in each set generally indicates the number of entries that may be stored in each set. One skilled in the art will understand that, given two caches with the same number of total entries (e.g. 2048), the cache organized into fewer sets and a greater number of ways (e.g. 256 sets in 8 ways) will be more architecturally flexible than one having a greater number of sets and fewer ways (e.g. 512 sets in 4 ways). In particular, the former will be able to store data in more combinations than the latter. However, the expanded options provided by the former arrangement generally lead to longer search times.</p><p>As noted above, an embodiment of the present invention utilizes two arrays A<b>1</b> and A<b>2</b>, each organized into, for example, 256 sets and 8 ways, which are used to store address tags. The separate arrays A<b>1</b> and A<b>2</b> store different portions of the address tag. The first array A<b>1</b> stores, for example, tag bits <b>15</b>-<b>23</b> of an address tag.</p><p>These bits form a so-called \u201cmicro-tag\u201d or \u201c\u03bctag\u201d which is used, for example, for way prediction. The second array A<b>2</b> stores, for example, tag bits <b>24</b>-<b>35</b> of an address tag. These bits form a so-called \u201cupper tag\u201d and may be used to confirm a predicted address hit. Thus in an exemplary embodiment, the first array A<b>1</b> stores a nine bit tag (bits <b>15</b>-<b>23</b>) in 256 sets and 8 ways, while the second array A<b>2</b> stores a 12 bit tag (bits <b>24</b>-<b>35</b>) in 256 sets and 8 ways. In array A<b>1</b>, the 256 sets are organized into, for example, 32 blocks of 8 sets each. It can be understood that the address tag may be any suitable length. In addition, the bits comprising the address tag may be apportioned between the two arrays A<b>1</b> and A<b>2</b> in any suitable manner (i.e. the micro-tag and upper tag may each include any suitable number of bits).</p><p>The cache index <b>30</b> according to the illustrated embodiment of the present invention differs from known cache indexes in that it includes, for example, auxiliary memory structure B<b>1</b> for receipt and storage of intermediate search results. As described below, this auxiliary memory structure B<b>1</b> allows searching of the cache index based upon a partial physical address that need not uniquely identify an individual set that can contain the requested data.</p><p>In the system employing the illustrated embodiment of the cache index <b>30</b><b>25</b> of the present invention, bits <b>0</b>-<b>11</b> of each virtual or linear address are, for example, identical to (or otherwise untranslated from) bits <b>0</b>-<b>11</b> of each corresponding physical address. Of these bits, bits <b>0</b>-<b>6</b> are used, for example, to address the data within each entry of the cache. Thus these bits are not used for addressing the entries themselves within the cache index <b>30</b>. In contrast, bits <b>7</b>-<b>11</b> of the physical address may be used for indexing the entries stored in the cache data array <b>40</b>. These bits therefore identify, for example, a partial physical address for cache indexing purposes. It can be understood that this partial physical address need not include the exemplary bits <b>7</b>-<b>11</b>, but that other bit strings may be equally useful in practicing the present invention.</p><p>In the exemplary embodiment, the 5-bit string <b>7</b>-<b>11</b> may be used to identify 2<sup>5</sup>, or 32, individual memory locations. These 32 individual memory locations correspond, for example, to the 32 blocks of 8 sets each in the array A<b>1</b>. Accordingly, bits <b>7</b>-<b>11</b> may be used (by, for example, the control block <b>20</b>) to identify the particular block in array A<b>1</b> that might contain the address of a requested piece of data. The control block <b>20</b> may then cause the selected block to be read to the additional memory structure B<b>1</b>. Because bits <b>7</b>-<b>11</b> are available as soon as the data request is received, the control block <b>20</b> may perform these functions without waiting for a translation of the requested address.</p><p>Unlike bits <b>7</b>-<b>11</b>, bits <b>12</b>-<b>35</b> of each virtual address are, for example, not identical to bits <b>12</b>-<b>35</b> of the corresponding physical address. Rather bits <b>12</b>-<b>35</b> must be translated by the system to generate bits <b>12</b>-<b>35</b> of the physical address. This translation may be performed using any known technique and typically requires a full clock cycle or more. In an exemplary embodiment, the translation occurs while bits <b>7</b>-<b>11</b> are used to identify the selected block discussed above. The translation may also be performed in parts, so that a portion of the (translated) bits become available before the remaining bits. In an exemplary embodiment, bits <b>12</b>-<b>23</b> are available to the cache index <b>30</b> first, followed by bits <b>24</b>-<b>35</b>.</p><p>Bits <b>12</b>-<b>35</b> of the physical address may perform a variety of functions with respect to addressing data within the cache. In an exemplary embodiment, the 3-bit string of bits <b>12</b>-<b>14</b> are used, for example, to index the eight individual sets within each block, so that bits <b>7</b>-<b>14</b>, as a group, uniquely index each of the 256 sets of the cache index <b>30</b>. Thus when bits <b>12</b>-<b>14</b> are available, they may be used, for example, by control block <b>20</b> to multiplex the eight sets of the identified block down to a single selected set that might contain an address tag of the requested data.</p><p>Once the selected set is identified, bits <b>15</b>-<b>35</b> may be used to identify the individual way, if any, which contains the address of the requested data. In the exemplary embodiment, bits <b>15</b>-<b>23</b> are used, for example, to execute a 9-bit compare for way prediction. Specifically, these bits are compared, for example, on the eight ways of the selected set. Alternatively, this 9-bit compare may be performed on all eight sets before bits <b>12</b>-<b>14</b> are used to multiplex the eight sets of the identified block down to a selected set.</p><p>If a hit is predicted (i.e. if bits <b>15</b>-<b>23</b> of the requested data match a 9-bit tag in the selected set), then bits <b>24</b>-<b>35</b> may be used to confirm whether the predicted way actually contains the requested data. Specifically, these bits may be compared on array A<b>2</b> or some portion thereof (e.g. a single set) to determine if a predicted way contains the requested data or instead contains a different piece of data having the same 9-bit tag as the requested data. Techniques and algorithms for performing the necessary compares are well known in the art.</p><p>FIGS. 5A, <b>5</b>B and <b>6</b> outline a method of searching an embodiment of a cache index according to the present invention. The method begins with step <b>101</b> of FIG. 5, with the cache index maintained in an initial configuration organized, for example, into 2 arrays. For purposes of clarity, the illustrated method is described in connection with the exemplary cache index described above. Thus the first array stores, for example, a number of 9-bit strings, and the second array stores, for example, 12-bit strings.</p><p>Upon receiving a request for data that contains a virtual address for the requested data (step <b>102</b>), the cache index (aided by, for example, a control block <b>20</b>) receives bits <b>7</b>-<b>11</b>. These bits <b>7</b>-<b>11</b> are untranslated, for example, from bits <b>7</b>-<b>11</b> of the physical address of the data. As noted above, this 5-bit string of bits <b>7</b>-<b>11</b> uniquely identifies one of 32 blocks of 8 sets in the 256 set cache index.</p><p>Accordingly, upon receiving bits <b>7</b>-<b>11</b>, the system (e.g. the cache unit <b>10</b>) can identify a single block of 8 sets in first array, as shown in FIG. <b>3</b>. The system can then read out this block of 8 sets (step <b>103</b>) into the auxiliary-memory structure B<b>1</b>, as shown in FIG. <b>4</b>. Because bits <b>7</b>-<b>11</b> in the virtual address are untranslated from bits <b>7</b>-<b>11</b> in the physical address, the system can perform this initial search and retrieval without waiting for the translation of the entire virtual address.</p><p>While the system performs this preliminary searching and reading out, the remainder of the virtual address may be translated in the background to generate the remainder of the physical address. In an embodiment of the present invention, the system receives the translated bits in two steps, first bits <b>12</b>-<b>23</b> and later bits <b>24</b>-<b>35</b>.</p><p>Once the translation of bits <b>12</b>-<b>23</b> from the virtual address to physical address is complete, the cache index can receive these bits, including bits <b>12</b>-<b>14</b> (step <b>104</b>).</p><p>At this point, the system may perform several sets of steps concurrently. First, the 3-bit string <b>12</b>-<b>14</b> allows the system to multiplex the 8 sets of the read-out block down to a single set (step <b>105</b>). This single set potentially stores an address tag for the requested data. The system then compares, for example, bits <b>15</b>-<b>23</b> of the physical address on each of the ways of the single selected set identified in step <b>105</b> (step <b>108</b>). In the present exemplary embodiment, this 9-bit string is compared on all eight ways of the set. If bits <b>15</b>-<b>23</b> match any of the 9-bit strings contained in the read-out block (step <b>109</b>), the system predicts a hit and ships, for example, the identity of a predicted way to the data array and the array A<b>2</b> (step <b>110</b>). If bits <b>15</b>-<b>23</b> do not match any of the 9-bit strings contained in the memory structure B<b>1</b>, then the data is not in the cache, and the system must look elsewhere for the requested data (step <b>109</b>N).</p><p>Second, concurrent with the above steps, an individual corresponding index set of the array A<b>2</b> may be identified using the bits <b>7</b>-<b>14</b>. The system may then read out the corresponding index set from the second array into, for example, the comparitor <b>32</b> (step <b>106</b>).</p><p>Third, concurrent with the above steps, address bits <b>7</b>-<b>14</b> may likewise be used to identify a corresponding data set in the cache data array <b>40</b>. This corresponding data set is, for example, the single selected set that might contain the requested data (as opposed to the requested data address tags, which are contained in arrays A<b>1</b> and A<b>2</b>).</p><p>Assuming a hit has been predicted in step <b>110</b>, the cache may begin a read out of the predicted way of the selected set of the data array (step <b>110</b>B). Next, while the data is being shipped, the system receives, for example, bits <b>24</b>-<b>35</b> of the physical address and compares those bits, for example, on the predicted way of the corresponding index set identified in step <b>106</b>. In other words, the 12-bit physical address string is compared to the 12-bit string in the predicted way of the corresponding index set (step <b>111</b>). If a match occurs (e.g. if the 12-bit string is identical to the 12-bit string in the predicted way), the predicted hit is confirmed (step <b>112</b>) and the data being shipped by the cache to the processor may be used. If no match occurs, the data being shipped is not the requested data. The processor can, for example, ignore the shipped data, or the shipped data may otherwise be canceled (step <b>113</b>).</p><p>It can be understood that the method and apparatus according to the present invention need not be limited to cache indexes of the structure described above. Rather, the method and apparatus according to the present invention may be used with any cache index in which each virtual address and corresponding physical address share some untranslated bits and in which these common bits do not uniquely identify a set containing the requested data.</p><p>FIG. 7 shows, for example, a cache index organized into 2<sup>n </sup>sets. One skilled in the art can understand that a string containing at least n bits is required to uniquely identify each of the 2<sup>n </sup>sets contained in the cache index as shown in FIG. <b>5</b>. In searching this array for a particular set, if less than n bits are common between the virtual address and the physical address, then the virtual address must be translated to obtain the physical address before the particular set can be uniquely identified.</p><p>The method and apparatus according to an embodiment of the present invention, however, allow a search to begin based upon the partial physical address formed by any bits common to the virtual and physical addresses. If a number k of bits are shared between the virtual address and the physical address, where k is less than n, then the cache index can be subdivided into, for example, 2<sup>k </sup>blocks, each block containing 2<sup>(n\u2212k) </sup>sets. Each string of k shared bits can then be used to uniquely identify one of the 2<sup>k </sup>blocks within the cache index. The 2<sup>(n\u2212k) </sup>sets may therefore be read out into an auxiliary memory structure B shown in FIG. 5, and these sets may be later multiplexed down to 1 set when the full physical address is available.</p><p>It can be understood that the \u201cblocks\u201d need not be represented in the actual architecture of the cache index. Instead, it is merely required that the available common bits be utilized to reduce the potential hits (i.e. the potential sets) to a minimum, and that these potential sets be read out to an auxiliary memory structure for later multiplexing down to a single set.</p><p>A further exemplary method corresponding to the above is outlined in detail in FIG. <b>8</b>. In step <b>201</b>, the cache index array is organized, for example, into 2<sup>k </sup>blocks, where k is the number of shared bits between the virtual address and the physical address. Each block contains, for example, 2<sup>(n\u2212k) </sup>sets, with 2<sup>n </sup>being the total number of sets contained in the cache.</p><p>Upon receiving a request for data that includes the virtual address of the requested data, the system immediately receives the string of k bits common to both the virtual address and the physical address (step <b>202</b>). Using this string, and without waiting for the translation of the full physical address, the system searches the array and determines which block might contain the requested data (step <b>203</b>). Once that block is identified, the system reads out the 2<sup>(n\u2212k) </sup>sets contained within that block to an auxiliary memory structure B shown in FIG. 5 (step <b>204</b>).</p><p>Once the full physical address has been translated, the 2<sup>(n\u2212k) </sup>sets can be multiplexed down to 1 set (step <b>206</b>). Remaining address bits may then, for example, be read (step <b>207</b>) and compared to the address strings contained in the ways of the set to determine whether the requested data is contained within the cache (step <b>208</b>). If the compare registers a hit, the data may be read out (step <b>210</b>). If no hit occurs, the data is not within the cache (step <b>209</b>N).</p><p>It can also be understood that the number or sets and number of blocks need not be powers of two (e.g. 2<sup>n </sup>where n is an integer). Even if the number of sets or blocks is not a power of two, bits common to both the virtual and physical addresses can be used to eliminate all but a subset of the sets. This subset of sets (e.g. a block) may the be read out and later multiplexed down to one set when other address bits become available.</p><p>The cache index and method according to the present invention have been described with respect to several exemplary embodiments. It can be understood, however, that there are many other variations of the above described embodiments which will be apparent to those skilled in the art. It is understood that these modifications are within the teaching of the present invention which is to be limited only by the claims appended hereto.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Roland", "last_name": "Pang", "name": ""}, {"first_name": "Gregory Mont", "last_name": "Thornton", "name": ""}, {"first_name": "Bryon George", "last_name": "Conley", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTEL CORPORATION"}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/10        20060101A I20051008RMUS"}], "national_classes": [{"primary": true, "label": "711118"}, {"primary": false, "label": "711E12063"}, {"primary": false, "label": "711003"}, {"primary": false, "label": "711203"}], "ecla_classes": [{"label": "S06F212:6082"}, {"label": "G06F  12/10L4P"}], "cpc_classes": [{"label": "G06F  12/1054"}, {"label": "G06F2212/6082"}, {"label": "G06F  12/1054"}, {"label": "G06F2212/6082"}], "f_term_classes": [], "legal_status": "Expired - Fee Related", "priority_date": "1997-12-31", "application_date": "1997-12-31", "family_members": [{"ucid": "US-6516386-B1", "titles": [{"lang": "EN", "text": "Method and apparatus for indexing a cache"}]}, {"ucid": "US-20030074537-A1", "titles": [{"lang": "EN", "text": "Method and apparatus for indexing a cache"}]}]}