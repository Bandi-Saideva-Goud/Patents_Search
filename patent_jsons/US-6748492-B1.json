{"patent_number": "US-6748492-B1", "publication_id": 73868280, "family_id": 24540708, "publication_date": "2004-06-08", "titles": [{"lang": "EN", "text": "Deterministic setting of replacement policy in a cache through way selection"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11704541\" source=\"national office\"><p>A cache is configured to receive direct access transactions. Each direct access transaction explicitly specifies a way of the cache. The cache may alter the state of its replacement policy in response to a direct access transaction explicitly specifying a particular way of the cache. The state may be altered such that a succeeding cache miss causes an eviction of the particular way. Thus, a direct access transaction may be used to provide a deterministic setting to the replacement policy, providing predictability to the entry selected to store a subsequent cache miss. In one embodiment, the replacement policy may be a pseudo-random replacement policy. In one embodiment, a direct access transaction also explicitly specifies a cache storage entry to be accessed in response to the transaction. The cache may access the cache storage entry (bypassing the normal tag comparisons and hit determination used for memory transactions) and either read the data from the cache storage entry (for read transactions) or write data from the transaction to the cache storage entry (for write transactions). Other embodiments may set the replacement policy based on other types of transactions.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50679123\"><p>A cache is configured to receive direct access transactions. Each direct access transaction explicitly specifies a way of the cache. The cache may alter the state of its replacement policy in response to a direct access transaction explicitly specifying a particular way of the cache. The state may be altered such that a succeeding cache miss causes an eviction of the particular way. Thus, a direct access transaction may be used to provide a deterministic setting to the replacement policy, providing predictability to the entry selected to store a subsequent cache miss. In one embodiment, the replacement policy may be a pseudo-random replacement policy. In one embodiment, a direct access transaction also explicitly specifies a cache storage entry to be accessed in response to the transaction. The cache may access the cache storage entry (bypassing the normal tag comparisons and hit determination used for memory transactions) and either read the data from the cache storage entry (for read transactions) or write data from the transaction to the cache storage entry (for write transactions). Other embodiments may set the replacement policy based on other types of transactions.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00001\" num=\"1\"><claim-text>1. A cache comprising:</claim-text><claim-text>an associative memory having a plurality of entries, each of said plurality of entries configured to store a cache line of data, said plurality of entries arranged in a plurality of ways; and </claim-text><claim-text>a replacement circuit configured to select an entry of said associative memory for eviction responsive to a cache miss by a memory transaction, and wherein said replacement circuit is configured, responsive to a first transaction specifying an explicit update of said replacement circuit to select a first way of said plurality of ways, to establish a first state corresponding to a selection of said first way, wherein said replacement circuit comprises a linear feedback shift register configured to store a value used to select said entry for eviction, and wherein said replacement circuit is configured to update said linear feedback shift register with a predetermined value representing said first state responsive to said first transaction. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00002\" num=\"2\"><claim-text>2. The cache as recited in <claim-ref idref=\"US-6748492-B1-CLM-00001\">claim 1</claim-ref> wherein said replacement circuit employs a pseudo-random replacement policy.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00003\" num=\"3\"><claim-text>3. The cache as recited in <claim-ref idref=\"US-6748492-B1-CLM-00001\">claim 1</claim-ref> wherein said replacement circuit is coupled to receive a signal indicative of a memory transaction, and wherein said replacement circuit is configured to cause said linear feedback shift register to shift and establish a new state responsive to said signal.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00004\" num=\"4\"><claim-text>4. The cache as recited in <claim-ref idref=\"US-6748492-B1-CLM-00001\">claim 1</claim-ref> wherein said replacement circuit is coupled to receive an indication of said first way, and wherein said replacement circuit is configured to select said predetermined value from a plurality of predetermined values responsive to said indication.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00005\" num=\"5\"><claim-text>5. The cache as recited in <claim-ref idref=\"US-6748492-B1-CLM-00001\">claim 1</claim-ref> wherein said replacement circuit, responsive to a first memory transaction which misses said cache subsequent to said first transaction, is configured to select a first entry of said plurality of entries for eviction, said first entry in said first way of said cache and at a first index corresponding to said first memory transaction.</claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00006\" num=\"6\"><claim-text>6. The cache as recited in <claim-ref idref=\"US-6748492-B1-CLM-00005\">claim 5</claim-ref> wherein said first transaction includes a second index and explicitly specifies a second entry of said plurality of entries, and wherein said first entry and said second entry are a same entry if said first index and said second index are equal.</claim-text></claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00007\" num=\"7\"><claim-text>7. The cache as recited in <claim-ref idref=\"US-6748492-B1-CLM-00001\">claim 1</claim-ref> wherein said associative memory is set associative.</claim-text></claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00008\" num=\"8\"><claim-text>8. The cache as recited in <claim-ref idref=\"US-6748492-B1-CLM-00001\">claim 1</claim-ref> wherein said associative memory is fully associative.</claim-text></claim>"}, {"num": 9, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00009\" num=\"9\"><claim-text>9. A system comprising:</claim-text><claim-text>an associative cache having a plurality of entries, each of said plurality of entries configured to store a cache line of data, said plurality of entries arranged in a plurality of ways; and </claim-text><claim-text>a first circuit coupled to said cache, wherein said first circuit is configured to initiate a first transaction specifying an explicit update of a replacement policy of said cache to select a first way of said plurality of ways; </claim-text><claim-text>wherein said cache is configured to select an entry of said cache for eviction in response to a cache miss by a memory transaction, and wherein said cache is configured to establish a first state corresponding to a selection of said first way of said cache responsive to said first transaction, wherein said cache comprises a linear feedback shift register configured to store a value used to select said entry for eviction, and wherein said cache is configured to update said linear feedback shift register with a predetermined value representing said first state responsive to said first transaction. </claim-text></claim>"}, {"num": 10, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00010\" num=\"10\"><claim-text>10. The system as recited in <claim-ref idref=\"US-6748492-B1-CLM-00009\">claim 9</claim-ref> wherein said first circuit is further configured to initiate a first memory transaction subsequent to said first transaction, and wherein, if said first memory transaction is a miss in said cache, said cache is configured to select a first entry of said plurality of entries for eviction, said first entry in said first way of said cache.</claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00011\" num=\"11\"><claim-text>11. The system as recited in <claim-ref idref=\"US-6748492-B1-CLM-00010\">claim 10</claim-ref> wherein said first transaction explicitly specifies a second entry of said plurality of entries, and wherein said second entry is a same entry as said first entry if an index of said first memory transaction equals an index of said first transaction.</claim-text></claim>"}, {"num": 12, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00012\" num=\"12\"><claim-text>12. The system as recited in <claim-ref idref=\"US-6748492-B1-CLM-00009\">claim 9</claim-ref> wherein said associative cache is set associative.</claim-text></claim>"}, {"num": 13, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00013\" num=\"13\"><claim-text>13. The system as recited in <claim-ref idref=\"US-6748492-B1-CLM-00009\">claim 9</claim-ref> wherein said associative cache is fully associative.</claim-text></claim>"}, {"num": 14, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00014\" num=\"14\"><claim-text>14. A method for synchronizing a cache, the method comprising:</claim-text><claim-text>performing one or more transactions; </claim-text><claim-text>performing a first transaction explicitly specifying a first way of a cache subsequent to said performing one or more transactions; and </claim-text><claim-text>establishing a state in a replacement policy of said cache by updating a linear feedback shift register with a predetermined value that causes said first way to be selected responsive to said performing, wherein said state corresponds to a selection of said first way for eviction in response to a cache miss. </claim-text></claim>"}, {"num": 15, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00015\" num=\"15\"><claim-text>15. A method for flushing a cache, the method comprising:</claim-text><claim-text>performing a first transaction explicitly specifying a first way of said cache; </claim-text><claim-text>establishing said first way as a way to be selected for eviction by updating a linear feedback shift register with a predetermined value that causes said first way to be selected responsive to said performing a first transaction; </claim-text><claim-text>performing a second transaction which misses said cache; and </claim-text><claim-text>evicting a first cache line from said first way of said cache responsive to said performing a second transaction. </claim-text></claim>"}, {"num": 16, "parent": 15, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00016\" num=\"16\"><claim-text>16. The method as recited in <claim-ref idref=\"US-6748492-B1-CLM-00015\">claim 15</claim-ref> further comprising:</claim-text><claim-text>performing a third transaction explicitly specifying a second way of said cache, said second way different from said first way; </claim-text><claim-text>establishing said second way as a way to be selected for eviction responsive to said performing a third transaction; </claim-text><claim-text>performing a fourth transaction which misses said cache; and </claim-text><claim-text>evicting a second cache line from said second way of said cache responsive to said performing a fourth transaction. </claim-text></claim>"}, {"num": 17, "parent": 15, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00017\" num=\"17\"><claim-text>17. The method as recited in <claim-ref idref=\"US-6748492-B1-CLM-00015\">claim 15</claim-ref> further comprising searching a plurality of entries of said cache at a first index for a first cache line prior to performing said first transaction, and wherein said first way used in said first transaction is a way at which said first cache line is stored.</claim-text></claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00018\" num=\"18\"><claim-text>18. The method as recited in <claim-ref idref=\"US-6748492-B1-CLM-00017\">claim 17</claim-ref> wherein said searching comprises, for each one of a plurality of ways of said cache or until said first cache line is found:</claim-text><claim-text>performing a first read transaction explicitly specifying said one of a plurality of ways; </claim-text><claim-text>loading a tag corresponding to said one of said plurality of ways into a register within said cache; </claim-text><claim-text>performing a second read transaction to read said register; and </claim-text><claim-text>comparing said tag to a tag corresponding to said first cache line. </claim-text></claim>"}, {"num": 19, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00019\" num=\"19\"><claim-text>19. A method comprising:</claim-text><claim-text>performing a first transaction explicitly specifying a first way of a cache; and </claim-text><claim-text>establishing said first way as a way to be selected for eviction by updating a linear feedback shift register with a predetermined value that causes said first way to be selected responsive to said performing a first transaction. </claim-text></claim>"}, {"num": 20, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00020\" num=\"20\"><claim-text>20. A carrier medium comprising a database representing:</claim-text><claim-text>an associative memory having a plurality of entries, each of said plurality of entries configured to store a cache line of data, said plurality of entries arranged in a plurality of ways; and </claim-text><claim-text>a replacement circuit configured to select an entry of said associative memory for eviction responsive to a cache miss by a memory transaction, and wherein said replacement circuit is configured, responsive to a first transaction specifying an explicit update of said replacement circuit to select a first way of said plurality of ways, to establish a first state corresponding to a selection of said first way, wherein said replacement circuit comprises a linear feedback shift register configured to store a value used to select said entry for eviction, and wherein said replacement circuit is configured to update said linear feedback shift register with a predetermined value representing said first state responsive to said first transaction. </claim-text></claim>"}, {"num": 21, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00021\" num=\"21\"><claim-text>21. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00020\">claim 20</claim-ref> wherein said replacement circuit employs a pseudo-random replacement policy.</claim-text></claim>"}, {"num": 22, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00022\" num=\"22\"><claim-text>22. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00020\">claim 20</claim-ref> wherein said replacement circuit is coupled to receive a signal indicative of a memory transaction, and wherein said replacement circuit is configured to cause said register to shift and establish a new state responsive to said signal.</claim-text></claim>"}, {"num": 23, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00023\" num=\"23\"><claim-text>23. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00020\">claim 20</claim-ref> wherein said replacement circuit is coupled to receive an indication of said first way, and wherein said replacement circuit is configured to select said predetermined value from a plurality of predetermined values responsive to said indication.</claim-text></claim>"}, {"num": 24, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00024\" num=\"24\"><claim-text>24. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00020\">claim 20</claim-ref> wherein said replacement circuit, responsive to a first memory transaction which misses said cache subsequent to said first transaction, is configured to select a first entry of said plurality of entries for eviction, said first entry in said first way of said cache and at a first index corresponding to said first memory transaction.</claim-text></claim>"}, {"num": 25, "parent": 24, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00025\" num=\"25\"><claim-text>25. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00024\">claim 24</claim-ref> wherein said first transaction includes a second index and explicitly specifies a second entry of said plurality of entries, and wherein said first entry and said second entry are a same entry if said first index and said second index are equal.</claim-text></claim>"}, {"num": 26, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00026\" num=\"26\"><claim-text>26. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00020\">claim 20</claim-ref> wherein said associative memory is set associative.</claim-text></claim>"}, {"num": 27, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00027\" num=\"27\"><claim-text>27. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00020\">claim 20</claim-ref> wherein said associative memory is fully associative.</claim-text></claim>"}, {"num": 28, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00028\" num=\"28\"><claim-text>28. A carrier medium comprising a database representing:</claim-text><claim-text>an associative cache having a plurality of entries, each of said plurality of entries configured to store a cache line of data, said plurality of entries arranged in a plurality of ways; and </claim-text><claim-text>a first circuit coupled to said cache, wherein said first circuit is configured to initiate a first transaction specifying an explicit update of a replacement policy of said cache to select a first way of said plurality of ways; </claim-text><claim-text>wherein said cache is configured to select an entry of said cache for eviction in response to a cache miss by a memory transaction, and wherein said cache is configured to establish a first state corresponding to a selection of said first way of said cache responsive to said first transaction, wherein said cache comprises a linear feedback shift register configured to store a value used to select said entry for eviction, and wherein said cache is configured to update said linear feedback shift register with a predetermined value representing said first state responsive to said first transaction. </claim-text></claim>"}, {"num": 29, "parent": 28, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00029\" num=\"29\"><claim-text>29. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00028\">claim 28</claim-ref> wherein said first circuit is further configured to initiate a first memory transaction subsequent to said first transaction, and wherein, if said first memory transaction is a miss in said cache, said cache is configured to select a first entry of said plurality of entries for eviction, said first entry in said first way of said cache.</claim-text></claim>"}, {"num": 30, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00030\" num=\"30\"><claim-text>30. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00029\">claim 29</claim-ref> wherein said first transaction explicitly specifies a second entry of said plurality of entries, and wherein said second entry is a same entry as said first entry if an index of said first memory transaction equals an index of said first transaction.</claim-text></claim>"}, {"num": 31, "parent": 28, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00031\" num=\"31\"><claim-text>31. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00028\">claim 28</claim-ref> wherein said associative cache is set associative.</claim-text></claim>"}, {"num": 32, "parent": 28, "type": "dependent", "paragraph_markup": "<claim id=\"US-6748492-B1-CLM-00032\" num=\"32\"><claim-text>32. The carrier medium as recited in <claim-ref idref=\"US-6748492-B1-CLM-00028\">claim 28</claim-ref> wherein said associative cache is fully associative.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54193900\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. Field of the Invention</p><p>This invention is related to digital systems and, more particularly, to caches within digital systems.</p><p>2. Description of the Related Art</p><p>Processors and/or the computer systems including the processors typically provide caches to alleviate the high memory latency frequently experienced in computer systems. Generally, a cache is a relatively small, high speed memory which may store copies of data corresponding to various recently-accessed memory locations. Generally, cache storage is allocated and deallocated in units of cache lines (a group of bytes from contiguous memory locations). In other words, the cache may include multiple entries, and each entry may include storage for a cache line of bytes. If requested data for an access is not in the cache (a \u201cmiss\u201d), an entry is allocated for the cache line including the requested data and the cache line is filled into the allocated entry. Subsequently, the data may be found in the cache upon request (a \u201chit\u201d). In some cases, a portion of the cache line (often called a \u201csector\u201d) may be valid while other portions are invalid. However, the entire cache entry is allocated for the cache line if one or more of the sectors are valid.</p><p>Since a cache is generally smaller than the system memory for which the cache is used, cache lines currently stored in the cache may need to be deleted from the cache (referred to as \u201cevicting\u201d the cache line) to make room for newly accessed data which is not stored in the cache. The newly accessed data may be statistically more likely to be accessed again in the near future than is data that has been in the cache for some time, particularly for code which exhibits locality of reference (in which access to a particular datum makes access to nearby data within the memory more likely). Typically, the cache selects one or more cache entries which are eligible to store data corresponding to a given transaction, and searches these entries to detect a hit or miss. In a direct-mapped cache, one entry is eligible to store the data based on the address of the data. If a miss is detected in a direct mapped cache, that cache line in that entry is evicted. In a set associative cache, on the other hand, two or more entries are eligible to store the data based on the address of the data. The cache line of any one of the two or more entries could be evicted on a miss. Set associative caches employ a replacement policy to select one of the two or more eligible entries for eviction. A variety of replacement policies exist.</p><p>Unfortunately, it is frequently difficult to predict, from a viewpoint external to the cache, which cache entry will be allocated to a given cache line. Complex monitoring of the transactions presented to the cache, along with detailed knowledge of the implemented replacement policy, would be required to determine the state of the replacement policy at any given point in time. During the typical access of various data from memory, this lack of ability to determine which cache entry will be selected is generally not a problem. However, in some cases, it may be desirable or even critical to know which cache entry will be allocated according to the replacement policy. For example, in certain testing situations, it may be desirable to ensure that a particular entry is used for a particular transaction. Additionally, knowing which entry will be allocated to a cache miss could be used to intentionally evict the cache line in the entry (e.g. to flush the particular entry from the cache). Thus, a method for easily determining which entry will be selected by a replacement policy is desired.</p><h4>SUMMARY OF THE INVENTION</h4><p>The problems outlined above are in large part solved by a cache as described herein. The cache is configured to receive direct access transactions. Each direct access transaction explicitly specifies a way of the cache. The cache may alter the state of its replacement policy in response to a direct access transaction explicitly specifying a particular way of the cache. The state may be altered such that a succeeding cache miss causes an eviction of the particular way. Thus, a direct access transaction may be used to provide a deterministic setting to the replacement policy, providing predictability to the entry selected to store a subsequent cache miss. In one embodiment, the replacement policy may be a pseudo-random replacement policy. In other embodiments, the replacement circuit may receive a deterministic setting in response to other transactions (e.g. a memory-mapped transaction directed to the replacement circuit or a dedicated bus command).</p><p>The deterministic setting of the replacement policy may have a number of uses. For example, the transaction used to set the replacement policy may provide a synchronization point for the cache. Thus, the same tests may be run in multiple test environments (which may have varying initialization procedures) and the portion after the synchronization may operate in the same manner in the different environments, at least with respect to the cache replacement policy.</p><p>In one embodiment, a direct access transaction also explicitly specifies a cache storage entry to be accessed in response to the transaction. The cache may access the cache storage entry (bypassing the normal tag comparisons and hit determination used for memory transactions) and either read the data from the cache storage entry (for read transactions) or write data from the transaction to the cache storage entry (for write transactions).</p><p>The combination of the direct access transactions and the deterministic setting of the replacement policy may be used in a variety of ways as well. For example, a cache entry flush may be accomplished by performing a direct access transaction to the desired way, followed by a memory transaction which misses. The direct access transaction causes the replacement policy to select the entry in the desired way for eviction for the following memory transaction.</p><p>Additionally, the combination of direct access transactions and the deterministic setting may be used to provide cache testing by using a direct access transaction to select a test way, then using a memory transaction which misses the cache to cause test data to be loaded into the test way. A subsequent direct access transaction may then read the data from the test way to check the test data for correct storage in the selected entry. Additionally, the tag information may be captured in a register within the cache. The tag information may be read from the register and checked for accuracy.</p><p>Broadly speaking, a cache is contemplated comprising an associative memory and a replacement circuit. The memory has a plurality of entries, and each of the plurality of entries is configured to store a cache line of data. The plurality of entries are arranged in a plurality of ways. The replacement circuit is configured to select an entry of the associative memory for eviction responsive to a cache miss by a memory transaction. The replacement circuit is configured, responsive to a first transaction specifying an explicit update of said replacement circuit to select a first way of the plurality of ways, to establish a first state corresponding to a selection of the first way.</p><p>Additionally, a system is contemplated comprising an associative cache and a first circuit coupled to the cache. The cache has a plurality of entries. Each of the plurality of entries configured to store a cache line of data. The plurality of entries are arranged in a plurality of ways. The first circuit is configured to initiate a first transaction specifying an explicit update of a replacement policy of said cache to select a first way of the plurality of ways. The cache is configured to select an entry of the cache for eviction in response to a cache miss by a memory transaction. Additionally, the cache is configured to establish a first state corresponding to a selection of the first way of the cache responsive to the first transaction.</p><p>Moreover, a method for flushing a cache is contemplated. A first transaction explicitly specifying a first way of the cache is performed. The first way is established as a way to be selected for eviction responsive to performing the first transaction. A second transaction is performed which misses the cache. A first cache line is evicted from the first way of the cache responsive to performing the second transaction.</p><p>Still further, a method for synchronizing a cache is contemplated. One or more transactions are performed. A first transaction explicitly specifying a first way of a cache is performed subsequent to performing the one or more transactions. A state in a replacement circuit of the cache is established responsive to the first transaction. The state corresponds to a selection of the first way for eviction in response to a cache miss.</p><p>Additionally, a method for resetting a cache is contemplated. A plurality of write transactions are performed. Each of the plurality of write transactions explicitly identifies a different entry of a cache. Each entry of the cache is initialized with data from a corresponding one of the plurality of write transactions.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>Other objects and advantages of the invention will become apparent upon reading the following detailed description and upon reference to the accompanying drawings in which:</p><p>FIG. 1 is a block diagram of one embodiment of a system.</p><p>FIG. 2 is a block diagram of one embodiment of a cache shown in FIG. <b>1</b>.</p><p>FIG. 3 is a block diagram of one embodiment of an address from a memory address space and one embodiment of an address from a direct access address space.</p><p>FIG. 4 is a flowchart illustrating operation of one embodiment of the cache shown in FIGS. 1 and 2 for a read transaction.</p><p>FIG. 5 is a flowchart illustrating operation of one embodiment of the cache shown in FIGS. 1 and 2 for a write transaction.</p><p>FIG. 6 is a block diagram of one embodiment of a replacement circuit shown in FIG. <b>2</b>.</p><p>FIG. 7 is a flowchart illustrating operation of one embodiment of a control unit shown in FIG. <b>6</b>.</p><p>FIG. 8 is a flowchart illustrating one embodiment of testing the cache shown in FIGS. 1 and 2.</p><p>FIG. 9 is a flowchart illustrating one embodiment of resetting the cache shown in FIGS. 1 and 2.</p><p>FIG. 10 is a flowchart illustrating one embodiment of synchronization of the cache shown in FIGS. 1 and 2.</p><p>FIG. 11 is a flowchart illustrating one embodiment of flushing the cache shown in FIGS. 1 and 2.</p><p>FIG. 12 is a flowchart illustrating one embodiment of flushing one cache line shown in FIGS. 1 and 2.</p><p>FIG. 13 is a block diagram of an exemplary carrier medium.</p><p>While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</h4><p>Turning now to FIG. 1, a block diagram of one embodiment of a system <b>10</b> is shown. Other embodiments are possible and contemplated. In the embodiment of FIG. 1, system <b>10</b> includes processors <b>12</b>A-<b>12</b>B, an L2 cache <b>14</b>, a memory controller <b>16</b>, a high speed input/output (I/O) bridge <b>18</b>, an I/O bridge <b>20</b>, and I/O interfaces <b>22</b>A-<b>22</b>B. System <b>10</b> may include a bus <b>24</b> for interconnecting the various components of system <b>10</b>. As illustrated in FIG. 1, each of processors <b>12</b>A-<b>12</b>B, L2 cache <b>14</b>, memory controller <b>16</b>, high speed I/O bridge <b>18</b> and I/O bridge <b>20</b> are coupled to bus <b>24</b>. I/O bridge <b>20</b> is coupled to I/O interfaces <b>22</b>A-<b>22</b>B. L2 cache <b>14</b> is coupled to memory controller <b>16</b>, which is further coupled to a memory <b>26</b>.</p><p>Generally, processors <b>12</b>A-<b>12</b>B and/or the I/O bridges/interfaces may initiate transactions on the bus <b>24</b>. Transactions may include read transactions (transfers of data to the transaction initiator) and write transactions (transfers of data from the transaction initiator). Transactions may further include various coherency commands (e.g. an invalidate command) which may or may not involve a transfer of data.</p><p>System <b>10</b> supports various types of transactions on bus <b>24</b>. Memory transactions are transactions which target a memory location. Additionally, system <b>10</b> supports direct access transactions to L2 cache <b>14</b>. As used herein, the term \u201cdirect access transaction\u201d refers to a transaction which targets an entry in L2 cache <b>14</b> and explicitly specifies that entry. If the direct access transaction is a read, the data in the specified entry is returned by L2 cache <b>14</b>. If the direct access transaction is a write, the data provided in the write transaction is stored in the entry. System <b>10</b> may further support I/O transactions and configuration transactions on bus <b>24</b>.</p><p>An addressable range of system <b>10</b> is defined by the size of the addresses which may be transmitted on bus <b>24</b>. The addressable range may be divided into several address spaces including a memory address space, a direct access address space, an I/O address space, and various configuration address spaces. In this embodiment, the address space which includes the address of a transaction may identify the type of the transaction. Thus, an address within the memory address space indicates that the transaction is a memory transaction and the address identifies a targeted memory location in memory <b>26</b> (and thus memory controller <b>16</b> and L2 cache <b>14</b> may respond to the transaction). An address within the I/O memory mapped address space indicates that the transaction is an I/O transaction and the address targets an I/O device on one of the I/O interfaces. An address within the configuration address space indicates that the transaction is a configuration transaction and the address targets various configuration registers in devices within system <b>10</b>.</p><p>An address within the direct access address space indicates that the transaction is a direct access transaction and the address specifies the entry of L2 cache <b>14</b> to be directly accessed by the direct access transaction. For memory transactions, the entry (if any) of L2 cache <b>14</b> accessed to store or return data for the memory transaction is determined by comparing the tags of cache lines stored in the entries to the address of the memory transaction. On the other hand, direct access transactions explicitly specify the entry to be accessed. L2 cache <b>14</b> may access the specified entry without regard to the tag comparisons normally used to select the accessed entry. In one embodiment, direct access transactions may transfer an entire cache line of data. However, other embodiments may transfer a portion of a cache line in response to direct access transactions.</p><p>While the above description uses address spaces to determine transaction type, other embodiments may determine transaction type in other ways. For example, command type encodings could be provided on control signals transmitted during the address portion of the transaction.</p><p>Using direct access transactions, L2 cache <b>14</b> may be tested for defects by any device attached to bus <b>24</b>. The device may initiate direct access transactions to read and write the entries of L2 cache <b>14</b>. Test data may be written, and then read back and checked to ensure that no errors occurred in storing of the test data in the specified entry.</p><p>Each entry may be tested in this manner. For example, one of processors <b>12</b>A-<b>12</b>B may execute a code sequence which performs the desired tests. Since the tests are performed via software, the test algorithm is flexible and may easily be changed. The problem of incorrectly implementing a test algorithm in BIST hardware may thus be eliminated.</p><p>Additionally, since software is used to implement the test instead of BIST hardware, there may be more flexibility in the algorithms that can be used since the requirement to keep the hardware small is eliminated.</p><p>Additionally, since the test is conducted via transactions received by L2 cache <b>14</b>, any device attached to the bus <b>24</b> may be used to perform the test. Thus, if there is a problem (bug, manufacturing defect, etc.) with one or both of processors <b>12</b>A-<b>12</b>B, other devices may be used to perform the test. In one embodiment, the direct access address space is located within 32 bits of address (i.e. more significant bits than the 32 bits are zero), which allows any device capable of generating 32 bits of address to perform direct access transactions. Thus, for example, a device on the PCI bus (one example of an I/O interface) could be used to perform the tests. Accordingly, testing can be performed even if processors <b>12</b>A-<b>12</b>B are non-functional.</p><p>In addition to specifically identifying an entry, another advantage direct access transactions may have over attempting to use memory transactions to perform testing is that, if an entry has a defect in the tag portion of the entry, it may be difficult to get a hit in that entry (since the tag is stored in a faulty manner). By using direct access transactions, the hit circuitry is ignored and the specified entry is accessed.</p><p>In one embodiment, L2 cache <b>14</b> may include a register which captures the tag portion of the specified entry in response to direct access transactions. This register may be read as part of the test transactions, to check that the tag is stored without error as well.</p><p>In one embodiment, L2 cache <b>14</b> may employ error checking and correction (ECC) to protect the tags and/or data in the cache. If an uncorrectable ECC error is detected, a direct access write transaction may be used to overwrite the entry for which the error is detected. In this manner, the data in error may be eliminated from the cache. ECC bits corresponding to the data being written may be generated and stored by L2 cache <b>14</b> in response to the direct access write transaction.</p><p>In one embodiment L2 cache <b>14</b> includes a replacement circuit implementing the replacement policy of the cache. The replacement circuit may, in response to a direct access transaction specifying a first way, establish a state corresponding to the first way. If the next transaction is a memory transaction which misses L2 cache <b>14</b>, the first way may be selected from the addressed set for eviction. In this manner, the way selected for the next memory transaction is deterministic. Alternatively, the replacement circuit may establish a state responsive to other types of transactions than direct access transactions. For example, the replacement circuit may be memory-mapped for a write transaction to a predetermined address, and the data in the write transaction may indicate the desired state (or the first way). As another example, a dedicated bus command could be used to convey the state or the first way.</p><p>The deterministic setting of the replacement policy may be used for enhanced testing. Since the direct access transactions, in one embodiment, are determined from an address space, some of the address bits in the tag of the entry may not be varied using direct access write transactions. Thus, a direct access transaction to the desired way may be performed, followed by a memory transaction (which misses the cache) to the desired index. The miss by the memory transaction causes an eviction to store the cache line addressed by the memory transaction, and the evicted cache line is from the desired way. The tag is updated with the address of the memory transaction. Subsequently, a direct access read transaction may be performed, and the tag may be captured by the above mentioned register. The tag may be checked to ensure it was stored without error. Thus, additional freedom in varying the tag bits may be achieved.</p><p>The deterministic setting of the replacement policy may have other uses as well. For example, the deterministic setting may be used, after various initialization procedures have been performed, to provide a synchronization point for the replacement policy. This may be useful in validation, especially if similar tests are to be run in different test environments. Furthermore, controlling which entry will be used for a miss may be useful generally in validation testing. Additionally, the deterministic setting may be used to flush L2 cache <b>14</b> without requiring an explicit flush command on bus <b>24</b>. Instead, sequences of a direct access transaction (to set the replacement policy) followed by a memory transaction which misses (to evict the cache line in the selected way) may be used to flush the cache.</p><p>In one embodiment, the replacement policy of L2 cache <b>14</b> is a pseudo-random policy (also referred to simply as random). In a \u201cpseudo-random\u201d policy, the replacement circuit sequences through a set of states, and the state existing when a particular miss is detected determines the way selected for eviction. In such a replacement policy, a state may be established consistent with selection of the way identified by the direct access transaction to provide determinism for a succeeding eviction.</p><p>Other replacement policies may be used as well. For example, if a least recently used (LRU) policy is employed, the LRU policy for the index identified by the direct access transaction may be set to indicate that the way identified by the direct access transaction is least recently used. A subsequent miss to the same index may generate an eviction of the way identified by the direct access transaction.</p><p>Processors <b>12</b>A-<b>12</b>B may be designed to any instruction set architecture, and may execute programs written to that instruction set architecture. Exemplary instruction set architectures may include the MIPS instruction set architecture (including the MIPS-3D and MIPS MDMX application specific extensions), the IA-32 or IA-64 instruction set architectures developed by Intel Corp., the PowerPC instruction set architecture, the Alpha instruction set architecture, the ARM instruction set architecture, or any other instruction set architecture.</p><p>L2 cache <b>14</b> is a high speed cache memory. L2 cache <b>14</b> is referred to as \u201cL2\u201d since processors <b>12</b>A-<b>12</b>B may employ internal level <b>1</b> (\u201cL1\u201d) caches. If L1 caches are not included in processors <b>12</b>A-<b>12</b>B, L2 cache <b>14</b> may be an L1 cache. Furthermore, if multiple levels of caching are included in processors <b>12</b>A-<b>12</b>B, L2 cache <b>14</b> may be a lower level cache than L2. L2 cache <b>14</b> may employ any organization, including direct mapped, set associative, and fully associative organizations. In one particular implementation, L2 cache <b>14</b> may be a 512 kilobyte, 4 way set associative cache having 32 byte cache lines. A set associative cache is a cache arranged into multiple sets, each set comprising two or more entries. A portion of the address (the \u201cindex\u201d) is used to select one of the sets (i.e. each encoding of the index selects a different set). The entries in the selected set are eligible to store the cache line accessed by the address. Each of the entries within the set is referred to as a \u201cway\u201d of the set. The portion of the address remaining after removing the index (and the offset within the cache line) is referred to as the \u201ctag\u201d, and is stored in each entry to identify the cache line in that entry. The stored tags are compared to the corresponding tag portion of the address of a memory transaction to determine if the memory transaction hits or misses in the cache, and is used to select the way in which the hit is detected (if a hit is detected).</p><p>Memory controller <b>16</b> is configured to access memory <b>26</b> in response to memory transactions received on bus <b>24</b>. Memory controller <b>16</b> receives a hit signal from L2 cache <b>14</b>, and if a hit is detected in L2 cache <b>14</b> for a memory transaction, memory controller <b>16</b> does not respond to that memory transaction. If a miss is detected by L2 cache <b>14</b>, or the memory transaction is non-cacheable, memory controller <b>16</b> may access memory <b>26</b> to perform the read or write operation. Memory controller <b>16</b> may be designed to access any of a variety of types of memory. For example, memory controller <b>16</b> may be designed for synchronous dynamic random access memory (SDRAM), and more particularly double data rate (DDR) SDRAM. Alternatively, memory controller <b>16</b> may be designed for DRAM, Rambus DRAM (RDRAM), SRAM, or any other suitable memory device.</p><p>High speed I/O bridge <b>18</b> may be an interface to a high speed I/O interconnect. For example, high speed I/O bridge <b>18</b> may implement the Lightning Data Transport (LDT) I/O fabric developed by Advanced Micro Devices, Inc. Other high speed interfaces may be alternatively used.</p><p>I/O bridge <b>20</b> is used to link one or more I/O interfaces (e.g. I/O interfaces <b>22</b>A-<b>22</b>B) to bus <b>24</b>. I/O bridge <b>20</b> may serve to reduce the electrical loading on bus <b>24</b> if more than one I/O interface <b>22</b>A-<b>22</b>B is bridged by I/O bridge <b>20</b>. Generally, I/O bridge <b>20</b> performs transactions on bus <b>24</b> on behalf of I/O interfaces <b>22</b>A-<b>22</b>B and relays transactions targeted at an I/O interface <b>22</b>A-<b>22</b>B from bus <b>24</b> to that I/O interface <b>22</b>A-<b>22</b>B. I/O interfaces <b>22</b>A-<b>22</b>B may be lower bandwidth, higher latency interfaces. For example, I/O interfaces <b>22</b>A-<b>22</b>B may include one or more serial interfaces, Personal Computer Memory Card International Association (PCMCIA) interfaces, Ethernet interfaces (e.g. media access control level interfaces), Peripheral Component Interconnect (PCI) interfaces, etc.</p><p>Bus <b>24</b> may have any suitable protocol and construction. According to one implementation, bus <b>24</b> may be a split transaction bus. The implementation may include an address bus supporting up to 40 bits of addressable range and a data bus capable of transmitting one cache line per clock cycle (e.g. 32 bytes). Other widths for either the address bus or data bus are possible and contemplated. The bus may also include transactions to support maintaining memory coherency (e.g. an invalidate command). The bus may use any suitable signalling technique (e.g. differential or non-differential signalling).</p><p>It is noted that system <b>10</b> (and more particularly processors <b>12</b>A-<b>12</b>B, L2 cache <b>14</b>, memory controller <b>16</b>, I/O interfaces <b>22</b>A-<b>22</b>B, I/O bridge <b>20</b>, I/O bridge <b>18</b> and bus <b>24</b> may be integrated onto a single integrated circuit as a system on a chip configuration. In another configuration, memory <b>26</b> may be integrated as well. Alternatively, one or more of the components may be implemented as separate integrated circuits, or all components may be separate integrated circuits, as desired. Any level of integration may be used.</p><p>As used herein, a transaction \u201ctargets\u201d a location or device if the location or device is the provider of data for the transaction (for a read transaction) or receiver of data for the transaction (for a write transaction). Viewed in another way, a transaction may target a location or device if the address of the transaction is mapped to that location or device.</p><p>Turning now to FIG. 2, a block diagram of one embodiment of L2 cache <b>14</b> is shown. Other embodiments are possible and contemplated. In the embodiment of FIG. 2, L2 cache <b>14</b> includes a tags memory <b>30</b>, a data memory <b>32</b>, a set of comparators <b>34</b>A-<b>34</b>D, a control circuit <b>36</b>, a pair of decoders <b>38</b> and <b>40</b>, a tag register <b>42</b>, a replacement circuit <b>44</b>, and multiplexors (muxes) <b>46</b> and <b>48</b>. Tags memory <b>30</b> and data memory <b>32</b> are each coupled to receive an index portion of the address of a transaction (the address of the transaction may be referred to herein as the \u201cinput address\u201d). Data memory <b>32</b> is coupled to receive and provide data corresponding to the transaction. Tags memory <b>30</b> is further coupled to receive a tag portion of the input address, and is coupled to comparators <b>34</b>A-<b>34</b>D and mux <b>46</b>. Comparators <b>34</b>A-<b>34</b>D are further coupled to receive the tag portion of the input address and are coupled to control circuit <b>36</b>. Control circuit <b>36</b> is coupled to receive a portion of the input address, control information corresponding to a transaction, and a direct access signal from decoder <b>38</b>. Control circuit <b>36</b> is coupled to provide a way selection to tags memory <b>30</b>, data memory <b>32</b>, and mux <b>46</b>. Control circuit <b>36</b> is further coupled to provide control signals to tags memory <b>30</b> and data memory <b>32</b>, and is coupled to provide a hit signal to memory controller <b>16</b>. Control circuit <b>36</b> is still further coupled to tag register <b>42</b> and replacement circuit <b>44</b>, which is further coupled to receive a portion of the input address and the direct access signal from decoder <b>38</b>. Tag register <b>42</b> is coupled to receive the direct access signal and is coupled to mux <b>48</b>. Decoders <b>38</b> and <b>40</b> are coupled to receive a portion of the input address, and decoder <b>40</b> is coupled to mux <b>48</b>.</p><p>Generally, tags memory <b>30</b> stores the tag information for each entry in L2 cache <b>14</b>, and data memory <b>32</b> stores the cache line of data for each entry in L2 cache <b>14</b>. Thus, an entry comprises a tag memory storage location and a data memory storage location. The tag memory storage location stores the tag for the entry (and possibly other information, such as validity and dirty information). For example, in one implementation, the tag information for an entry includes the tag portion of the address (e.g. bits <b>39</b>:<b>17</b> in the illustrated embodiment), a valid bit indicating the validity or lack of validity of the entry, and a dirty bit indicating the dirty or clean state of the cache line. A cache line is dirty if at least one byte of the cache line has been modified in L2 cache <b>14</b> and the modification has not been written to memory <b>26</b>. The data memory storage location stores the cache line of data in the entry.</p><p>During memory transactions, the index portion of the input address (e.g. bits <b>16</b>:<b>5</b> in the illustrated embodiment) is provided to tags memory <b>30</b> and data memory <b>32</b>. Each memory selects a set of storage locations in response to the index. Tags memory <b>30</b> outputs the tag from each selected storage location to comparators <b>34</b>A-<b>34</b>D, which compare the tags to the tag portion of the input address. If the tag compares equally, and the entry is valid, the corresponding comparator <b>34</b>A-<b>34</b>D may signal a hit to control circuit <b>36</b>. Control circuit <b>36</b> may assert the hit signal to memory controller <b>16</b> if any of the comparators <b>34</b>A-<b>34</b>D indicates a hit, and may determine a way selection from the output of comparators <b>34</b>A-<b>34</b>D as well. Each comparator <b>34</b>A-<b>34</b>D is comparing the tag from a different way of L2 cache <b>14</b>, and thus the comparator output indicating a hit is an indication of the hitting way. Control circuit <b>36</b> provides the way selection to tags memory <b>30</b> and data memory <b>32</b>.</p><p>Data memory <b>32</b> provides data from the storage location at the selected index and way, or receives data into that storage location, depending upon whether the memory transaction is a read or write transaction. Control circuit <b>36</b> receives the control information corresponding to the transaction, and generates control signals for data memory <b>32</b> and tags memory <b>30</b>. The control signals may include, for example, an enable signal and a read/write signal to indicate whether the memory is to read or write.</p><p>Tags memory <b>30</b> may be updated in response to the transaction as well. For example, if the transaction is a write, the dirty bit in the hitting entry may be updated. Additionally, if the transaction is a miss in L2 cache <b>14</b> and is cacheable, L2 cache <b>14</b> may select a way for eviction to receive a line fill of the missing line. More particularly, replacement circuit <b>44</b> may be configured to select the way to be evicted. The evicted way may be provided as the way selection, and the valid bit in the evicted entry may be cleared to invalidate the cache line. The cache line may also be provided from data memory <b>32</b> for writing to memory <b>26</b> if the cache line is dirty. It is noted that tag updates and evictions may not occur in the same clock cycle that L2 cache <b>14</b> is accessed to determine the hit/miss of the input address, in some embodiments.</p><p>Replacement circuit <b>44</b> may additionally change state responsive to a memory transaction. The state may be changed after each memory transaction, regardless of whether the transaction is a hit or miss, or may be changed only after memory transactions which miss, according to design choice.</p><p>During direct access transactions, control circuit <b>36</b> receives an assertion of the direct access signal from decoder <b>38</b>. Decoder <b>38</b> decodes the address of the transaction to detect that the address is in the direct access address space, and asserts the direct access signal if the address is in the direct access address space. For example, in the illustrated embodiment, the direct access address space may be the addresses having a predetermined combination of address bits <b>39</b>:<b>27</b>. In one particular implementation, the combination of bits <b>39</b>:<b>28</b> may be (in hexadecimal) 00D and bit <b>27</b> may be 0. It is noted that the address space may be made smaller by including more of the most significant address bits to decoder <b>38</b> (e.g. additional bits below bit position <b>27</b>) or larger by decoding fewer bits. Furthermore, the selection of an address range for the direct access address space is arbitrary and may be located anywhere in the addressable range, as desired.</p><p>In response to the direct access signal, control circuit <b>36</b> ignores the hit signals from comparators <b>34</b>A-<b>34</b>D. The direct access transaction is treated as a cache hit. The entry to be accessed (read or written) is explicitly identified by the direct access transaction. For example, in the present embodiment, address bits other than those used to identify the direct access address space are used to supply the index and way of the entry. More particularly in the illustrated embodiment, the same address bits used to index the cache in memory transactions are used to supply the index in a direct access transaction. In this manner, additional hardware to provide the index to tags memory <b>30</b> and data memory <b>32</b> for direct access transactions may be avoided. The way is supplied in other address bits (e.g. more significant address bits than the index). In the illustrated embodiment, the more significant address bits contiguous to the index bits are used to convey the way selection (e.g. address bits <b>18</b>:<b>17</b> provided to control circuit <b>36</b>). Control circuit <b>36</b> provides the way selection indicated by the direct access transaction as the way selection to tags memory <b>30</b> and data memory <b>32</b>.</p><p>Since the hit signals from comparators <b>34</b>A-<b>34</b>D are ignored by control circuit <b>36</b> for direct access transactions, the tag of the selected entry need not match the tag portion of the input address for direct access transactions. If the direct access transaction is a read, the data in the selected entry is provided regardless of any tag match or mismatch. If the direct access transaction is a write, the data provided in the direct access transaction is written to the selected entry, overwriting the data currently stored in the entry. For direct access write transactions, control circuit <b>36</b> may update the tag in the selected entry with the tag portion of the input address. In this manner, if the entry was previously storing valid memory transaction data, the entry will be a miss for memory transactions affecting that memory transaction data. Additionally, bits in the tag portion of the input address may be used to specify the desired state of the valid and dirty bits in the tag information. These bits may be written to the valid and dirty bits in the tag information of the specified entry. Additionally, since the direct access transactions are treated as cache hits, there may be no eviction of a cache line in response to direct access transactions.</p><p>Control circuit <b>36</b> may assert the hit signal to memory controller <b>16</b> in response to direct access transactions, if desired. Alternatively, since the illustrated embodiment employs a separate address space for memory transactions and direct access transactions, memory controller <b>16</b> may ignore direct access transactions on bus <b>24</b>.</p><p>Replacement circuit <b>44</b> also receives the direct access signal and the portion of the input address specifying the way for direct access transactions. If a direct access transaction is detected, replacement circuit <b>44</b> establishes a state corresponding to the way specified by the direct access transaction. Thus, if the next memory transaction is a miss, replacement circuit <b>44</b> selects the way specified by the direct access transaction for eviction.</p><p>Tag register <b>42</b> receives the direct access signal as well, and may use the signal as a write enable. Tag register <b>42</b> receives, as a data input, the tag information from the way selected for the transaction. More particularly, tag register <b>42</b> may receive a data input from mux <b>46</b>. Mux <b>46</b> receives the tag information from the indexed entries, and selects the tag information from one of the indexed entries using the way selection provided by control circuit <b>36</b> as a selection control. Since, for direct access transactions, the way selection is the way specified by the direct access transaction, mux <b>46</b> selects the tag information corresponding to the entry specified by the direct access transaction. Thus, tag register <b>42</b> captures the tag information of the entry specified by the direct access transaction. The information captured by tag register <b>42</b> may include the tag portion of the address as well as other tag information (e.g. the valid indication and the dirty indication). In one embodiment, the tag may be protected by ECC. The ECC bits may be captured by tag register <b>42</b> as well. In one embodiment, the way from which the tag was read may also be captured by register <b>42</b>.</p><p>Tag register <b>42</b> outputs the data stored therein to mux <b>48</b>. Decoder <b>40</b> provides the selection control to mux <b>48</b>, and selects the data from data memory <b>32</b> unless a transaction to the address mapped to register <b>42</b> is detected. Tag register <b>42</b> may be mapped to any suitable address within the addressable range. Decoder <b>40</b> decodes the address of a transaction and, if the address is the address to which tag register <b>42</b> is mapped, decoder <b>40</b> selects the contents of tag register <b>42</b> via mux <b>48</b>.</p><p>It is noted that the embodiment illustrated in FIG. 2 shows various exemplary address bit ranges for a particular implementation of the L2 cache (e.g. 4 way set associative, 512 kilobytes, with 32 byte cache lines) and the size of the addresses provided on bus <b>24</b>. Other embodiments may vary any of these features and the bit ranges may be updated accordingly. For example, if more ways are provided, the bit range providing the way for direct access transactions may be increased. If the size of the cache is increased and the number of ways remains the same, the index bit range may be expanded (and the tag range reduced). Also, the bit range for the way selection may be moved to accommodate the larger index. The size of the address (40 bits in the illustrated embodiment) may be varied, affecting the bit ranges appropriately as well. Furthermore, the bit ranges may be selected differently in different implementations, according to design choice.</p><p>It is noted that, while tags memory <b>30</b> and data memory <b>32</b> are illustrated separately in FIG. 2, these memories may be integrated if desired. Generally, tags memory <b>30</b> and data memory <b>32</b> may form a memory for storing tags and corresponding cache lines of data, whether the memory is divided into portions as illustrated or is a single integrated memory.</p><p>It is noted that, while the embodiment illustrated in FIG. 2 detects direct access transactions via an address space, other embodiments may detect direct access transactions in other ways. For example, an alternative embodiment may employ different encodings on the control signals of bus <b>24</b> to identify memory transactions and direct access transactions, if desired.</p><p>It is noted that, while the illustrated embodiment conveys the index and way as portions of the address of a direct access transaction, other embodiments may convey this information on separate control signals, if desired. Furthermore, rather than using an index and way to identify an entry, each entry could be assigned an entry number and the entry number may be conveyed (as part of the address of a direct access transaction or on control signals, for example). Generally, any method of transmitting an identification of the way may be used to explicitly identify the first entry. It is still further noted that, while the illustrated embodiment is set associative, other embodiments may have other configurations. For example, direct mapped embodiments are contemplated (in which an entry may be identified by index only, by an entry number, or any other method of transmitting the identification) and fully associative embodiments are contemplated (in which an entry may be identified by way only, by an entry number, or any other method of transmitting the identification).</p><p>It is noted that FIG. 2 illustrates address, data, and control signals being supplied to the L2 cache circuitry. L2 cache <b>14</b> may include buffers or queues (not shown) to capture address and data portions of transactions. The supplied address, data, and control signals may correspond to the transaction at the head of the buffers or queues.</p><p>Turning now to FIG. 3, a block diagram illustrating an exemplary memory transaction address <b>50</b> and an exemplary direct access transaction address <b>52</b> is shown. The addresses illustrated in FIG. 3 may correspond to the embodiment illustrated in FIG. <b>2</b>.</p><p>Memory transaction address <b>50</b> includes an offset field <b>54</b>, an index field <b>56</b>, and a tag field <b>58</b>. Offset field <b>54</b> includes the bits defining the offset within a cache line. Index field <b>56</b> includes the bits used to index L2 cache <b>14</b> (e.g. bits <b>16</b>:<b>5</b> in the embodiment illustrated in FIG. <b>2</b>). Tag field <b>58</b> includes the remaining bits of the address not included in offset field <b>54</b> and index field <b>56</b>. Tag field <b>58</b> includes the address bits stored in tag memory <b>30</b> and compared to the corresponding portion of the input address.</p><p>Direct access transaction address <b>52</b> includes offset field <b>54</b> and index field <b>56</b>, similar to memory transaction address <b>50</b>. Additionally, direct access transaction address <b>52</b> includes a way field <b>60</b> identifying the way to be accessed in response to the direct access transaction (e.g. bits <b>18</b>:<b>17</b> in the embodiment illustrated in FIG. <b>2</b>). A field <b>62</b> including a set of most significant bits of direct access transaction address <b>52</b> are encoded to select the direct access memory address space (e.g. bits <b>39</b>:<b>27</b> in the embodiment illustrated in FIG. <b>2</b>). Any encoding may be used to identify the direct access address space according to design choice. Direct access transaction address <b>52</b> further includes a valid bit <b>64</b> and a dirty bit <b>66</b>. These bits may be written to the valid and dirty bits of the selected tag entry if a tag update is performed (e.g. in response to a direct access write transaction, in one embodiment). Additionally, since way field <b>60</b>, valid bit <b>64</b> and dirty bit <b>66</b> are part of the tag portion of the address in the illustrated embodiment, these bits are written to the corresponding tag bits in the selected tag entry as well. The remaining bits of the direct transaction address <b>52</b> (field <b>68</b>) may be don't cares in the present embodiment. However, the value provided in field <b>68</b> may be written to the tag of the entry if the direct access transaction is a write.</p><p>It is noted that the bits comprising offset field <b>54</b> may not actually be transmitted on one embodiment of bus <b>24</b>. Instead, byte enables may be transmitted indicating which bytes are accessed by the transaction. The byte enable for the byte identified by offset field <b>54</b> is set, and additional byte enables based on the size of the transaction may be set.</p><p>Turning now to FIG. 4, a flowchart illustrating operation of one embodiment of L2 cache <b>14</b> (and more particularly control circuit <b>36</b> and/or replacement circuit <b>44</b>, in the embodiment of FIG. 2) for a read transaction is shown. Other embodiments are possible and contemplated. While the blocks shown in FIG. 4 may be illustrated in a particular order for ease of understanding, the blocks may be performed in parallel by combinatorial logic circuitry within L2 cache <b>14</b>. Furthermore, various blocks may be performed in different clock cycles (e.g. the operation may be pipelined) according to design choice.</p><p>If the read transaction is a direct access transaction (decision block <b>70</b>), L2 cache <b>14</b> provides the data from the selected entry in response to the read transaction (block <b>72</b>). The selected entry is identified by the explicit index and way provided by the direct access transaction. Whether or not the tag portion of the address in the selected entry matches the address of the read transaction does not affect the forwarding of data, and no cache eviction may occur.</p><p>Additionally, replacement circuit <b>44</b> may establish a state corresponding to the specified way in response to the direct access transaction (block <b>73</b>). In other words, the state established may result in an eviction from the specified way if the next transaction is a miss in L2 cache <b>14</b>.</p><p>If the read transaction is a memory transaction (\u201cno\u201d leg of decision block <b>70</b>), L2 cache <b>14</b> determines if the address hits (decision block <b>74</b>). If the address hits, the data from the hitting entry is provided in response to the read transaction (block <b>76</b>). If the read transaction is a miss, L2 cache <b>14</b> selects an entry for eviction of the cache line stored therein, to be replaced by the cache line accessed by the read transaction (block <b>78</b>).</p><p>Turning now to FIG. 5, a flowchart illustrating operation of one embodiment of L2 cache <b>14</b> (and more particularly control circuit <b>36</b> and/or replacement circuit <b>44</b>, in the embodiment of FIG. 2) for a write transaction is shown. Other embodiments are possible and contemplated. While the blocks shown in FIG. 5 may be illustrated in a particular order for ease of understanding, the blocks may be performed in parallel by combinatorial logic circuitry within L2 cache <b>14</b>. Furthermore, various blocks may be performed in different clock cycles (e.g. the operation may be pipelined) according to design choice.</p><p>If the write transaction is a direct access transaction (decision block <b>80</b>), L2 cache <b>14</b> stores the data included in the write transaction into the selected entry (block <b>82</b>). The selected entry is identified by the explicit index and way provided by the direct access transaction. Whether or not the tag portion of the address in the selected entry matches the address of the write transaction does not affect the updating of the selected entry. Furthermore, if valid data is stored in the entry, that data is overwritten (even if the tag does not match the address of the write transaction). Additionally, the tag of the selected entry may be updated with the corresponding portion of the address of the write transaction (block <b>84</b>). In this manner, the entry may not be affected by coherency activity in the memory address space.</p><p>Still further, replacement circuit <b>44</b> may establish a state corresponding to the specified way in response to the direct access transaction (block <b>85</b>). In other words, the state established may result in an eviction from the specified way if the next transaction is a miss in L2 cache <b>14</b>.</p><p>If the write transaction is a memory transaction (\u201cno\u201d leg of decision block <b>80</b>), L2 cache <b>14</b> determines if the address hits (decision block <b>86</b>). If the address hits, the data included in the write transaction is written to the hitting entry (block <b>88</b>). If the write transaction is a miss, L2 cache <b>14</b> selects an entry for eviction of the cache line stored therein, to be replaced by the cache line accessed by the write transaction (block <b>90</b>).</p><p>While the embodiment illustrated via FIG. 5 allocates an entry for write memory transactions which miss L2 cache <b>14</b>, other embodiments may not allocate an entry for write misses or may provide for programmability of write allocation, as desired. Additionally, the embodiment illustrated via FIGS. 4 and 5 assumes that the transaction is cacheable in L2 cache <b>14</b>. Some embodiments may provide for indicating the cacheability of each transaction. If a transaction is indicated to be non-cacheable, L2 cache <b>14</b> may not respond to the transaction.</p><p>Turning next to FIG. 6, a block diagram of one embodiment of replacement circuit <b>44</b> is shown. Other embodiments are possible and contemplated. In the embodiment of FIG. 6, replacement circuit <b>44</b> includes a control circuit <b>100</b>, a register <b>102</b>, an output circuit <b>104</b>, and a next state circuit <b>106</b>. Control circuit <b>100</b> is coupled to receive the direct access signal from decoder <b>38</b>, the portion of the input address specifying the way for direct access transactions, and an access signal from control circuit <b>36</b>. Control circuit <b>100</b> is coupled to provide control signals and an override value to register <b>102</b>, which is coupled to output circuit <b>104</b> and next state circuit <b>106</b>. Output circuit <b>104</b> is coupled to provide a replacement way to control circuit <b>36</b>.</p><p>Generally, replacement circuit <b>44</b> provides a replacement way to control circuit <b>36</b> for use in evicting a cache line if a miss is detected. Register <b>102</b> stores a state of replacement circuit <b>36</b>, and output circuit <b>104</b> generates the replacement way from the state. More particularly, output circuit <b>104</b> may logically combine various bits from register <b>102</b> to generate the replacement way. The logic gates and bits combined by the logic gates as illustrated in output circuit <b>104</b> are merely exemplary. Any bits may be combined in any logic equation to generate the replacement way.</p><p>In the illustrated embodiment, replacement circuit <b>44</b> changes state for each access of L2 cache <b>14</b> (irrespective of whether or not the access hits or misses). Thus, control circuit <b>36</b> signals replacement circuit <b>44</b> if an access is received by L2 cache <b>14</b> via the access signal. Control circuit <b>100</b> may cause register <b>102</b> to capture a new state in response to the access signal. More particularly, register <b>102</b> may be a linear feedback shift register. Next state circuit <b>106</b> may generate a bit to be shifted into register <b>102</b>, and the remaining bits may be shifted to the right (as illustrated in FIG. <b>6</b>), with the rightmost bit being deleted from register <b>102</b>. Control circuit <b>100</b> may assert a shift control signal to register <b>102</b>, causing register <b>102</b> to shift in the bit from next state circuit <b>106</b> and shift the remaining bits. The logic gate and bits combined by the logic gate as illustrated in next state circuit <b>106</b> are merely exemplary. Any bits may be combined in any logic equation to generate the next state. Generally, the combination of output circuit <b>104</b> and next state circuit <b>106</b> may be selected so that the distribution of ways selected over time has reasonable dispersion (e.g. the pattern of ways selected over consecutive state changes tends not to select the same way consecutively and repeatedly).</p><p>On the other hand, if a direct access transaction is received (signalled via the direct access signal from decoder <b>38</b>), control circuit <b>100</b> overrides the value in register <b>102</b> with a predetermined value. The predetermined value represents a state in register <b>102</b> which generates a particular way as the replacement way to control circuit <b>36</b>. The particular way is the way indicated by the direct access transaction, which is received by control circuit <b>100</b>. Accordingly, control circuit <b>100</b> may select the predetermined value from one of a set of predetermined values (one for each way of L2 cache <b>14</b>). The predetermined value is provided to register <b>102</b> (override[<b>7</b>:<b>0</b>] in FIG. <b>6</b>), and control circuit <b>100</b> asserts a control signal to register <b>102</b> causing register <b>102</b> to update with the predetermined value.</p><p>In the illustrated embodiment, register <b>102</b> may be an eight bit register. However, any number of bits may be used in other embodiments. For the illustrated embodiment, table 1 below provides an example of predetermined values that may be used by control circuit <b>100</b> to establish a state in register <b>102</b> which causes the way identified by a direct access transaction to be the way used for a succeeding miss. The values are shown in binary, with bit <b>0</b> being the rightmost bit of register <b>102</b> as shown in FIG. <b>6</b> and bit <b>7</b> being the leftmost bit of register <b>102</b>. Don't care bits are shown as an \u201cx\u201d and may be zero or one (or may be left at the state currently in register <b>102</b>). Any other predetermined values which generate the desired replacement way for the circuitry shown in FIG. 6 may be used as well.</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE 1</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Exemplary Values for Loading into Register</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"offset\" colwidth=\"35pt\"></colspec><colspec align=\"center\" colname=\"1\" colwidth=\"63pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"119pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry>Direct Access Way</entry><entry>Override[7:0]</entry></row><row><entry></entry><entry align=\"center\" nameend=\"2\" namest=\"offset\" rowsep=\"1\"></entry></row><row><entry></entry><entry>0</entry><entry>x1x10000</entry></row><row><entry></entry><entry>1</entry><entry>x1x00000</entry></row><row><entry></entry><entry>2</entry><entry>x0x10000</entry></row><row><entry></entry><entry>3</entry><entry>x0x00000</entry></row><row><entry></entry><entry align=\"center\" nameend=\"2\" namest=\"offset\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>In the illustrated embodiment, register <b>102</b> may be a linear feedback shift register. However, other embodiments may employ other registers. For example, a counter could be used to count through the possible ways, rather than the linear feedback shift register.</p><p>It is noted that, rather than using direct access transactions to set the state of replacement circuit <b>44</b>, other transactions may be used. For example, register <b>102</b> may be memory mapped, and a memory mapped write to register <b>102</b> may set the state. Alternatively, the memory mapped write may provide the desired way, and the corresponding state may be set. In yet another example, a dedicated bus command may be used to convey the state or desired way.</p><p>It is further noted that, while the above discussion refers to a set associative cache, a similar replacement circuit may be used for a fully associative cache (in which each entry is effectively a way of the cache). Generally, an \u201cassociative cache\u201d may be any type of cache in which two or more entries are eligible to store data corresponding to a given address. An associative cache may include both set associative and fully associative caches.</p><p>Turning now to FIG. 7, a flowchart is shown illustrating operation of one embodiment of control circuit <b>100</b>. Other embodiments are possible and contemplated. While the blocks shown in FIG. 7 may be illustrated in a particular order for ease of understanding, the blocks may be performed in parallel by combinatorial logic circuitry within control circuit <b>100</b>.</p><p>If a direct access transaction is received (decision block <b>110</b>), control circuit <b>100</b> may override the state of replacement circuit <b>44</b> with a predetermined value corresponding to the way specified by the direct access transaction (block <b>112</b>). On the other hand, if a memory access is received (decision block <b>114</b>), control circuit <b>100</b> may cause register <b>102</b> to change to the next random state (e.g. to shift in the bit from next state circuit <b>106</b> and right shift the other bits\u2014block <b>116</b>).</p><p>Turning next to FIG. 8, a flowchart is shown illustrating an exemplary sequence of transactions which may be performed to achieve a test of an entry in the L2 cache memory. Other embodiments are possible and contemplated. The sequence of transactions could be generated, e.g., by a processor <b>12</b>A-<b>12</b>B executing a code sequence which includes instructions which result in the transactions. Additionally illustrated in FIG. 8 are certain checks, which could be performed by other instructions than those resulting in the transactions. Alternatively, the sequence of transactions and checks could be performed by any other device connected to bus <b>24</b>.</p><p>A first direct access transaction is performed to select a test way (block <b>120</b>). More particularly, the replacement circuit in L2 cache <b>14</b> may establish the test way as the way to be selected for eviction if the next transaction is a miss in response to the first direct access transaction. The first direct access transaction may be a read or a write.</p><p>Subsequent to the first direct access transaction, a memory transaction may be performed (block <b>122</b>). The memory transaction may be a read or a write, and reads the desired test data from memory <b>26</b> or writes the desired test data to memory <b>26</b>. The memory transaction should be a miss in L2 cache <b>14</b>, so that L2 cache <b>14</b> allocates an entry for the cache line and stores the test data. More particularly, since the first direct access transaction established the test way as the way to be selected for eviction, the entry allocated to the test data is in the test way. The index from the memory transaction address selects the set of entries from which the entry is allocated. Thus, the entry is written with the test data has been directly selected via the first direct access transaction and the memory transaction, and the desired test data has been written to the selected entry.</p><p>Subsequent to the memory transaction, a direct access read transaction is performed (block <b>124</b>). The direct access read transaction explicitly specifies the entry written with the test data (e.g. by index and way). Accordingly, the data returned for the direct access read transaction should be the test data, if no error occurred in storing the data in the entry.</p><p>The read data returned in response to the direct access read transaction is compared to the test data (decision block <b>126</b>). If the read data does not match the test data, then the test fails (block <b>128</b>).</p><p>Additionally, the L2 cache entry includes storage for tag information. The tag is updated with the address of the memory transaction from block <b>122</b>. In response to the direct access read transaction from block <b>124</b>, L2 cache <b>14</b> stores the tag of the entry in tag register <b>42</b>. Accordingly, the test may include a read of tag register <b>42</b> (block <b>130</b>). The tag information received in response to the read of the tag register <b>42</b> may be compared to corresponding information from the address used in the memory transaction (decision block <b>132</b>) and expected values for the other information (e.g. valid, dirty, ECC, etc.). If the tag information does not match, then the test fails (block <b>128</b>). If the tag information does match, then the test passes (block <b>134</b>).</p><p>The above sequence of transactions and checks tests one entry of L2 cache <b>14</b>. Other entries may be tested by repeating the above sequence for each index and each way within each index. The transactions for each entry may be interleaved with the transactions for other entries, to investigate the possibility of cross coupling between entries. Additionally, the transactions may be repeated for each desired test data pattern or test tag pattern, to allow for robust testing of the memory.</p><p>While the above transactions include a first direct access transaction to set the test way, a memory transaction to store the test data in the selected entry, and a direct access read transaction to read the data for validation, an alternative is contemplated. In the alternative, a direct access write transaction is used to store the test data and a direct access read transaction is used to read the test data for comparison.</p><p>Turning now to FIG. 9, a flowchart is shown illustrating an exemplary sequence of transactions which may be performed to achieve a reset of the L2 cache memory. Other embodiments are possible and contemplated. The sequence of transactions could be generated, e.g., by a processor <b>12</b>A-<b>12</b>B executing a code sequence which includes instructions which result in the transactions. Alternatively, the sequence of transactions and checks could be performed by any other device connected to bus <b>24</b>.</p><p>To begin the reset sequence, a first index is selected as the selected index and a first way is selected as the selected way (block <b>140</b>). For example, index zero and way zero may be selected as the selected index and selected way.</p><p>A direct access write transaction is performed to the selected index and the selected way (block <b>142</b>). The data for the direct access write transaction may be any data, and the data is written to the entry corresponding to the selected index and the selected way. The valid indication carried by the address of the direct access write transaction may be set to zero to indicate that the cache line in the entry is invalid. However, the data is set to a known state. Since evictions are not performed for direct access transactions, the data formerly stored in the entry is overwritten without causing an eviction. Additionally, for embodiments employing ECC protection, correct ECC data is written so no ECC errors should occur after the L2 cache is reset.</p><p>If all ways at the selected index have not been written with direct access transactions (decision block <b>144</b>), the next consecutive way is selected as the selected way (block <b>146</b>). Block <b>142</b> is then repeated for the selected index and selected way. Once all ways at the selected index have been written, unless all indexes have been processed (decision block <b>148</b>), the next index is selected as the selected index and the first way is selected as the selected way (block <b>150</b>). Block <b>142</b> is then repeated for the selected index and the selected way.</p><p>In other words, block <b>142</b> is repeated for each index and each way within each index. The order of traversal (first all the ways of the index and then moving to the next index versus all the indexes in one way and then moving to the next way) is unimportant and may be varied as desired. Subsequent to performing block <b>142</b> for each index and each way within each index, L2 cache <b>14</b> has been reset and all entries are storing information of a known state. Thus, ensuring that the L2 cache memory resets to a known state in hardware may not be required. Instead, direct access transactions may be used to perform the reset.</p><p>Turning next to FIG. 10, a flowchart is shown illustrating an exemplary sequence of transactions which may be performed to synchronize the L2 cache (particularly the pseudo-random replacement algorithm). Other embodiments are possible and contemplated. The sequence of transactions could be generated, e.g., by a processor <b>12</b>A-<b>12</b>B executing a code sequence which includes instructions which result in the transactions. Alternatively, the sequence of transactions and checks could be performed by any other device connected to bus <b>24</b>.</p><p>The sequence may include one or more \u201cpre-synchronization\u201d operations (block <b>160</b>). After the pre-synchronization operations have been performed, a direct access transaction may be performed to initialize the replacement circuit to a desired way explicitly specified by the direct access transaction (block <b>162</b>). The direct access transaction may be either a read or a write, as desired. Subsequently, one or more \u201cpost-synchronization\u201d operations may be performed (block <b>164</b>).</p><p>Synchronizing the L2 cache replacement policy using the deterministic setting provided in response to direct access transactions may have a variety of uses. For example, it may be desirable to run validation tests used to test the L2 cache or other system components in a variety of test environments (e.g. simulation of the VHDL code representing the system <b>10</b>, emulation in which the system <b>10</b> is implemented in programmable logic devices for test purposes, a test board validation environment with the manufactured component or components, and/or a system validation environment with the manufactured component or components). The mechanisms used to establish an initial state in these various environments may differ, and thus the state of the L2 replacement circuit may differ when the test itself is to be started. Having a different state in the replacement circuit may affect the operation of the test, and thus the same validation may not occur. However, by performing the same direct access transaction after the initialization but prior to beginning the test, the same state in the replacement circuit may be established. Additionally, if a particular entry is desired to store data corresponding to a particular transaction within a test, that entry can be selected using a direct access transaction prior to the particular transaction.</p><p>Turning next to FIG. 11, a flowchart is shown illustrating an exemplary sequence of transactions which may be performed to flush the L2 cache without requiring an explicit flush command on bus <b>24</b>. More particularly, the sequence shown in FIG. 11 may be used to flush every entry of the L2 cache. An entry is flushed if the cache line stored in the entry is invalidated, and the cache line is written to memory <b>26</b> if dirty. Other embodiments are possible and contemplated. The sequence of transactions could be generated, e.g., by a processor <b>12</b>A-<b>12</b>B executing a code sequence which includes instructions which result in the transactions. Alternatively, the sequence of transactions and checks could be performed by any other device connected to bus <b>24</b>.</p><p>To begin the flush sequence, a first index is selected as the selected index and a first way is selected as the selected way (block <b>170</b>). For example, index zero and way zero may be selected as the selected index and selected way.</p><p>A direct access read transaction is performed to the selected index and selected way (block <b>172</b>). In response to the direct access transaction, replacement circuit <b>44</b> establishes a state indicating that the selected way is to be selected for eviction for the next transaction.</p><p>After the direct access read transaction, a memory transaction which misses the L2 cache is performed to the selected index (block <b>174</b>). Since the memory transaction misses, L2 cache <b>14</b> allocates an entry for the affected cache line. The entry is allocated from the selected way, evicting the cache line in the selected way.</p><p>Blocks <b>176</b>, <b>178</b>, <b>180</b>, and <b>182</b> illustrate the repeating of blocks <b>172</b> and <b>174</b> for each entry in the L2 cache, similar to blocks <b>144</b>, <b>146</b>, <b>148</b> and <b>150</b> shown in FIG. <b>9</b>. Again, the order of traversal may be any suitable order. After repeating blocks <b>172</b> and <b>174</b> for each entry, the prior contents of the L2 cache have been flushed, and no explicit flush command was used. Having an explicit flush command may require additional hardware in L2 cache <b>14</b>, and may occupy a command code point on bus <b>24</b>, and thus may be undesirable.</p><p>Turning next to FIG. 12, a flowchart is shown illustrating an exemplary sequence of transactions which may be performed to flush a particular cache line from the L2 cache without requiring an explicit flush command on bus <b>24</b>. Other embodiments are possible and contemplated. The sequence of transactions could be generated, e.g., by a processor <b>12</b>A-<b>12</b>B executing a code sequence which includes instructions which result in the transactions. Alternatively, the sequence of transactions and checks could be performed by any other device connected to bus <b>24</b>.</p><p>If a particular cache line is desired to be flushed, the address of the cache line is known. Thus, the index of the desired cache line may be selected as the selected index and the first way of the index may be selected as the selected way (block <b>190</b>).</p><p>A direct access read transaction is performed to the selected index and the selected way (block <b>192</b>). In response to the direct access read transaction, the replacement circuit <b>44</b> establishes a state indicating that the selected way is to be selected for eviction for the next transaction. Additionally, the tag of the entry explicitly identified (by the selected index and selected way) is stored into tag register <b>42</b>.</p><p>A read transaction may subsequently be performed to the tag register <b>42</b> to retrieve the tag information corresponding to the entry identified by the above direct access read transaction (block <b>194</b>). Since the read transaction is not a direct access transaction nor an access to the cache memory, the replacement policy may be unaffected by the read transaction.</p><p>If the tag information matches the corresponding address of the desired cache line (decision block <b>196</b>), a transaction to the selected index which misses L2 cache <b>14</b> may be performed (block <b>198</b>). Since the transaction misses, an eviction occurs and, due to the setting of the replacement policy via the direct access read transaction, the way storing the desired cache line is the way selected for eviction. Thus, the desired cache line is flushed from L2 cache <b>14</b>.</p><p>On the other hand, if the tag information does not match the corresponding address of the desired cache line (decision block <b>196</b>), and all ways within the selected index have not yet been searched (decision block <b>200</b>) then the next consecutive way is selected (block <b>202</b>) as the selected way and blocks <b>192</b>, <b>194</b>, and <b>196</b> may be repeated. If all ways are exhausted without finding a tag match, then the desired cache line is not stored in the cache and thus the flush is not needed.</p><p>While FIGS. 8-12 have illustrated various uses for the direct access transactions and/or the deterministic setting of the replacement policy, these features of the cache may be used for a variety of uses. Furthermore, any cache may employ these features.</p><p>Turning next to FIG. 13, a block diagram of a carrier medium <b>300</b> including a database representative of system <b>10</b> is shown. Generally speaking, a carrier medium may include storage media such as magnetic or optical media, e.g., disk or CD-ROM, volatile or non-volatile memory media such as RAM (e.g. SDRAM, RDRAM, SRAM, etc.), ROM, etc., as well as transmission media or signals such as electrical, electromagnetic, or digital signals, conveyed via a communication medium such as a network and/or a wireless link.</p><p>Generally, the database of system <b>10</b> carried on carrier medium <b>300</b> may be a database which can be read by a program and used, directly or indirectly, to fabricate the hardware comprising system <b>10</b>. For example, the database may be a behavioral-level description or register-transfer level (RTL) description of the hardware functionality in a high level design language (HDL) such as Verilog or VHDL. The description may be read by a synthesis tool which may synthesize the description to produce a netlist comprising a list of gates in a synthesis library. The netlist comprises a set of gates which also represent the functionality of the hardware comprising system <b>10</b>. The netlist may then be placed and routed to produce a data set describing geometric shapes to be applied to masks. The masks may then be used in various semiconductor fabrication steps to produce a semiconductor circuit or circuits corresponding to system <b>10</b>. Alternatively, the database on carrier medium <b>300</b> may be the netlist (with or without the synthesis library) or the data set, as desired.</p><p>While carrier medium <b>300</b> carries a representation of system <b>10</b>, other embodiments may carry a representation of any portion of system <b>10</b>, as desired, including any set of one or more agents (e.g. processors, L2 cache, memory controller, etc.) or circuitry therein (e.g. replacement circuits, caches, tags, etc.), etc.</p><p>Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Joseph B.", "last_name": "Rowlands", "name": ""}, {"first_name": "Michael P.", "last_name": "Dickman", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "BROADCOM CORPORATION"}, {"first_name": "", "last_name": "AVAGO TECHNOLOGIES INTERNATIONAL SALES PTE. LIMITED", "name": ""}, {"first_name": "", "last_name": "AVAGO TECHNOLOGIES INTERNATIONAL SALES PTE. LIMITED", "name": ""}, {"first_name": "", "last_name": "BROADCOM CORPORATION", "name": ""}, {"first_name": "", "last_name": "AVAGO TECHNOLOGIES GENERAL IP (SINGAPORE) PTE. LTD.", "name": ""}, {"first_name": "", "last_name": "BANK OF AMERICA, N.A., AS COLLATERAL AGENT", "name": ""}, {"first_name": "", "last_name": "BROADCOM CORPORATION", "name": ""}, {"first_name": "", "last_name": "SIBYTE, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/08"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/12        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711128"}, {"primary": false, "label": "711133"}, {"primary": false, "label": "711137"}, {"primary": false, "label": "711E1207"}, {"primary": false, "label": "711E12075"}], "ecla_classes": [{"label": "G06F  12/12B"}, {"label": "G06F  12/12B6"}], "cpc_classes": [{"label": "G06F  12/126"}, {"label": "G06F  12/121"}, {"label": "G06F  12/126"}, {"label": "G06F  12/121"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "2000-08-07", "application_date": "2000-08-07", "family_members": [{"ucid": "US-6748492-B1", "titles": [{"lang": "EN", "text": "Deterministic setting of replacement policy in a cache through way selection"}]}, {"ucid": "EP-1179782-A3", "titles": [{"lang": "FR", "text": "R\u00e9glage d\u00e9terministe de politique de remplacement dans une ant\u00e9m\u00e9moire"}, {"lang": "EN", "text": "Deterministic setting of replacement policy in a cache"}, {"lang": "DE", "text": "Deterministische Einstellung von Austauschverfahrensweisen in einem Cachespeicher"}]}, {"ucid": "EP-1179782-A2", "titles": [{"lang": "FR", "text": "R\u00e9glage d\u00e9terministe de politique de remplacement dans une ant\u00e9m\u00e9moire"}, {"lang": "EN", "text": "Deterministic setting of replacement policy in a cache"}, {"lang": "DE", "text": "Deterministische Einstellung von Austauschverfahrensweisen in einem Cachespeicher"}]}, {"ucid": "US-20040221110-A1", "titles": [{"lang": "EN", "text": "Deterministic setting of replacement policy in a cache"}]}, {"ucid": "US-6961824-B2", "titles": [{"lang": "EN", "text": "Deterministic setting of replacement policy in a cache"}]}]}