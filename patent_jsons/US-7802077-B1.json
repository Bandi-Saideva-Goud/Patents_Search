{"patent_number": "US-7802077-B1", "publication_id": 110123257, "family_id": 42734022, "publication_date": "2010-09-21", "titles": [{"lang": "EN", "text": "Trace indexing via trace end addresses"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA80268908\"><p num=\"p-0001\">A new class traces for a processing engine, called \u201cextended blocks,\u201d possess an architecture that permits possible many entry points but only a single exit point. These extended blocks may be indexed based upon the address of the last instruction therein. Use of the new trace architecture provides several advantages, including reduction of instruction redundancies, dynamic block extension and a sharing of instructions among various extended blocks.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00001\" num=\"00001\"><claim-text>1. A front-end system for a processor, comprising:\n<claim-text>an instruction cache system;</claim-text>\n<claim-text>an extended block cache system, comprising:\n<claim-text>a fill unit coupled to the instruction cache system,</claim-text>\n<claim-text>a block cache,</claim-text>\n<claim-text>a block predictor to store masks associated with complex blocks, the masks distinguishing block prefixes from each other; and</claim-text>\n</claim-text>\n<claim-text>a selector coupled to the output of the instruction cache system and to an output of the block cache.</claim-text>\n</claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00002\" num=\"00002\"><claim-text>2. The front-end system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the extended block cache system further comprises a block predictor coupled to the fill unit and the block cache.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00003\" num=\"00003\"><claim-text>3. The front-end system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the block cache is to store blocks having a multiple-entry, single exit architecture.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00004\" num=\"00004\"><claim-text>4. The front-end system of <claim-ref idref=\"CLM-00001\">claim 1</claim-ref>, wherein the block cache is to store complex blocks having multiple independent prefixes and a common suffix.</claim-text></claim>"}, {"num": 5, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00005\" num=\"00005\"><claim-text>5. A method of managing extended blocks, comprising:\n<claim-text>predicting an address of a terminal instruction of an extended block to be used,</claim-text>\n<claim-text>determining whether the predicted address matches an address of a terminal instruction of a previously created extended block, and</claim-text>\n<claim-text>selecting one of the extended block in the event of a match.</claim-text>\n</claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00006\" num=\"00006\"><claim-text>6. The method of <claim-ref idref=\"CLM-00005\">claim 5</claim-ref>, further comprising creating a new extended block when there is no match.</claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00007\" num=\"00007\"><claim-text>7. The method of <claim-ref idref=\"CLM-00006\">claim 6</claim-ref>, wherein the creating comprises:\n<claim-text>receiving new instructions until a terminal condition occurs,</claim-text>\n<claim-text>assembling the new instructions into an extended block,</claim-text>\n<claim-text>determining whether an address of a terminal instruction in the new block matches an address of a terminal instruction of a pre-existing block, and</claim-text>\n<claim-text>unless a match occurs, storing the new block in a memory.</claim-text>\n</claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00008\" num=\"00008\"><claim-text>8. The method of <claim-ref idref=\"CLM-00007\">claim 7</claim-ref>, wherein the storing comprises, when an older block causes a match, storing the new block over the old block in a memory if the old block is subsumed within the new block.</claim-text></claim>"}, {"num": 9, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00009\" num=\"00009\"><claim-text>9. The method of <claim-ref idref=\"CLM-00007\">claim 7</claim-ref>, wherein the storing comprises, when an older block causes a match, dropping the new block if the new block is subsumed within the older block.</claim-text></claim>"}, {"num": 10, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00010\" num=\"00010\"><claim-text>10. The method of <claim-ref idref=\"CLM-00007\">claim 7</claim-ref>, wherein the storing comprises, when an older block causes a match, creating a complex block if the new block and the older block share a common suffix but include different prefixes.</claim-text></claim>"}, {"num": 11, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00011\" num=\"00011\"><claim-text>11. The method of <claim-ref idref=\"CLM-00005\">claim 5</claim-ref>, further comprising outputting instructions of the selected extended block for execution.</claim-text></claim>"}, {"num": 12, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00012\" num=\"00012\"><claim-text>12. A processing engine, comprising:\n<claim-text>a front end stage storing blocks of instructions in a multiple-entry, single exit architecture when considered according to program flow, and</claim-text>\n<claim-text>an execution unit in communication with the front end stage,</claim-text>\n<claim-text>wherein the front-end stage includes</claim-text>\n<claim-text>an instruction cache system,</claim-text>\n<claim-text>an extended block cache system, including\n<claim-text>a fill unit provided in communication with the instruction cache system,</claim-text>\n<claim-text>a block cache, and</claim-text>\n</claim-text>\n<claim-text>a selector coupled to the output of the instruction cache system and to an output of the block cache.</claim-text>\n</claim-text></claim>"}, {"num": 13, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00013\" num=\"00013\"><claim-text>13. The processing engine of <claim-ref idref=\"CLM-00012\">claim 12</claim-ref>, wherein the block cache is to store the multiple-entry, single exit traces.</claim-text></claim>"}, {"num": 14, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"CLM-00014\" num=\"00014\"><claim-text>14. The processing engine of <claim-ref idref=\"CLM-00012\">claim 12</claim-ref>, wherein the extended block cache system further comprises a block predictor coupled to the fill unit and the block cache.</claim-text></claim>"}, {"num": 15, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"CLM-00015\" num=\"00015\"><claim-text>15. A memory comprising storage for a plurality of traces and means for indexing the traces by an address of a last instruction therein according to program flow, wherein the traces include a plurality of instructions assembled according to program flow and at least one trace includes at least three segments of executable instructions in which, when considered according to program flow, first and second segments are mutually exclusive of each other and lead into the third segment.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES38354100\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND</h4><p num=\"p-0002\">The present invention provides a new trace assembly paradigm for processing circuits.</p><p num=\"p-0003\"><figref idrefs=\"DRAWINGS\">FIG. 1</figref> is a block diagram illustrating the process of program execution in a conventional processor. Program execution may include three stages: front end <b>110</b>, execution <b>120</b> and memory <b>130</b>. The front-end stage <b>110</b> performs instruction pre-processing. Front end processing is designed with the goal of supplying valid decoded instructions to an execution core with low latency and high bandwidth. Front-end processing can include instruction prediction, decoding and renaming.</p><p num=\"p-0004\">As the name implies, the execution stage <b>120</b> performs instruction execution. The execution stage <b>120</b> typically communicates with a memory <b>130</b> to operate upon data stored therein.</p><p num=\"p-0005\">The front end stage <b>110</b> may include a trace cache (not shown) to reduce the latency of instruction decoding and to increase front end bandwidth. A trace cache is a circuit that assembles sequences of dynamically executed instructions into logical units called \u201ctraces.\u201d The program instructions may have been assembled into a trace from non-contiguous regions of an external memory space but, when they are assembled in a trace, the instructions appear in program order. Typically, a trace may begin with an instruction of any type. The trace may end when one of number of predetermined trace end conditions occurs, such as a trace size limit, a maximum number of conditional branches occurs or an indirect branch or return instruction occurs.</p><p num=\"p-0006\">Prior art traces are defined by an architecture having a single entry point but possibly many exit points. This architecture, however, causes traces to exhibit instruction redundancy. Consider, by way of example, the following code sequence:</p><p num=\"p-0007\">If (cond)\n</p><ul><li id=\"ul0001-0001\" num=\"0000\"><ul><li id=\"ul0002-0001\" num=\"0007\">A</li></ul></li></ul>\n<p num=\"p-0008\">B</p><p num=\"p-0009\">This simple code sequence produces two possible traces: 1) B and 2) AB. When assembled in a trace cache, each trace may be stored independently of the other. Thus, the B instruction would be stored twice in the trace cache. This redundancy lowers system performance. Further, because traces may start on any instruction, the B instruction also may be recorded in multiple traces due to instruction alignment discrepancies that may occur. This instruction redundancy limits the bandwidth of front-end processing.</p><p num=\"p-0010\">Accordingly, there is a need in the art for a front-end stage that reduces instruction redundancy in traces.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><description-of-drawings><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p num=\"p-0011\"><figref idrefs=\"DRAWINGS\">FIG. 1</figref> is a block diagram illustrating functional processing in program execution.</p><p num=\"p-0012\"><figref idrefs=\"DRAWINGS\">FIG. 2</figref> is a block diagram of a front-end stage <b>200</b> according to an embodiment of the present invention.</p><p num=\"p-0013\"><figref idrefs=\"DRAWINGS\">FIG. 3</figref> is a flow diagram illustration operation <b>1000</b> of the XFU <b>260</b> according to an embodiment of the invention.</p><p num=\"p-0014\"><figref idrefs=\"DRAWINGS\">FIGS. 4(</figref><i>a</i>)-<b>4</b>(<i>c</i>) illustrate construction of extended blocks according to embodiments of the present invention.</p><p num=\"p-0015\"><figref idrefs=\"DRAWINGS\">FIG. 5</figref> illustrates construction of an extended block according to an embodiment of the present invention.</p><p num=\"p-0016\"><figref idrefs=\"DRAWINGS\">FIG. 6</figref> illustrates construction of a complex extended block according to a embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION</h4><p num=\"p-0017\">Embodiments of the present invention assemble a new type of traces, called \u201cextended blocks\u201d herein, according to an architecture that permits several entry points but only a single exit point. These extended blocks may be indexed based upon the address of the last instruction therein. The extended block architecture provides several advantages over prior architectures:</p><p num=\"p-0018\">instruction redundancies can be eliminated,</p><p num=\"p-0019\">multiple entry points are permitted,</p><p num=\"p-0020\">extended blocks may be extended dynamically, and</p><p num=\"p-0021\">basic blocks may be shared among various extended blocks.</p><p num=\"p-0022\"><figref idrefs=\"DRAWINGS\">FIG. 2</figref> is a block diagram of a front-end stage <b>200</b> according to an embodiment of the present invention. The front end <b>200</b> may include an instruction cache <b>210</b> and an extended block cache (\u201cXBC\u201d) <b>220</b>. The instruction cache <b>210</b> may be based on any number of known architectures for front-end systems. Typically, they include an instruction memory <b>230</b>, a branch predictor <b>240</b> and an instruction decoder <b>250</b>. Program instructions may be stored in the cache memory <b>230</b> and indexed by an instruction pointer. Instructions may be retrieved from the cache memory <b>230</b>, decoded by the instruction decoder <b>250</b> and passed to the execution unit (not shown). The branch predictor <b>240</b> may assist in the selection of instructions to be retrieved from the cache memory <b>230</b> for execution. As is known, instructions may be indexed by an address, called an \u201cinstruction pointer\u201d or \u201cIP.\u201d</p><p num=\"p-0023\">According to an embodiment, an XBC <b>220</b> may include a fill unit (\u201cXFU\u201d) <b>260</b>, a block predictor (\u201cXBTB\u201d) <b>270</b> and a block cache <b>280</b>. The XFU <b>260</b> may build the extended blocks. The block cache <b>280</b> may store the extended blocks. The XBTB <b>270</b> may predict which extended blocks, if any, are likely to be executed and may cause the block cache to furnish any predicted blocks to the execution unit. The XBTB <b>270</b> may store masks associated with each of the extended blocks stored by the block cache <b>280</b>, indexed by the IP of the terminal instruction of the extended blocks.</p><p num=\"p-0024\">The XBC <b>220</b> may receive decoded instructions from the instruction cache <b>210</b>. The XBC <b>220</b> also may pass decoded instructions to the execution unit (not shown). A selector <b>290</b> may select which front-end source, either the instruction cache <b>210</b> or the XBC <b>220</b>, will supply instructions to the execution unit. In an embodiment, the block cache <b>280</b> may control the selector <b>290</b>.</p><p num=\"p-0025\">As discussed, the block cache <b>280</b> may be a memory that stores extended blocks. According to an embodiment, the extended blocks may be multiple-entry, single-exit traces. An extended block may include a sequence of program instructions. It may terminate in a conditional branch, an indirect branch or based upon a predetermined termination condition such as a size limit. Again, the block cache <b>280</b> may index the extended blocks based upon an IP of the terminal instruction in the block.</p><p num=\"p-0026\">Extended blocks are useful because, whenever program flow enters the extended block, the flow necessarily progresses to the terminal instruction in the extended block. An extended block may contain any conditional or indirect branches only as a terminal instruction. Thus, the extended block may have multiple entry points. According to an embodiment, an unconditional branch need not terminate an extended block.</p><p num=\"p-0027\">According to an embodiment, a hit/miss indication from the block cache <b>280</b> may control the selector <b>290</b>.</p><p num=\"p-0028\"><figref idrefs=\"DRAWINGS\">FIG. 3</figref> is a flow diagram illustrating operation <b>1000</b> of the XBC <b>220</b> according to an embodiment of the invention. Operation may begin when the XBC <b>220</b> determines whether an IP of a terminal instruction from an extended block may be predicted (Stage <b>1010</b>). If so, the XBC <b>200</b> performs such a prediction (Stage <b>1020</b>). The prediction may be made by the XBTB <b>220</b>. Based on the IP of the predicted terminal instruction, the block cache <b>280</b> may indicate a \u201chit\u201d or a \u201cmiss\u201d (Stage <b>1030</b>). A hit indicates that the block cache <b>280</b> stores an extended block that terminates at the predicted IP. In this case, the XFU <b>260</b> may cause an extended block to be retrieved from the block cache <b>280</b> and forwarded to the execution units (Stage <b>1040</b>). Thereafter, the process may return to Stage <b>1010</b> and repeat.</p><p num=\"p-0029\">If the predicted IP does not hit the block cache <b>280</b> or if an IP of a terminal instruction could not be predicted at Stage <b>1010</b>, the XFU <b>260</b> may build a new extended block. Decoded instructions from the instruction cache may be forwarded to the execution unit (Stage <b>1050</b>). The XFU <b>260</b> also may receive the retrieved instructions from the instruction cache system <b>210</b>. It stores instructions in a new block until it reaches a terminal condition, such as a conditional or implicit branch or a size limitation (Stage <b>1060</b>). Having assembled a new block, the XFU <b>260</b> may determine how to store it in the block cache <b>280</b>.</p><p num=\"p-0030\">The XFU <b>260</b> may determine whether the terminal IP of the new block hits the block cache (Stage <b>1070</b>). If not, then the XFU <b>260</b> simply may cause the new block to be stored in the block cache <b>280</b> (Stage <b>1080</b>).</p><p num=\"p-0031\">If the IP hits the block cache, then the XFU <b>260</b> may compare the contents of the new block with the contents of an older block stored in the block cache that generated the hit. The XFU <b>260</b> may determine whether the contents of the new block are subsumed entirely within the old block (Stage <b>1090</b>). If so, the XFU <b>260</b> need not store the new block in the block cache <b>280</b> because it is present already in the old block. If not, the XFU <b>260</b> may determine whether the contents of the old block are subsumed within the new block (Stage <b>1100</b>). If so, the XFU <b>260</b> may write the new block over the old block in the cache (Stage <b>1110</b>). This has the effect of extending the old block to include the new block.</p><p num=\"p-0032\">If neither of the above conditions is met, then the new block and the old block may be only partially co-extensive. There are several alternatives for this case. In a first embodiment, the XFU <b>260</b> may store the non-overlapping portion of the new block in the block cache <b>280</b> as a separate extended block (Stage <b>1120</b>). Alternatively, the XFU <b>260</b> may create a complex extended block from the new block and the old block (Stage <b>1130</b>). These are discussed in greater detail below.</p><p num=\"p-0033\">Once the new block is stored in the block cache <b>280</b>, at the conclusion of Stages <b>1110</b>, <b>1120</b> or <b>1130</b>, the XBTB may be updated to reflect the contents of the block cache <b>280</b> (Stage <b>1140</b>). Thereafter, operation may return to Stage <b>1010</b> for a subsequent iteration.</p><p num=\"p-0034\"><figref idrefs=\"DRAWINGS\">FIGS. 4(</figref><i>a</i>)-<b>4</b>(<i>c</i>) schematically illustrate the different scenarios that may occur if the IP pointer of the new extended block XB<sub>new </sub>matches that of an extended block stored previously within the block cache <b>280</b> (XB<sub>old</sub>). In <figref idrefs=\"DRAWINGS\">FIG. 4(</figref><i>a</i>), the older extended block XB<sub>old </sub>is co-extensive with the new extended block XB<sub>new </sub>but is longer. In this case, the new extended block XB<sub>new </sub>should not be stored separately within the block cache <b>280</b>; the older extended block may be used instead. In <figref idrefs=\"DRAWINGS\">FIG. 4(</figref><i>b</i>), the older extended block XB<sub>old </sub>is co-extensive with a portion of the new extended XB<sub>new </sub>but XB<sub>new </sub>is longer. In this case, the older extended block may be extended to include the additional instructions found in XB<sub>new</sub>.</p><p num=\"p-0035\">In a third case, shown in <figref idrefs=\"DRAWINGS\">FIG. 4(</figref><i>c</i>), only a portion of XB<sub>new </sub>and XB<sub>old </sub>are co-extensive. In this case, a \u201csuffix\u201d of each extended block coincides but the two extended blocks have different \u201cprefixes.\u201d In a first embodiment, the XFU <b>260</b> may store a prefix of the new extended block as an extended block all its own. The prefix may end in an unconditional jump pointing to an appropriate location in the older extended block. This solution is shown in <figref idrefs=\"DRAWINGS\">FIG. 5</figref>.</p><p num=\"p-0036\">Alternatively, the XFU <b>260</b> may assemble a single, complex extended block merging the two extended blocks. In this embodiment, the XFU <b>260</b> may extend the older extended block by adding the prefix of the new extended block to a head of the older extended block. The prefix of the new extended block may conclude in an unconditional jump pointing to the common suffix. This solution is shown in <figref idrefs=\"DRAWINGS\">FIG. 6</figref>. This embodiment creates a single, longer extended block instead of two short extended blocks and thereby contributes to increased bandwidth. In such an embodiment, the XFU <b>260</b> may generate a mask in the block cache <b>280</b> that is associated with the complex extended block.</p><p num=\"p-0037\">According to an embodiment, the XBTB <b>270</b> may predict extended blocks to be used.</p><p num=\"p-0038\">Returning to <figref idrefs=\"DRAWINGS\">FIG. 2</figref>, the XBTB <b>270</b> may predict extended blocks for use during program execution. The XBTB <b>270</b> may store information for each of the extended blocks stored in the block cache <b>280</b>. In an embodiment, the XBTB <b>270</b> may store masks for each block cache. These masks may identify whether a corresponding extended block is a complex or non-complex block (compare <figref idrefs=\"DRAWINGS\">FIGS. 4(</figref><i>a</i>) and <b>4</b>(<i>b</i>) with <figref idrefs=\"DRAWINGS\">FIG. 6)</figref>. For non-complex extended blocks, the XBTB <b>270</b> may store a mask identifying the length of the extended blocks. For complex extended blocks, the XBTB <b>270</b> may store a mask that distinguishes multiple prefixes from each other. Thus, while the prefixes may be linearly appended to each other as shown in <figref idrefs=\"DRAWINGS\">FIG. 6</figref>, a mask as stored in the XBTB permits the XBTB to determine the position of an entry point to an extended block based on an instruction's IP.</p><p num=\"p-0039\">As described above, an XBTB <b>270</b> may store a mapping among blocks. As noted, the XBTB <b>270</b> may identify the terminal IP of each block and may store masks for each extended block. The XBTB <b>270</b> also may store a mapping identifying links from one XBTB to another. For example, if a first extended block ended in a conditional branch, program execution may reach a second extended block by following one of the directions of the terminal branch and execution may reach a third extended block by following the other direction. The XBTB <b>270</b> may store a mapping of both blocks. In this embodiment, the XFU <b>260</b> may interrogate the XBTB <b>270</b> with an IP. By way of response, the XBC <b>220</b> may respond with a hit or miss indication and, if the response is a hit, may identify one or more extended blocks in the block cache to which the IP may refer. In this embodiment, the XBC <b>220</b> may determine whether a terminal IP may be predicted and whether the predicted address hits the cache (Stages <b>1010</b>, <b>1030</b>).</p><p num=\"p-0040\">According to an embodiment, XBC bandwidth may be improved by using conditional branch promotion for terminal instructions. As is known, conditional branch promotion permits a conditional branch to be treated as an unconditional branch if it is found that the branch is nearly monotonic. For example, if during operation, it is determined that program execution at a particular branch tends to follow one of the branches 99% of the time, the branch may be treated as an unconditional jump. In this case, two extended blocks may be joined as a single extended block. This embodiment further contributes to XBC bandwidth.</p><p num=\"p-0041\">According to another embodiment, XBC latency may be minimized by having the block cache <b>280</b> store extended block instructions in decoded form. Thus, the instructions may be stored as microinstructions (commonly, \u201cuops\u201d).</p><p num=\"p-0042\">Several embodiments of the present invention are specifically illustrated and described herein. However, it will be appreciated that modifications and variations of the present invention are covered by the above teachings and within the purview of the appended claims without departing from the spirit and intended scope of the invention.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "STEPHEN J.", "last_name": "JOURDAN", "name": ""}, {"first_name": "Lihu", "last_name": "Rappoport", "name": ""}, {"first_name": "Ronny", "last_name": "Ronen", "name": ""}, {"first_name": "Adi", "last_name": "Yoaz", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTEL CORPORATION"}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  15/00        20060101ALI20100921BHUS"}, {"label": "G06F   9/40        20060101ALI20100921BHUS"}, {"label": "G06F   9/30        20060101AFI20100921BHUS"}], "national_classes": [{"primary": true, "label": "712207"}, {"primary": false, "label": "711118"}, {"primary": false, "label": "711140"}, {"primary": false, "label": "711137"}, {"primary": false, "label": "711128"}, {"primary": false, "label": "712227"}, {"primary": false, "label": "717128"}, {"primary": false, "label": "711123"}, {"primary": false, "label": "717129"}, {"primary": false, "label": "712219"}, {"primary": false, "label": "717153"}], "ecla_classes": [{"label": "G06F   9/38B4"}], "cpc_classes": [{"label": "G06F   9/3808"}, {"label": "G06F   9/3808"}], "f_term_classes": [], "legal_status": "Expired - Fee Related", "priority_date": "2000-06-30", "application_date": "2000-06-30", "family_members": [{"ucid": "US-7802077-B1", "titles": [{"lang": "EN", "text": "Trace indexing via trace end addresses"}]}]}