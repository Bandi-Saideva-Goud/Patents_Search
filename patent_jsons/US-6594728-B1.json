{"patent_number": "US-6594728-B1", "publication_id": 73476822, "family_id": 23262186, "publication_date": "2003-07-15", "titles": [{"lang": "EN", "text": "Cache memory with dual-way arrays and multiplexed parallel output"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11542978\" source=\"national office\"><p>A two-way cache memory having multiplexed outputs and alternating ways is disclosed. Multiplexed outputs enable the cache memory to be more densely packed and implemented with fewer sense amplifiers. Alternating ways enable two distinct cache access patterns. According to a first access pattern, two doublewords in the same way may be accessed simultaneously. Such access facilities the leading of data into main memory. According to a second access pattern, two doublewords in the same location but in different ways may be accessed simultaneously. Such access facilitates the loading a particular word into a register file.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50521887\"><p>A two-way cache memory having multiplexed outputs and alternating ways is disclosed. Multiplexed outputs enable the cache memory to be more densely packed and implemented with fewer sense amplifiers. Alternating ways enable two distinct cache access patterns. According to a first access pattern, two doublewords in the same way may be accessed simultaneously. Such access facilities the leading of data into main memory. According to a second access pattern, two doublewords in the same location but in different ways may be accessed simultaneously. Such access facilitates the loading a particular word into a register file.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00001\" num=\"1\"><claim-text>1. A cache memory accessed by an address, said cache memory comprising:</claim-text><claim-text>a first array of RAM cells containing a first plurality of sets of cells; </claim-text><claim-text>a second array of RAM cells containing a second plurality of sets of cells and operating at about the same time as said first array, wherein said RAM cells of said first array are interleaved such that a first cell within a first set of said first plurality of sets corresponds to a first way and each subsequent cell within said first set corresponds to ways alternating between a second way and said first way, and said RAM cells of said second array are interleaved such that a second cell within a second set of said second plurality of sets corresponds to said second way and each subsequent cell within said second set corresponds to ways alternating between said first and second ways, and wherein said first and second sets are each associated with a particular bit position; </claim-text><claim-text>a decoder coupled to said first array and said second array for enabling said first and second arrays at about the same time; </claim-text><claim-text>a first multiplexer coupled to said first set for outputting selected contents of said first array; and </claim-text><claim-text>a second multiplexer coupled to said second set for outputting selected contents of said second array at about the same time as said first multiplexer. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00002\" num=\"2\"><claim-text>2. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00001\">claim 1</claim-ref> wherein said first and second multiplexers each receive at about the same time contents of arrays associated with both said first way and said second way.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00003\" num=\"3\"><claim-text>3. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00001\">claim 1</claim-ref> wherein said first set and said second set include a portion of a first doubleword in said first way and a portion of a first doubleword in said second way, respectively.</claim-text></claim>"}, {"num": 4, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00004\" num=\"4\"><claim-text>4. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00003\">claim 3</claim-ref> wherein said first set and said second set include a portion of a second doubleword in said second way and a portion of a second doubleword in said first way, respectively.</claim-text></claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00005\" num=\"5\"><claim-text>5. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00004\">claim 4</claim-ref> wherein said first and second multiplexers output at about the same time said portion of said first doubleword in said first way and said portion of said first doubleword in said second way, respectively, or said portion of said first doubleword in said first way and said portion of said second doubleword in said first way, respectively.</claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00006\" num=\"6\"><claim-text>6. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00005\">claim 5</claim-ref> further comprising an output data line coupled to said first and second multiplexers, said output data line being a single doubleword in width.</claim-text></claim>"}, {"num": 7, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00007\" num=\"7\"><claim-text>7. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00005\">claim 5</claim-ref> further comprising:</claim-text><claim-text>a third multiplexer coupled to said first multiplexer; </claim-text><claim-text>a fourth multiplexer coupled to said second multiplexer; and </claim-text><claim-text>a CPU register file coupled to said third and fourth multiplexers, wherein said portion of said first doubleword in said first way and said portion of said first doubleword in said second way are directed to said CPU register file through said third and fourth multiplexers, respectively. </claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00008\" num=\"8\"><claim-text>8. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00007\">claim 7</claim-ref> further comprising:</claim-text><claim-text>a fifth multiplexer coupled to said first multiplexer; </claim-text><claim-text>a sixth multiplexer coupled to said second multiplexer; and </claim-text><claim-text>an external interface coupled to said fifth and sixth multiplexers, wherein said portion of said first doubleword in said first way and said portion of said second doubleword in said first way are directed to said external interface through said fifth and sixth multiplexers, respectively. </claim-text></claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00009\" num=\"9\"><claim-text>9. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00001\">claim 1</claim-ref> wherein said RAM cells of said first array and said second array are interlaced by bit positions such that cells representing bit position <b>0</b> within each byte of said first plurality of sets of cells are disposed adjacent to each other.</claim-text></claim>"}, {"num": 10, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00010\" num=\"10\"><claim-text>10. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00001\">claim 1</claim-ref> further comprising a first sense amplifier having an input and an output, said input being coupled to said first multiplexer and said output being determined exclusively by said first multiplexer.</claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00011\" num=\"11\"><claim-text>11. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00010\">claim 10</claim-ref> further comprising a second sense amplifier having an input and an output, said input being coupled to said second multiplexer and said output being determined exclusively by said second multiplexer.</claim-text></claim>"}, {"num": 12, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00012\" num=\"12\"><claim-text>12. The cache memory of <claim-ref idref=\"US-6594728-B1-CLM-00001\">claim 1</claim-ref> further comprising a first sense amplifier coupled to said first multiplexer, said first sense amplifier uncontrolled by said address.</claim-text></claim>"}, {"num": 13, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00013\" num=\"13\"><claim-text>13. A memory comprising:</claim-text><claim-text>a first array of memory cells, wherein said memory cells of said first array are interleaved in an alternating pattern corresponding to first and second ways beginning with said first way; </claim-text><claim-text>a second array of memory cells, wherein said memory cells of said second array are interleaved in an alternating pattern corresponding to first and second ways beginning with said second way; </claim-text><claim-text>a first multiplexer coupled to said first array for outputting select contents of said first array; and </claim-text><claim-text>a second multiplexer coupled to said second array for outputting select contents of said second array at about the same time as said first multiplexer, wherein said first and second multiplexers each receive at about the same time contents of arrays contained within a set of cells, each set associated with a particular bit position and containing cells interleaved between said first way and said second way. </claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00014\" num=\"14\"><claim-text>14. The memory of <claim-ref idref=\"US-6594728-B1-CLM-00013\">claim 13</claim-ref> further comprising a decoder coupled to said first array and said second array for enabling said first and second arrays at about the same time.</claim-text></claim>"}, {"num": 15, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00015\" num=\"15\"><claim-text>15. The memory of <claim-ref idref=\"US-6594728-B1-CLM-00013\">claim 13</claim-ref> further comprising a first sense amplifier coupled to said first multiplexer and a second sense amplifier coupled to said second multiplexer.</claim-text></claim>"}, {"num": 16, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00016\" num=\"16\"><claim-text>16. The memory of <claim-ref idref=\"US-6594728-B1-CLM-00013\">claim 13</claim-ref> wherein said select contents of said first array comprise a.portion of a first dataword of said first way, and said select contents of said second array comprise a portion of a second dataword of said first way.</claim-text></claim>"}, {"num": 17, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6594728-B1-CLM-00017\" num=\"17\"><claim-text>17. The memory of <claim-ref idref=\"US-6594728-B1-CLM-00013\">claim 13</claim-ref> wherein select contents of said first array comprise a portion of a first dataword of said first way, and said select contents of said second array comprise a portion of a second dataword of said first way or a portion of a first dataword of said second way.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53955895\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><p>This is a continuation of application No. 08/324,124 filed Oct. 14, 1994, now abandoned.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><p>A preferred embodiment of the present invention is incorporated in a supercalar processor identified as \u201cR10000, \u201d which was developed by Silicon Graphics, Inc., of Mountain View, California. Various aspects of the R10000 are U.S. Ser. Nos. 08/324,128, 08/324,129 and 08/324,127, all incorporated herein by reference for all purposes. The R10000 is also described is J. Heinrich, MIPS R10000 Microprocessor User's Manual, MIPS Technologies, Inc. (1994).</p><h4>MICROFICHE APPENDIX</h4><p>A microfiche appendix containing one sheet and forty-eight frames is included as Appendices I and II to this application and is hereby incorpated by reference in its entirety for all purposes. The microfiche appendix is directed to Chapters 16 and 17 of the design notes describing the R10000 processor.</p><h4>BACKGROUND OF THE INVENTION</h4><p>This invention relates in general to computers and in particular, to cache memory.</p><p>CPU designers, since the inception of computers, have been driven to design faster and better processors in a cost-effective manner. For example, as faster versions of a particular CPU becomes available, designers will often increase the CPU's clock frequency as a simple and cost effective means of improving the CPU's throughput.</p><p>After a certain point, the speed of the system's main memory (input/output) becomes a limiting factor as to how fast the CPU can operate. When the CPU's operating speed exceeds the main memory's operating requirements, the CPU must issue one or more wait states to allow memory to catch up. Wait states, however, have a deleterious effect on CPU's performance. In some instances, one wait state can decrease the CPU's performance by about 20-30%</p><p>Although wait states can be eliminated by employing faster memory, it is very expensive and may be impractical.</p><p>Typically, the difference between the price of a fast memory chip and the next fastest speed grade can range from 50-100%.</p><p>Thus, the cost can be quite prohibitive, especially for a system requiring a large memory.</p><p>A cost effective solution has been to provide the CPU with a hierarchical memory consisting of multiple levels of memory with different speeds and sizes. Since the fastest memories are more expensive per bit than slower memories, they are usually smaller in size. This smaller memory, referred to as a \u201ccache\u201d, is closely located to the microprocessor or even integrated into the same chip as the microprocessor.</p><p>Conceptually, the memory controller retrieves instructions and data that are currently used by the processor and stores them into the cache. When a processor fetches instructions or data, it first checks the cache. The control logic determines if the required information is stored in the cache (cache hit). If a cache hit occurs, the CPU does not need to access to main memory. The control logic uses valuable cycles to determine if the requested data is in the cache. However, this cost is acceptable since accesses to main memory is much slower.</p><p>As can been seen, the higher the cache \u201chit\u201d rate is, the faster the CPU can perform its duties. obviously, the larger the cache, the more data it can store, and thus, a higher probability of a hit. However, in the real world, microprocessor designers are always faced with size constraints due to the fact that as there is limited available space on a die. Using a larger die size, although effective, is not practical since the cost increases as die size increases. Further, reducing the size of the cache without reducing the performance allows the designer to improve the performance of other functional units of the CPU.</p><p>Thus, there is a need for designing a cache that can determine if a hit has occurred using a minimum number of cycles and a high hit rate while reducing space needed on the chip.</p><h4>SUMMARY OF THE INVENTION</h4><p>The present invention offers a highly efficient mechanism for implementing cache memory in a computer system. This mechanism enables the cache memory to have high a \u201chit\u201d rate, fast access time, low latency, and reduced physical size.</p><p>In one embodiment, the present invention provides a cache which operates in parallel with the translation lookaside buffer to reduce its latency. The cache contains two 2-way set-associative arrays that are interleaved together. Each 2-way set-associative array includes two arrays, one each for the tag and data. By having four independently operating cache arrays, up to four instructions can operate simultaneously. The bits in each data array are interleaved to allow two distinct access patterns. For example, when the cache is loaded or copied back, two double words in the same block are accessed simultaneously. When the cache is read, the same doubleword location is simultaneously read from both blocks with the set. Further, by using a multiplexer, the number of sense amplifiers for reading and writing are reduced, thereby saving significantly valuable space on the die.</p><p>A better understanding of the nature and advantages of the present invention may be had with reference to the detailed description and the drawings below.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1 discloses a functional block diagram of a superscalar processor;</p><p>FIG. 2 discloses a functional block diagram of a load/store unit;</p><p>FIG. 3 discloses a block diagram of a cache bank;</p><p>FIG. 4 discloses a block diagram of a cache data array and control logic;</p><p>FIG. 5 discloses the block organization within each bank of the cache data array;</p><p>FIG. 6 illustrates the bit arrangement within each bank of the data cache;</p><p>FIG. 7 discloses a logic diagram of the cache control logic;</p><p>FIG. 8 discloses the connection between the two banks of the cache;</p><p>FIG. 9 discloses a block diagram of a cache tag array and control logic;</p><p>FIG. 10 discloses bit fields of the tag;</p><p>FIGS. 11A-11B disclose the tag check logic;</p><p>FIG. 12 discloses a logic diagram for generating a cache hit pulse; and</p><p>FIG. 13 discloses a block diagram of the row decoder for the cache tag array.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DESCRIPTION OF THE PREFERRED EMBODIMENT</h4><h4>Contents</h4><p>I. Superscalar Processor Architecture</p><p>A. Superscalar Processor Overview</p><p>B. Operation</p><p>II. Load/Store Unit</p><p>A. Load/Store Unit Overview</p><p>III. Data Cache</p><p>A. Data Cache Overview</p><p>B. Data Array</p><p>1. Data Array Organization</p><p>2. Data Array Control Logic</p><p>C. Tag Array</p><p>1. Tag Array Organization</p><p>2. Tag Array Control Logic</p><p>D. Cache Interface</p><p>I. Superscalar Processor Architecture</p><p>FIG. 1 discloses a functional block diagram of a superscalar processor <b>100</b> which incorporates a cache memory in accordance with the present invention. Processor <b>100</b>, which generally represents the R10000 Superscalar Processor developed by Silicon Graphics, Inc., of Mountain View, Calif., provides only one example of an application for the cache memory of the present invention.</p><p>A. Superscalar Processor Overview</p><p>A superscalar processor can fetch and execute more than one instruction in parallel. Processor <b>100</b> fetches and decodes four instructions per cycle. Each decoded instruction is appended to one of three instruction queues. These queues can issue one new instruction per cycle to each of five execution pipelines.</p><p>The block diagram of FIG. 1 is arranged to show the stages of an instruction pipeline and illustrates functional interconnectivity between various processor elements. Generally, instruction fetch and decode are carried out in stages <b>1</b> and <b>2</b>; instructions are issued from various queues in stage <b>3</b>; and instruction execution is performed in stages <b>4</b>-<b>7</b>.</p><p>Referring to FIG. 1, a primary instruction cache <b>102</b> reads four consecutive instructions per cycle, beginning on any word boundary within a cache block. A branch target cache <b>104</b>, instruction register <b>106</b>, instruction decode, and dependency logic <b>200</b>, convey portions of issued instructions to floating point mapping table <b>204</b> (32 word by 6 bit RAM) or integer mapping table <b>206</b> (33 word by 6 bit RAM). These tables carry out a \u201cregister renaming\u201d operation, described in detail below, which renames logical registers identified in an instruction with a physical register location for holding values during instruction execution. A redundant mapping mechanism is built into these tables to facilitate efficient recovery from branch mispredictions. Mapping tables <b>204</b> and <b>206</b> also receive input from a floating point free list <b>208</b> (32 word by 6 bit RAM) and an integer free list <b>210</b> (32 word by 6 bit RAM), respectively. Output of both mapping tables is fed to active list <b>212</b> which, in turn, feeds the inputs of free lists <b>208</b> and <b>210</b>.</p><p>A branch unit <b>214</b> also receives information from instruction register <b>106</b>, as shown in FIG. <b>1</b>. This unit processes no more than one branch per cycle. The branch unit includes a branch stack <b>216</b> which contains one entry for each conditional branch. Processor <b>100</b> can execute a conditional branch speculatively by predicting the most likely path and decoding instructions along that path.</p><p>The prediction is verified when the condition becomes known. If the correct path is taken, processing continues along that path. Otherwise, the decision must be reversed, all speculatively decoded instructions must be aborted, and the program counter and mapping hardware must be restored.</p><p>Referring again to FIG. 1, mapping tables <b>204</b> and <b>206</b> support three general pipelines, which incorporate five execution units. A floating-point pipeline is coupled to floating-point mapping table <b>204</b>. The floating-point pipeline includes a sixteen-entry instruction queue <b>300</b> which communicates with a sixty-four-location floating point register file <b>302</b>. Register file <b>302</b> and instruction queue <b>300</b> feed parallel multiply unit <b>400</b> and adder <b>404</b> (which performs, among other things, comparison operations to confirm floating-point branch predictions). Multiply unit <b>400</b> also provides input to a divide unit <b>408</b> and square root unit <b>410</b>.</p><p>Second, an integer pipeline is coupled to integer mapping table <b>206</b>. The integer pipeline includes a sixteen-entry integer instruction queue <b>304</b> which communicates with a sixty- four-location integer register file <b>306</b>. Register file <b>306</b> and instruction queue <b>304</b> feed arithmetic logic units (\u201cALU\u201d) ALU#1 <b>412</b> (which contains an ALU, shifter and integer branch comparator) and ALU#2 <b>414</b> (which contains an ALU, integer multiplier and divider).</p><p>Third, a load/store pipeline (or load/store unit) <b>416</b> is coupled to integer mapping table <b>206</b>. This pipeline includes a sixteen-entry address queue <b>308</b> which communicates with register file <b>306</b>. The architecture of address queue <b>308</b> is described in detail in commonly-owned, co-pending patent application, Ser. No. 08/324,128, which is hereby incorporated by reference in its entirety for all purposes.</p><p>Register file <b>306</b> and address queue <b>308</b> feed integer address calculate unit <b>418</b> which, in turn, provides virtual- address entries for address stack <b>420</b>. These virtual addresses are converted to physical addresses in joint translation lookaside buffer (JTLB) <b>422</b> and used to access a data cache <b>424</b>.</p><p>Data input to and output from data cache <b>424</b> pass through store aligner <b>430</b> and load aligner <b>428</b>, respectively. Address stack <b>420</b> and data cache <b>424</b> also communicate with external hardware controller and interface <b>434</b>. Further, data cache <b>424</b> and controller/interface <b>434</b> communicate with secondary cache <b>432</b>.</p><p>B. Operation</p><p>Processor <b>100</b> uses multiple execution pipelines to overlap instruction execution in five functional units. As described above, these units include the two integer ALUs <b>412</b>, <b>414</b>, load/store unit <b>416</b>, floating-point adder <b>404</b> and floating-point multiplier <b>400</b>. Each associated pipeline includes stages for issuing instructions, reading register operands, executing instructions, and storing results. There are also three \u201citerative\u201d units (i.e., ALU#2 <b>414</b>, floating- point divide unit <b>408</b>, and floating-point square root unit <b>410</b>) which compute more complex results.</p><p>Register files <b>302</b> and <b>306</b> must have multiple read and write ports to keep the functional units of processor <b>100</b> busy. Integer register file <b>306</b> has seven read and three write ports; floating-point register file <b>302</b> has five read and three write ports. The integer and floating-point pipelines each use two dedicated operand ports and one dedicated result port in the appropriate register file. Load/Stote unit <b>416</b> uses two dedicated integer operand ports for address calculation. Load/Store unit also loads or stores either integer or floating-point values via a shared write port and a shared read port in both register files. These shared ports are also used to move data between the integer and floating-point register files.</p><p>In a pipeline, the execution of each instruction is divided into a sequence of simpler operations. Each operation is performed by a separate hardware section called a stage. Each stage passes its result to the next stage. Usually, each instruction requires only a single cycle in each stage, and each stage can begin a new instruction while previous instructions are being completed by later stages. Thus, a new instruction can often begin during every cycle.</p><p>Pipelines greatly improve the rate at which instructions can be executed. However, the efficient use of a pipeline requires that several instructions be executed in parallel. The result of each instruction is not available for several cycles after that instruction enters the pipeline. Thus, new instructions must not depend on the results of instructions which are still in the pipeline.</p><p>Processor <b>100</b> fetches and decodes instructions in their original program order but may execute and complete these instructions out of order. Once completed, instructions are \u201cgraduated\u201d in their original program order. Instruction fetching is carried out by reading instructions from instruction cache <b>102</b>, shown in FIG. <b>1</b>. Instruction decode operation includes dependency checks and register renaming, performed by instruction decode and dependency logic <b>200</b> and mapping tables <b>204</b> or <b>206</b>, respectively. The execution units identified above compute an arithmetic result from the operands of an instruction. Execution is complete when a result has been computed and stored in a temporary register identified by register file <b>302</b> or <b>306</b>. Finally, graduation commits this temporary result as a new permanent value.</p><p>An instruction can graduate only after it and all previous instructions have been successfully completed. Until an instruction has graduated, it can be aborted, and all previous register and memory values can be restored to a precise state following any exception. This state is restored by \u201cunnaming\u201d the temporary physical registers assigned to subsequent instructions. Registers are unnamed by writing an old destination register into the associated mapping table and returning a new destination register to the free list. Renaming is done in reverse program order, in the event a logical register was used more than once. After renaming, register files <b>302</b> and <b>306</b> contain only the permanent values which were created by instructions prior to the exception. Once an instruction has graduated, however, all previous values are lost.</p><p>Active list <b>212</b> is a list of \u201cactive\u201d instructions in program order. It records status, such as which instructions have been completed or have detected exceptions. Instructions are appended to its bottom when they are decoded. Completed instructions are removed from its top when they graduate.</p><p>II. Load/Store Unit</p><p>A. Load/Store Unit Overview</p><p>Microprocessor <b>100</b> uses register files <b>306</b> and <b>302</b> to store integer and floating point register values, respectively. As such, the width of each file is equal to the width of microprocessor's data path. Since physical registers are used also to store tentative results for instructions which are completed but not yet graduated, register files <b>302</b> and <b>306</b> should contain more physical registers than there are logical registers. In one embodiment, register files contain 64 physical registers, twice the number of logical registers. Multiple read and write ports are provided for each register file to allow data to be read and written from microprocessor's various functional units in parallel.</p><p>Primary instruction cache <b>102</b>, data cache <b>424</b>, and branch stack <b>216</b> are interconnected by a data path. To minimize the necessary wiring, the functional units share the data path. Sharing data paths creates bus contention. This problem is alleviated by employing a two phase-multiplexed unidirectional data paths to interconnect the functional units.</p><p>Load/Store Unit <b>416</b> facilitates data transfer instructions between microprocessor's register files, data cache <b>424</b>, and main memory such as \u201cloads\u201d, \u201cstores\u201d, \u201cprefetch\u201d, and \u201ccache\u201d instructions.</p><p>Normally, main memory is accessed via data cache <b>424</b>. Data cache greatly improve memory performance by retaining recently used data in local, high speed buffer memories. Microprocessor <b>100</b> also includes secondary cache <b>432</b> to augment the data cache. Depending on availability of space, secondary cache <b>432</b> may be implemented as a separate chip.</p><p>All \u201ccached\u201d operations first access data cache <b>424</b>. If the data is present therein (a \u201ccache hit\u201d), a load can be completed in two cycles. Otherwise, access to secondary cache is initiated. If it \u201chits\u201d, the primary cache is \u201crefilled\u201d, and a load takes at least 8 cycles. Otherwise, main memory must be read and both caches refilled. In such cases, a load would take significantly longer.</p><p>Microprocessor <b>100</b> executes cached operations \u201cout-of- order\u201d. An instruction's address can be calculated as soon as its index registers are valid, even if previous instructions are waiting for their index registers to become valid. Cache misses do not block later instructions (\u201cnon-blocking\u201d); the unit can begin new operations while as many as eight cache misses are processed.</p><p>\u201cUncached\u201d operations bypass the caches and always access the system bus. Typically, uncached operations access input/output devices or special-purpose memories.</p><p>Uncached operations are executed only when the instruction is about to graduate. Uncached operations must be performed sequentially in original program order because they cannot be undone in the event of an exception. Both uncached writes and reads may alter the state of the I/O subsystem. Uncached operations are kept in the address stack, but no dependency checks are performed for them. The operand of an uncached store is copied into the Store Buffer, but no load bypass can occur. When the store graduates, the buffered data is transferred to the external interface.</p><p>Although uncached operations are delayed until they graduate, cached operations may proceed out of order. That is, subsequent cached loads may be executed, and cached stores may initiate tag check and cache refill operations.</p><p>Prefetch instructions are used to fetch memory blocks into the primary and secondary caches. They are used to increase performance by reducing delays required to refill caches, but they have no effect on the logical execution of the program. Prefetch instructions can significantly improve programs which have predictable memory accesses but have a high cache miss ratio. However, improper use of prefetch instructions can reduce performance by interfering with normal memory accesses.</p><p>There are two formats of prefetch instructions, so that either \u201cbase+offset\u201d (PREF, opcode 63 octal) or \u201cbase+index\u201d (PFETCH, opcode 23 function 17 octal) addressing may be used. These instructions are defined in C. Price, MIPS R10000-MIPS IV ISA Manual, MIPS Technologies, Inc. (1994). Each format includes a 5-bit \u201chint\u201d field which indicates what prefetching operation is expected. However, the architecture allows any hardware implementation to ignore the hint field or the entire instruction because it does not affect the program's result. If any problem is encountered, prefetch instructions are aborted without generating any exceptions.</p><p>Prefetched data is loaded into both the secondary and primary data caches. The \u201chint\u201d field applies to both caches.</p><p>If the external interface is busy when the address queue executes a prefetch instruction, the queue will retry that instruction later. However, if the addressed cache set cannot be refilled due to a dependency lock or previous refill operations, the instruction causes no action.</p><p>Microprocessor <b>100</b> uses only the low three bits of the hint field. If bit <b>0</b> is set, the cache will request an exclusive copy of the cache block, which can be written. Otherwise, the cache will request a shared copy of the cache block. If bit <b>2</b> is set, bit <b>1</b> selects which way is refilled if there is a cache miss. If the selected way is locked or already in refill in the primary data cache, the prefetch instruction causes no action.</p><p>Prefetch instructions are decoded, queued, issued, and tag-checked like other memory operations. But the prefetch is marked \u201cdone\u201d after only a single tag check cycle. If there is a cache hit (with the required write permission), the instruction is complete. If there is a miss and a cache block is available, a cache refill operation is requested from the external interface. The refill status is recorded in the cache tag. However, because the entry in the address stack is \u201cdone\u201d, it will not wait for the refill to be completed.</p><p>The Load/Store unit can speculatively execute instructions. These must be aborted in case a branch is reversed. If an aborted instruction imitated a cache refill, the refill operation must be completed. These refills are called \u201corphans\u201d because they no longer correspond to any instruction in the processor. Prefetch instructions also create orphans because they are \u201cdone\u201d as soon as the initial tag cycle is completed.</p><p>The address tag of this cache block remains in a \u201crefilling\u201d state until the cache refill has been completed. If a subsequent instruction addresses this cache block, it can use this block, initially in a \u201cwait on refill\u201d state.</p><p>B. Operation</p><p>Referring to FIG. 2, Load/store Unit <b>416</b> comprises an address queue <b>308</b>, address stack <b>420</b>, address calculate unit (ACU) <b>418</b>, store aligner <b>430</b>, load aligner <b>428</b>, translation lookaside buffer (JTLB) <b>422</b>, and data cache <b>424</b>. Data cache <b>424</b>, being a set-associative data cache, comprises cache tag array <b>650</b>, cache data array <b>610</b>, and the tag check logic <b>660</b>. The TLB and data cache are configured to operate in parallel so as to reduce the latency for load instructions, translating to about 15% performance improvement in operating speed.</p><p>Address queue <b>308</b> communicates with register file <b>306</b> and address calculate unit <b>418</b>. Address queue, containing 16 entries organized as a circular first-in first out (FIFO) buffer, keeps track of all memory instructions such as loads, stores, and \u201cCache\u201d instructions that manipulate any of the caches. Any time a memory instruction is decoded, it is allocated to the next sequential entry at the bottom of the queue. When an instruction graduates, it is deleted from the top of list. Graduation occurs if the instruction completes without an error and all previous instructions have graduated. Instructions are graduated in the original program order even though they may not have been executed in order.</p><p>Each entry in the address queue comprises several instruction fields which are exemplified in Table I. A more detailed description of the contents and structure of the address queue can be found in commonly owned and co-pending patent application Serial No. 08/324,129.</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE I</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Address Queue Instruction Fields</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"147pt\"></colspec><tbody valign=\"top\"><row><entry>Bits</entry><entry>Field</entry><entry>   Description</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"char\" char=\".\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"147pt\"></colspec><tbody valign=\"top\"><row><entry>1</entry><entry>AQvActiveF</entry><entry> Entry is active. (Decoded from queue pointers,</entry></row><row><entry></entry><entry></entry><entry>delayed one cycle.)</entry></row><row><entry>5</entry><entry>AQvTag</entry><entry>Active List tag uniquely identifies this</entry></row><row><entry></entry><entry></entry><entry>instruction within the pipeline.</entry></row><row><entry>7</entry><entry>AQvFunc</entry><entry>Instruction opcode and function:</entry></row><row><entry></entry><entry>0nnnnnn</entry><entry>6-bit major opcode (modified during</entry></row><row><entry></entry><entry></entry><entry>instruction predecode), or</entry></row><row><entry></entry><entry>10nnnnn</entry><entry>6-bit function code from COPIX opcode</entry></row><row><entry></entry><entry></entry><entry>(AQ gets codes #00-#37 octal only.)</entry></row><row><entry></entry><entry>11 fff cc</entry><entry>5-bit subfunction code for CACHE operations</entry></row><row><entry></entry><entry></entry><entry>(3-bit function, 2-bit cache select.)</entry></row><row><entry>16</entry><entry>AQvImm</entry><entry>16-bit immediate field contains instruction</entry></row><row><entry></entry><entry></entry><entry>bits [15:0].</entry></row><row><entry></entry><entry></entry><entry>Base Register:</entry></row><row><entry>6</entry><entry>AQvOpSelA</entry><entry>Operand A, select physical register#  in</entry></row><row><entry></entry><entry></entry><entry>Integer Register File.</entry></row><row><entry>1</entry><entry>AQvOpRdyA</entry><entry>Operand A is ready for address calculation.</entry></row><row><entry>1</entry><entry>AQvOpValA</entry><entry>Operand A is vaiid for address calculation</entry></row><row><entry></entry><entry></entry><entry>(Integer register# is not zero.)</entry></row><row><entry></entry><entry></entry><entry>Index Register, or Integer Operand:</entry></row><row><entry>6</entry><entry>AQvOpSelB</entry><entry>Operand B, select physical register# in</entry></row><row><entry></entry><entry></entry><entry>Integer Register File.</entry></row><row><entry></entry><entry></entry><entry>(For integer stores, this 6 bit value is duplicated in</entry></row><row><entry></entry><entry></entry><entry>AQvOpSelC.)</entry></row><row><entry>1</entry><entry>AQVOpRdyB</entry><entry>Operand B is ready.</entry></row><row><entry>1</entry><entry>AQvOpValB</entry><entry>Operand B is valid. (Integer register# is not zero.)</entry></row><row><entry></entry><entry></entry><entry>Floating Point Operands</entry></row><row><entry>6</entry><entry>AQvOpSelC</entry><entry>Operand C, select physical register# in Flt. Pt.</entry></row><row><entry></entry><entry></entry><entry>Register File. (For integer stores, this fieid</entry></row><row><entry></entry><entry></entry><entry>contains a copy of AQvOpSelB.)</entry></row><row><entry>1</entry><entry>AQvOpRdyC</entry><entry>Operand C is ready.</entry></row><row><entry>1</entry><entry>AQvOpValC</entry><entry>Operand C is valid.</entry></row><row><entry>6</entry><entry>AQvDest</entry><entry>Destination, select physical register#.</entry></row><row><entry>2</entry><entry>AQvDType</entry><entry>Destination type (or hint):</entry></row><row><entry></entry><entry></entry><entry>00=No destination register.</entry></row><row><entry></entry><entry></entry><entry>(If prefetch instruction,</entry></row><row><entry></entry><entry></entry><entry>hint=\u201cshared\u201d.)</entry></row><row><entry></entry><entry></entry><entry>01=No designation register.</entry></row><row><entry></entry><entry></entry><entry>(If prefetch instruction,</entry></row><row><entry></entry><entry></entry><entry>hint=\u201cexclusive\u201d.)</entry></row><row><entry></entry><entry></entry><entry>10=Integer destination register.</entry></row><row><entry></entry><entry></entry><entry>11=Floating-point destination register.</entry></row><row><entry>4</entry><entry>AQvUseR</entry><entry>Which ports of the shared register files are</entry></row><row><entry></entry><entry></entry><entry>required to execute this instruction?</entry></row><row><entry></entry><entry></entry><entry>Bit 3: Flt.pt. Write.</entry></row><row><entry></entry><entry></entry><entry>Bit 2: Flt.pt. Read.</entry></row><row><entry></entry><entry></entry><entry>Bit 1: Integer Write.</entry></row><row><entry></entry><entry></entry><entry>Bit 0: Integer Read.</entry></row><row><entry>1</entry><entry>AQvStore</entry><entry>This instruction is a store.</entry></row><row><entry>1</entry><entry>AQvFlt</entry><entry>This instruction loads or stores a floating</entry></row><row><entry></entry><entry></entry><entry>point register.</entry></row><row><entry>1</entry><entry>AQvFltHi</entry><entry>Load or store high half of floating-point</entry></row><row><entry></entry><entry></entry><entry>register (if FR=0).</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>When the operands for a memory instruction are available, address queue issues it for execution by sending the necessary operands to the ACU <b>418</b>. For \u201cIndexed\u201d operations, ACU receives base register and index register operands from Register File <b>306</b>. As for other load or store instructions, address queue provides a base register operand via Register File <b>306</b> and an immediate value directly.</p><p>ACU <b>418</b> calculates a virtual address corresponding to the operands it received during the previous cycle. As discussed, data cache is virtually indexed and physically tagged. As such, the virtual address is divided into two portions, the \u201ctag\u201d and \u201cindex\u201d. The index of the virtual address is passed to the cache to determine which cache location to access while the TLB <b>422</b> translates the virtual address into a physical address or real page address. The architecture of the TLB and virtual memory is discussed in detail in commonly owned and co-pending application Ser. No. 08/324,128. The real page address, referred to as the tag or physical tag, is stored in cache Tag array <b>650</b>.</p><p>While TLB is translating the virtual address into a physical address, the virtual index is used to access data and tag in data cache data array and cache tag array, respectively. In this manner, the physical address, tag, and data are available simultaneously. Tag check <b>660</b> compares the tag and physical address and, if there is a match, generates a hit signal to indicate that the requested data is present in the data cache. The requested data are aligned by load aligner <b>428</b> according to the lower address bits and then written to its destination in register files <b>302</b> or <b>306</b>.</p><p>A store path is provided for writing register values from register files <b>302</b>, and <b>306</b> into data cache <b>424</b>. Store aligner <b>430</b> aligns the data to be written into the cache. Bypass path <b>601</b> enables data for uncached operations to bypass the data cache.</p><p>Additionally, a bypass path <b>390</b> is provided to improve performance of the load/store unit. Bypass path <b>390</b> allows data to circumvent the register files or memory when microprocessor is reading a location during the same cycle it is written. For example, the result of an execution unit can be multiplexed directly into its operand registers so that a dependent instruction can be executed while that result is written into the register file. This bypass is selected whenever the operand register number equals the previous instruction's destination register number.</p><p>The physical tag and virtual index are also written into address stack <b>420</b>, which is logically part of the address queue but physically separate due to layout considerations. Microprocessor uses address stack <b>420</b> to store physical memory corresponding to each instruction in the address queue. Consequently, address stack is implemented with the same number of entries as address queue. Data are loaded into the address stack <b>420</b> during address calculation sequence. The address stack is described in detail in commonly owned and co-pending patent application Serial No. 08/324,129.</p><p>III. Data Cache</p><p>A. Data Cache Overview</p><p>The specification and operations for the data cache is included as Appendices I and II.</p><p>Data cache <b>424</b> is used to load and store instructions that access \u201ccacheable\u201d regions of main memory. The data cache <b>424</b> is interleaved with two identical banks, bank \u201c<b>0</b>\u201d and bank \u201c<b>1</b>\u201d.</p><p>Referring to FIG. 3 each bank comprises a tag cache array <b>650</b> and cache data array <b>610</b>. The tag array stores the tag associated with a block of data in the data array. The data array, on the other hand, retains recently used memory data.</p><p>In one embodiment, microprocessor <b>100</b> employs a 32 K-byte data cache. As such, each data array comprises 16 K-byte divided into 256 rows or word lines, each containing two blocks of 4 doublewords (8 words). Each doubleword has 64 bits plus 8 parity bits for a total of 72 bits. The data array can access two doublewords in parallel. As for tag array <b>650</b>, it has 64 rows of 35 bits each and can access two 32 bit tags in parallel.</p><p>Bank <b>0</b> and bank <b>1</b> operate independently and are accessed depending on the values of the virtual index. The tag and data arrays are allocated among requests from address queue, address stack, ACU, and external interface. Some instructions allow the tag and data array to operate independently. For example, store instructions require only the tag array, thus leaving the data array free. Thus, the four functional units can conceivably operate simultaneously if they are allocated the cache array(s) they need.</p><p>Each bank is 2-way set-associative. In effect, cache data array <b>610</b> and cache tag array <b>620</b> are each sub-divided into two sub-arrays or ways to provide an additional location into which main memory addresses with shared index bits can be mapped. This decreases thrashing in the cache and improves the hit rate without having to increase the size of the cache.</p><p>Sub-arrays for tag array <b>650</b> are referred to as way \u201c<b>0</b>\u201d and way \u201c<b>1</b>\u201d; those for the data array are referred to as sub- array <b>0</b> and sub-array <b>1</b>. Thus, tag array can access two tags (tag <b>0</b> and tag <b>1</b>) in parallel and each data array can access two doublewords (ar<b>0</b>data and ar<b>1</b>data) in parallel. For CPU and external \u201cinterrogate\u201d operations, Tag<b>0</b> and tag<b>1</b> are checked in parallel (read and compared) to determine which way of the cache, if any, contains the desired data. The way is remembered and used later for graduating stores or for external refill or writeback operations.</p><p>The arrays are \u201cvirtually indexed\u201d using the index portion (bits <b>13</b>:<b>0</b>) of the virtual address. Bit <b>5</b> selects bank #<b>0</b> or bank #<b>1</b>. Bits <b>2</b>:<b>0</b> select a byte within a doubleword and bits <b>4</b>:<b>3</b> select a doubleword within a block. Bits <b>13</b>:<b>6</b>, which address a block within an array, are decoded to select one of 256 \u201cword lines\u201d. Each word line contains 8 doublewords or two blocks. The bits are interlaced so that doublewords within these blocks are accessed differently for processor or external interface operations. The processor associatively accesses doublewords with two blocks. On the other hand, external interface accesses two doublewords within the same block.</p><p>Separate address multiplexers are provided for data and tag arrays. Multiplexer <b>621</b> selects address inputs from among external interface, address queue, address stack, and ACU for use by data array <b>610</b>. As for the tag array, multiplexer <b>620</b> selects address inputs from external interface, address stack, or ACU. Select signals (select tag and select data) for multiplexer <b>610</b> and <b>620</b> are generated by address queue and decoded by cache control logic in order to determine which functional unit is controlling-each array, as shown in Table II.</p><p><tables id=\"TABLE-US-00002\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE II</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Data Cache Index Address</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"5\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"28pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"28pt\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"49pt\"></colspec><colspec align=\"center\" colname=\"4\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"5\" colwidth=\"84pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry></entry><entry>Input Address</entry><entry>Data</entry><entry></entry></row><row><entry>Enable</entry><entry>Select</entry><entry>(Virtual)</entry><entry>Width</entry><entry>Description</entry></row><row><entry align=\"center\" nameend=\"5\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>0</entry><entry>00</entry><entry>(none)</entry><entry>\u2014</entry><entry>Power down. Do not enable</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>any word line or amplifier.</entry></row><row><entry>1</entry><entry>00</entry><entry>ACAdr[13:3]</entry><entry>64</entry><entry>Address calculation.</entry></row><row><entry>1</entry><entry>01</entry><entry>ASIndex[13:3]</entry><entry>64</entry><entry>Retry tag check or load</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>using address from</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>Address Slack.</entry></row><row><entry>1</entry><entry>10</entry><entry>ASStore[13:3 ]</entry><entry>64</entry><entry>Address for writing</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>data into the data array</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>during graduation of a</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>store instruction. (Not</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>used for tag arrays.)</entry></row><row><entry>1</entry><entry>11</entry><entry>ExtIndex[13.4]</entry><entry>128</entry><entry>Address from external</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>interface, for refill</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>or interrogate.</entry></row><row><entry align=\"center\" nameend=\"5\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>Separate data multiplexers are also provided for tag and data arrays. Multiplexer <b>625</b> selects an address from either the external interface or JTLB to write to the tag array. Multiplexers <b>630</b> and <b>631</b> select among data from external interface or register files for writing into the data array.</p><p>When a cache section is not used as indicated by an address selection value of \u201c00\u201d, it is powered down. In power-down mode, the address decoder is disabled so that it does not select any word line; the dummy word line is disabled so that none of the sense amplifiers turn on. The decoder is disabled using an extra input in the first level of gates.</p><p>In some embodiments, the data cache is not initialized by hardware during reset. These embodiments require a bootstrap program to initialize all tags to the \u201cInvalid\u201c state before it makes any use of the data cache. If a block is \u201cInvalid\u201d, the contents of its data array are not used.</p><p>B. Data Array</p><p>1. Data Array Organization</p><p>Referring to FIG. 4, data array <b>610</b> contains 256 rows. Decoder <b>450</b> selects which row is accessed by driving its \u201cword line\u201d. high. Each word line drives a row of 576 cells (512 data bits and 64 parity bits) or bits and is gated and buffered every 32 cells. The 576 bits equals one cache set with each way containing 4 doublewords (a word equals 4 bytes).</p><p>Each-bit, as represented by <b>460</b>, in a doubleword contains eight cells <b>461</b><i>a</i>-<b>461</b><i>h</i>. The cells correspond to one bit from each of the four doublewords in each way of the cache. The number on the top of each cell represents the cache way; the number on the bottom represents the doubleword number within the way.</p><p>Multiplexer <b>470</b>, controlled by signal S<b>0</b>, selects 1 of 4 bits (1 from each of the 4 doubleword in the block) to input into sense amplifier <b>475</b>. Output of sense amplifier represents data from sub-array <b>0</b>. Similarly, S<b>1</b> controls which bit multiplexer <b>471</b> and sense amplifier <b>476</b> is read from sub-array <b>1</b>.</p><p>Microprocessor <b>100</b> uses different select signals S<b>0</b> and S<b>1</b> for processor and external interface accesses due to their different access patterns. Select signal for external interface operations uses virtual address bit <b>4</b>:<b>3</b> and way bit;</p><p>CPU accesses use virtual address bits <b>4</b>:<b>3</b>. Access pattern for CPU and external interface is shown in Table III.</p><p><tables id=\"TABLE-US-00003\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE III</entry></row><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Sense Amplifier Multiplexer in Data Cache</entry></row><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row></thead><tbody valign=\"top\"><row><entry>CUP Accesses (64-bits, Associative)</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"84pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"42pt\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"91pt\"></colspec><tbody valign=\"top\"><row><entry>Adr[4:3]</entry><entry>S0 (Array 0)</entry><entry>S1 (Array 1)</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>00</entry><entry>1000</entry><entry>1000</entry></row><row><entry>01</entry><entry>0100</entry><entry>0100</entry></row><row><entry>10</entry><entry>0010</entry><entry>0010</entry></row><row><entry>11</entry><entry>0001</entry><entry>0001</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><tbody valign=\"top\"><row><entry>External Interface (128-bits in one way)</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"84pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"49pt\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"84pt\"></colspec><tbody valign=\"top\"><row><entry>Adr[4] Way</entry><entry>S0 (Array 0)</entry><entry>S1 (Array 1)</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"5\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"offset\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"35pt\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"49pt\"></colspec><colspec align=\"center\" colname=\"4\" colwidth=\"84pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry>0</entry><entry>0</entry><entry>1000</entry><entry>0100</entry></row><row><entry></entry><entry>0</entry><entry>1</entry><entry>0100</entry><entry>1000</entry></row><row><entry></entry><entry>1</entry><entry>0</entry><entry>0010</entry><entry>0001</entry></row><row><entry></entry><entry>1</entry><entry>1</entry><entry>0001</entry><entry>0010</entry></row><row><entry></entry><entry align=\"center\" nameend=\"4\" namest=\"offset\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>Data from sub-array <b>0</b> and sub-array <b>1</b> are either loaded into the register files or written to main memory via external interface. For register loads, data are multiplexed with corresponding sub-array <b>0</b> and sub-array <b>1</b> data from the other cache bank by multiplexer <b>480</b> and <b>485</b>. Select bank signal (bit <b>5</b>) passes data from the appropriate bank to load aligner <b>428</b><i>a </i>and <b>428</b><i>b</i>, respectively, and into multiplexer <b>486</b>. Cache hit signals, generated from tag check logic, dictate which data, if any, are read out of the cache. Whenever the cache is read and its tag indicates a valid entry, all bytes are checked for proper parity by parity checker <b>477</b>. If any byte is in error during a load instruction, the processor takes a \u201cData Cache Error\u201d exception.</p><p>As for writes to memory, multiplexer <b>490</b> and <b>491</b> select the desired data as indicated by virtual addtess bit <b>5</b>. Thereafter, the data is passed into phase multiplexer circuit <b>495</b>, which writes the first doubleword during \u00f8<sub>1 </sub>of the clock cycle and the second doubleword during \u00f8<sub>2 </sub>of the same clock cycle. Parity checker <b>478</b> checks all bytes of the doubleword for proper parity, and if any error occurs, the processor takes an \u201cExternal Interface Data Cache Error\u201d exception.</p><p>Data are written into the cache arrays either from the register files or from external interface. Data from register files are aligned by store aligner <b>430</b> and multiplexed with data from the external interface by multiplexers <b>488</b> and <b>489</b>. Multiplexers select the data according to the select signals and write into cache via drivers <b>469</b><i>a</i>-<b>469</b><i>h </i>located at the bottom of each column of cells. These drivers are enabled according to the address being written. An even parity bit generated by parity generator <b>499</b><i>a </i>for register stores or parity generator <b>499</b><i>b </i>for external interface stores is appended to each byte stored in the data cache. Each parity bit is written whenever its byte is written.</p><p>As previous discussed, data cache arrays are organized for two distinct access patterns. For loading or copying a block to secondary cache, the two data arrays access a pair of adjacent doublewords in the same block. For reading, which occurs simultaneously with the tag check, each addressed word is read from both blocks, and the block with the matching tag is selected. The data from the other block is ignored. For writing, which occurs after the tag check has been completed, only the addressed block is written.</p><p>Referring to FIG. 5, each array is configured such that words <b>455</b>-<b>458</b> therein alternate between the two cache ways to allow either access pattern. This is why the arrays do not correspond to cache ways.</p><p>Each cache set contains two blocks (e.g., block 0 and block 1) which belong to Way 0 and Way 1. Within each block, the four datawords alternate between the two data arrays. This permits two distinct access patterns. When the cache is loaded or copied back (e.g., external interface access), two doublewords in the same block are accessed simultaneously, as indicated by lines <b>460</b><i>a </i>and <b>460</b><i>b </i>in FIG. <b>5</b>. However, when the cache is read (e.g., CPU access), the same doubleword location is simultaneously read from both blocks within the set, as indicated by lines <b>461</b><i>a </i>and <b>461</b><i>b </i>in FIG. <b>5</b>. The addressed data is selected by tag circuitry.</p><p>Accordingly, doublewords <b>0</b> in either array. For block <b>0</b>, even doublewords (Adr[3]=O) are in Array <b>0</b> and odd doublewords are in Array 1. This is reversed for block <b>1</b>. This allows access of a two doubleword from the same way which otherwise would be impossible in conventional 2-way set-associative caches, unless the data line from each way is 2-doublewords in width. This requires twice the number of sense amplifiers.</p><p>Also, by using multiplexers, the external interface can swap doublewords within its quadword accesses.</p><p>Sense amplifiers, in comparison to ram cells, are relativelylarge. As such, the density of the cache arrays is limited by the width of the sense amplifiers. By employing multiplexers, the number of sense amplifiers is reduced by a factor of four, allowing the ram cells to be more densely packed. The benefits which result are twofold. First, by being able to locate the cells in closer proximity to each other, the propagation delay of array is decreased. Second, the significant savings in chip space can be used for decreasing the die size to reduce cost, and/or designing more aggressive functional units to effectively increase CPU performance.</p><p>Referring to FIG. 6, the 576 cells of each line are arranged in a pattern which minimizes the wiring in the load and store aligners. At the high level, bits are interlaced by their position within bytes. That is, each doubleword contain eight 8-bit bytes, and the bits are numbered <b>0</b> to <b>7</b> within each byte, which equals the bit number modulo <b>8</b>. All \u201cbits <b>0</b>. . .\u201d are grouped together (bits <b>0</b>, <b>8</b>, <b>16</b>, <b>24</b>, <b>32</b>, <b>40</b>, <b>48</b>, <b>56</b>), then \u201cbits 1. . .\u201d are grouped, etc.</p><p>For each sub-array, there are 32 cells within each bit group <b>488</b>. Due to the dense layout of the cells, there is only room for a single local word line per row. These 32 cells consist of four cells for each of the eight bits within the bit group. These four cells are adjacent and wired to the same sense amplifier. One of these cells is selected by a 4-to-1 multiplexer, which has already been discussed.</p><p>Each bank of the cache array includes 148 sense amplifiers along the bottom edge. Of these, 144 amplifiers read 64 bits of data and 8 bits of parity for each of the two arrays. Each of these amplifiers is beneath four columns of cells and includes a 4-to-1 input multiplexer.</p><p>2. Data Array Control Logic</p><p>Referring to FIG. 7, the logic <b>700</b> controls the data cache. Each bank of the Data Cache can be read or written either by the processor or by the external interface. Two operations can occur simultaneously on separate banks. The processor writes bytes within a doubleword (64-bits). Byte mask decoder <b>701</b> decodes the 8-bit byte mask from the address stack to control the writing of each byte. Writing is enabled in each bank if a store instruction graduates and its bank is selected. The external interface writes an entire quadword (128-bits). Writing is enabled using the \u201crefill\u201d or \u201crefill done\u201d command. Select bank signal determines which bank's cache array is written.</p><p>The processor reads a cache bank if its select bank is selected. The external interface reads a cache bank if the command is \u201cData Read\u201d. Select bank signal dictates to which bank data is written.</p><p>FIG. 8 illustrates an 8-bit slice, including all bits equal to 0 modulo <b>8</b>. Data cache contains two identical banks <b>720</b><i>a </i>and <b>720</b><i>b</i>, each having redundant columns of memory cells <b>725</b><i>a </i>and <b>725</b><i>b </i>which can be used to replace defective columns. These banks are physically adjacent, with a 500 \u03bcA-wide wiring channel <b>727</b> between them. Their layouts are mirror images, so that all read and write amplifiers <b>726</b><i>a </i>and <b>726</b><i>b </i>are adjacent to the channel.</p><p>The CPU and the External Interface each read and write the data cache. The CPU does doubleword operations, which contain 64 data bits plus 8 parity bits (72 bits total). The External Interface does quadword operations, which contain 128 bits plus 16 parity bits (144 bits total). To minimize wiring, this data is phase multiplexed onto a doubleword bus. The CPU and External Interface each use 72-bit wide unidirectional buses <b>730</b> and <b>731</b> for reading and writing, respectively. These buses can share channels. Each CPU bus is full width at the bottom of the Data Cache but tapers to zero width at the top; each bus is full width at the top but tapers to zero width at the bottom.</p><p>These buses and associated control signals are wired in metal <b>3</b>. The channel is wire limited.</p><p>The external interface writes the data cache only during refill operations. Two doublewords are transferred during the cycle prior to the write cycle. The first doubleword is latched twice, using phase-1 and phase-2 latches <b>735</b> and <b>736</b>. (This creates an edge-triggered register which is clocked mid-cycle.) The second doubleword is latched in the phase-2 latch <b>737</b> at the end of the cycle. This data is written into either cache bank during the following phase 1. For way <b>0</b>, the first doubleword is written into sub-array <b>0</b> through multiplexer <b>745</b> or <b>746</b>, and the second doubleword is written into sub-array <b>1</b> using multiplexer <b>747</b> or <b>748</b>. For way <b>1</b>, the doublewords are reversed.</p><p>External interface reads the data cache only for write-back operations. It always reads one quadword per cycle. This data is latched in a phase-1 latch within each sense amplifier. This data is sent in two doublewords during phase 2 and the following phase 1. For speed, the sending multiplexer <b>740</b> is selected directly using the clock <b>741</b><i>a </i>and <b>741</b><i>b</i>. Its inputs are driven by two 72-bit 4-to-1 multiplexers. The second doubleword is latched in a phase-2 latch, so that its output will remain valid during phase 1 of the following cycle. Each input can be selected from either array of either bank. For way <b>0</b>, the first doubleword is selected from array <b>0</b>, and the second doubleword is selected from array <b>1</b>. For way <b>1</b>, the doublewords are reversed.</p><p>For uncached load instructions, External Interface data bypasses the cache into the CPU's load aligner <b>428</b><i>a </i>and <b>428</b><i>b</i>, as in a freeload operation, except that no data is written into the cache. For uncached store instructions, CPU data bypasses the cache and is sent to External Interface during the following phase 2.</p><p>C. Tag Array</p><p>1. Tag Array Organization</p><p>The cache tag array, which stores a 36-bit address tag for each 8-word block in the data array, has about an eighth as many bits as the data arrays. There are 64 word lines (one fourth as many as in the data arrays) and 288 cells per row (less than half as many). Thus, the tag access time is faster than the data array.</p><p>Like the cache data arrays, the cache tag array is divided into two identical banks and each can operate independently for either the processor or an external request. A bank is selected by the low bit of the block address (bit #<b>5</b>). Cache tag array is addressed by virtual address bits [<b>13</b>:<b>6</b>], which select a \u201cset\u201d of two blocks. There are 256 sets in each bank. Each set contains two blocks. Thus, the two banks contain 1024 blocks (cache size 32K-byte\u00f732-byte/block). The two tags in each set are read in parallel and are simultaneously compared to the desired physical address (bits <b>37</b>:<b>12</b>) to determine if the cache contains the addressed data (a \u201chit\u201d).</p><p>FIG. 9 illustrates one of the tag banks and associated control logic. The tag array contains 64 rows. Decoder <b>752</b> selects which row is accessed by driving its \u201cword line\u201d high using virtual address bits <b>13</b>:<b>8</b>. Each word line <b>753</b> drives a row of 288, (8 36-bit tags). The 36 bits equals to one tag set with each way containing 4 tags.</p><p>For each bit <b>751</b> in the tag, eight cells <b>755</b><i>a</i>-<b>755</b><i>h </i>are provided. The cells correspond to one bit from each of the four tags in each way of the cache. So for a 36 bit tag, this is repeated 36 times.</p><p>The number on the top of each cell represents the way; the number on the bottom represents the tag number within that row of the way. Unlike the data arrays, the tags bits are interleaved so that each sub-array contains only tags belonging to the same way.</p><p>Multiplexer <b>758</b>, as determined by signal virtual address bits <b>7</b>:<b>6</b>, selects one of four bits (1 from each of the 4 tags) to input into sense amplifier <b>760</b>. Output of sense amplifier represents tag data (tag<b>0</b>) from way <b>0</b>. Similarly, multiplexer <b>759</b> and sense amplifier <b>761</b> output selected tag data (tag<b>1</b>) from way <b>1</b>. In this manner, two tags from each set are read in parallel (2 from bank <b>0</b> and 2 from bank <b>1</b>). Again, the use of multiplexers reduce the number of sense amplifiers needed.</p><p>Each bank includes four tag check comparators: two for the processor (<b>765</b> and <b>766</b>) and two for the external interface (<b>763</b> and <b>768</b>). Each needs two comparators, because the cache is interleaved with two independent 2-way set-associative banks. Each bank can read two tags for either the processor or external interface. These tag signals are multiplexed using multiplexers <b>770</b>-<b>773</b> at the input of the comparators.</p><p>Microprocessors <b>100</b> employs multiplexer <b>776</b> to select either the translated physical address from the JTLB or an address from the address stack it compares with the tag. The JTLB is the critical timing path. The result of the compares are cache \u201chit\u201d signals (hit if tag is present, miss if tag is not present). Also, the tags parity bit is checked by parity checker <b>767</b> and <b>768</b>. A parity error causes an exception.</p><p>Tags from either the external interface or the load/store unit can be stored in the tag array. Multiplexer <b>775</b> selects the desired tag and buffers <b>756</b><i>a</i>-<b>756</b><i>h</i>, which are selectively enabled according to the virtual index, write the data into appropriate location in the tag. Parity generator generates a parity bit whenever a tag is written into the array.</p><p>Referring to FIG. 10, each tag contains the following fields: address <b>785</b>, parity <b>786</b>, way <b>787</b>, state <b>788</b>, parity <b>789</b>, modifier <b>890</b>, and LRU (least recently used) <b>791</b>. The tag fields are described in Table IV.</p><p><tables id=\"TABLE-US-00004\"><table colsep=\"0\" frame=\"none\" pgwide=\"1\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"329pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE IV</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Data Cache Tag Fields</entry></row><row><entry>(Signals are listed for Bank 0. Bank 1 signal mnemonics are</entry></row><row><entry>similar, but include \u201cBank1\u201d instead of \u201cBank0\u201d.)</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"4\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"98pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"182pt\"></colspec><tbody valign=\"top\"><row><entry> Bits</entry><entry>Group</entry><entry>Field</entry><entry>                   Description</entry></row><row><entry align=\"center\" nameend=\"4\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"4\" colsep=\"0\" rowsep=\"0\"><colspec align=\"char\" char=\".\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"98pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"182pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry></entry><entry></entry><entry>These fields are implemented for both cache ways 0 and 1.</entry></row><row><entry>28</entry><entry>Adr</entry><entry>DCBank0Way0Tag[39:12]</entry><entry>Physical address tag identifies the contents of this block.</entry></row><row><entry></entry><entry></entry><entry>DCBank0Way1Tag[39:12]</entry></row><row><entry>1</entry><entry>Adr</entry><entry>DCBank0Way0TagP</entry><entry>Parity bit for address tag field. (Even parity.)</entry></row><row><entry></entry><entry></entry><entry>DCBank0Way1TagP</entry></row><row><entry>2</entry><entry>State</entry><entry>DCBank0Way0TagSt[1:0]</entry><entry>The refill bit in the state modifier and the two state bits</entry></row><row><entry></entry><entry></entry><entry>DCBank0Way1TagSt[ 1:0]</entry><entry>determine the state of each cache block.</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"offset\" colwidth=\"147pt\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"154pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry>0,00 =</entry><entry><u>Invalid</u>. Block is empty</entry></row><row><entry></entry><entry>0,01 =</entry><entry><u>Shared</u>. Block may be read, but not written.</entry></row><row><entry></entry><entry>0,10 =</entry><entry><u>Clean Exclusive</u>. Block may be written, but it</entry></row><row><entry></entry><entry></entry><entry>has not yet been modified. Its contents equal</entry></row><row><entry></entry><entry></entry><entry>the copy in main memory.</entry></row><row><entry></entry><entry>0,11 =</entry><entry><u>Dirty Exclusive</u>. Block may be written. It has</entry></row><row><entry></entry><entry></entry><entry>been modified.</entry></row><row><entry></entry><entry>1,00 =</entry><entry><u>Refill Clean</u>. Block is being refilled for a load</entry></row><row><entry></entry><entry></entry><entry>instruction.</entry></row><row><entry></entry><entry>1,01 =</entry><entry><u>UpgradeShared</u>. Converting \u201cShared\u201d to</entry></row><row><entry></entry><entry></entry><entry>\u201cDirty\u201d.</entry></row><row><entry></entry><entry>1,10 =</entry><entry><u>UpgradeClean</u>. Converting \u201cClean\u201d  to \u201cDirty\u201d.</entry></row><row><entry></entry><entry>1,11 =</entry><entry><u>Refill Dirty</u>. Refill is being refilled for a store</entry></row><row><entry></entry><entry></entry><entry>instruction.</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"4\" colsep=\"0\" rowsep=\"0\"><colspec align=\"char\" char=\".\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"98pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"182pt\"></colspec><tbody valign=\"top\"><row><entry>1</entry><entry>State</entry><entry>DCBank0Way0TagSWay</entry><entry>Which way of the secondary cache was this block</entry></row><row><entry></entry><entry></entry><entry>DCBank0Way1TagSWay</entry><entry>refilled from. This indicated where to write the block</entry></row><row><entry></entry><entry></entry><entry></entry><entry>if it is written back to secondary cache.</entry></row><row><entry>1</entry><entry>State</entry><entry>DCBank0Way0TagStP</entry><entry>Parity bit for state field and way bit. (Odd parity.)</entry></row><row><entry></entry><entry></entry><entry>DCBank0Way1TagStP</entry></row><row><entry>3</entry><entry>Mod</entry><entry>DCBank0Way0TagStMod[2:0]</entry><entry>Tag state modifier:</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"5\" colsep=\"0\" rowsep=\"0\"><colspec align=\"char\" char=\".\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"98pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"5\" colwidth=\"154pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry>2-port</entry><entry>DCBank0Way1TagStMod[2:0]</entry><entry>001 =</entry><entry>Neither refill or written.</entry></row><row><entry></entry><entry></entry><entry></entry><entry>010 =</entry><entry>Written. Block has been written by a store</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>instruction. Cache block may be consistent with</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>secondary.</entry></row><row><entry></entry><entry></entry><entry></entry><entry>100 =</entry><entry>Refill. Cache block is being refilled or is</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>waiting for its state to be modified. (See State bits.)</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"4\" colsep=\"0\" rowsep=\"0\"><colspec align=\"char\" char=\".\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"98pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"182pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry></entry><entry></entry><entry>This bit is imptemented once per set in the cache.</entry></row><row><entry>1</entry><entry>LRU</entry><entry>DCBank0LRU</entry><entry>\u201cLeast Recently Used\u201d way of this cache set.</entry></row><row><entry></entry><entry>2-port</entry><entry></entry><entry>\u201c0\u201d if Way 0 was least recently used by the processor.</entry></row><row><entry></entry><entry></entry><entry></entry><entry>\u201c1\u201d if Way 1 was least recently used.</entry></row><row><entry align=\"center\" nameend=\"4\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>The address and tag bits have separate write enables, so the state bits may be modified without changing the address bits. Thus, these fields must have separate parity bits <b>786</b> and <b>789</b>.</p><p>When a block is refilled from Secondary Cache, the way in which it was found in the Secondary Cache is written into the block's Data Cache tag way field <b>787</b>. This information is used if the block is written back to Secondary Cache.</p><p>The state of each Data Cache block is determined by a 3-bit code. This code is formed by catenating the refill bit (TagStMod[2]) with the 2-bit state code (TagSt[<b>1</b>:<b>0</b>]). There are seven states.</p><p>Invalid (000, \u201cN\u201d): This block is empty. The address and data fields are ignored. The tag comparator always generates a \u201cmiss\u201d for an invalid block.</p><p>Shared (001, \u201cS\u201d) : This block is \u201cShared\u201d. That is, a valid copy of this block may also exist in other caches. The processor may read this block, but it may not modify it.</p><p>Clean Exclusive (010, \u201cE\u201d): This cache contains the only valid copy of this cache block. The processor may read this block, but it may not modify it until it has marked it \u201cdirty\u201din both the primary and the secondary cache.</p><p>Dirty Exclusive (011, \u201cD\u201d): This cache contains the only valid copy of this cache block. It may read or write it.</p><p>Refill Clean (100\u201cRC\u201d): This cache has initiated a refill to load this block of the cache and is waiting for the data to be returned. This refill was initiated by a load instruction. The block's state may be shared or exclusive.</p><p>Upgrade Share (101, \u201cUS\u201d): This cache contains a shared block, but it has requested that it be upgraded to dirty-exclusive. It is waiting for the external interface to do an invalidate.</p><p>Upgrade Clean (110, \u201cUC\u201d): This cache contains a clean exclusive block, but it has requested that it be upgraded to dirty-exclusive. IT is waiting for the external interface to mark the secondary cache block as \u201cdirty\u201d.</p><p>Refill Dirty (\u201cRD\u201d): This cache has initiated a refill to load this block of the cache and is waiting for the data to be returned. This refill was initiated by a store instruction, so the block's state will be \u201cDirty Exclusive\u201d.</p><p>LRU field <b>791</b> indicates which block within each set of the cache was \u201cLeast Recently Used\u201d. When it is necessary to replace one of two old blocks, the LRU block is selected because it is statistically less likely to be used next. This bit is used only when the processor initiates a cache refill, and both blocks in the selected cache set are valid and not locked. (An LRU cache replacement algorithm usually reduces the number of misses a few percent less than a random replacement algorithm, although it is not necessarily the best algorithm for all programs.)</p><p>The tag array contains one LRU bit per set of the cache (i.e. per two blocks). Whenever the processor gets a hit on a block in the cache, this bit is updated to select the other block in this set. That is, this block has been used more recently than the other block. When there is a miss, and a new block is refilled into the cache, this bit is updated to select the other block.</p><p>Conventionally, the W bit is located in the data array, not the tag array. As discussed above, the W bit is read whenever data is removed from the data cache, such as cache refills, external interrogates or cache invalidates.</p><p>These operations require allocation of the tag array as well as checking the W bit. Consequently, both the tag array and data array must be allocated.</p><p>However, by locating the W bit in the tag arrays any operation which removes data from the data array needs to access only the tag array. This allows the data array to be allocated to another execution unit simultaneously, thus improving the performance of the microprocessor.</p><p>LRU improves the performance of microprocessor by statically increasing the cache's hit rate. Thus, it is a performance feature only; it is not architecturally defined. Tag check cycles, which can result in hits or misses, can occur out of sequence, and they can occur speculatively. As such, the LRU bit is not guaranteed to exactly match the data references of the program.</p><p>The LRU bit is fabricated using a special dual-port RAM cell. The second port is used to update the LRU bit during phase 2 of any processor tag check cycle, if there was a cache hit. The extra port requires two extra transistors than the standard 6-transistor cache cell.</p><p>The LRU bit can be read along with the rest of the tag. The LRU bit is written only using the second port, when the tag is written during phase 2.</p><p>The 3-bit modifier field modifies the meaning of a block's 2-bit state. These bits are separate from the state field, because they are implemented with special dual-port memory cells, similar to the LRU bit. This field may be written during phase 2 of a tag check cycle, depending on whether there was a cache hit.</p><p>There are twelve modifier cells per row, which store the 3-bit modifier for each of the four blocks in each row. There are three sense amplifiers. These bits are read when the external interface snoops the primary data cache.</p><p>Bit <b>2</b> of the state modifier is a \u201crefill\u201d bit. It Indicates that the processor has issued a request for a refill or an upgrade to the External Interface. Only the processor sets it. It is written (along with the rest of the tag) during the next cycle after the processor issues a refill command. Or it can be set by modifying only the state modifier field during phase 2.</p><p>Bit <b>1</b> of the state modifier is a \u201cwritten\u201d bit (\u201cW\u201d) for each block. This bit indicates that data has been written into the primary data cache and that it is inconsistent with the Secondary Cache. The external interface reads this bit whenever a block is removed from the cache in order to determine if it must be written back to the Secondary Cache. When a block is refilled into the cache, this bit is initially \u2018O\u2019 for a load instruction or \u20181\u2019 for a store instruction. It may also be set later, whenever a store instruction uses this block.</p><p>Bit <b>0</b> is set whenever neither of refill or written bits is set. This bit serves as an odd parity check on the state modifier field. Each valid state has exactly one \u201c1\u201d bit set.</p><p>The three bits encode three states. Because each code has one bit set, it effectively implements odd parity. A parity error is signalled if any other pattern is read.</p><p>2. Tag Array Control Logic</p><p>Address queue performs \u201ctag check\u201d cycles to determine if the Data Cache contains the data it requires. External Interface performs tag check cycles when it invalidates secondary cache blocks.</p><p>FIG. 11A illustrates one embodiment of the tag check circuit. The desired address to two 28-bit address tags (physical address bits <b>39</b>:<b>12</b>) are each compared to its corresponding tag bit in an exclusive-or gate <b>801</b>. For sake of simplicity, only one gate is illustrated, but it will be apparent to those skilled in the art that there is one gate per bit. If any bit position differs, the output of gate <b>801</b> is a logic \u201c0\u201d indicating a \u201ccache miss\u201d. The exclusive-or gates' outputs are combined in a 28-input dynamic \u201cor\u201d gate <b>802</b>, using the rising edge of \u00f8<sub>2</sub>. The dynamic \u201cor\u201d is much faster than a static gate, but it depends on the timing and skew of the clock. The dynamic \u201cmatch\u201d node <b>803</b> is precharged high during \u00f8<sub>1</sub>. It is discharged during \u00f8<sub>2 </sub>if any address bit does not match. Thus, the signal remains high for a \u201chit\u201d; a \u201cmiss\u201d results in a falling edge shortly after \u00f8<sub>2 </sub>begins. Output of the dynamic or gate is inverted by an inverter 803, whose output is a pulse which rises about 2.5 gate-delays after \u00f8<sub>2 </sub>begins when there is a \u201cmiss\u201d. Otherwise, its output remains zero. This clean output signal allows subsequent logic to be optimized for a single edge transition. It also minimizes noise on 64-bit buses which are distributed long distances.</p><p>An extra input to the comparator <b>805</b> forces a \u201cmiss\u201d if the block's state is \u201cinvalid\u201d. (The block is invalid if the tags state DCOState[<b>1</b>:<b>01</b>] is \u201c00\u201d and the block is not in \u201crefill\u201d (DCOMod[<b>2</b>]=<b>0</b>). High-speed dynamic comparator <b>805</b> naturally generates a pulse for a \u201ccache miss\u201d, because it implements logical \u201cor\u201d gates, which have transistors in parallel. A dynamic node is precharged high. This node is pulled low, and an output pulse is generated, if any input bit mismatches. The leading edge of this pulse can be used for switching dynamic or biased logic. However, there is no edge for a \u201chit\u201d.</p><p>Way check logic <b>811</b> determines which way of the cache contains the desired data during the tag check cycle. If either data array is being read simultaneously for a load instruction, the tag check selects between its two ways. Otherwise, the \u201cway\u201d is stored in the address queue until the instruction is retried.</p><p>The cache \u201cmiss\u201d pulses (MissA, MissB) correspond to the two ways of the Data Cache. However, as previously discussed, these ways do not correspond with the data arrays.</p><p>Within each cache block, double words alternate between arrays. For even doublewords (Adr[<b>3</b>]=0), way <b>0</b> is in array <b>0</b>, and way 1 is in array <b>1</b>. For odd doublewords (Adr[<b>3</b>]=1), way <b>0</b> is in array <b>1</b>, and way <b>1</b> is in array <b>0</b>. Consequently the miss signals is interchanged when Adr[<b>3</b>]=1 using two dynamic 3-to-1 multiplexers (Miss<b>0</b>, Miss <b>1</b>). For convenience, only one multiplexer <b>815</b> is shown. Multiplexer <b>815</b> selects between MissA and MissB. The multiplexer's third input is used when the way is already known. This circuit is precharged during \u00f81. All inputs are gated with \u00f8<sub>2</sub>.</p><p>The cache \u201cmiss\u201d pulses are used to select a dynamic data multiplexer <b>820</b>. This circuit is actually an \u201cand-or\u201d gate. If there is a miss on way <b>0</b>, data for way <b>1</b> is selected. If there is a miss on way <b>1</b>, data for way <b>0</b> is selected. Thus, if both ways miss, the data bits for both ways are logically or-ed, but this result is not used. (The comparators generate an edge only for a \u201cmiss\u201d, not for a \u201chit\u201d. This is a nuisance, but it causes no problems with the dynamic multiplexer. However, if a pass-gate multiplexer is used, turning on both inputs will create significant noise.) This means that each \u201cmiss\u201d signal can be optimized for speed; there is no race condition.</p><p>The miss multiplexer drives a long wire and a large buffer. To switch low quickly, it uses n-channel transistors for the \u201cmiss\u201d signals. The \u201cknown\u201d input can use a smaller transistor because it switches earlier. The final \u201cmiss\u201d buffers drives 64 transistors and about 6000 \u03bc of wire along the spine of the Data Cache.</p><p>Referring to FIG. 11B, logic circuit <b>850</b> provides a \u201cload is done\u201d signal (LoadDone) to the instruction queues and Busy Bit Table. This signal, which is derived from outputs of the tag check circuit, may be generated during any cycle when the processor successfully completes a \u201cload\u201d instruction. During tag check cycles, it indicates that the cache contains the addressed data and that no dependencies prevent its use. During refill cycles, it indicates that the Secondary Cache contains the address data and that no ECC error was detected. During \u201cJust Load\u201d cycles, which read only the data array, LoadDone is always asserted. LoadDone is a critical path signal. For speed, it is partially implemented using dynamic logic, which is driven from the hit signals and state bits of the primary cache. Logic circuit <b>850</b> is physically adjacent to the tag hit comparator to avoid delay associated with buffering the hit signals.</p><p>As shown LoadDone signal is generated in two circuit stages <b>851</b> and <b>852</b>. Circuit stage <b>851</b> generates a LoadMiss in response to IgnoreHitB, IgnoreHitA, Miss A, Miss B.</p><p>The \u201cLoad Miss\u201d signal indicates that neither way of the cache generated a qualified \u201chit\u201d signal. The outputs of the tag comparators (HitA and HitB) must be gated, however. The address queue inhibits cache hits on either or both ways of the cache, if it detects dependencies between blocks. Cache hits must also be ignored if the block is still being refilled. In this case, the addresses match and the tag comparator generates a \u201chit\u201d, but the data is not yet available. For a refill, tag modifier bit <b>2</b> is set, and the tag state is either 00 (refill clean) or 11 (refill dirty). (Tag modifier bit 2 is also set when a block is upgraded for a store operation. The tag state is either 01 or 10. The cache data is valid in the cache and can be used for a load.)</p><p>Circuit stage <b>852</b> derives the LoadDone signal from LoadMiss and two control signals sent by the address queue, LoadDoneDef, and LoadDoneHit. LoadDoneDef indicates that the load is \u201cdone\u201d regardless of the cache hit signals and LoadDoneHit indicates that a load is \u201cdone\u201d if there is a cache hit. Table V shows the logical equations for LoadDone signal.</p><p><tables id=\"TABLE-US-00005\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"2\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"1\" colwidth=\"112pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"105pt\"></colspec><thead><row><entry nameend=\"2\" namest=\"1\" rowsep=\"1\">TABLE V</entry></row><row><entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Signal Name</entry><entry>Description</entry></row><row><entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry></row></thead><tbody valign=\"top\"><row><entry>\u02dcLoadMiss = HitA &amp; \u02dcIgnoreHitA |</entry><entry>Hit on way 0 and block is not</entry></row><row><entry>HitB &amp; \u02dcIgnoreHitB</entry><entry>in refill state. Hit on way 1 and</entry></row><row><entry></entry><entry>block is not in refill state.</entry></row><row><entry>IgnoreHitA = InhHit0 |</entry><entry>Dependency in Address Queue</entry></row><row><entry>TagModA[2] &amp;</entry><entry>inhibits \u201chit\u201d on block 0. Block 0</entry></row><row><entry></entry><entry>is in refill state.</entry></row><row><entry></entry><entry>(Upgrade state is okay.)</entry></row><row><entry>(TagStA=O|TagStA=3)</entry></row><row><entry>IgnoreHitB = InhHit1 |</entry><entry>Dependency in Address Queue</entry></row><row><entry>TagModB[2] &amp;</entry><entry>inhibits \u201chit\u201d on block 1. Block 1</entry></row><row><entry></entry><entry>is in refill state.</entry></row><row><entry></entry><entry>(Upgrade state is okay.)</entry></row><row><entry>(TagStB=0 | TagStB=3)</entry></row><row><entry>LoadDone = LoadDoneDef |</entry><entry>Queue generates \u201cdone\u201d regardless</entry></row><row><entry>LoadDoneHit &amp; \u02dcLoadMiss</entry><entry>of cache \u201chit\u201d. Load is \u201cdone\u201d only</entry></row><row><entry></entry><entry>if the cache \u201chits\u201d.</entry></row><row><entry>\u02dcLoadDone =</entry><entry>Load is not done if: Miss on</entry></row><row><entry></entry><entry>both ways.</entry></row><row><entry>\u02dcLoadDoneDef &amp; MissA &amp; MissB |</entry><entry>Miss on way 0, and block in</entry></row><row><entry>\u02dcLoadDoneDef &amp; MissA &amp;</entry><entry>1 hits must be ignored. Miss on</entry></row><row><entry>IgnoreRitB |</entry><entry>way 1, and block in way 0 hits</entry></row><row><entry>\u02dcLoadDoneDef &amp; MissB &amp;</entry><entry>must be ignored. Address Queue</entry></row><row><entry>IgnoreHitA |</entry><entry>does not enable done.</entry></row><row><entry>\u02dcLoadDoneDef &amp;</entry></row><row><entry>\u02dcLoadDoneTent</entry></row><row><entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>Circuit stages <b>851</b> and <b>852</b> may be implemented with a 4\u00d73 dynamic \u201cand-or\u201d gate. The circuit's critical path inputs are the \u201cmiss\u201d pulses from the tag comparators. These are complements of the \u201chit\u201d signals, so this equation is complemented. (A fifth term IgnoreHitA&amp;IgnoreHitB has been omitted. It is redundant because the cache cannot properly generate a hit on both ways simultaneously).</p><p>This output signal is a pulse during phase 2. It is buffered to drive long wires. Its leading edge is optimized for speed by ratioing the transistors of its output buffer.</p><p>FIG. 12 illustrates a circuit <b>870</b> which provides pulses to the LRU and tag modifier circuits for each \u201ccache hit\u201d. Circuit inverts the \u201cmiss\u201d signal and gates it with a timing pulse. To avoid glitches, the timing pulse should start after the \u201cmiss\u201d signal has switched. The speed of that signal depends on how many bits differ because each different bit turns on one of the parallel transistors. Switching is slowest when only one bit differs. The timing pulse is generated using a dummy comparator circuit, which simulates timing for a single bit difference. Its output is gated with an enable and TagMod[<b>2</b>]*, which inhibits a \u201chit\u201d if the block is being refilled. The delay through this gate provides timing margin which eliminates any switching glitches.</p><p>FIG. 13 shows tag row decoder <b>900</b> which is a 6-bit to 64-bit row decoder which selects which word line will be asserted. The decoder's input is selected from the addresses provided by the Address Calculation unit, address stack, or external interface. The address is latched at the end of phase 2, so that it will be stable while the word line is driven during the following phase 1.</p><p>Decoding is split into predecode and drivers. In the predecoder <b>901</b>, the high 3 bits (<b>13</b>:<b>11</b>) and low 3 bits (<b>10</b>:<b>8</b>) are separately decoded by 3-to-8 decoders <b>902</b> and <b>903</b>, respectively. Each predecoder has one output high. Low decoder <b>903</b> can force all its outputs low to disable the tag array, thereby eliminating most power dissipation in the tag array. These decoders are next to the array at the center. The outputs drive signals across the array to the row decoders. Each output drives 8 loads, which may be distributed across the tag array.</p><p>There are 64 word line drivers <b>910</b> in each array. One driver is selected by logically and-ing one input from predecoder <b>901</b>. The output of the \u201cand\u201d gate should be stable by the end of each cycle. It is gated with \u00f8<sub>1 </sub>to generate a pulse during the first half of the next cycle.</p><p>The predecoders have special circuitry to latch their output for use during the next cycle. The outputs are latched during phase 1, while the word line is being driven. This latched output can be selected in place of the new input, during phase 2. This selection is done on the output of the predecoders because the select signal occurs too late. (If the latched decode is used, the latch will be transparent during the next phase 1, with its inputs tied to its outputs. This is stable because these signals will be equal.)</p><p>The select signal is based on the cache hit signals. For a tag check by the processor, the tags are written with a new address following a cache miss. For an interrogate by the external interface, the tags are written with a new state, following a cache hit. Otherwise, the decoder selects a new location.</p><p>The tag state is changed both by the processor and the external interface. The processor writes a new tag address and state during the cycle after it initiates refilling a cache block. Its state is initially \u201cRefilling\u201d because the data has not yet been loaded. The external interface updates this state when the refill has been completed. It must also check the Data Cache contents when secondary blocks are replaced or in response to an external intervention.</p><p>Tag writes must be coordinated between the processor and external interface in order to prevent interference in case both units modify the same block. This is simplified by making most state changes \u201catomically\u201d. That is, whenever either unit decides to change a tag's state, it must modify that tag on the next cycle. This prevents any other operation from accessing the tag before it is updated. The processor does not modify a tag while it is in the \u201crefill\u201d state.</p><p>Thus, the external interface can simply write a block's new state at the end of each refill operation. It does not need to do an atomic operation here. State changes for the Data Cache Tags are listed in Table VI.</p><p><tables id=\"TABLE-US-00006\"><table colsep=\"0\" frame=\"none\" pgwide=\"1\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"385pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE VI</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Data Cache Refill Way</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"8\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"1\" colwidth=\"35pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"42pt\"></colspec><colspec align=\"left\" colname=\"5\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"6\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"7\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"8\" colwidth=\"168pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry>Old</entry><entry>Old</entry><entry></entry><entry>New</entry><entry>New</entry><entry>Update</entry><entry></entry></row><row><entry>Oper</entry><entry>State</entry><entry>Mod</entry><entry>Condition</entry><entry>State</entry><entry>Mod</entry><entry>Cycle</entry><entry>Description </entry></row><row><entry align=\"center\" nameend=\"8\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>CPU tagck</entry><entry>(input)</entry><entry>(input)</entry><entry>(input)</entry><entry>(dec)</entry><entry>(dec)</entry><entry></entry><entry>(CPU does tag check cycles.)</entry></row><row><entry>load/store</entry><entry>xx</entry><entry>001</entry><entry>Cache miss.</entry><entry>00</entry><entry>100</entry><entry>next</entry><entry>Write new tag during next cycle.</entry></row><row><entry></entry><entry></entry><entry></entry><entry>Busy=0x.</entry></row><row><entry>load, store</entry><entry>xx</entry><entry>010</entry><entry>Cache miss.</entry><entry>00</entry><entry>100</entry><entry>next</entry><entry>Must also schedule write-back to secondary. (State 3</entry></row><row><entry></entry><entry></entry><entry></entry><entry>Busy=00.</entry><entry>11</entry><entry>100</entry><entry></entry><entry>indicates block will be writable.)</entry></row><row><entry>store</entry><entry>01</entry><entry>001</entry><entry>Cache hit.</entry><entry>xx</entry><entry>100</entry><entry>this \u03c62</entry><entry>Upgrade \u201cshared\u201d to \u201cdirty exclusive\u201d</entry></row><row><entry></entry><entry></entry><entry></entry><entry>Busy=0x.</entry></row><row><entry>store</entry><entry>10</entry><entry>001</entry><entry>Cache hit.</entry><entry>xx</entry><entry>100</entry><entry>this \u03c62</entry><entry>Upgrade \u201cclean\u201d to \u201cdirty exclusive\u201d</entry></row><row><entry></entry><entry></entry><entry></entry><entry>Busy=0x.</entry></row><row><entry>store</entry><entry>11</entry><entry>001</entry><entry>Cache hit.</entry><entry>xx</entry><entry>100</entry><entry>this \u03c62</entry><entry>Set \u201cW-bit\u201d: inconsistent with secondary.</entry></row><row><entry>Ext.Int.</entry><entry>(Info</entry><entry>(Info</entry><entry>(inputs)</entry><entry>from</entry><entry>from</entry><entry></entry><entry>(Ext.Int always provides the new state and modifer bits.</entry></row><row><entry>(inputs)</entry><entry>only)</entry><entry>only)</entry><entry></entry><entry>Ext.Int</entry><entry>ExtInt</entry><entry></entry><entry>old state and modifer bits are shown only for reference,</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>but they are not decoded.)</entry></row><row><entry>DCmd=3</entry><entry>\u2014</entry><entry>\u2014</entry><entry></entry><entry>nn</entry><entry>nnn</entry><entry>this</entry></row><row><entry>DCmd=5</entry><entry>\u2014</entry><entry>100</entry><entry></entry><entry>01</entry><entry>001</entry><entry>this</entry></row><row><entry>DCmd=5</entry><entry>\u2014</entry><entry>100</entry><entry></entry><entry>10</entry><entry>001</entry><entry>this</entry></row><row><entry>DCmd=5</entry><entry>\u2014</entry><entry>100</entry><entry></entry><entry>11</entry><entry>010</entry><entry>this</entry></row><row><entry>DCmd=8</entry><entry>\u2014</entry><entry>\u2014</entry><entry>Cache hit.</entry><entry>00</entry><entry>001</entry><entry>next</entry></row><row><entry>DCmd=9</entry><entry>\u2014</entry><entry>\u2014</entry><entry>Cache hit.</entry><entry>01</entry><entry>001</entry><entry>next</entry></row><row><entry>DCmd=11</entry><entry>01</entry><entry>001</entry><entry>Cache hit.</entry><entry>11</entry><entry>001</entry><entry>next</entry><entry>Mark entry \u201cdirty exclusive\u201d on next cycle in response to</entry></row><row><entry></entry><entry>10</entry><entry>001</entry><entry></entry><entry>11</entry><entry>001</entry><entry></entry><entry>earlier \u201cupgrade\u201d. Set \u201cinconsistent\u201d if</entry></row><row><entry></entry><entry>11</entry><entry>001</entry><entry></entry><entry>xx</entry><entry>xxx</entry><entry></entry><entry>previously in \u201cupgrade\u201d state. </entry></row><row><entry></entry><entry>00</entry><entry>100</entry><entry></entry><entry>xx</entry><entry>xxx</entry><entry></entry><entry>Do not change state if normal refill.</entry></row><row><entry></entry><entry>01</entry><entry>100</entry><entry></entry><entry>11</entry><entry>010</entry><entry></entry></row><row><entry></entry><entry>10</entry><entry>100</entry><entry></entry><entry>11</entry><entry>010</entry><entry></entry></row><row><entry></entry><entry>11</entry><entry>100</entry><entry></entry><entry>xx</entry><entry>xxx</entry><entry></entry></row><row><entry align=\"center\" nameend=\"8\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>The top part of Table VI shows processor operations. The old state and modifier bits (and the cache hit, external interface \u201cbusy\u201d signals, and processor refill enables) are decoded to determine the new state and modifier bits. The low part shows External Interface operations. The old state and modifier bits are not decoded, but the cache hit signal is used for \u201cMark\u201d operations. The new state and modifier bits are provided by the External Interface.</p><p>Atomic tag operations require two cycles. The first cycle reads the tag and does a tag check. The second cycle conditionally writes a new value into the tag. Usually only the first cycle is required. For example, the Data Cache typically has a 96% hit ratio, so the processor's second cycle is required only 4% of the time. To avoid wasting cache bandwidth, only the first cycle is allocated. Other processor operations can be scheduled during the second cycle. If the second cycle is needed, it may collide with this other operation. That operation is aborted and retried several cycles later. The external interface cannot retry operations. It does not schedule other operations after its own check cycles. The processor delays any refill operation, if the external interface has requested use of the next cycle.</p><p>Each cache bank has separate write enables for its tags. The processor writes both the state and the address sections. The external interface writes only the state. Table VII defines the write enable signal for Bank <b>0</b>. Bank <b>1</b> is similar, except that bit <b>5</b> is \u201c1\u201d. Writing a tag array is enabled on the previous cycle, if a refill is done or if a tag check requires a write.</p><p><tables id=\"TABLE-US-00007\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"2\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"1\" colwidth=\"133pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"84pt\"></colspec><thead><row><entry nameend=\"2\" namest=\"1\" rowsep=\"1\">TABLE VII</entry></row><row><entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Signal</entry><entry>Description</entry></row><row><entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry></row></thead><tbody valign=\"top\"><row><entry>Bank0TagWrEn=\u02dcEX1Index[5]&amp;</entry><entry>\u201cRefill Done\u201d</entry></row><row><entry>(EX0DCmdD=5)| Bank0ModTag;</entry><entry>Modify tag (read/write</entry></row><row><entry></entry><entry>cycle pair).</entry></row><row><entry>Bank0ModTag = Bank0TSeID[1]&amp;WrTg</entry><entry>Processor initiated refill.</entry></row><row><entry>IfMissC &amp; \u02dcDCHitCpu| EX2Index[5] &amp;</entry><entry>External interrogate</entry></row><row><entry>WrTag1fHitX &amp; DCHitExt</entry><entry>updates tag.</entry></row><row><entry align=\"center\" nameend=\"2\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>The processor can initiate a data cache refill during a tag check, if the cache misses and refill is enabled. Refill is enabled if all of the following conditions are met:</p><p>These signals are combined into a signal RefEn.</p><p>1. The virtual address selects a \u201ccacheable\u201d attribute (\u201cnon-coherent\u201d, \u201cexclusive\u201d, or \u201cshared\u201d).</p><p>2. The instruction is not a \u201cStore Conditional\u201d. (SC is always used following a \u201cLoad Linked\u201d instruction. The LL will refill the cache if necessary. If the addressed block is no longer in the cache when the SC graduates, the SC \u201cfails\u201d, and the write is aborted.)</p><p>3. The external interface Miss-Handling-Table is not busy. (CCOBusy bit <b>1</b>.)</p><p>4. If a write-back is required, the Secondary Cache's write buffer is not busy. (CCOBusy bit <b>0</b>.) These signals are combined into separate AvForRef signals for each cache way, as shown in Table VII.)</p><p>5. The old cache state modifier is not \u201crefill\u201d. (When a cache block is in \u201crefill\u201d state, it must wait for the external interface to complete before any new operation can be initiated for that block.)</p><p>6. The address queue enables refills, indicating that the way of the cache is available. (AQOWavO:1Av).</p><p>A way is not available for refill if it is already flagged as \u201clocked\u201d or \u201cused\u201d in the queue. This indicates that another entry needs the existing block, so that it cannot be replaced. If the current instruction has any cache dependency (DepRowC), either flag will make both ways unavailable because one way must be reserved for the oldest instruction.</p><p>A way is also not available for refill if the external interface will use the tag array of the same cache bank during the following cycle. Because the tag check is in cycle \u201cC2\u201d, this interlock checks the \u201ccycle C2\u201d usage bits (ExtUseCD).</p><p>Whenever a block is refilled into the Data Cache, tag logic determines which way of the cache will be replaced, as shown in Table VIII. If either way is \u201cinvalid\u201d, a new block can be loaded without invalidating any previous block. Specifically, if block <b>0</b> is invalid, it is replaced. Otherwise, if block <b>1</b> is invalid, it is replaced.</p><p><tables id=\"TABLE-US-00008\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE VIII</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>Data Cache Refill Way</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"6\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"28pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"35pt\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"21pt\"></colspec><colspec align=\"center\" colname=\"4\" colwidth=\"21pt\"></colspec><colspec align=\"center\" colname=\"5\" colwidth=\"28pt\"></colspec><colspec align=\"left\" colname=\"6\" colwidth=\"84pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>Select</entry><entry></entry></row><row><entry>Refill</entry><entry>AvForRef</entry><entry>Valid</entry><entry></entry><entry>Way to</entry></row><row><entry>Enable</entry><entry>B,A</entry><entry>B,A</entry><entry>LRU</entry><entry>Replace</entry><entry>Description</entry></row><row><entry align=\"center\" nameend=\"6\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>0</entry><entry>xx</entry><entry> xx</entry><entry>x</entry><entry>no refill</entry><entry>Refill is not enabled.</entry></row><row><entry>1</entry><entry>00</entry><entry>xx</entry><entry>x</entry><entry>no refill</entry><entry>Refill is not allowed for</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>aset if neither block</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>is available.</entry></row><row><entry>1</entry><entry>01</entry><entry>xx</entry><entry>x</entry><entry>refill 0</entry><entry>Replace Way 0 if it is</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>available and Way 1 is not.</entry></row><row><entry>1</entry><entry>10</entry><entry>xx</entry><entry>x</entry><entry>refill 1</entry><entry>Replace Way 1 if it</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>is available and Way 0</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>is not. (Unavailable</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>if already in \u201cRefill\u201d,</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>or if \u201cLocked\u201d</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>or \u201cUse\u201d in AQ.)</entry></row><row><entry>1</entry><entry>11</entry><entry>x0</entry><entry>x</entry><entry>refill 0</entry><entry>If Way 0 contains an</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>\u201cInvalid\u201d block,</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>refill Way 0.</entry></row><row><entry>1</entry><entry>11</entry><entry>01</entry><entry>x</entry><entry>refill 1</entry><entry>Else, if Way 1 contains an</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>\u201cInvalid\u201d block, refill Way</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>0.</entry></row><row><entry>1</entry><entry>11</entry><entry>11</entry><entry>0</entry><entry>refill 0</entry><entry>Way 0 is \u201cLeast Recently</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>Used\u201d</entry></row><row><entry>1</entry><entry>11</entry><entry>11</entry><entry>1</entry><entry>refill 1</entry><entry>Way 1 is \u201cLeast Recently</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry></entry><entry>Used\u21c4</entry></row><row><entry align=\"center\" nameend=\"6\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>If both blocks are valid, the cache must replace a valid block. However, these blocks may not be available for replacement. The cache must keep blocks which are in \u201cRefill\u201d tag state or are \u201cLocked\u201d or \u201cUsed\u201d in the address queue. If a block is in a \u201cRefill\u201d state, it cannot be refilled again until the first refill has been completed. If neither block is available, a new refill cannot be initiated. If only one block is available, it is replaced. If both are available, the \u201cLeast Recently Used\u201d way is refilled. (See next subsection.)</p><p>The RefEn and AvForRef[1:O] signals are described in Subsection 16.3.8. A tag is \u201cvalid\u201d if its state is not zero or if its state modifier is \u201crefill\u201d. The LRU is read from the cache tag array.</p><p>This table generates two signals. DCBeginRef indicates that a refill operation has been initiated. DCRefWay indicates which way of the cache will be refilled.</p><p>D. Cache Interface</p><p>The Data Cache interfaces to the processor's load/store and to the external interface. The external interface the processor and Data Cache a 4-bit \u201ccommand\u201d code, indicating which operation it is performing. These commands are listed in Table IV.</p><p><tables id=\"TABLE-US-00009\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"217pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE IV</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>External Commands to Data Cache</entry></row><row><entry>(EXODCmd[3:0].)</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"147pt\"></colspec><tbody valign=\"top\"><row><entry>Code</entry><entry>Mnemonic</entry><entry>Description</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"char\" char=\".\" colname=\"1\" colwidth=\"21pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"147pt\"></colspec><tbody valign=\"top\"><row><entry>0</entry><entry>Idle</entry><entry>Idle. No operation begun during this cycle.</entry></row><row><entry>1</entry><entry>Uncached Load</entry><entry>Data response from an uncached load instruction.</entry></row><row><entry>2</entry><entry>Read Tag</entry><entry>Write tag array for CACHE operation. (All fields:</entry></row><row><entry></entry><entry></entry><entry>State, W-bit, LRU, Tag address). Contents of Tag</entry></row><row><entry></entry><entry></entry><entry>are loaded into the TagHi and TagLo registers.</entry></row><row><entry>3</entry><entry>Write Tag</entry><entry>Write tag array for CACHE operation. (All fields:</entry></row><row><entry></entry><entry></entry><entry>State, W-bit, LRU, Tag address). Tag is written</entry></row><row><entry></entry><entry></entry><entry>from contents of the TagHi and TagLo registers.</entry></row><row><entry>4</entry><entry>Refill</entry><entry>Refill data for first quadword of a block into</entry></row><row><entry></entry><entry></entry><entry>the Data Cache.</entry></row><row><entry>5</entry><entry>Refill Done</entry><entry>Refill data for second quadword into the</entry></row><row><entry></entry><entry></entry><entry>Data Cache. Change the cache line state from</entry></row><row><entry></entry><entry></entry><entry>\u201crefilling\u201d to equal the secondary cache state,</entry></row><row><entry></entry><entry></entry><entry>and \u201cconsistent\u201d for load instructions or</entry></row><row><entry></entry><entry></entry><entry>\u201cinconsistent\u201d for store instructions.</entry></row><row><entry></entry><entry></entry><entry>This command is also used as the \u201csuccessful\u201d</entry></row><row><entry></entry><entry></entry><entry>response to an invalidate request.</entry></row><row><entry>6</entry><entry>Data Read</entry><entry>Read data from the Data Cache.</entry></row><row><entry></entry><entry></entry><entry>(128-bit quadword.)</entry></row><row><entry>7</entry><entry>Write Tag State</entry><entry>First, read state to determine if write-back</entry></row><row><entry></entry><entry></entry><entry>is required. The write \u201c state\u201d and</entry></row><row><entry></entry><entry></entry><entry>\u201cmodifier\u201d bits of tag array (to \u201cinvalid\u201d),</entry></row><row><entry></entry><entry></entry><entry>regardless of cache \u201chit\u201d.</entry></row><row><entry>8</entry><entry>Mark Invalid</entry><entry>Interrogate the Data Cache tags. If the specified</entry></row><row><entry></entry><entry></entry><entry>block is present, change its tag to \u201cInvalid\u201d</entry></row><row><entry></entry><entry></entry><entry>during the next cycle. If it was inconsistent,</entry></row><row><entry></entry><entry></entry><entry>initiate a write-back operation.</entry></row><row><entry></entry><entry></entry><entry>(The external interface's write buffer must</entry></row><row><entry></entry><entry></entry><entry>not be busy during this cycle.)</entry></row><row><entry>9</entry><entry>Mark Shared</entry><entry>Interrogate the Data Cache tags. If the specified</entry></row><row><entry></entry><entry></entry><entry>block is present, change its tag to \u201cShared\u201d</entry></row><row><entry></entry><entry></entry><entry>during the next cycle.</entry></row><row><entry>10</entry><entry>(unused)</entry></row><row><entry>11</entry><entry>Mark Dirty</entry><entry>Interrogate the Data Cache tags. If the specified</entry></row><row><entry></entry><entry></entry><entry>block is present, change its tag to \u201cDirty</entry></row><row><entry></entry><entry></entry><entry>Exclusive\u201d and \u201cinconsistent\u201d during</entry></row><row><entry></entry><entry></entry><entry>the next cycle.</entry></row><row><entry>12</entry><entry>Nack on</entry><entry>The system interface detected a \u201ccancel\u201d</entry></row><row><entry></entry><entry>Uncached Load</entry><entry>acknowledge on a cache refill operation.</entry></row><row><entry></entry><entry></entry><entry>The processor will retry this operation</entry></row><row><entry></entry><entry></entry><entry>(except for prefetch).</entry></row><row><entry>13</entry><entry>Nack on</entry><entry>The system interface detected an error on an</entry></row><row><entry></entry><entry>Cached Access</entry><entry>uncached load operation. This operation was</entry></row><row><entry></entry><entry></entry><entry>aborted. The processor will take an exception</entry></row><row><entry></entry><entry></entry><entry>on this operation.</entry></row><row><entry>14</entry><entry>Bus Error on</entry><entry>The system interface detected an error on an</entry></row><row><entry></entry><entry>Uncached Load</entry><entry>uncached load operation. This operation was</entry></row><row><entry></entry><entry></entry><entry>aborted. The processor will take an exception</entry></row><row><entry></entry><entry></entry><entry>on this operation.</entry></row><row><entry>15</entry><entry>Bus Error on</entry><entry>The system interface detected an error on</entry></row><row><entry></entry><entry>Cached Access</entry><entry>a cache refill. This operation was aborted.</entry></row><row><entry></entry><entry></entry><entry>The processor will take an exception on this</entry></row><row><entry></entry><entry></entry><entry>operation (except for prefetch).</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>The External Interface sends this command, a new state code, state modifier, an index address, a tag address, two cycles before the actual cache operation. The cache and the address queue each pipeline these fields for use during the next two cycle.</p><p>For each external command, Table X lists the operations performed in the Data Cache's data array, tag array, and in the address queue. The address queue decodes this code to determine which sections of the cache are needed by the External Interface.</p><p><tables id=\"TABLE-US-00010\"><table colsep=\"0\" frame=\"none\" pgwide=\"1\" rowsep=\"0\"><tgroup align=\"left\" cols=\"1\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"294pt\"></colspec><thead><row><entry nameend=\"1\" namest=\"1\" rowsep=\"1\">TABLE X</entry></row></thead><tbody valign=\"top\"><row><entry align=\"center\" nameend=\"1\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>External Commands to Data Cache, cont.</entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"5\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"offset\" colwidth=\"14pt\"></colspec><colspec align=\"left\" colname=\"1\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"91pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"91pt\"></colspec><tbody valign=\"top\"><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>Address Queue (if block</entry></row><row><entry></entry><entry>ExtCmd[3:0]</entry><entry>Data Array</entry><entry>Tag Array</entry><entry>1 match)</entry></row><row><entry></entry><entry align=\"center\" nameend=\"4\" namest=\"offset\" rowsep=\"1\"></entry></row></tbody></tgroup><tgroup align=\"left\" cols=\"5\" colsep=\"0\" rowsep=\"0\"><colspec align=\"char\" char=\".\" colname=\"1\" colwidth=\"14pt\"></colspec><colspec align=\"left\" colname=\"2\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"49pt\"></colspec><colspec align=\"left\" colname=\"4\" colwidth=\"91pt\"></colspec><colspec align=\"left\" colname=\"5\" colwidth=\"91pt\"></colspec><tbody valign=\"top\"><row><entry>0</entry><entry>Idle</entry><entry></entry><entry></entry><entry></entry></row><row><entry>1</entry><entry>Uncached Load</entry><entry></entry><entry></entry><entry>Graduate load (no match</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>required.)</entry></row><row><entry>2</entry><entry>Read Tag</entry><entry></entry><entry>Read/State/W/LRU/Tag</entry></row><row><entry>3</entry><entry>Write Tag</entry><entry></entry><entry>Write State/W/LRU/Tag</entry></row><row><entry>4</entry><entry>Refill</entry><entry>Write 128 bits</entry><entry></entry><entry>Reset refill and enable</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>freeload if quadwordword</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>match.</entry></row><row><entry>5</entry><entry>Refill Done</entry><entry>Write 128 bits</entry><entry>Write W, state = (N,S,C,D).</entry><entry>Reset refill and enable</entry></row><row><entry></entry><entry></entry><entry></entry><entry>(\u201cN\u201d indicates ECC error.)</entry><entry>freeload if quadword match.</entry></row><row><entry>6</entry><entry>Data Read</entry><entry>Read 128 bits</entry></row><row><entry>7</entry><entry>Write Tag State</entry><entry></entry><entry>1: Read state.</entry></row><row><entry></entry><entry></entry><entry></entry><entry>2: Write state&amp;modifier field.</entry></row><row><entry>8</entry><entry>Mark Invalid</entry><entry></entry><entry>Read and check tag. If hit,</entry><entry>Reset \u201chit\u201d status if cache hit.</entry></row><row><entry></entry><entry></entry><entry></entry><entry>write state &amp; modifier fields.</entry><entry>Set soft exception if load is</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>\u201cdone\u201d but not graduated.</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>Way selected by hit.</entry></row><row><entry>9</entry><entry>Mark Shared</entry><entry></entry><entry>Read and check tag. If hit,</entry><entry>Reset \u201chit\u201d status if entry</entry></row><row><entry></entry><entry></entry><entry></entry><entry>set state to \u201cshared\u201d next</entry><entry>contains a store instruction if</entry></row><row><entry></entry><entry></entry><entry></entry><entry>cycle.</entry><entry>cache hit. Way selected by</entry></row><row><entry></entry><entry></entry><entry></entry><entry></entry><entry>hit.</entry></row><row><entry>10</entry><entry>unused</entry></row><row><entry>11</entry><entry>Mark Dirty</entry><entry></entry><entry>Read and check tag. If hit,</entry><entry>Reset \u201cupgrade\u201d status bit if</entry></row><row><entry></entry><entry></entry><entry></entry><entry>write state and modifier bits</entry><entry>cache hit. Way selected by</entry></row><row><entry></entry><entry></entry><entry></entry><entry>to \u201cdirty inconsistent\u201d on next</entry><entry>hit.</entry></row><row><entry></entry><entry></entry><entry></entry><entry>cycle.</entry></row><row><entry>12</entry><entry>Nack on</entry><entry></entry><entry></entry><entry>Abort, then retry operation.</entry></row><row><entry></entry><entry>Uncached Load</entry></row><row><entry>13</entry><entry>Nack on</entry><entry></entry><entry>Write state = \u201cN\u201d</entry><entry>Abort, then retry operation</entry></row><row><entry></entry><entry>Cached</entry><entry></entry><entry>(Refill was not completed)</entry><entry>(except prefetch). Use way</entry></row><row><entry></entry><entry>Address</entry><entry></entry><entry></entry><entry>from ExtInt.</entry></row><row><entry>14</entry><entry>Bus Error on</entry><entry></entry><entry></entry><entry>Set exception code = \u201cbus</entry></row><row><entry></entry><entry>Uncached Load</entry><entry></entry><entry></entry><entry>error\u201d</entry></row><row><entry>15</entry><entry>Bus Error on</entry><entry></entry><entry>Write state = \u201cN\u201d</entry><entry>Set exception code = \u201cbus</entry></row><row><entry></entry><entry>Cached</entry><entry></entry><entry>(Refill was not completed)</entry><entry>error\u201d</entry></row><row><entry></entry><entry>Address</entry><entry></entry><entry></entry><entry>Use way from ExtInt.</entry></row><row><entry align=\"center\" nameend=\"5\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>If the External Interface sends a \u201cMarklnvalid\u201d or \u201cMarkShared\u201d command, it does not send commands to the same bank's tag array on the following cycle. These operations perform read/modify/write operations.</p><p>The external interface sends the processor a \u201cbusy\u201d signal which indicates when it can accept new operations. Bits 1 indicates if the Miss Handling Table is busy. If it is set the External Interface cannot accept any new command. Bits 0 indicates if the Write-Back Buffer is busy. If it is set, the External Interface cannot accept any refill request for an \u201cinconsistent\u201d block and data is written back to secondary cache.</p><p>During cycle \u201cCO\u201d, the External Interface sends the address queue a 10-bit \u201cindex\u201d address (EXOIndex[<b>13</b>:<b>4</b>] and EXOWay), identifying the Data Cache block it will access two cycles later (cycle \u201cC2\u201d). The queue uses an associative compare port to identify any active instruction which is affected by this block.</p><p>The Data Cache registers this address for decoding during the next cycle (cycle \u201cC1\u201d).</p><p>The Data Cache provides address and hit signals to the external interface during tag check cycles.</p><p>For Processor Tag Checks: from the tar section of the selected Data Cache bank.)</p><p>DC2CpuVAdr[<b>13</b>:<b>0</b>]: The Data Cache multiplexes the \u201cindex\u201d bits of the virtual address from the ACU or the address stack during the previous cycle (\u201cC1\u201d). This address is delayed in a register until \u201cC2\u201d.</p><p>DC2CpuPAdr[<b>39</b>:<b>12</b>]: The Data Cache multiplexes the translated physical addresses from the TLB or the address stack during the tag check cycle.</p><p>Five \u201cWrite-Back\u201d fields provide address and status for writing a cache block back to secondary cache. If the cache hits, these fields select the \u201chit\u201d way. Otherwise, if a refill is initiated, they select the way being refilled.</p><p>DC2WBTag[<b>22</b>:<b>12</b>]: The tag helps determine where to write the data in the secondary cache, because it uses more index bits than primary cache.</p><p>DC2WBState[<b>1</b>:<b>0</b>]:</p><p>DC2WBSCWay: Way in the secondary cache.</p><p>DC2WBIndex:</p><p>For External Interface Tar Checks: (from the tag section of the selected Data Cache bank.)</p><p>MDOTag[<b>39</b>:<b>121</b>: This bus is bidirectional.</p><p>DC2RdState[<b>1</b>:<b>0</b>]:</p><p>DC2RdMod[<b>2</b>:<b>0</b>]:</p><p>DC2RdSCWay:</p><p>While the above is a complete description of the preferred embodiment of the invention, various modifications, alternatives and equivalents may be used. For example, the cache may be implemented as a n-way set-associative cache. Other variations may include different block sizes and different size address lines. Therefore, the above description should not be taken as limiting the scope of the invention which is defined by the appended claims.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Kenneth C.", "last_name": "Yeager", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "MIPS TECHNOLOGIES, INC."}, {"first_name": "", "last_name": "MIPS TECHNOLOGIES, INC.", "name": ""}, {"first_name": "", "last_name": "JEFFERIES FINANCE LLC, AS COLLATERAL AGENT", "name": ""}, {"first_name": "", "last_name": "MIPS TECHNOLOGIES, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/08"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMJP"}], "national_classes": [{"primary": true, "label": "711127"}, {"primary": false, "label": "711128"}, {"primary": false, "label": "711E12047"}, {"primary": false, "label": "711120"}], "ecla_classes": [{"label": "S06F12:08B22D"}, {"label": "G06F  12/08B6M4"}, {"label": "S06F12:08B8"}, {"label": "S06F12:08B10"}], "cpc_classes": [{"label": "G06F  12/0895"}, {"label": "G06F  12/0864"}, {"label": "G06F   9/30043"}, {"label": "G06F   9/3857"}, {"label": "G06F   9/3824"}, {"label": "G06F   9/3857"}, {"label": "G06F  12/0864"}, {"label": "G06F  12/1063"}, {"label": "G06F  12/0895"}, {"label": "G06F  12/0862"}, {"label": "G06F  12/0851"}, {"label": "G06F   9/3824"}, {"label": "G06F   9/30043"}, {"label": "G06F  12/0862"}, {"label": "G06F  12/0851"}], "f_term_classes": [], "legal_status": "Expired - Fee Related", "priority_date": "1994-10-14", "application_date": "1997-03-07", "family_members": [{"ucid": "US-5978887-A", "titles": []}, {"ucid": "JP-H10509819-A", "titles": [{"lang": "EN", "text": "Indecking and multiplexing of interleaved cache memory arrays"}, {"lang": "JA", "text": "\u30a4\u30f3\u30bf\u30fc\u30ea\u30fc\u30d6\u3055\u308c\u308b\u30ad\u30e3\u30c3\u30b7\u30e5\u30e1\u30e2\u30ea\u30a2\u30ec\u30a4\u306e\u30a4\u30f3\u30c7\u30c3\u30ad\u30b7\u30f3\u30b0\u3068\u30de\u30eb\u30c1\u30d7\u30ec\u30ad\u30b7\u30f3\u30b0"}]}, {"ucid": "US-6594728-B1", "titles": [{"lang": "EN", "text": "Cache memory with dual-way arrays and multiplexed parallel output"}]}, {"ucid": "EP-1278125-A2", "titles": [{"lang": "FR", "text": "Indexation et multiplexage de r\u00e9seaux entrelac\u00e9s de m\u00e9moires d'attente"}, {"lang": "EN", "text": "Indexing and multiplexing of interleaved cache memory arrays"}, {"lang": "DE", "text": "Indexierung und Multiplexierung von verschachtelten Cache-Speichermatrixen"}]}, {"ucid": "EP-0803095-A4", "titles": []}, {"ucid": "EP-0803095-A1", "titles": [{"lang": "FR", "text": "INDEXATION ET MULTIPLEXAGE DE MATRICES ENTRELACEES DE MEMOIRES D'ATTENTE"}, {"lang": "EN", "text": "INDEXING AND MULTIPLEXING OF INTERLEAVED CACHE MEMORY ARRAYS"}, {"lang": "DE", "text": "INDEXIERUNG UND MULITPLIZIERUNG VON VERSCHACHTELTEN CACHE-SPEICHERMATRIXEN"}]}, {"ucid": "WO-1996012229-A1", "titles": [{"lang": "EN", "text": "INDEXING AND MULTIPLEXING OF INTERLEAVED CACHE MEMORY ARRAYS"}, {"lang": "FR", "text": "INDEXATION ET MULTIPLEXAGE DE MATRICES ENTRELACEES DE MEMOIRES D'ATTENTE"}]}]}