{"patent_number": "US-6295600-B1", "publication_id": 72791968, "family_id": 24711320, "publication_date": "2001-09-25", "titles": [{"lang": "EN", "text": "Thread switch on blocked load or store using instruction thread field"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72618354\"><p>A method and apparatus for switching between threads of a program in response to a long-latency event. In one embodiment, the long-latency events are load or store operations which trigger a thread switch if there is a miss in the level <b>2 </b>cache. In addition to providing separate groups of registers for multiple threads, a group of program address registers pointing to different threads are provided. A switching mechanism switches between the program address registers in response to the long-latency events.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00001\" num=\"1\"><claim-text>1. A microprocessor for executing a plurality of reads, the microprocessor comprising:</claim-text><claim-text>an instruction cache for storing instructions for the plurality of threads; </claim-text><claim-text>an instruction decode unit coupled to the instruction cache and configured to decode said instructions for the plurality of threads; </claim-text><claim-text>a plurality of instruction buffers coupled to the instruction decode unit, wherein each of the plurality of instruction buffers is configured to receive decoded instructions corresponding to one of the plurality of threads from the instruction decode unit, and to store said decoded instructions; </claim-text><claim-text>a plurality of execution units configured to receive and execute said decoded instructions from a first selected one of the plurality of instruction buffers and corresponding to a first thread, wherein one of the plurality of execution units is configured to execute a first instruction which invokes a memory access, wherein the first instruction includes a thread indictor stored in a thread indicator field of the first instruction; </claim-text><claim-text>a plurality of program address registers, wherein each of the program address registers is associated with a corresponding thread of the plurality of threads, wherein each of the program address registers is configured to store an address for the corresponding thread; </claim-text><claim-text>thread switching logic configured to receive a cache-miss indication signal indicating a level-two cache miss associated with the memory access of the first instruction, and in response to the cache-miss indication signal, (a) to receive the thread indicator of the first instruction from said one of the plurality of execution units, (b) to select a first program address register of the plurality of program address registers which corresponds to the thread, indicator, (c) to invoke the fetching of a new thread based on the address stored in the first program address register, (d) to disable dispatch of decoded instructions from the first selected instruction buffer to the execution units, and (e) to enable dispatch of decoded instructions from a second selected instruction buffer to the execution units, wherein the second selected instruction buffer is determined by the thread indicator. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00002\" num=\"2\"><claim-text>2. The microprocessor of claim <b>1</b>, wherein the first instruction is a load instruction.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00003\" num=\"3\"><claim-text>3. The microprocessor of claim <b>1</b>, wherein the first instruction is a branch instruction.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00004\" num=\"4\"><claim-text>4. The microprocessor of claim <b>1</b>, wherein an operating system determines the thread indicator of the first instruction at compile time.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00005\" num=\"5\"><claim-text>5. The microprocessor of claim <b>1</b>, wherein the thread switching logic is additionally configured to switch among said plurality of program address registers in a round-robin fashion in response to assertions of the cache-miss indication signal.</claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00006\" num=\"6\"><claim-text>6. The microprocessor of claim <b>1</b> further comprising a plurality of register files, wherein each of the plurality of register files stores data values for an associated thread of the plurality of threads.</claim-text></claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00007\" num=\"7\"><claim-text>7. The microprocessor of claim <b>1</b> further comprising a main register file and a plurality of shadow register files, wherein each of the shadow register files stores data values for an associated thread of the plurality of threads.</claim-text></claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00008\" num=\"8\"><claim-text>8. The microprocessor of claim <b>1</b> further comprising a plurality of load buffers, wherein each load buffer is assigned to a unique thread among the plurality of threads.</claim-text></claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00009\" num=\"9\"><claim-text>9. The microprocessor of claim <b>1</b>, wherein the first instruction belongs to the first thread.</claim-text></claim>"}, {"num": 10, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00010\" num=\"10\"><claim-text>10. A microprocessor for executing a plurality of threads, the microprocessor comprising:</claim-text><claim-text>an instruction cache for storing instructions for the plurality of threads; </claim-text><claim-text>an instruction decode unit coupled to the instruction cache and configured to decode said instructions for the plurality of threads; </claim-text><claim-text>a plurality of execution units configured to receive and execute said decoded instructions for the plurality of threads; </claim-text><claim-text>a plurality of program address registers, wherein each of the program address registers is associated with a corresponding thread of the plurality of threads, wherein each of the program address registers is configured to store an address for the corresponding thread; </claim-text><claim-text>thread switching logic configured to receive a cache-miss indication signal indicating a level-two cache miss, and in response to an assertion of the cache-miss indication signal, to access a thread indicator stored in a thread indicator field of a first instruction which invoked the level-two cache miss, to disable fetching of a first thread, to enable fetching and execution of a second thread based on one of the program address registers determined by the thread indicator. </claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00011\" num=\"11\"><claim-text>11. The microprocessor of claim <b>10</b>, wherein the first instruction is a load instruction.</claim-text></claim>"}, {"num": 12, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00012\" num=\"12\"><claim-text>12. The microprocessor of claim <b>10</b>, wherein the first instruction is a branch instruction.</claim-text></claim>"}, {"num": 13, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00013\" num=\"13\"><claim-text>13. The microprocessor of claim <b>10</b>, wherein the thread indicator is stored in the thread indicator field of the first instruction at a compile time prior to execution of the first instruction in said microprocessor.</claim-text></claim>"}, {"num": 14, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00014\" num=\"14\"><claim-text>14. The microprocessor of claim <b>10</b>, wherein the thread switching logic is additionally configured to switch among said plurality of program address registers in a round-robin fashion in response to the assertion of the cache-miss indication signal.</claim-text></claim>"}, {"num": 15, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00015\" num=\"15\"><claim-text>15. The microprocessor of claim <b>10</b> further comprising a plurality of register files, wherein each of the plurality of register files stores data values for an associated thread of the plurality of threads.</claim-text></claim>"}, {"num": 16, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00016\" num=\"16\"><claim-text>16. The microprocessor of claim <b>10</b>, wherein, in response to execution of ajump thread instruction in one of the execution units, the thread switching logic is configured (a) to disable fetching of the first thread, and (b) to enable fetching and execution of a third thread based on a third program address register of the program address registers, wherein the third program address register is determined by a thread indicator field of the jump thread instruction.</claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00017\" num=\"17\"><claim-text>17. The microprocessor of claim <b>16</b>, wherein the jump thread instruction includes a logical condition, wherein the thread switching logic is configured to perform said disabling (a) and said enabling (b) only if the logical condition is satisfied.</claim-text></claim>"}, {"num": 18, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00018\" num=\"18\"><claim-text>18. The microprocessor of claim <b>10</b> further comprising a plurality of load buffers, wherein each load buffer is assigned to a unique thread among the plurality of threads.</claim-text></claim>"}, {"num": 19, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00019\" num=\"19\"><claim-text>19. The microprocessor of claim <b>10</b>, wherein the first instruction belongs to the first thread.</claim-text></claim>"}, {"num": 20, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6295600-B1-CLM-00020\" num=\"20\"><claim-text>20. A computer system comprising:</claim-text><claim-text>a memory; </claim-text><claim-text>a bus coupled to said memory; </claim-text><claim-text>a microprocessor coupled to said bus, wherein the microprocessor comprises: </claim-text><claim-text>an instruction cache for storing instructions for the plurality of threads; </claim-text><claim-text>an instruction decode unit coupled to the instruction cache and configured to decode said instructions for the plurality of threads; </claim-text><claim-text>a plurality of instruction buffers coupled to the instruction decode unit, wherein each of the plurality of instruction buffers is configured to receive decoded instructions corresponding to one of the plurality of threads from the instruction decode unit, and to store said decoded instructions; </claim-text><claim-text>a plurality of execution units configured to receive and execute said decoded instructions from a first selected one of the plurality of instruction buffers and corresponding to a first thread, wherein one of the plurality of execution units is configured to execute a firrt instruction which invokes a memory access, wherein the first instruction includes a thread indictor stored in a thread indicator field of the first instruction; </claim-text><claim-text>a plurality of program address registers, wherein each of the program address registers is associated with a corresponding thread of the plurality of threads, wherein each of the program address registers is configured to store an address for the corresponding thread; </claim-text><claim-text>thread switching logic configured to receive a cache-miss indication signal indicating a level-two cache miss associated with the memory access of the first instruction, and in response to the cache-miss indication signal, (a) to receive the thread indicator of the first instruction from said one of the plurality of execution units, (b) to select a first program address register of the plurality of program address registers which corresponds to the thread indicator, (c) to invoke the fetching of a new thread based on the address stored in the first program address register, (d) to disable dispatch of decoded instructions from the first selected instruction buffer to the execution units, and (e) to enable dispatch of decoded instructions from a second selected instruction buffer to the execution units, wherein the second selected instruction buffer is determined by the thread indicator.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54730413\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><p>This application is a continuation of U.S. patent application Ser. No. 08/675,627, filed Jul. 1, 1996 now U.S. Pat. No. 5,933,627 entitled \u201cThread Switch on Blocked Load or Store Using Instruction Thread Field.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>The present invention relates to microprocessors which execute multi-threaded programs, and in particular to the handling of blocked (waiting required) memory accesses in such programs.</p><p>Many modern computers support \u201cmulti-tasking\u201d in which two or more programs are run at the same time. An operating system controls the alternating between the programs, and a switch between the programs or between the operating system and one of the programs is called a \u201ccontext switch.\u201d</p><p>Additionally, multi-tasking can be performed in a single program, and is typically referred to as \u201cmulti-threading.\u201d Multiple actions can be processed concurrently using multi-threading.</p><p>Most modern computers include at least a first level and typically a second level cache memory system for storing frequently accessed data and instructions. With the use of multi-threading, multiple programs are sharing the cache memory, and thus the data or instructions for one thread may overwrite those for another, increasing the probability of cache misses.</p><p>The cost of a cache miss in the number of wasted processor cycles is increasing. This is due to the processor speed increasing at a higher rate than the memory access speeds over the last several years and into the foreseeable future. Thus, more processors cycles are required for memory accesses, rather than less, as speeds increase. Accordingly, memory accesses are becoming a limited factor on processor execution speed.</p><p>In addition to multi-threading or multi-tasking, another factor which increases the frequency of cache misses is the use of object oriented programming languages. These languages allow the programmer to put together a program at a level of abstraction away from the steps of moving data around and performing arithmetic operations, thus limiting the programmer control of maintaining a sequence of instructions or data at the execution level to be in a contiguous area of memory.</p><p>One technique for limiting the effect of slow memory accesses is a \u201cnon-blocking\u201d load or store (read or write) operation. \u201cNon-blocking\u201d means that other operations can continue in the processor while the memory access is being done. Other load or store operations are \u201cblocking\u201d loads or stores, meaning that processing of other operations is held up while waiting for the results of the memory access (typically a load will block, while a store won't). Even a non-blocking load will typically become blocking at some later point, since there is a limit on how many instructions can be processed without the needed data from the memory access.</p><p>Another technique for limiting the effect of slow memory accesses is a thread switch. A discussion of the effect of multi-threading on cache memory systems is set forth in the article \u201cEvaluation of Multi-Threaded Uniprocessors for Commercial Application Environments\u201d by R. Eickemeyer et al. of IBM, May 22-24, 1996, 23rd Annual International Symposium on Computer Architecture. The IBM article shows the beneficial effect of a thread switch in a multi-threaded processor upon a level <b>2</b> cache miss. The article points out that the use of separate registers for each thread and instruction dispatch buffers for each thread will affect the efficiency. The article assumes a non-blocking level <b>2</b> cache, meaning that the level <b>2</b> cache can continue to access for a first thread and it can also process a cache request for a second thread at the same time, if necessary.</p><p>The IBM article points out that there exist fine-grain multi-threading processors which interleave different threads on a cycle-by-cycle basis. Coarse-grain multi-threading interleaves the instructions of different threads on some long-latency event(s).</p><p>As pointed out in the IBM article, switching in the Tera supercomputer, which switches every cycle, is done in round-robin fashion. The Alewife project is cited as handling thread switching in software using a fast trap.</p><p>It would be desirable to have an efficient mechanism for switching between threads upon long-latency events.</p><h4>SUMMARY OF THE INVENTION</h4><p>The present invention provides a method and apparatus for switching between threads of a program in response to a long-latency event. In one embodiment, the long-latency events are load or store operations which trigger a thread switch if there is a miss in the level <b>2</b> cache. A miss in a level <b>1</b> cache, or a hit in a level <b>2</b> cache will not trigger a thread switch.</p><p>In addition to providing separate groups of registers for multiple threads, a group of program address registers pointing to different threads are provided. A switching mechanism switches between the program address registers in response to the long-latency events.</p><p>In one embodiment, the next program address register to be switched to is indicated in a thread field within the long-latency instruction itself. In an alternate embodiment, the program address registers are switched in a round-robin fashion.</p><p>Preferably, in addition to the program address registers for each thread and the register files for each thread, instruction buffers are provided for each thread. In a preferred embodiment, there are up to four sets of registers to support four threads.</p><p>For a further understanding of the nature and advantages of the invention, reference should be made to the following description taken in conjunction with the accompanying drawings.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1 is a block diagram of a Ultrasparc\u2122 microprocessor which can be modified to incorporate the present invention.</p><p>FIG. 2 is a block diagram of a computer system including the processor of FIG. <b>1</b>.</p><p>FIG. 3 is a diagram of a portion of the processor of FIG. 1 modified to include a multi-threading capability of the present invention.</p><p>FIG. 4 is a diagram of an instruction including the thread field of the present invention.</p><p>FIG. 5 is a block diagram of a microprocessor incorporating one embodiment of the present invention using multiple register files.</p><p>FIG. 6 is a block diagram of an alternate embodiment of a microprocessor using shadow register files.</p><p>FIG. 7 is a diagram of the register files of the embodiment of FIG. <b>6</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DESCRIPTION OF THE PREFERRED EMBODIMENT</h4><p>FIG. 1 is a block diagram of an UltraSparc\u2122 microprocessor <b>10</b>, modified to incorporate the present invention. An instruction cache <b>12</b> provides instructions to a decode unit <b>14</b>. The instruction cache can receive its instructions from a prefetch unit <b>16</b>, which either receives instructions from branch unit <b>18</b> or provides a virtual address to an instruction TLB (translation look-aside buffer) <b>20</b>, which then causes the instructions to be fetched from an off-chip cache through a cache control/system interface <b>22</b>. The instructions from the off-chip cache are provided to a pre-decode unit <b>24</b> to provide certain information, such as whether it is a branch instruction, to instruction cache <b>12</b>.</p><p>Instructions from decode unit <b>14</b> are provided to an instruction buffer <b>26</b>, where they are accessed by dispatch unit <b>28</b>. Dispatch unit <b>28</b> will provide four decoded instructions at a time along a bus <b>30</b>, each instruction being provided to one of eight functional units <b>32</b>-<b>46</b>. The dispatch unit will dispatch four such instructions each cycle, subject to checking for data dependencies and availability of the proper functional unit.</p><p>The first three functional units, the load/store unit <b>32</b> and the two integer ALU units <b>34</b> and <b>36</b>, share a set of integer registers <b>48</b>. Floating-point registers <b>50</b> are shared by floating point units <b>38</b>, <b>40</b> and <b>42</b> and graphical units <b>44</b> and <b>46</b>. Each of the integer and floating point functional unit groups have a corresponding completion unit, <b>52</b> and <b>54</b>, respectively. The microprocessor also includes an on-chip data cache <b>56</b> and a data TLB <b>58</b>.</p><p>FIG. 2 is a block diagram of a chipset including processor <b>10</b> of FIG. <b>1</b>. Also shown are L<b>2</b> cache tags memory <b>80</b>, and L<b>2</b> cache data memory <b>82</b>. In addition, a data buffer <b>84</b> for connecting to the system data bus <b>86</b> is shown. In the example shown, a 16-bit address bus <b>88</b> connects between processor <b>10</b> and tag memory <b>80</b>, with the tag data being provided on a 28-bit tag data bus <b>89</b>. An 18-bit address bus <b>90</b> connects to the data cache <b>82</b>, with a 144 bit data bus <b>92</b> to read or write cache data.</p><p>FIG. 3 illustrates portions of the processor of FIG. 1 modified to support the present invention. As shown, a decode unit <b>14</b> is the same as in FIG. <b>1</b>. However, four separate instruction buffers <b>102</b>, <b>104</b>, <b>106</b> and <b>108</b> are provided to support four different threads, threads <b>0</b>-<b>3</b>. The instructions from a particular thread are provided to dispatch unit <b>28</b>, which then provides them to instruction units <b>41</b>, which include the multiple pipelines <b>32</b>-<b>46</b> shown in FIG. <b>1</b>.</p><p>Integer register file <b>48</b> is divided up into four register files to support threads <b>0</b>-<b>3</b>. Similarly, floating point register file <b>50</b> is broken into four register files to support threads <b>0</b>-<b>3</b>. This can be accomplished either by providing physically separate groups of registers for each thread, or alternately by providing separate register windows for each thread.</p><p>The present invention adds four program address registers <b>110</b> for threads <b>0</b>-<b>3</b>. The particular thread address pointed to will provide the starting address for the fetching of instructions to the appropriate one of instruction buffers <b>102</b>-<b>108</b>. Upon a thread switch, the stream of instructions in one of instruction buffers <b>102</b>-<b>108</b> will simply pick up where it left off.</p><p>Thread switching logic <b>112</b> is provided to give a hardware thread-switching capability. The indication that a thread switch is required is provided on a line <b>114</b> providing an L2-miss indication from cache control/system interface <b>22</b> of FIG. <b>1</b>. Upon such an indication, a switch to the next thread will be performed, using, in one embodiment, the next thread pointer on line <b>116</b>. The next thread pointer is 2 bits indicating the next thread from an instruction which caused the cache miss.</p><p>Referring to FIG. 4, these two bits of the next thread pointer come from a thread field <b>118</b> in an instruction <b>120</b>. Instruction <b>120</b> also includes an OP code field <b>122</b> and source and destination register fields <b>124</b> and <b>126</b>, respectively. By adding the 2 bit thread field <b>118</b> to appropriate instructions, control can be maintained over thread-switching operations. In one embodiment, the thread field is added to all load and store operations. Alternately, it could be added to other potentially long-latency operations, such as jump instructions.</p><p>Referring back to FIG. 3, in an alternate embodiment, the thread switching can be done by simply using a round-robin counter <b>128</b> which alternately points to two different ones of PA registers <b>110</b>.</p><p>In alternate embodiments, other numbers of threads could be used, but it has been determined that in most applications, more than four threads do not provide an increase in performance sufficient to justify the additional hardware. In particular, the more threads that are added the greater the chance of a cache miss.</p><p>The programmable 2 bits for thread field <b>118</b> of FIG. 4 can be used to inter-relate two threads which need to be coordinated. Accordingly, the process could jump back and forth between two threads even though a third thread is available. Alternately, a priority thread could be provided with transitions from other threads always going back to the priority thread. The bits in field <b>118</b> would be inserted in an instruction at the time it is compiled in one embodiment. The operating system could control the number of threads that are allowed to be created and exist at one time. In a preferred embodiment, the operating system would limit the number to four threads.</p><p>In a preferred embodiment, multi-threading is used only for user programs. Since operating system threads will have a higher proportion of memory access, a lot of load store operations will be required. This, in addition to the fact that there is often a long-latency between operating system functions, increasing the likelihood that operating system data in the caches will have been overwritten, limits the benefits of such multi-threading switches on a blocked memory access in an operating system environment. However, the present invention could be applied to operating system multi-threading as well.</p><p>In a preferred embodiment, upon a completion of the memory access which caused the thread switch, the thread with the memory access must wait until it is pointed to again by the round robin or thread pointer bits to continue with its operation. Alternately, a particular thread could be identified as a critical thread, and generate an interrupt as soon as the memory access is completed. The returned data from the load must be provided to the appropriate register for the thread which requested it. This could be done by using separate load buffers for each thread, or by storing a two bit tag in the load buffer indicating the appropriate thread.</p><p>In one embodiment, the present invention also supports non-blocking loads which allow the program to continue in the same program thread while the memory access is being completed. Preferably, such non-blocking loads would be supported in addition to blocking loads, which stall the operation of the program thread while the memory access is being completed. Thus, there would not be a thread switch immediately on a non-blocking load, but would be upon becoming a blocking load waiting for data (or store or other long-latency event).</p><p>In a preferred embodiment, the instruction set includes the following instructions to support the present invention:</p><p>(1) Conditional or unconditional jump to thread (<b>0</b>-<b>3</b>).</p><p>(2) Conditional or unconditional jump to thread starting at program address (begins thread).</p><p>(3) Jump to next thread.</p><p>(4) Stop thread and jump to next thread. Stop if current thread is <b>00</b>.</p><p>(5) Load, go to thread if blocked.</p><p>(6) Branch, go to thread if blocked.</p><p>FIG. 5 illustrates a microprocessor according to one embodiment of the present invention using duplicate register files. A prefetch and dispatch unit <b>150</b> includes an instruction cache <b>152</b> and four instruction buffers <b>154</b>, one for each of threads <b>0</b>-<b>3</b>. Integer execution logic <b>156</b> includes four sets of integer register files <b>158</b>. Load and store unit <b>160</b> includes four sets of load buffers <b>162</b>, but only a single store buffer <b>164</b> is needed. That is because there may potentially be a switch through all four threads before a load returns, and the load needs to be associated with its originating thread. But a save will be dispatched without worrying about what thread it came from. A single data cache <b>166</b> is also provided.</p><p>Floating point unit <b>168</b> and graphics unit <b>170</b> also are connected to four floating point register files <b>172</b>. The system also has a memory management unit <b>174</b>, an external cache unit <b>176</b>, a memory interface unit <b>178</b>, an external cache <b>180</b> and a system bus <b>182</b>.</p><p>FIG. 6 is a block diagram of an alternate embodiment of the present invention. FIG. 6 is similar to FIG. 5, except that a main integer register file <b>184</b> is used, with four shadow register files <b>186</b> for threads <b>0</b>-<b>3</b>. Also, a main floating point register file <b>188</b> is used, along with four shadow floating point register files <b>190</b>.</p><p>Register files often have 5 or more ports, and the ports can take up more silicon than simply duplicating the registers. Thus, it may be more economical to swap the thread data in and out of the four, single or dual-ported shadow register files. This can require two ports to be added to the main register file, if the loading and flushing of register files is not dispatched through existing functional units such as the load/store unit.</p><p>FIG. 7 is a diagram of one embodiment of the connection of main register file <b>184</b> to the shadow register files <b>186</b>. A data switch <b>192</b> can be used to route data to and from the shadow registers. Alternately, a path <b>194</b> could be used for a write from the shadow registers to the main register, with only the appropriate shadow register being enabled.</p><p>As will be understood by those of skill in the art, the present invention may be embodied in other specific forms without departing from the spirit or essential characteristics thereof. Accordingly, the foregoing embodiments are intended to be illustrative, but not limiting, of the scope of the invention which is set forth in the following claims.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Bodo", "last_name": "Parady", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "SUN MICROSYSTEMS, INC."}], "ipc_classes": [{"primary": true, "label": "G06F  15/16"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F   9/318       20060101A I20051008RMEP"}, {"label": "G06F   9/46        20060101A I20051008RMEP"}, {"label": "G06F   9/38        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "712228"}, {"primary": false, "label": "711141"}, {"primary": false, "label": "711122"}, {"primary": false, "label": "712E0906"}, {"primary": false, "label": "712E09053"}, {"primary": false, "label": "711152"}, {"primary": false, "label": "712E09035"}, {"primary": false, "label": "711147"}], "ecla_classes": [{"label": "G06F   9/30X"}, {"label": "G06F   9/46G2"}, {"label": "G06F   9/38H"}, {"label": "G06F   9/38E4"}], "cpc_classes": [{"label": "G06F   9/3861"}, {"label": "G06F   9/3851"}, {"label": "G06F   9/3861"}, {"label": "G06F   9/462"}, {"label": "G06F   9/462"}, {"label": "G06F   9/3851"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1996-07-01", "application_date": "1999-06-28", "family_members": [{"ucid": "US-5933627-A", "titles": [{"lang": "EN", "text": "COMPUTER PROGRAM PRODUCT ON A COMPUTER"}, {"lang": "EN", "text": "Thread switch on blocked load or store using instruction thread field"}]}, {"ucid": "US-6295600-B1", "titles": [{"lang": "EN", "text": "Thread switch on blocked load or store using instruction thread field"}]}, {"ucid": "US-6578137-B2", "titles": [{"lang": "EN", "text": "Branch and return on blocked load or store"}]}, {"ucid": "US-20010047468-A1", "titles": [{"lang": "EN", "text": "Branch and return on blocked load or store"}]}]}