{"patent_number": "US-20010054139-A1", "publication_id": 75708381, "family_id": 23626837, "publication_date": "2001-12-20", "titles": [{"lang": "EN", "text": "MECHANISM FOR POWER EFFICIENT PROCESSING IN A PIPELINE PROCESSOR"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA48274098\"><p id=\"A-0001\">A processor including a plurality of execution pipeline stages where each stage accepts a plurality of operand inputs and generates a result. A pipefile having at least the same number of entries as the number of execution pipeline stages is included in the processor A pointer register is associated with each execution pipeline stage. A value is stored in at least one of the pointer registers, the value indicating a particular one of the entries in the pipefile. </p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00001\" num=\"1\"><claim-text><b>1</b>. A method for forwarding data within a pipeline of a pipelined data processor comprising the steps of: \n<claim-text>providing a plurality of execution pipeline stages where each stage accepts a plurality of operand inputs and generates a result; </claim-text><claim-text>providing a pipefile comprising at least the same number of entries as the number of execution pipeline stages; </claim-text><claim-text>assigning each new instruction to one of the entries in the pipefile before the new instruction is executed, wherein the pipefile entry assignment remains valid while the instruction remains in any of the execution pipeline stages; </claim-text><claim-text>passing the new instruction through the execution pipeline stages to generate a result; </claim-text><claim-text>storing the result in the assigned pipefile entry; and </claim-text><claim-text>upon successful completion of executing the new instruction, writing back the result from the assigned pipefile entry to an architectural register. </claim-text></claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00002\" num=\"2\"><claim-text><b>2</b>. The method of <claim-ref idref=\"US-20010054139-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> further comprising selectively coupling the result generated by each execution pipeline stage to an operand input of one of the execution pipeline stages. </claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00003\" num=\"3\"><claim-text><b>3</b>. The method of <claim-ref idref=\"US-20010054139-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> wherein the step of assigning is performed at a decode stage before the new instruction is passed though any of the execution pipeline stages. </claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00004\" num=\"4\"><claim-text><b>4</b>. The method of <claim-ref idref=\"US-20010054139-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> wherein the assigning is performed so that each instruction in each execution pipeline stage is assigned to a unique one of the pipefile entries. </claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00005\" num=\"5\"><claim-text><b>5</b>. The method of <claim-ref idref=\"US-20010054139-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> wherein the execution pipeline stages comprise a write back pipeline stage, the write back pipeline stage having an instruction therein assigned to one of the pipefile entires, and the assigning further comprises assigning the new instruction to the pipefile entry currently being used by the write back pipeline stage. </claim-text></claim>"}, {"num": 6, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00006\" num=\"6\"><claim-text><b>6</b>. The method of <claim-ref idref=\"US-20010054139-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> further comprising: \n<claim-text>providing a pointer register associated with each execution pipeline stage; and </claim-text>\n<claim-text>storing in each pointer register a value indicating the pipefile entry assigned to the instruction currently in the associated execution pipeline stage. </claim-text>\n</claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00007\" num=\"7\"><claim-text><b>7</b>. The method of <claim-ref idref=\"US-20010054139-A1-CLM-00006\"><claim-text>claim 6</claim-text></claim-ref> further comprising moving the value stored in each pointer register to another pointer register at each cycle of the pipeline so that the value is always stored in a pointer register associated with the instruction to which the pipefile entry identified by the value is assigned. </claim-text></claim>"}, {"num": 8, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00008\" num=\"8\"><claim-text><b>8</b>. A data processor comprising: \n<claim-text>a plurality of execution pipeline stages where each stage accepts a plurality of operand inputs and generates a result; </claim-text><claim-text>a pipefile comprising at least the same number of entries as the number of execution pipeline stages; </claim-text><claim-text>a pointer register associated with each execution pipeline stage; and </claim-text><claim-text>a value stored in at least one of the pointer registers, the value indicating a particular one of the entries in the pipefile. </claim-text></claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00009\" num=\"9\"><claim-text><b>9</b>. The data processor of <claim-ref idref=\"US-20010054139-A1-CLM-00008\"><claim-text>claim 8</claim-text></claim-ref> further comprising: \n<claim-text>a selector coupled to each execution pipeline stage that produces a result, the selector coupled to selectively route the result to one of the pipefile entries identified by the value stored in the pointer register associated with that execution pipeline stage. </claim-text>\n</claim-text></claim>"}, {"num": 10, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00010\" num=\"10\"><claim-text><b>10</b>. The data processor of <claim-ref idref=\"US-20010054139-A1-CLM-00008\"><claim-text>claim 8</claim-text></claim-ref> further comprising: \n<claim-text>a pipefile bus communicating data stored in the pipefile, the pipefile bus comprising a plurality of lines where each line is associated with a particular pipeline execution stage; </claim-text>\n<claim-text>a selector controlled by the values stored in the pointer registers, the selector coupled to each entry of the pipefile and the selector coupled to selectively route the data stored in each entry of the pipefile to a particular line of the pipefile bus. </claim-text>\n</claim-text></claim>"}, {"num": 11, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00011\" num=\"11\"><claim-text><b>11</b>. The data processor of <claim-ref idref=\"US-20010054139-A1-CLM-00008\"><claim-text>claim 8</claim-text></claim-ref> further comprising a decoder pipeline stage operative to receive a new instruction before the new instruction is passed to the execution pipeline stages, the decoder including logic for assigning the value to be stored in the pointer registers. </claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00012\" num=\"12\"><claim-text><b>12</b>. The data processor of <claim-ref idref=\"US-20010054139-A1-CLM-00011\"><claim-text>claim 11</claim-text></claim-ref> wherein the execution pipeline stages include a write back pipeline stage, wherein the logic for assigning operates to assign values in a round-robin fashion such that the new instruction is assigned a value currently in the pointer register associated with the write back stage. </claim-text></claim>"}, {"num": 13, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00013\" num=\"13\"><claim-text><b>13</b>. A method for forwarding data within a pipeline of a pipelined data processor comprising the steps of: \n<claim-text>providing a plurality of execution pipeline stages where each stage includes logic for producing an instruction result; </claim-text><claim-text>providing a pipefile comprising a plurality of entries where each entry is associated with an execution pipeline stage; </claim-text><claim-text>when a result is generated by an execution pipeline stage, capturing the result in the associated entry in the pipefile; and </claim-text><claim-text>forwarding the captured result from the pipefile upon demand from an execution pipeline stage. </claim-text></claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010054139-A1-CLM-00014\" num=\"14\"><claim-text><b>14</b>. The method of <claim-ref idref=\"US-20010054139-A1-CLM-00013\"><claim-text>claim 13</claim-text></claim-ref> further comprising: \n<claim-text>passing the instruction through the execution pipeline stages; </claim-text>\n<claim-text>shifting the captured results in the pipefile so that the captured result remains in a pipefile entry associated with an execution stage in which its producing instruction resides.</claim-text>\n</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54983015\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><summary-of-invention><h4>BACKGROUND OF THE INVENTION </h4><p id=\"P-0001\" num=\"0001\">[0001] 1. Field of the Invention </p><p id=\"P-0002\" num=\"0002\">[0002] The present invention relates in general to microprocessors and, more particularly, to a system, method, and mechanism providing power efficient operation in a pipeline processor. </p><p id=\"P-0003\" num=\"0003\">[0003] 2. Relevant Background </p><p id=\"P-0004\" num=\"0004\">[0004] Computer programs comprise a series of instructions that direct a data processing mechanism to perform specific operations on data. These operations including loading data from memory, storing data to memory, adding, multiplying, and the like. Data processors, including microprocessors, microcontrollers, and the like include a central processing unit (CPU) comprising one or more functional units that perform various tasks. Typical functional units include a decoder, an instruction cache, a data cache, an integer execution unit, a floating point execution unit, a load/store unit, and the like. A given program may run on a variety of data processing hardware. </p><p id=\"P-0005\" num=\"0005\">[0005] Early data processors executed only one instruction at a time. Each instruction was executed to completion before execution of a subsequent instruction was begun. Each instruction typically requires a number of data processing operations and involves multiple functional units within the processor. Hence, an instruction may consume several clock cycles to complete. In serially executed processors each functional unit may be busy during only one step, and idle during the other steps. The serial execution of instructions results in the completion of less than one instruction per clock cycle. </p><p id=\"P-0006\" num=\"0006\">[0006] As used herein the term \u201cdata processor\u201d includes complex instruction set computers (CISC), reduced instruction set computers (RISC) and hybrids. A data processor may be a stand alone central processing unit (CPU) or an embedded system comprising a processor core integrated with other components to form a special purpose data processing machine. The term \u201cdata\u201d refers to a digital or binary information that may represent memory addresses, data, instructions, or the like. </p><p id=\"P-0007\" num=\"0007\">[0007] In response to the need for improved performance several techniques have been used to extend the capabilities of these early processors including pipelining, superpipelining, and superscaling. Pipelined architectures attempt to keep all the functional units of a processor busy at all times by overlapping execution of several instructions. Pipelined designs increase the rate at which instructions can be executed by allowing a new instruction to begin execution before a previous instruction is finished executing. A simple pipeline may have only five stages whereas an extended pipeline may have ten or more stages. In this manner, the pipeline hides the latency associated with the execution of any particular instruction. </p><p id=\"P-0008\" num=\"0008\">[0008] The goal of pipeline processors is to execute multiple instructions per cycle (IPC). Due to pipeline hazards, actual throughput is reduced. Pipeline hazards include structural hazards, data hazards, and control hazards. Structural hazards arise when more than one instruction in the pipeline requires a particular hardware resource at the same time (e.g., two execution units requiring access to a single ALU resource in the same clock cycle). Data hazards arise when an instruction needs as input the output of an instruction that has not yet produced that output. Control hazards arise when an instruction changes the program counter (PC) because execution cannot continue until the target instruction from the new PC is fetched. </p><p id=\"P-0009\" num=\"0009\">[0009] When hazards occur, the processor must stall or place \u201cbubbles\u201d (e.g., NOPs) in the pipeline until the hazard condition is resolved. This increases latency and decreases instruction throughput. As pipelines become longer, the likelihood of hazards increases. Hence, an effective mechanism for handling hazard conditions is important to achieving the benefits of deeper pipelines. </p><p id=\"P-0010\" num=\"0010\">[0010] Another goal of many processors is to control the power used by the processor. Many applications, particularly those directed at mobile or battery operated environments, require low power usage. The execution pipelines of a computer consume a significant amount of power. Power consumption is largely caused by moving data between registers, files, and execution units. As data paths become wider, the power consumed to move the data increases. </p><p id=\"P-0011\" num=\"0011\">[0011] Hence, in order to execute instructions efficiently at a high throughput within a pipeline it is important to coordinate and control the flow of instructions, operations, and data within the execution pipeline. The order and manner in which the operands and results of these instructions are made available to each other within the execution pipeline is of critical importance to the throughput of the pipeline. </p><h4>SUMMARY OF THE INVENTION </h4><p id=\"P-0012\" num=\"0012\">[0012] The present invention involves a processor including a plurality of execution pipeline stages where each stage accepts a plurality of operand inputs and generates a result. A pipefile having at least the same number of entries as the number of execution pipeline stages is included in the processor. A pointer register is associated with each execution pipeline stage. A value is stored in at least one of the pointer registers, the value indicating a particular one of the entries in the pipefile. </p><p id=\"P-0013\" num=\"0013\">[0013] The present invention involves a method, system and apparatus for forwarding data within a pipeline of a pipelined data processor having a plurality of execution pipeline stages where each stage accepts a plurality of operand inputs and generates a result. A pipefile is implemented having at least the same number of entries as the number of execution pipeline stages Each new instruction is assigned to one of the entries in the pipefile before the new instruction is executed. The pipefile entry assignment remains valid while the instruction remains in any of the execution pipeline stages. The new instruction is passed through the execution pipeline stages to generate a result. Upon successful completion of executing the new instruction, the result is written back from the assigned pipefile entry to an architectural register. </p><p id=\"P-0014\" num=\"0014\">[0014] The foregoing and other features, utilities and advantages of the invention will be apparent from the following more particular description of a preferred embodiment of the invention as illustrated in the accompanying drawings.</p></summary-of-invention><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS </h4><p id=\"P-0015\" num=\"0015\">[0015]FIG. 1 shows in block diagram form a computer system incorporating an apparatus and system in accordance with the present invention; </p><p id=\"P-0016\" num=\"0016\">[0016]FIG. 2 shows a processor in block diagram form incorporating the apparatus and method in accordance with the present invention; </p><p id=\"P-0017\" num=\"0017\">[0017]FIG. 3 illustrates a CPU core useful in the implementation of the processor and system shown in FIG. 1 and FIG. 2 in accordance with the present invention; </p><p id=\"P-0018\" num=\"0018\">[0018]FIG. 4 shows an instruction fetch unit in which features of the present invention are embodied in a particular implementation; </p><p id=\"P-0019\" num=\"0019\">[0019]FIG. 5 illustrates an exemplary execution pipeline in accordance with a specific embodiment of the present invention; </p><p id=\"P-0020\" num=\"0020\">[0020]FIG. 6 illustrates comparative pipeline timing for the execution pipeline shown in FIG. 5; </p><p id=\"P-0021\" num=\"0021\">[0021]FIG. 7A and FIG. 7B show exemplary a snapshot register entries in accordance with embodiments of the present invention; and </p><p id=\"P-0022\" num=\"0022\">[0022]FIG. 8 shows an operand multiplexing mechanism in accordance with an embodiment of the present invention; and </p><p id=\"P-0023\" num=\"0023\">[0023]FIG. 9 schematically illustrates internal operand forwarding mechanism in accordance with the present invention. </p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS </h4><p id=\"P-0024\" num=\"0024\">[0024] Power efficient operation is an important feature for many data processors. This is particularly true for embedded processors so that they do not place undue demands on the power supply requirements for the system in which they are embedded. The present invention is illustrated in terms of a particular embedded processor system using a multi-stage pipeline for processing instructions. The present invention particularly involves a structure for efficiently forwarding data within the pipefile mechanism so that, for example, operands that are determined by a first instruction within the pipeline can be used by subsequent instructions before the first instruction has completed to write back. </p><p id=\"P-0025\" num=\"0025\">[0025] Operand forwarding is important in avoiding pipeline stalls, but can lead to a significant amount of power loss as data is copied and moved between registers to make the data available throughout the pipeline. The power required is more significant when wide data words (e.g., 64-bit, 128-bit, or larger) are used. The present invention provides a mechanism that limits the need to copy data between registers within the pipeline. </p><p id=\"P-0026\" num=\"0026\">[0026] The present invention implements a mechanism called a \u201cpipefile\u201d to improve power performance. Results from execution units are written on the results busses only once. They are captured by the pipefile which acts as a sort of cache. The results are forwarded as needed from the pipefile. A less efficient pipeline processor implementation simply moves the results from stage-to-stage through the execution pipeline without using a pipefile. However, since the results busses are heavily loaded due to the loads they are driving and parasitic impedance, driving the busses multiple times for the same interim result can be very power inefficient. Using the pipefile in accordance with the present invention, results from the execution stages need only be driven onto the results bus once. </p><p id=\"P-0027\" num=\"0027\">[0027] In one implementation the pipefile mimics the pipeline and shifts the result from entry-to-entry as its producing instruction moves through the pipeline. This offers some improvement as the data is moved without the penalty of the heavily loaded results bus. In an improved implementation, once into the pipefile, a result stays in the entry until the instruction has completed and the result has been committed to the register file. The improved implementation avoids power loss associated with switching the transistor in the pipefile. </p><p id=\"P-0028\" num=\"0028\">[0028] Any system is usefully described as a collection of processes or modules communicating via data objects or messages as shown in FIG. 1. The modules may be large collections of circuitry whose properties are somewhat loosely defined, and may vary in size or composition significantly. The data object or message is a communication between modules that make up the system. To actually connect a module within the system it is necessary to define an interface between the system and the component module. </p><p id=\"P-0029\" num=\"0029\">[0029] The present invention is illustrated in terms of a media system <b>100</b> shown in FIG. 1. Media processor <b>100</b> comprises, for example, a \u201cset-top box\u201d for video processing, a video game controller, a digital video disk (DVD) player, and the like. Essentially, system <b>100</b> is a special purpose data processing system targeted at high throughput multimedia applications. Features of the present invention are embodied in processor <b>101</b> that operates to communicate and process data received through a high speed bus <b>102</b>, peripheral bus <b>104</b>, and memory bus <b>106</b>. </p><p id=\"P-0030\" num=\"0030\">[0030] Video controller <b>105</b> receives digital data from system bus <b>102</b> and generates video signals to display information on an external video monitor, television set, and the like. The generated video signals may be analog or digital Optionally, video controller may receive analog and/or digital video signals from external devices as well. Audio controller <b>107</b> operates in a manner akin to video controller <b>105</b>, but differs in that it controls audio information rather than video Network I/O controller <b>109</b> may be a conventional network card, ISDN connection, modem, and the like for communicating digital information Mass storage device <b>111</b> coupled to high speed bus <b>102</b> may comprise magnetic disks, tape drives, CDROM, DVD, banks of random access memory, and the like. A wide variety of random access and read only memory technologies are available and are equivalent for purposes of the present invention. Mass storage <b>111</b> may include computer programs and data stored therein. In a particular example, high speed bus <b>102</b> is implemented as a peripheral component interconnect (PCI) industry standard bus. An advantage of using an industry standard bus is that a wide variety of expansion units such as controller's <b>105</b>, <b>107</b>, <b>109</b> and <b>111</b> are readily available. </p><p id=\"P-0031\" num=\"0031\">[0031] Peripherals <b>113</b> include a variety of general purpose I/O devices that may require lower bandwidth communication than provided by high speed bus <b>102</b>. Typical I/O devices include read only memory (ROM) devices such as game program cartridges, serial input devices such as a mouse or joystick, keyboards, and the like. Processor <b>101</b> includes corresponding serial port(s), parallel port(s), printer ports, and external timer ports to communicate with peripherals <b>113</b>. Additionally, ports may be included to support communication with on-board ROM, such as a BIOS ROM, integrated with processor <b>101</b>. External memory <b>103</b> is typically required to provide working storage for processor <b>101</b> and may be implemented using dynamic or static RAM, ROM, synchronous DRAM, or any of a wide variety of equivalent devices capable of storing digital data in a manner accessible to processor <b>101</b>. </p><p id=\"P-0032\" num=\"0032\">[0032] Processor <b>101</b> is illustrated in a greater detail in the functional diagram of FIG. 2. One module in a data processing system is a central processor unit (CPU) core <b>201</b>. The CPU core <b>201</b> includes, among other components execution resources (e.g., arithmetic logic units, registers, control logic) and cache memory. These functional units, discussed in greater detail below, perform the functions of fetching instructions and data from memory, preprocessing fetched instructions, scheduling instructions to be executed, executing the instructions, managing memory transactions, and interfacing with external circuitry and devices. </p><p id=\"P-0033\" num=\"0033\">[0033] CPU core <b>201</b> communicates with other components shown in FIG. 2 through a system bus <b>202</b>. In the preferred implementation system bus <b>202</b> is a high-speed network bus using packet technology and is referred to herein as a \u201csuper highway\u201d. Bus <b>202</b> couples to a variety of system components. Of particular importance are components that implement interfaces with external hardware such as external memory interface unit <b>203</b>, PCI bridge <b>207</b>, and peripheral bus <b>204</b>. </p><p id=\"P-0034\" num=\"0034\">[0034] The organization of interconnects in the system illustrated in FIG. 2 is guided by the principle of optimizing each interconnect for its specific purpose. The bus system <b>202</b> interconnect facilitates the integration of several different types of sub-systems. It is used for closely coupled subsystems which have stringent memory latency/bandwidth requirements. The peripheral subsystem bus <b>204</b> supports bus standards which allow easy integration of hardware of types indicated in reference to FIG. 1 through interface ports <b>213</b>. PCI bridge <b>207</b> provides a standard interface that supports expansion using a variety of PCI standard devices that demand higher performance that available through peripheral port <b>204</b>. The system bus <b>202</b> may be outfitted with an expansion port which supports the rapid integration of application modules without changing the other components of system <b>101</b>. External memory interface <b>203</b> provides an interface between the system bus <b>202</b> and the external main memory subsystem <b>103</b> (shown in FIG. 1). The external memory interface comprises a port to system bus <b>202</b> and a DRAM controller. </p><p id=\"P-0035\" num=\"0035\">[0035] The CPU core <b>201</b> can be represented as a collection of interacting functional units as shown in FIG. 3. These functional units, discussed in greater detail below, perform the functions of fetching instructions and data from memory, preprocessing fetched instructions, scheduling instructions to be executed, executing the instructions, managing memory transactions, and interfacing with external circuitry and devices. </p><p id=\"P-0036\" num=\"0036\">[0036] A bus interface unit (BIU) <b>301</b> handles all requests to and from the system bus <b>202</b> and external memory. An instruction flow unit (IFU) <b>303</b> is the front end of the CPU pipe and controls fetch, predecode, decode, issue and branch operations in the preferred embodiment. In accordance with the preferred embodiment, IFU <b>303</b> includes a pipe control unit <b>401</b> (shown in FIG. 4) that implements features of the present invention. However, it is contemplated that the inventive features of the present invention may be usefully embodied in a number of alternative processor architectures that will benefit from the performance features of the present invention. Accordingly, these alternative embodiments are equivalent to the particular embodiments shown and described herein. </p><p id=\"P-0037\" num=\"0037\">[0037] An execution unit (IEU) <b>305</b> handles all integer and multimedia instructions. The main CPU datapath includes an instruction cache unit (ICU) <b>307</b> implements an instruction cache (Icache not shown) and an instruction translation lookaside buffer (ITLB, not shown). Load store unit (LSU) <b>309</b> handles all memory instructions. A data cache control unit (DCU) <b>311</b> includes a data cache (Dcache, not shown) and a data translation lookaside buffer (DTLB, not shown). Although the present invention preferably uses separate data and instruction caches, it is contemplated that a unified cache can be used with some decrease in performance. In a typical embodiment, the functional units shown in FIG. 2, and some or all of cache memory <b>105</b> may be integrated in a single integrated circuit, although the specific components and integration density are a matter of design choice selected to meet the needs of a particular application. </p><p id=\"P-0038\" num=\"0038\">[0038]FIG. 4 shows hardware resources within IFU <b>303</b> including a pipe control unit <b>401</b> in accordance with the present invention. FIG. 4 shows a simplified IFU block diagram with the internal blocks as well as the external interfacing units. As shown in FIG. 4, IFU <b>303</b> can be divided into the following functional blocks according to their functions: the Instruction Cache Control Unit (ICC) <b>413</b>, the Fetch Unit (FE) <b>403</b>, the Branch Unit (BR) <b>411</b>, the Decode Unit <b>405</b>, the Pipe Control Unit <b>401</b>, and the Operand File Unit comprising register file <b>407</b> and pipe file <b>409</b>. </p><p id=\"P-0039\" num=\"0039\">[0039] IFU <b>303</b> functions as the sequencer of the CPU core <b>201</b> in accordance with the present invention. It coordinates the flow of instructions and data within the core <b>201</b> as well as merges the external events with the core internal activities. Its main functions are to fetch instructions from ICU <b>307</b> using fetch unit <b>403</b> and decode the instructions in decoder <b>405</b>. IFU <b>303</b> checks for instruction inter-dependency, reads the operands from the register file <b>407</b> and sends the decoded instructions and the operands to the execution units (e.g., IEU <b>305</b>, and LSU <b>309</b>). In addition, IFU <b>303</b> couples to BIU <b>301</b> on instruction cache misses to fill the instruction cache within ICU <b>307</b> with the missing instructions from external memory. </p><p id=\"P-0040\" num=\"0040\">[0040] Because of the sequencing role within the CPU core <b>201</b>, IFU <b>303</b> interfaces with almost every other functional unit. The interface between IFU <b>303</b> and BIU <b>301</b> initiates the loading of instructions into the instruction cache. The interface between IFU <b>303</b> and ICU <b>307</b> provides the flow of instructions for execution. The interface between IFU <b>303</b> and IMU <b>305</b> and LSU <b>309</b> provides the paths for sending/receiving instructions, operands, results, as well as the control signals to enable the execution of instructions. In addition to these interfaces, IFU <b>303</b> may also receive external interrupt signals from an external interrupt controller (shown in FIG. 2), which samples and arbitrates external interrupts. IFU <b>303</b> will then arbitrate the external interrupts with internal exceptions and activates the appropriate handler to take care of the asynchronous events. </p><p id=\"P-0041\" num=\"0041\">[0041] Once instructions are decoded, pipe control unit <b>401</b> monitors their execution through the remaining pipe stages. The main function of pipe control unit <b>401</b> is to ensure that instructions are executed smoothly and correctly that (i) instructions will be held in the decode stage until the source operands are ready or can be ready when needed, (ii) that synchronization and serialization requirements imposed by the instruction as well as internal/external events are observed, and (iii) that data operands/temporary results are forwarded correctly. </p><p id=\"P-0042\" num=\"0042\">[0042] The operand file unit implements the architecturally defined general purpose register file <b>407</b>. In addition, it also implements a limited version of a reorder buffer called \u201cpipe file\u201d <b>409</b> for storing and forwarding temporary results that are yet to be committed to architectural registers. Because CPU core <b>201</b> is principally directed at in-order execution, there is only a small window of time that execution results may be produced out-of-order. The present invention takes advantage of this property and implements a simplified version of the reorder buffer that allows temporary results to be forwarded as soon as they are produced, while avoiding the expensive tag passing/matching mechanism usually associated with a reorder buffer. The operand file implements the data path portion of this pipe file. The control is implemented in the pipe control unit <b>401</b>. </p><p id=\"P-0043\" num=\"0043\">[0043] Pipe file <b>409</b> operates to collect results from the execution units, and writes them back to the register file <b>407</b> during the writeback stage. Pipe file <b>409</b> is an important component of the present invention. One option for using pipe file <b>409</b> is to have a pipe file entry associated with each execution stage. This requires that interim results determined at an early execution stage be copied from entry-to-entry within pipefile <b>409</b> so that the interim result follows the instruction through the pipeline. The present invention involves a mechanism and method of operation that avoids this entry-to-entry data shifting. These features are described in greater detail hereinafter with respect to FIG. 9. </p><p id=\"P-0044\" num=\"0044\">[0044]FIG. 5 and FIG. 6 illustrate an example execution pipeline in accordance with the present invention. The particular example is a scalar (i.e., single pipeline), single issue machine. The implementation in FIG. 5 and FIG. 6 includes three execution stages. Many instructions however execute in a single cycle. The present invention implements features to enable comprehensive forwarding within the pipeline to achieve a high instruction throughput. Although illustrated in terms of a single pipeline (i.e., scalar) machine, the teachings of the present invention are adapted to multiple pipeline machines in a straightforward manner. </p><p id=\"P-0045\" num=\"0045\">[0045] In the pre-decode stage <b>503</b> the instruction cache access which was initiated in the previous cycle is completed and the instruction is returned to IFU <b>303</b> where it can be latched by mid-cycle. An instruction may spend from 1 to n cycles in stage <b>503</b> depending on downstream pipeline instructions. In the second half of stage <b>503</b>, some pre-decoding of the instruction will be carried out. Decode stage <b>505</b> handles the full instruction decode, operand dependency checks and register file read and instruction issue to the execution units. </p><p id=\"P-0046\" num=\"0046\">[0046] The first execution stage <b>507</b> implements the execution of all single cycle integer instructions as well as the address calculation for memory and branch instructions. The second execution stage <b>509</b> implements the second cycle of execution for all multicycle integer/multimedia instructions. Additionally it corresponds to the second cycle for load instructions. The third execution stage <b>511</b> implements the third cycle of execution for all multicycle integer/multimedia instructions and corresponds to the completion cycle for load instructions. Write back stage <b>513</b> is where all architectural state modified by an instruction (e.g. general purpose register, program counter etc.) is updated. The exception status of the instruction arriving in this stage or any external exception can prevent the update in this stage. </p><p id=\"P-0047\" num=\"0047\">[0047] The pipe control unit <b>401</b> performs a number of operations in handling the instruction flow. An important feature of the pipe control unit <b>401</b> is the pipeline snapshot file <b>415</b> (shown in FIG. 4) implemented within pipe control unit <b>401</b>. Snapshot file <b>415</b> may be implemented as a lookup table having a table entry <b>701</b> (shown in FIG. 7) corresponding to each execution stage in the pipeline. The snapshot file <b>415</b> provides a central resource for all pipeline control operations such as dependency checks, operand forwarding, exception handling, and the like. In a particular implementation, snapshot file <b>415</b> includes four entries corresponding to the three execution pipeline stages and the writeback pipeline stage. </p><p id=\"P-0048\" num=\"0048\">[0048]FIG. 7A and FIG. 7B show exemplary snapshot files <b>701</b> and <b>702</b> indicating entries holding metadata describing the instruction execution state at the corresponding pipe stage. As instructions move from one stage to another, their associated snapshot entry moves to the corresponding snapshot entry <b>701</b> or <b>702</b>. The contents of each snapshot entry <b>701</b> may be varied to meet the needs of a particular application. The specific examples shown in FIG. 7 correspond to pipeline control operations described hereinbelow. The essential functionality of examples <b>701</b> and <b>702</b> are similar although the implementation of that essential functionality differs between the examples. In comparing the examples, snapshot file <b>701</b> does not include a \u201cSTAGE\u201d entry as that is implied by the index of the entry whereas example <b>702</b> includes an explicit STAGE entry. The single STAGE_RDY entry of FIG. 7B is implemented using three separate entries (E<b>1</b>_RESULT, E<b>2</b>_RESULT and E<b>3</b>_RESULT) in the example of FIG. 7A. The fields have the function generally described in the figures and additional or fewer fields may be added to meet the needs of a particular application. </p><p id=\"P-0049\" num=\"0049\">[0049] In particular, snapshot entry <b>701</b> includes a pointer to the pipefile entry corresponding to that instruction. An instruction is assigned an entry in pipefile <b>409</b> in decode and the assigned value indicated in the instruction's pipefile entry <b>701</b>. Other execution stages or hardware resources that desire to know which pipefile stage is being used by the instruction can look to the snapshot entry <b>701</b> for that information. In the particular example there are three pipefile entries corresponding to the three execution stages of the pipeline. Hence, only two bits of information are needed to point to the correct pipefile entry. </p><p id=\"P-0050\" num=\"0050\">[0050] As an instruction moves through the pipeline, and results become available, the results are written to the specified pipe file entry in the execution stage indicated by the \u201cstage_rdy\u201d field in snapshot entry <b>702</b>. Subsequently, the result remains in the same pipefile entry while the instruction moves through the pipeline. In this manner the present invention avoids power usage normally required to move the result from entry to entry within pipefile <b>409</b>. Instead, only the two-bit pointer needs to be moved from entry to entry within snapshot entry <b>701</b> and <b>702</b>. This can translate to hundreds or thousands of fewer transistor switching operations per clock cycle for a wide data word. </p><p id=\"P-0051\" num=\"0051\">[0051] In operation, the snapshot register may be used by the pipe control unit <b>401</b> to perform a number of parallel checks to classify the instruction currently being processed by the decoder <b>405</b>. For example, the three potential operand register fields of the instruction word are checked against the existing pipe snapshot to detect data dependency, forwarding dependence, write after write hazard, and write after write for an accumulating-type instruction. </p><p id=\"P-0052\" num=\"0052\">[0052] Under normal conditions once an instruction has been issued to an execution unit its entry will progress through each stage of the snapshot file on each clock edge. At the beginning of each execution stage the control for writing the result to the pipefile is generated. This is determined by checking the E<b>1</b>_RESULT, E<b>2</b>_RESULT, and E<b>3</b>_RESULT fields of the current execution stage. For example, if E<b>1</b>_RESULT field is set for the instruction executing in the EXE_<b>1</b> stage <b>507</b>, the result from EXE_<b>1</b> stage <b>507</b> will then be written into the pipefile entry indexed by the PIPE_FILE_ENTRY field. Similarly, the result from the EXE_<b>2</b> and EXE_<b>3</b> stages will be written into the pipefile <b>409</b> when the E<b>2</b>_RESULT and E<b>3</b>_RESULT fields of the corresponding snapshot file entries are set. The write into pipefile <b>409</b> will occur even if the EXCEPTION field in snapshot file <b>702</b> is set. This is to allow transportation data for exceptions back to the branch unit. Once an instruction reaches write-back, the rdest_valid field also determines if the contents of the pipefile is written back to the architectural register file. Once in write-back, if no exception has occurred, the instruction has completed. </p><p id=\"P-0053\" num=\"0053\">[0053] The snapshot register plays a role in managing pipefile <b>409</b> and operand file <b>407</b> updates in the event of exceptions. Even though an exception has been detected the pipefile <b>409</b> will continue to be updated with data according to the \u201cstage_rdy\u201d field of the snapshot file, While an excepting instruction is executing through the pipe, in certain cases the result data associated with the excepting data is of interest. A key point is that these results are written to pipefile <b>409</b> in the normal stage_rdy stage of the excepting instruction. As long as this rule is honored exception data is transported through the pipefile <b>409</b> as normal and will indicate to the branch unit <b>411</b> at write-back that exception data of interest is on the write-back bus. </p><p id=\"P-0054\" num=\"0054\">[0054] Another general utility of the snapshot register is in handling internal operand forwarding within the pipeline. Because the snapshot entry <b>701</b> indicates which pipestage will produce a result to the pipefile <b>409</b>, subsequent instructions can reliably use the interim result from the pipefile <b>409</b> before the interim result is committed to architectural state. This process is called internal operand forwarding. The present invention supports internal operand forwarding by providing a pipefile entry from which the interim result can be readily forwarded. </p><p id=\"P-0055\" num=\"0055\">[0055] When decode indicates that it has a valid instruction the pipe control block determines from the instruction code the source of the operands for the instruction. The operand can be sourced from, for example: </p><p id=\"P-0056\" num=\"0056\">[0056] Register operands; </p><p id=\"P-0057\" num=\"0057\">[0057] Indirectly forwarded operands through the three pipefile entries; </p><p id=\"P-0058\" num=\"0058\">[0058] Directly forwarded operands from the result busses; </p><p id=\"P-0059\" num=\"0059\">[0059] The extended immediate field from the instruction; </p><p id=\"P-0060\" num=\"0060\">[0060] The program counter; </p><p id=\"P-0061\" num=\"0061\">[0061] The contents of an instruction address register (IAR); </p><p id=\"P-0062\" num=\"0062\">[0062] The contents of a control register; and </p><p id=\"P-0063\" num=\"0063\">[0063] A tied low constant field; </p><p id=\"P-0064\" num=\"0064\">[0064] The above gives up to 12 possible sources of input to some operand. FIG. 8 illustrates an exemplary operand multiplexing (\u201cmuxing\u201d) mechanism that enables rich sharing of operands within the pipeline. The mechanism shown in FIG. 8 is distributed throughout pipe control unit <b>401</b> as described below. The operand multiplexer mechanism of FIG. 8 produces three choices (e.g., IFU_SRC<b>1</b>, IFU_SRC<b>2</b>, IFU_SRC<b>3</b>) for the source operands provided to the first execution stage <b>507</b>. Each execution stage produces a result (labeled EXE_<b>1</b>, EXE_<b>2</b>, and EXE_<b>3</b> in FIG. 8) that may be used as a source operand input to the first execution stage <b>507</b>. Execution stage <b>507</b> is associated with a multiplexors <b>809</b><i>a</i>-<b>809</b><i>c </i>for selecting up to three source operands from those available. The specific examples given herein are for purposes of explanation and understanding, and are not a limitation on the actual implementation. </p><p id=\"P-0065\" num=\"0065\">[0065] It should also be understood that execution stage <b>507</b>, <b>509</b> and <b>511</b> shown in FIG. 8 are representative of all of the hardware resources used in that execution stage as defined by the processor microarchitecture. An execution stage is physically implemented using the hardware resources such as those shown in FIG. 3. The outputs of multiplexors <b>809</b> are physically coupled to each of the hardware resources that will use the source operands during its operation. </p><p id=\"P-0066\" num=\"0066\">[0066] The multiplexing of these operand sources in the particular example is distributed in the following way: </p><p id=\"P-0067\" num=\"0067\">[0067] The program counter (PC), instruction address registers, and control register contents are pre-muxed in the branch unit using multiplexors <b>801</b> and <b>803</b>. All these inputs are available at the start of the cycle. </p><p id=\"P-0068\" num=\"0068\">[0068] The decode constant extracted from the instruction and possibly tied high zeroes are pre-muxed in the decode stage using multiplexor <b>811</b>. </p><p id=\"P-0069\" num=\"0069\">[0069] The outputs of the pipefile <b>409</b> are muxed with the program counter data and decode constant data respectively in multiplexors <b>805</b> and <b>813</b>. </p><p id=\"P-0070\" num=\"0070\">[0070] The register file contents are muxed with the pipefile outputs using multiplexors <b>807</b>, <b>815</b>, and <b>821</b> to produce source operands which are distributed down the execution datapath (IFU_SRC<b>1</b>, IFU_SRC<b>2</b>, IFU_SRC<b>3</b> in FIG. 8). </p><p id=\"P-0071\" num=\"0071\">[0071] Forwarding of completing results is done locally within the execution datapath as suggested by the connection from the output of EXE_<b>3</b> stage to the input of multiplexor <b>809</b>. As the result is being driven back up the datapath from the various stages of execution (imu_result_ex<b>1</b>, _ex<b>2</b> and _ex<b>3</b>), the result taps back into the multiplexor <b>809</b> latch at the input to the execution sub-units. The result is also driven back up to the pipefile for ultimate storage in the register file. Pipe control unit <b>401</b> controls the selection of the multiplexer <b>809</b> latches. </p><p id=\"P-0072\" num=\"0072\">[0072] The LSU ex<b>3</b> result is muxed with the output of the IMU ex<b>3</b> result (from the multiplier). This is also controlled by the pipe control unit <b>401</b>. </p><p id=\"P-0073\" num=\"0073\">[0073] In this manner, pipe control unit <b>401</b> generates the control signals for multiplexors and execution stage resources. This enables the source operand inputs used by each execution stage to be selected from among a plurality of possible inputs. Of particular significance is that each source operand can be forwarded from the interim results stored in the pipefile if valid results are available in the pipefile. This is useful in handling data hazards in a manner that limits the need to stall the pipeline or fill the pipeline with bubbles while data dependencies resolve. The particular choice and distribution of operand sources can include more or fewer sources to meet the needs of a particular application and unless specified otherwise herein the examples are provided for example purposes only. </p><p id=\"P-0074\" num=\"0074\">[0074] Moreover, each source operand is desirably allowed to be taken from the execution unit's own result output. This is particularly useful for accumulate-type operations where the destination register is used in a series of instructions to hold an accumulating result. Without this feature, pipeline bubbles would likely be inserted between accumulate instructions thereby reducing throughput significantly. Using this feature, the decoder can issue accumulating type instructions one-after-another. </p><p id=\"P-0075\" num=\"0075\">[0075]FIG. 9 that schematically illustrates the execution stages of a pipeline and the operand sources for each stage. Each execution stage (EXE_<b>1</b>, EXE_<b>2</b> and EXE_<b>3</b>) may generate a result. The specific stage that generates a result for any given instruction will vary from instruction-to-instruction, but is preferably indicated in the \u201cstage_rdy\u201d field of the snapshot file entry <b>702</b> or the E<b>1</b>_RESULT, E<b>2</b>_RESULT and E<b>3</b>_RESULT fields described hereinbefore. Each source operand can be taken from the execution unit's own result output. FIG. 9 shows an operand bus comprising IFU_SRC<b>1</b>, IFU_SRC<b>2</b> and IFU_SRC<b>3</b> (determined as shown in FIG. 8) and a results bus comprising EXE_<b>1</b>_RESULT, EXE_<b>2</b>_RESULT and EXE_<b>3</b>_RESULT. The results bus carries results to appropriate entries in pipefile <b>409</b>. </p><p id=\"P-0076\" num=\"0076\">[0076] In the embodiment shown in FIG. 9 each execution stage corresponds to a specific entry in the pipe file <b>409</b> (e.g., EXE_<b>2</b> corresponds to pipefile entry <b>409</b>A, EXE_<b>3</b> stage <b>509</b> corresponds to entry <b>409</b>B). Results are written from the result bus into pipefile <b>409</b> according to the \u201cstage_rdy\u201d value in the snapshot register (FIG. 7A) or the E<b>1</b>_RESULT through E<b>3</b>_RESULT entries (FIG. 7B) as described hereinbefore. Pipefile <b>409</b>A takes the EXE_<b>1</b> result and can forward its contents when the instruction that produces the result is in the EXE_<b>2</b> stage. Similarly, pipefile entry <b>409</b>B takes the EXE_<b>2</b> result and <b>409</b>C takes the EXE_<b>3</b> result respectively. Otherwise, results are moved sequentially from entry <b>409</b>A to <b>409</b>B to <b>409</b>C. Entry <b>409</b>C corresponds to the write back pipe stage. Assuming the snapshot register entry <b>701</b> corresponding to the instruction in the write back stage is valid and does not indicate an exception, the value stored in pipefile stage <b>409</b> is copied to the appropriate register in register file <b>407</b>. </p><p id=\"P-0077\" num=\"0077\">[0077] Significantly, the operands for each execution stage can be selected from either the operand bus or the results bus. Hence, a result that is ready in EXE_<b>1</b> will be driven onto the EXE_<b>1</b>_RESULT line and can be used as an operand on the following cycle in the second and third execution stages before being written to either register file <b>407</b> or the pipefile <b>409</b>. Similarly, a result determined in EXE_<b>3</b> can be used on the next clock cycle as an operand for an instruction executing in the first execution stage (EXE_<b>1</b>). This enables the instruction to be issued to EXE_<b>1</b> without delays or pipeline bubbles normally associated with waiting for the EXE_<b>3</b>_RESULT to be written out to a register or rename register. </p><p id=\"P-0078\" num=\"0078\">[0078] Furthermore, execution stage <b>507</b> can use its own output as well as the outputs of stages <b>509</b> and <b>511</b> as an operand for the next cycle. This is done, for example, by selecting EXE_<b>1</b>_RESULT, EXE_<b>2</b>_RESULT or EXE_<b>3</b>_RESULT as one of its operand inputs. This is particularly useful for accumulate-type operations where the destination register is used in a series of instructions to hold an accumulating result. Without this feature, pipeline bubbles would likely be inserted between accumulate instructions thereby reducing throughput significantly. Using this feature, the decoder can issue accumulating type instructions one-after-another. </p><p id=\"P-0079\" num=\"0079\">[0079] The results are coupled to a corresponding selector unit <b>901</b>. Each selector selectively couples the result to one of the result bus lines. Each selector is controlled by, for example, the pointer value (labeled POINTER_<b>1</b>, POINTER_<b>2</b> and POINTER_<b>3</b> in FIG. 9) corresponding to that pipe stage. The pointer values are determined from the PIPE_FILE_ENTRY and E<b>1</b>_RESULT, E<b>2</b>_RESULT and E<b>3</b>_RESULT fields of snapshot entry <b>701</b>. Alternatively, the pointer value <b>903</b> may be stored in the snapshot file entry <b>701</b> as described hereinbefore, or may be stored in a separate register that operates in a manner such that the pointer value remains associated with a particular instruction as the instruction moves through the pipeline. The result is written to the specified pipefile entry <b>409</b><i>a</i>-<b>409</b><i>c. </i></p><p id=\"P-0080\" num=\"0080\">[0080] Pipefile <b>409</b> preferably comprises dual ported memory structure so that the contents of any entry <b>409</b><i>a</i>-<b>409</b><i>c </i>can be written to and/or read out at any time. The memory within pipefile <b>409</b> is typically implemented using CMOS or BiCMOS static random access memory (SRAM) technology using four or more transistors per stored bit. A multiplexor set <b>903</b> selectively couples the data stored in pipefile entries <b>409</b><i>a</i>-<b>409</b><i>c </i>to appropriate lines on a pipefile bus <b>904</b>. The pipefile bus <b>904</b> provides values to the multiplexing mechanism shown in FIG. 8, for example. Multiplexor set <b>903</b> is controlled by pipe control unit <b>401</b> to couple appropriate bus lines to corresponding entries <b>409</b><i>a</i>-<b>409</b><i>c </i>in pipefile <b>409</b>. </p><p id=\"P-0081\" num=\"0081\">[0081] As a particular example, assume an instruction that generates its result in EXE_<b>1</b> and the pointer values are set such that the EXE_<b>1</b> result is written to pipefile entry <b>409</b><i>b. </i>From pipefile entry <b>409</b><i>b </i>the result can be multiplexed onto any of the IFU_SRC lines by appropriate settings in multiplexor set <b>903</b>. On the next pipe cycle, the example instruction will move to pipe stage EXE_<b>2</b>, while pipefile entry <b>409</b><i>b </i>remains unchanged. In this manner, a result needs only be written to the results bus one time while remaining continuously available for forwarding while the instruction remains in the pipeline. the hundreds of transistors used to store the value in entry <b>409</b><i>b </i>do not have to be switched until after the value is written back and the pipe file entry is reassigned to an instruction in the decoder. </p><p id=\"P-0082\" num=\"0082\">[0082] It is contemplated that the functionality of multiplexor <b>903</b> may be implemented in a variety of ways depending on the level of operand forwarding needed in a particular implementation. For example, if operand forwarding from the pipefile is not needed, there would be no corresponding need to generate the PIPEFILE_SCR<b>1</b>, PIPEFILE_SCR<b>2</b> and PIPEFILE_SCR<b>3</b> lines. The writeback line is controlled by the writeback stage pointer and selects one of the pipefile entries for writeback to an architectural register in register file <b>407</b>. </p><p id=\"P-0083\" num=\"0083\">[0083] While the invention has been particularly shown and described with reference to a preferred embodiment thereof, it will be understood by those skills in the art that various other changes in the form and details may be made without departing from the spirit and scope of the invention. The various embodiments have been described using hardware examples, but the present invention can be readily implemented in software. For example, it is contemplated that a programmable logic device, hardware emulator, software simulator, or the like of sufficient complexity could implement the present invention as a computer program product including a computer usable medium having computer readable code embodied therein to perform precise architectural update in an emulated or simulated out-of-order machine. Accordingly, these and other variations are equivalent to the specific implementations and embodiments described herein. </p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Chih-Jui", "last_name": "Peng", "name": ""}, {"first_name": "Lew", "last_name": "Chua-Eoan", "name": ""}], "assignees": [{"first_name": "", "last_name": "HITACHI LTD.", "name": ""}, {"first_name": "", "last_name": "HITACHI, LTD.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  15/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F   9/38        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "712216"}, {"primary": false, "label": "712E09046"}, {"primary": false, "label": "712E09049"}, {"primary": false, "label": "712E09062"}], "ecla_classes": [{"label": "G06F   9/38D"}, {"label": "G06F   9/38P"}, {"label": "G06F   9/38E"}], "cpc_classes": [{"label": "G06F   9/3836"}, {"label": "G06F   9/3857"}, {"label": "G06F   9/3867"}, {"label": "G06F   9/384"}, {"label": "G06F   9/3855"}, {"label": "G06F   9/3824"}, {"label": "G06F   9/3867"}, {"label": "G06F   9/3824"}, {"label": "G06F   9/3857"}, {"label": "G06F   9/3855"}, {"label": "G06F   9/384"}, {"label": "G06F   9/3836"}], "f_term_classes": [], "legal_status": "Granted", "priority_date": "1999-10-01", "application_date": "1999-10-01", "family_members": [{"ucid": "US-20010054139-A1", "titles": [{"lang": "EN", "text": "MECHANISM FOR POWER EFFICIENT PROCESSING IN A PIPELINE PROCESSOR"}]}, {"ucid": "US-6351803-B2", "titles": [{"lang": "EN", "text": "Mechanism for power efficient processing in a pipeline processor"}]}, {"ucid": "JP-2001142700-A", "titles": [{"lang": "JA", "text": "\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u30d7\u30ed\u30bb\u30c3\u30b5\u306b\u304a\u3051\u308b\u96fb\u529b\u6709\u52b9\u51e6\u7406\u30e1\u30ab\u30cb\u30ba\u30e0"}, {"lang": "EN", "text": "EFFICIENT POWER PROCESSING MECHANISM IN PIPELINE PROCESSOR"}]}]}