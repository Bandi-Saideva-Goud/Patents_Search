{"patent_number": "US-20010011328-A1", "publication_id": 75654482, "family_id": 25475553, "publication_date": "2001-08-02", "titles": [{"lang": "EN", "text": "SOFTWARE-CONTROLLED CACHE MEMORY COMPARTMENTALIZATION"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA48232241\"><p id=\"A-0001\">A method and apparatus for controlling compartmentalization of a cache memory. A cache memory including a plurality of storage components receives one or more externally generated cache compartment signals. Based on the one or more cache compartment signals, cache compartment logic in the cache memory selects one of the plurality of storage compartments to store data after a cache miss. </p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00001\" num=\"1\"><claim-text><b>1</b>. A cache memory comprising: \n<claim-text>a plurality of storage compartments; </claim-text><claim-text>one or more inputs to receive one or more cache compartment signals from a source external to the cache memory; and </claim-text><claim-text>cache compartment logic to select based on the one or more cache compartment signals one of the plurality of storage compartments to store data after a cache miss. </claim-text></claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00002\" num=\"2\"><claim-text><b>2</b>. The cache memory of <claim-ref idref=\"US-20010011328-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> wherein the cache memory further comprises a plurality of ways, and wherein the plurality of storage compartments each include one or more of the plurality of ways. </claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00003\" num=\"3\"><claim-text><b>3</b>. The cache memory of <claim-ref idref=\"US-20010011328-A1-CLM-00002\"><claim-text>claim 2</claim-text></claim-ref> further including logic to select a least recently used way of the plurality of ways to store data after a cache miss, and wherein the logic to select a least recently used way is overridden by a compartment enable signal received on one of the one or more inputs. </claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00004\" num=\"4\"><claim-text><b>4</b>. The cache memory of <claim-ref idref=\"US-20010011328-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> wherein the one or more inputs include one input to receive a compartment enable signal and N inputs to receive an encoded value indicating one of the plurality of storage compartments. </claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00005\" num=\"5\"><claim-text><b>5</b>. The cache memory of <claim-ref idref=\"US-20010011328-A1-CLM-00001\"><claim-text>claim 1</claim-text></claim-ref> wherein the one or more inputs include one or more inputs to receive one or more signals indicating an organization of storage elements within the cache memory into the plurality of storage compartments. </claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00006\" num=\"6\"><claim-text><b>6</b>. The cache memory of <claim-ref idref=\"US-20010011328-A1-CLM-00005\"><claim-text>claim 5</claim-text></claim-ref> wherein the storage elements are ways of the cache memory, the ways being allocated to the plurality of storage compartments based on the one or more signals indicating an organization of the storage elements. </claim-text></claim>"}, {"num": 7, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00007\" num=\"7\"><claim-text><b>7</b>. An apparatus comprising: \n<claim-text>cache memory means for caching data; </claim-text><claim-text>means for executing one or more instructions that indicate a cache compartment mode; and </claim-text><claim-text>means for storing data in one of a plurality of storage compartments in the cache memory means based on the cache compartment mode. </claim-text></claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00008\" num=\"8\"><claim-text><b>8</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00007\"><claim-text>claim 7</claim-text></claim-ref> wherein the means for executing one or more instructions includes means for fetching an operand indicated by the one or more instructions, the operand indicating the cache compartment mode. </claim-text></claim>"}, {"num": 9, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00009\" num=\"9\"><claim-text><b>9</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00007\"><claim-text>claim 7</claim-text></claim-ref> wherein the means for storing data in one of a plurality of storage compartments in the cache memory means includes means for selecting one of a plurality of ways in the cache memory means. </claim-text></claim>"}, {"num": 10, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00010\" num=\"10\"><claim-text><b>10</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00007\"><claim-text>claim 7</claim-text></claim-ref> wherein the means for executing one or more instructions that indicate a cache compartment mode includes means for asserting one or more compartment selection signals to the cache memory means, the compartment selection signals indicating the one of the plurality of storage compartments. </claim-text></claim>"}, {"num": 11, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00011\" num=\"11\"><claim-text><b>11</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00007\"><claim-text>claim 7</claim-text></claim-ref> wherein the means for executing one or more instructions that indicate a cache compartment mode includes means for asserting one or more compartment organization signals to the cache memory means, the compartment organization signals indicating an organization of storage elements in the cache memory means into the plurality of storage compartments. </claim-text></claim>"}, {"num": 12, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00012\" num=\"12\"><claim-text><b>12</b>. An apparatus comprising: \n<claim-text>a cache memory; </claim-text><claim-text>a processor to execute one or more instructions that indicate a cache compartment mode; and </claim-text><claim-text>logic to store data in one of a plurality of storage compartments in the cache memory based on the cache compartment mode. </claim-text></claim-text></claim>"}, {"num": 13, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00013\" num=\"13\"><claim-text><b>13</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00012\"><claim-text>claim 12</claim-text></claim-ref> wherein the logic to store data in one of a plurality of storage compartments in the cache memory includes logic to select one of a plurality of ways in the cache memory. </claim-text></claim>"}, {"num": 14, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00014\" num=\"14\"><claim-text><b>14</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00012\"><claim-text>claim 12</claim-text></claim-ref> wherein the processor includes logic to output one or more compartment selection signals to the cache memory, the compartment selection signals indicating the one of the plurality of storage compartments. </claim-text></claim>"}, {"num": 15, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00015\" num=\"15\"><claim-text><b>15</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00012\"><claim-text>claim 12</claim-text></claim-ref> wherein the processor includes logic to output one or more compartment organization signals to the cache memory, the compartment organization signals indicating an organization of storage elements in the cache memory into the plurality of storage compartments. </claim-text></claim>"}, {"num": 16, "parent": 15, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00016\" num=\"16\"><claim-text><b>16</b>. The apparatus of <claim-ref idref=\"US-20010011328-A1-CLM-00015\"><claim-text>claim 15</claim-text></claim-ref> wherein the storage elements are ways in the cache memory. </claim-text></claim>"}, {"num": 17, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00017\" num=\"17\"><claim-text><b>17</b>. A computer system comprising: \n<claim-text>a processor; </claim-text><claim-text>a cache memory coupled to the processor and having a plurality of storage compartments; and </claim-text><claim-text>a system memory having stored therein sequences of instructions, including one or more instructions which, when executed by the processor, cause the processor to output one or more cache compartment signals to the cache memory, the cache compartment signals selecting one of the plurality of storage compartments to store data. </claim-text></claim-text></claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00018\" num=\"18\"><claim-text><b>18</b>. The computer system of <claim-ref idref=\"US-20010011328-A1-CLM-00017\"><claim-text>claim 17</claim-text></claim-ref> wherein the one or more cache compartment signals indicate an organization of ways in the cache memory into the plurality of storage compartments. </claim-text></claim>"}, {"num": 19, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00019\" num=\"19\"><claim-text><b>19</b>. A method comprising the steps of: \n<claim-text>executing one or more processor instructions that indicate a cache compartment mode; and </claim-text><claim-text>storing data in one of a plurality of storage compartments in a cache memory based on the cache compartment mode. </claim-text></claim-text></claim>"}, {"num": 20, "parent": 19, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00020\" num=\"20\"><claim-text><b>20</b>. The method of <claim-ref idref=\"US-20010011328-A1-CLM-00019\"><claim-text>claim 19</claim-text></claim-ref> wherein said step of executing one or more processor instructions includes the step of executing a store instruction that indicates a store operation to a read-only data storage element. </claim-text></claim>"}, {"num": 21, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00021\" num=\"21\"><claim-text><b>21</b>. The method of <claim-ref idref=\"US-20010011328-A1-CLM-00020\"><claim-text>claim 20</claim-text></claim-ref> wherein said step of executing a store instruction includes the step of fetching an operand indicated by the store instruction, the operand indicating the cache compartment mode. </claim-text></claim>"}, {"num": 22, "parent": 19, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00022\" num=\"22\"><claim-text><b>22</b>. The method of <claim-ref idref=\"US-20010011328-A1-CLM-00019\"><claim-text>claim 19</claim-text></claim-ref> wherein said step of executing one or more processor instructions that indicate a cache compartment mode includes the step of executing one or more processor instructions that indicate an organization of the plurality of compartments in the cache memory. </claim-text></claim>"}, {"num": 23, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00023\" num=\"23\"><claim-text><b>23</b>. The method of <claim-ref idref=\"US-20010011328-A1-CLM-00022\"><claim-text>claim 22</claim-text></claim-ref> wherein said step of executing one or more processor instructions that indicate an organization of the plurality of compartments includes the step of executing one or more processor instructions that allocate one or more ways in the cache memory to each one of the plurality of compartments. </claim-text></claim>"}, {"num": 24, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00024\" num=\"24\"><claim-text><b>24</b>. A computer-readable medium having a first sequence of instruction s stored thereon which, when executed by a processor, causes the processor to perform the steps of: \n<claim-text>executing one or more processor instructions that indicate a cache compartment mode; and </claim-text><claim-text>generating cache compartment signals based on the cache compartment mode, the cache compartment signals indicating one of a plurality of storage compartments in a cache memory in which data is to be stored. </claim-text></claim-text></claim>"}, {"num": 25, "parent": 24, "type": "dependent", "paragraph_markup": "<claim id=\"US-20010011328-A1-CLM-00025\" num=\"25\"><claim-text><b>25</b>. The computer-readable medium of <claim-ref idref=\"US-20010011328-A1-CLM-00024\"><claim-text>claim 24</claim-text></claim-ref> wherein one or more of the first sequence of instructions indicates a write operation to a read-only storage element within the processor. </claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54941138\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><summary-of-invention><h4>FIELD OF THE INVENTION </h4><p id=\"P-0001\" num=\"0001\">[0001] The present invention relates to the field of data storage, and more particularly to a method and apparatus for storing data in a cache memory. </p><h4>BACKGROUND OF THE INVENTION </h4><p id=\"P-0002\" num=\"0002\">[0002] Cache memories are relatively small, high-speed memories used to reduce memory access time. Cache memories exploit two characteristics of memory access to reduce access time: temporal locality, the tendency of computer programs to repeatedly access the same memory locations; and spatial locality, the tendency of computer programs to access memory locations that are close to one another. </p><p id=\"P-0003\" num=\"0003\">[0003] In order to exploit temporal and spatial locality, data from frequently accessed regions of system memory are stored in cache memory. That way, subsequent accesses to the cached memory regions will not incur the full system memory access time, but the shorter cache access time instead. A memory transaction that accesses cache memory instead of main memory is called a cache hit, and the cache \u201chit-rate\u201d is a fundamental metric of cache operation. </p><p id=\"P-0004\" num=\"0004\">[0004] Several techniques have been employed to increase cache hit-rates. For example, to further exploit spatial locality, caches have been designed with increasingly larger row sizes. The size of a cache row (also called a cache line) defines the quantum of data stored in a cache memory after a cache miss. As the row size increases, it becomes more likely that subsequent memory accesses will address data in the row, thus improving the cache hit-rate. </p><p id=\"P-0005\" num=\"0005\">[0005] Temporal locality is exploited to improve cache hit-rate by providing multiple storage elements that are addressed by the same cache index. The storage elements are commonly referred to as \u201cways\u201d and a cache memory that has multiple ways is called a \u201cmultiple-way, set-associative cache\u201d. The idea behind multiple-way cache memories is to allow more than one system memory address to correspond to each cache index. Because the cache index is a sub-field of the overall system memory address, multiple-way design avoids repeated cache misses that occur in single-way designs when different addresses having the same cache index are accessed in succession. In single-way or \u201cdirect-mapped\u201d cache designs, successive accesses at memory locations having the same cache index result in a sequence of cache miss/cache update operations. This phenomenon is referred to as \u201cthrashing\u201d because data is rapidly swapped into and out of the cache, and much of the benefit of the cache memory is lost. </p><p id=\"P-0006\" num=\"0006\">[0006] Despite the advantages of multiple-way, set-associative cache memories, a significant amount of thrashing still occurs when the processor switches between tasks or functions that have dislocated code and data spaces. For example, if, while executing a first task having program code located within a given region of system memory, the processor switches to a second task having program code located within a different region of system memory, it is likely that program code for the first task will be swapped out of the cache in favor of program code for the second task. Consequently, as the processor continues to switch between the first and second tasks, significant number of cache misses occur, thus lowering the average cache hit-rate. </p><p id=\"P-0007\" num=\"0007\">[0007] Similarly, when a single task alternately processes data stored in two different regions in memory (e.g., an audio data store and a video data store a multi-media application), cache thrashing tends to occur as the task alternates between processing the two different data stores. </p><h4>SUMMARY OF THE INVENTION </h4><p id=\"P-0008\" num=\"0008\">[0008] A method and apparatus for compartmentalizing a cache memory are disclosed. A cache memory having a plurality of storage compartments receives one or more cache compartment signals at one or more inputs. The cache compartment signals are from a source external to the cache memory. Based on the one or more cache compartment signals, cache compartment logic selects one of the plurality of storage compartments to store data after a cache miss. </p></summary-of-invention><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS </h4><p id=\"P-0009\" num=\"0009\">[0009] The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements and in which: </p><p id=\"P-0010\" num=\"0010\">[0010]FIG. 1 is a diagram of a cache memory. </p><p id=\"P-0011\" num=\"0011\">[0011]FIG. 2 is a diagram of Least-Recently-Used (LRU) logic. </p><p id=\"P-0012\" num=\"0012\">[0012]FIG. 3 is a logic table describing the operation of way update logic. </p><p id=\"P-0013\" num=\"0013\">[0013]FIG. 4 is a table of instructions that can be used to generate compartment control signals. </p><p id=\"P-0014\" num=\"0014\">[0014]FIG. 5A is a diagram of a cache organization. </p><p id=\"P-0015\" num=\"0015\">[0015]FIG. 5B is a diagram of a cache organization. </p><p id=\"P-0016\" num=\"0016\">[0016]FIG. 5C is a diagram of a cache organization. </p><p id=\"P-0017\" num=\"0017\">[0017]FIG. 5D is a diagram of a cache organization. </p><p id=\"P-0018\" num=\"0018\">[0018]FIG. 6 is a diagram of Least-Recently-Used logic. </p><p id=\"P-0019\" num=\"0019\">[0019]FIG. 7 is a logic table describing the operation of way update logic. </p><p id=\"P-0020\" num=\"0020\">[0020]FIG. 8 is a table of instructions that can be used to generate compartment control signals. </p><p id=\"P-0021\" num=\"0021\">[0021]FIG. 9 is a flow diagram of a computer program in which cache compartmentalization can be used to improve the cache hit-rate. </p><p id=\"P-0022\" num=\"0022\">[0022]FIG. 10 is a flow diagram illustrating one technique for using cache compartment control . </p><p id=\"P-0023\" num=\"0023\">[0023]FIG. 11 is a flow diagram of task switching logic. </p><p id=\"P-0024\" num=\"0024\">[0024]FIG. 12 illustrates a task structure. </p><p id=\"P-0025\" num=\"0025\">[0025]FIG. 13 is a flow diagram of a service for registering a cache compartment mode in a database. </p><p id=\"P-0026\" num=\"0026\">[0026]FIG. 14 is a diagram of a cache memory having alternate way banks. </p><p id=\"P-0027\" num=\"0027\">[0027]FIG. 15 is a system diagram of an apparatus that incorporates the present invention. </p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION </h4><p id=\"P-0028\" num=\"0028\">[0028] The hit-rate of a cache memory is improved in the present invention by compartmentalizing the cache memory under software control. According to one embodiment, special no-operation (NOP) instructions available in existing microprocessors are used to cause compartment control signals to be sent to a cache memory. The compartment control signals are used by cache logic to determine which way of a multiple-way cache should be updated in response to a cache miss. By issuing a NOP instruction that selects a particular way, or group of ways, to be updated in response to a cache miss, a task effectively selects a compartment of the cache in which data and code for that task is to be stored. By coding different tasks (processes or threads) to select different cache compartments, thrashing caused by task switching can be reduced so that a higher cache hit-rate is achieved. Similarly, tasks which must alternately access data located in different regions of system memory can be coded to select respective cache compartments for each region of data to be processed. This technique further reduces thrashing so that a higher cache hit-rate is achieved. </p><p id=\"P-0029\" num=\"0029\">[0029]FIG. 1 is a block diagram of a cache memory <b>5</b> according to one embodiment of the present invention. The cache memory <b>5</b> is a four-way, set-associative cache memory and includes four data ways <b>12</b> for storing data, four tag ways <b>11</b> for storing address tags, comparators <b>14</b>, way select logic <b>9</b>, multiplexer <b>13</b>, logic gates <b>16</b> and <b>17</b> and least-recently-used (LRU) logic <b>7</b>. The four data ways <b>12</b> constitute the data storage of the cache memory and the four tag ways <b>11</b> constitute the tag memory of the cache memory <b>5</b>. </p><p id=\"P-0030\" num=\"0030\">[0030] As shown in FIG. 1, the cache memory <b>5</b> is coupled to an M-bit data path <b>6</b> and an N-bit address path <b>8</b>. The cache memory is also coupled to a control path <b>3</b> that supplies one or more compartment control signals <b>19</b>, a read/write signal (RD/WE*) <b>18</b> indicating whether a read or write is requested, and an output conductor to transmit a hit/miss signal (HIT/M*) <b>20</b> from the cache memory <b>5</b> to an access-requesting device. Other control inputs and outputs may also be provided on control path <b>3</b>. Also, in alternate designs, the hit/miss signal <b>20</b> or the one or more compartment control signals <b>19</b> may be transmitted by conductors that are not included in control path <b>3</b>. </p><p id=\"P-0031\" num=\"0031\">[0031] The data path <b>6</b>, address path <b>8</b> and control path <b>3</b> are typically part of a system bus that intercouples the cache memory <b>5</b> with a microprocessor, a system memory and various other processor-addressable components. Alternatively, the data path <b>6</b>, address path <b>8</b> and control path <b>3</b> may be part of a more limited bus such as a bus dedicated between the cache memory <b>5</b> and a processor. </p><p id=\"P-0032\" num=\"0032\">[0032] Each address asserted on the address path <b>8</b> is an N-bit wide signal that includes a tag, an index and a word-select field. The most significant bits of the address constitute the tag, the next most significant bits of the address constitute the index and the least significant bits of the address constitute the word-select field. </p><p id=\"P-0033\" num=\"0033\">[0033] For each new address received on the address path, the index and word-select portions of the address are asserted to address the data ways <b>12</b>. The index selects a full cache row within each of the data ways <b>12</b> and the word-select bits select a word within the selected cache row. The selected word in each data way <b>12</b> is output to a respective input of the multiplexer <b>13</b>. </p><p id=\"P-0034\" num=\"0034\">[0034] The index portion of each new address received on the address path <b>8</b> is also asserted to address the tag ways <b>11</b>. The index selects one previously stored tag from each tag way <b>11</b>. The selected tags are output by the tag ways <b>11</b> to respective comparators <b>14</b> where they are compared to the tag portion of the address supplied on the address path <b>8</b>. Each of the comparators <b>14</b> outputs a binary signal to the way select logic <b>9</b> indicating whether the previously stored tag matches the tag portion of the address on the address path <b>8</b>. Because tags are stored in a tag way <b>11</b> only if there is a miss, the same tag is not stored in more than one tag way <b>11</b> for a given index. Consequently, at most one of the four comparators <b>14</b> will assert a signal indicating a tag match for any new address received on the address path <b>8</b>. </p><p id=\"P-0035\" num=\"0035\">[0035] If none of the four comparators <b>14</b> indicates a tag match, the way select logic <b>9</b> will output a miss signal (e.g., a logic low level HIT/M* signal) to indicate the tag miss. The miss signal is output by the cache memory <b>5</b> to the processor or bus controller via hit/miss signal conductor <b>20</b> to indicate that system memory must be accessed. The miss signal is also supplied to the LRU logic <b>7</b> to enable the LRU logic <b>7</b> to select one of the four tag ways <b>11</b> to be updated with the missed tag and to select a corresponding one of the four data ways <b>12</b> to receive data corresponding to the missed address. Also, the miss signal is supplied to an input of a logic gate <b>16</b> which outputs a signal to the tri-state buffer <b>17</b> to decouple the output of the multiplexer <b>13</b> from the data path <b>6</b>. This avoids contention on the data path <b>6</b> between data read from system memory and data output by the multiplexer <b>13</b>. </p><p id=\"P-0036\" num=\"0036\">[0036] If one of the four comparators <b>14</b> indicates a tag match, the way select logic <b>9</b> outputs a way select signal indicating which tag way <b>11</b> contains the matching tag. The way select signal is supplied to the input of the multiplexer <b>13</b> to select the output of the data way <b>12</b> corresponding to the tag way <b>11</b> that contains the matching tag. The way select logic <b>9</b> also outputs the hit signal (e.g., a logic high level HIT/M* signal) on hit/miss conductor <b>20</b> to indicate to the processor or bus controller that the cache memory <b>5</b> contains the value corresponding to the accessed memory address. The hit signal is also asserted to the logic gate <b>16</b> which, if a read operation is indicated by read write signal <b>18</b> (i.e., a logic high level RD/WE* signal), outputs a signal to cause the tri-state buffer <b>17</b> to couple the output of the multiplexer <b>13</b> to the data path <b>6</b>. This enables a value from the selected data way <b>12</b> onto the data path <b>6</b> where it can be received in the requesting device. </p><p id=\"P-0037\" num=\"0037\">[0037] If the read/write signal <b>18</b> indicates a data write operation (i.e., alogic low level RD/WE* signal), the output of the multiplexer <b>13</b> is decoupled from the data path <b>6</b> by the tri-state buffer <b>17</b>. Assuming a cache hit, the way select signal is then used to select the data way <b>12</b> to be updated with new data and the tag way <b>11</b> to be updated with the corresponding tag. Additional logic (not shown in FIG. 1) is provided for this purpose. </p><p id=\"P-0038\" num=\"0038\">[0038] As shown in FIG. 1, the index portion of each new address is also received in the LRU logic <b>7</b>. In the event that a cache miss occurs, the LRU logic <b>7</b> determines the data way <b>12</b> least recently accessed at the given index. This way is referred to as the \u201cleast recently used\u201d way. The LRU logic <b>7</b> then outputs a multiple-bit way-update signal to select one of the four data ways <b>12</b> and a corresponding one of the four tag ways <b>11</b> to be written with updated information. According to one embodiment of the present invention, the LRU logic <b>7</b> also receives the one or more compartment control signals <b>19</b> which affect the selection of the data and tag ways to be updated. </p><p id=\"P-0039\" num=\"0039\">[0039]FIG. 2 is a block diagram of the LRU logic <b>7</b> of FIG. 1 according to one embodiment of the present invention. As described above, the LRU logic <b>7</b> receives cache hit/miss signal (HIT/M*) and the index portion of an address. The index is suppled to an LRU memory <b>21</b> that contains a data value, referred to herein as a \u201cLRU code\u201d, indicating the least recently used one of the data ways (e.g., element <b>12</b> of FIG. 1). </p><p id=\"P-0040\" num=\"0040\">[0040] In one type of LRU logic design, called a \u201cpseudo LRU\u201d, the LRU code is made up of a number of bits (k) equal to the number of data ways in the cache memory. Each bit position in the LRU code corresponds to one of the data ways of the cache memory and one bit in each LRU code is set to a state different than all of the other bits to indicate that the indicated data way and its corresponding tag way should be used to receive new data and tag bits, respectively, after a cache miss. The LRU code is then updated to indicate that another one of the ways should be used when the next miss occurs. </p><p id=\"P-0041\" num=\"0041\">[0041] One disadvantage of the pseudo LRU technique is that the LRU code does not indicate the order of all of the ways from most recently used to least recently used. Consequently, after a way indicated to be the least recently used way is updated with new data, there is no indication of which of the remaining ways should become the new least recently used way. One of the remaining ways must be selected at random or according to predetermined logic. </p><p id=\"P-0042\" num=\"0042\">[0042] A true LRU logic design avoids the above-described problem by providing an LRU memory containing enough bits per index to indicate a complete hierarchy of the ways from most recently used to least recently used. This information is then used select the next least recently used way after every cache update. The present invention may be used in combination with any technique for selecting a way to update in response to a cache miss, including the pseudo and true LRU techniques. For the sake of simplicity, however, a pseudo LRU scheme is assumed in the following description. </p><p id=\"P-0043\" num=\"0043\">[0043] As shown in FIG. 2, the LRU code output by the LRU memory <b>23</b> and the hit/miss signal HIT/M* are input to LRU way update logic <b>23</b>. The LRU way update logic <b>23</b> also receives compartment control signals (e.g., element <b>19</b> of FIG. 1) which, according to one embodiment of the present invention, include a compartment enable signal CE and one or more (r) compartment select signals CS. As discussed further below, the compartment enable CE and compartment select CS signals are determined by software execution so that computer programmers can specify compartments within the cache in which frequently accessed data and code is to be stored. This can significantly reduce cache thrashing that otherwise occurs when task switching takes place and when programs access separately located code stores or data stores. </p><p id=\"P-0044\" num=\"0044\">[0044]FIG. 3 depicts a logic table <b>27</b> that describes the logical operation of the LRU way update logic <b>23</b> of FIG. 2. The logic table <b>27</b> lists an exemplary set of inputs to the LRU way update logic, including a compartment enable signal CE, two compartment select signals CS<b>1</b> and CS<b>0</b>, and a LRU code having constituent signals LCode<b>3</b>, LCode<b>2</b>, LCode <b>1</b> and LCode<b>0</b>. The outputs listed in the logic table represent an exemplary set of outputs from the LRU way update logic, including way update signals WU<b>3</b>, WU<b>2</b>, WU<b>1</b> and WU<b>0</b>. </p><p id=\"P-0045\" num=\"0045\">[0045] As indicated in the first four rows of the logic table <b>27</b>, when the compartment enable signal CE is deasserted (as indicated by a \u201c0\u201d), the state of the compartment select signals CS<b>1</b> and CS<b>0</b> do not affect the state of outputs WU<b>3</b>-WU<b>0</b>. Consequently, in the first four rows of the logic table <b>27</b>, CS<b>1</b> and CS<b>0</b> are indicated to have state X, indicating that they may be in any state. </p><p id=\"P-0046\" num=\"0046\">[0046] When the compartment enable signal CE is deasserted, outputs WU<b>3</b>-WU<b>0</b> are determined by the LRU code. Thus, in the first row, when signal LCode<b>0</b> is asserted (indicated by a \u201c1\u201d in the logic table <b>27</b>), WU<b>0</b> is asserted at the LRU logic output to select data way 0 and tag way 0 to be updated. Similarly, as shown in the second, third and fourth rows of the table, assertion of LCode<b>1</b>, LCode<b>2</b> and LCode<b>3</b> results in WU<b>1</b>, WU<b>2</b> and WU<b>3</b>, respectively, being asserted at the LRU logic output. In other words, so long as the compartment enable signal CE is deasserted, whichever way is indicated by the LRU code to be the least recently used is selected to be updated in response to the cache miss. In the logic table <b>27</b>, the bits of the LRU code have arbitrarily been prioritized so that if more than one bit of the LRU code is set, LCode<b>0</b> takes priority over LCode<b>1</b> which takes priority over LCode<b>2</b> which takes priority over LCode<b>3</b>. Other priority schemes could be used. </p><p id=\"P-0047\" num=\"0047\">[0047] In the bottom four rows of the logic table, the compartment enable signal CE is asserted and the way to update is determined based on the compartment select signals CS<b>1</b> and CS<b>0</b>. According to one embodiment of the present invention, a simple binary code is used so that the value of the compartment select signals CS<b>1</b> and CS<b>0</b>, taken together (i.e., 00=0, 01=1, 10=2, 11=3), indicates the way to update. Thus, for each different combination of compartment select signals CS<b>1</b> and CS<b>0</b> a different way update output is asserted. Assertion of the compartment enable signal CE effectively overrides the least recently inputs LCode<b>3</b>-LCode<b>0</b> so that the state of those inputs is indicated to be \u201cX\u201d. </p><p id=\"P-0048\" num=\"0048\">[0048]FIG. 4 is a table <b>28</b> of instructions that can be used to generate the compartment control signals discussed in reference to FIG. 2 and FIG. 3. According to one embodiment of the present invention, an instruction indicating a write operation to a read-only register within a processor is used to implement compartment control. For example, register R<b>0</b> is a read-only register within microprocessors from Intel Corporation. Ordinarily, attempting to write a value to register R<b>0</b> has no effect on the processor state and is considered a NOP instruction (i.e., no-operation). However, by providing logic within the microprocessor to detect an attempt to write to register R<b>0</b> and then to output compartment control signals based on the operand being written, it becomes possible to write program code that issues cache compartment control instructions in the modified microprocessor, but which has no effect in existing microprocessors. In other words, program code which includes the compartment control instructions may be executed by microprocessors that do not support compartment control without adverse effect. It will be appreciated that, rather than use presently available instructions in the manner described above, new instructions could also be added to an existing instruction set to provide cache compartment control. </p><p id=\"P-0049\" num=\"0049\">[0049] Still referring to FIG. 4, the operation indicated by each instruction and the compartment control signals that result from execution of the instruction are shown. Referring to the first row of table <b>28</b>, for example, instruction OUT R<b>0</b>, 0 indicates that the value 0 is to be transferred to register R<b>0</b>. As discussed above, because register R<b>0</b> is a read-only register, the contents of register R<b>0</b> are unaffected by this operation. However, in the modified processor architecture described above, execution of this instruction causes the processor to assert a compartment enable signal (e.g., CE=1) and to assert compartment select signals (CS<b>1</b>=0, CS<b>0</b>=0) that select cache data way 0 to be the cache compartment. After a cache miss, data way 0 is selected to receive updated data and tag way 0 is selected to receive the missed tag. </p><p id=\"P-0050\" num=\"0050\">[0050] According to one embodiment of the present invention, the operand attempted to be written to register R<b>0</b> is used to indicate different compartment control modes. Thus, for each successive instructions listed in table <b>28</b>, the value of the operand to be written to register R<b>0</b> is incremented. When the Out R<b>0</b> instruction is executed with an operand of 1, the compartment enable signal is asserted and compartment select signals are output to enable way 1 to be the cache compartment; when the operand is 2, the compartment enable signal is asserted and compartment select signals are output to select way 2 to be the cache compartment; when the operand is 3, the cache compartment enable signal is asserted and compartment select signals are output to select way 3 to be the cache compartment; and when the operand is 04, the compartment enable signal is deasserted (CE=0) to disable cache compartmentalization and to allow the least recently used logic to determine which way to be updated after a cache miss. Operands higher than 04 may default to one of the states described above (e.g., compartmentalization off) or may be reserved for expanded compartmentalization features. </p><p id=\"P-0051\" num=\"0051\">[0051] Although in the above-described embodiment of the present invention the cache compartments are of equal size and correspond to respective cache ways, it may be desirable to have cache compartments of different sizes. For example, if a computer programmer recognizes in advance that one task (or program operation) will require significantly more memory access than another task, the programmer may want to allocate a larger cache compartment to the more memory intensive task and a smaller cache compartment to the less memory intensive task. </p><p id=\"P-0052\" num=\"0052\">[0052]FIG. 5A, FIG. 5B, FIG. 5C and FIG. 5D illustrate different cache organizations that can be used to implement varied cache compartment sizes according to one embodiment of the present invention. The different cache organizations are referred to as compartment patterns and are selected by compartment organization signals (CO). Referring to FIG. 5A, for example, with CO signals set to 0,0, a cache compartment organization is selected in which each of the ways of a four-way cache is allocated to a respective cache compartment. As indicated in FIG. 5A, compartment select signals CS=00, 01, 10 and 11 select compartments 0, 1, 2 and 3, respectively. The compartment pattern depicted in FIG. 5A is referred to as compartment pattern 0 and is equivalent to the four compartment scheme described above in reference to FIG. 2 and FIG. 3. </p><p id=\"P-0053\" num=\"0053\">[0053]FIG. 5B illustrates compartment pattern 1, which is selected when cache organization signals CO are set to 0,1. In compartment pattern 1, way 0 is allocated to compartment 0, way 1 is allocated to compartment 1 and ways 2 and 3 are allocated to compartment 2. As a result, three cache compartments are provided with one cache compartment being twice the size of either of the other two compartments. Compartment select signals CS=00, 01 and 10 select compartments 0, 1 and 2, respectively. </p><p id=\"P-0054\" num=\"0054\">[0054]FIG. 5C illustrates compartment pattern 2, which is selected when cache organization signals are set to 1,0. In compartment pattern 2, way 0 is allocated to compartment 0 and ways 1, 2 and 3 are allocated to compartment 1. Thus, two cache compartments are provided with one cache compartment being three times the size of the other. Compartment select signals CS=00, and 01 select compartments 0 and 1, respectively. </p><p id=\"P-0055\" num=\"0055\">[0055]FIG. 5D illustrates compartment pattern 3, which is selected when cache organization signals are set to 1,1. In compartment pattern 3, two equally sized compartments are provided: compartment 0 to which ways 0 and 1 are allocated, and compartment 1 to which ways 2 and 3 are allocated. Compartment select signals CS=00, and 01 select compartments 0 and 1, respectively. </p><p id=\"P-0056\" num=\"0056\">[0056] It will be appreciated that the number of different compartment patterns that can be achieved increases with the number of ways in a multiple-way cache. Also, while a way-based allocation scheme has been described, any technique for allocating memory within the cache to different cache compartments that can be selected under software control is within the spirit and scope of the present invention. </p><p id=\"P-0057\" num=\"0057\">[0057]FIG. 6 is a diagram of LRU logic <b>31</b> that can be used to support the software-selectable compartment patterns shown in FIG. 5A, FIG. 5B, FIG. 5C and FIG. 5D. The LRU logic <b>31</b> is similar to the LRU logic <b>7</b> described in reference to FIG. 2, except that, instead of receiving a compartment enable signal, the LRU logic <b>31</b> receives one or more (p) compartment organization signals (CO). The compartment organization signals are supplied to the LRU way update logic <b>33</b> and determine whether cache compartmentalization is enabled and, if so, which cache compartment pattern to use (e.g., compartment pattern 0, 1, 2 or 3, described above). </p><p id=\"P-0058\" num=\"0058\">[0058]FIG. 7 is a logic table <b>36</b> that describes the operation of the LRU way update logic <b>33</b> of FIG. 6. According to one embodiment of the present invention, the LRU way update logic receives two cache organization signals, CO<b>1</b> and CO<b>0</b>, two compartment select signals, CS<b>1</b> and CS<b>0</b>, and four LRU code signals LCode<b>3</b>, LCode<b>2</b>, LCode<b>1</b> and LCode<b>0</b>. If a cache miss occurs, the LRU way update logic asserts one of four way update outputs, WU<b>3</b>, WU<b>2</b>, WU<b>1</b> or WU<b>0</b>, to enable a cache data way and its corresponding cache tag way to be updated. </p><p id=\"P-0059\" num=\"0059\">[0059] For rows <b>1</b>-<b>4</b> of the logic table, the cache organization signals CO<b>1</b> and CO<b>0</b> are both set to zero, thereby selecting compartment pattern 0. As discussed above, each of the four cache ways is allocated to a respective one of four compartments in compartment pattern 0. Consequently, the compartment select signals CS<b>1</b> and CS<b>0</b> determine which way is updated after a cache miss. Thus: </p><p id=\"P-0060\" num=\"0060\">[0060] if CS<b>1</b>,CS<b>0</b>=0,0 compartment 0 is selected and way update signal WU <b>0</b> is asserted to enable way 0 to be updated; </p><p id=\"P-0061\" num=\"0061\">[0061] if CS<b>1</b>,CS<b>0</b>=0,1 compartment 1 is selected and way update signal WU <b>1</b> is asserted to enable way 1 to be updated; </p><p id=\"P-0062\" num=\"0062\">[0062] if CS<b>1</b>,CS<b>0</b>=1,0 compartment 2 is selected and way update signal WU <b>2</b> is asserted to enable way 2 to be updated; and </p><p id=\"P-0063\" num=\"0063\">[0063] if CS<b>1</b>,CS<b>0</b>=1,1 compartment 3 is selected and way update signal WU <b>3</b> is asserted to enable way 3 to be updated. </p><p id=\"P-0064\" num=\"0064\">[0064] So long as compartment pattern 0 is selected (i.e., CO<b>1</b>, CO<b>0</b>=0,0), the LRU code (inputs LCode<b>3</b>-LCode<b>0</b>) has no effect on the way selected to be updated. </p><p id=\"P-0065\" num=\"0065\">[0065] For rows <b>5</b>-<b>12</b> of the logic table, cache organization signals CO<b>1</b> and CO<b>0</b> are set to 0 and 1, respectively, thereby selecting compartment pattern 1. Referring to FIG. 5B, compartment pattern 1 contains three compartments, with way 0 being allocated to compartment 0, way 1 being allocated to compartment 1, and ways 2 and 3 being allocated to compartment 2. Consequently: </p><p id=\"P-0066\" num=\"0066\">[0066] if CS<b>1</b>,CS<b>0</b>=0,0 compartment 0 is selected and way update signal WU <b>0</b> is asserted to enable way 0 to be updated; </p><p id=\"P-0067\" num=\"0067\">[0067] if CS<b>1</b>,CS<b>0</b>=0,1 compartment 1 is selected and way update signal WU <b>1</b> is asserted to enable way 1 to be updated; and </p><p id=\"P-0068\" num=\"0068\">[0068] if CS<b>1</b>,CS<b>0</b>=1,0 compartment 2 is selected and either way update signal WU<b>2</b> or WU<b>3</b> is asserted. </p><p id=\"P-0069\" num=\"0069\">[0069] Note that when compartment 2 is selected (CS<b>1</b>, CS<b>0</b>=1,0), then a determination must be made of which way (way 2 or way 3) within compartment 2 should be updated. According to one embodiment of the present invention, way 2 is the default way to update unless the LRU code indicates that way 3 is the least recently used way. Thus, way update signal WU<b>2</b> is asserted to enable way 2 to be updated if the LRU code indicates that way 3 is not the least recently updated way (i.e., LCode<b>3</b>=0). If, on the other hand, the LRU code indicates that way 3 is the least recently updated way, way update signal WU<b>3</b> is asserted to enable way 3 to be updated. It will be appreciated that other techniques may be used to determine which way of a multiple-way compartment should be updated. </p><p id=\"P-0070\" num=\"0070\">[0070] Because compartment pattern 1 contains only three compartments, compartments 0, 1 and 2, then an attempt to select a fourth compartment by setting CS<b>1</b>, CS<b>0</b> is invalid. Consequently such an attempt can be used for other purposes, such as disabling cache compartmentalization. More generally, when CS<b>1</b> and CS<b>0</b> select a compartment that is not present in the compartment pattern indicated by compartment organization signals CO<b>1</b> and CO<b>0</b>, the LRU way update logic may default to the least recently used logic described above. Referring, for example to rows <b>9</b>-<b>12</b> of the logic table, because CS<b>1</b> and CS<b>0</b> indicate a compartment (compartment 3) which is not included in compartment pattern 1, the LRU code inputs, LCode<b>3</b>, LCode<b>2</b>, LCode<b>1</b> and LCode<b>0</b> are relied upon to determine which way to update. This logic is as described above in reference to FIG. 3 when the compartment enable signal (CE) is deasserted. </p><p id=\"P-0071\" num=\"0071\">[0071] Referring now to rows <b>13</b>-<b>16</b> of the logic table, cache organization signals CO<b>1</b> and CO<b>0</b> are set to 1 and 0, respectively, thereby selecting compartment pattern 2. Referring to FIG. 5C, compartment pattern 2 contains two compartments, with way 0 being allocated to compartment 0 and ways 1, 2 and 3 being allocated to compartment 1. Consequently: </p><p id=\"P-0072\" num=\"0072\">[0072] if CS<b>1</b>,CS<b>0</b>=0,0 compartment 0 is selected and way update signal WU <b>0</b> is asserted to enable way 0 to be updated; and </p><p id=\"P-0073\" num=\"0073\">[0073] if CS<b>1</b>,CS<b>0</b>=0,1 compartment 1 is selected and either way update signal WU<b>1</b>, WU<b>2</b> or WU<b>3</b> is asserted. </p><p id=\"P-0074\" num=\"0074\">[0074] When compartment 1 is selected (CS<b>1</b>, CS<b>0</b>=0,1), then a determination must be made of which way (way 1, way 2 or way 3) within compartment 1 should be updated. According to one embodiment of the present invention, way 1 is the default way to update unless the LRU code indicates that either way 2 or way 3 is the least recently used way. If way 2 is the least recently used way, then signal WU<b>2</b> is asserted to enable way 2 to be updated. Otherwise, if way 3 is the least recently used way, then signal WU<b>3</b> is asserted to enable way 3 to be updated. As stated above, other techniques may be used to determine which way of a multiple-way compartment should be updated. </p><p id=\"P-0075\" num=\"0075\">[0075] Momentarily skipping rows <b>17</b>-<b>20</b> of the logic table and referring to rows <b>21</b>-<b>24</b>, cache organization signals CO<b>1</b> and CO<b>0</b> are both set to 1, thereby selecting compartment pattern 3. Referring to FIG. 5D, compartment pattern 3 contains two compartments with ways 0 and 1 being allocated to compartment 0 and ways 2 and 3 being allocated to compartment 1. Consequently: </p><p id=\"P-0076\" num=\"0076\">[0076] if CS<b>1</b>,CS<b>0</b>=0,0 compartment 0 is selected and either way update signal WU<b>0</b> or WU<b>1</b> is asserted; and </p><p id=\"P-0077\" num=\"0077\">[0077] if CS<b>1</b>,CS<b>0</b>=0,1 compartment 1 is selected and either way update signal WU<b>2</b> or WU<b>3</b> is asserted. </p><p id=\"P-0078\" num=\"0078\">[0078] When compartment 0 is selected (CS<b>1</b>, CS<b>0</b>=0,0), then it must be determined whether to update way 0 or way 1. Likewise, when compartment 1 is selected, then a determination of whether to update way 2 or way 3 must be made. According to one embodiment of the present invention, when compartment 0 is selected, way 0 is updated unless the LRU code indicates that way 1 is the least recently used way. If the LRU code indicates that way 1 is the least recently used way (i.e., LCode<b>1</b>=1), then way 1 is updated. Similarly, when compartment 1 is selected, way 2 is the default way to update unless the LRU code indicates that way 3 is the least recently used way. If the LRU code indicates that way 3 is the least recently used way (i.e., LCode<b>3</b>=1), then way 3 is updated. Again, other techniques may be used to determine which way of a multiple-way compartment should be updated. </p><p id=\"P-0079\" num=\"0079\">[0079] Returning now to rows <b>17</b>-<b>20</b> of the logic table, because compartment patterns 2 and 3 each have only two compartments (viz., compartments 0 and 1), then whenever either compartment pattern 2 or 3 is selected (i.e., CO<b>1</b>=1, CO<b>0</b>=X), a compartment selection of 2 or 3 (i.e., CS<b>1</b>=1, CS<b>0</b>=X) is invalid. This condition is shown in rows <b>17</b> to <b>20</b>. According to one embodiment of the present invention, whenever compartment 2 or 3 is selected for compartment pattern 2 or 3, cache compartmentalization is disabled. When cache compartmentalization is disabled, the LRU way update logic defaults to the least recently used logic described above in reference to FIG. 3 when the compartment enable signal (CE) is deasserted. </p><p id=\"P-0080\" num=\"0080\">[0080]FIG. 8 is a table <b>38</b> of instructions that can be used to generate the compartment control signals described in reference to FIG. 6 and FIG. 7. As in above-described embodiments, instructions specifying a write operation to a read-only register (e.g., register R<b>0</b>) are used to implement compartment control. Other techniques may be used. </p><p id=\"P-0081\" num=\"0081\">[0081] One assembly language instruction is listed in each row of the table. Beside the instruction is the indicated operation, and the compartment control signals that are output when the instruction is executed. As discussed above, because a read-only register is selected to be written, execution of the instruction is effectively a NOP for microprocessors which do not support compartment control. However, a microprocessor having an architecture modified according to the present invention detects the attempts to write to register R<b>0</b> and asserts compartment control signals according to the operand to be written. For example, instruction OUT R<b>0</b>, 0 indicates that the value 0 is to be transferred to register R<b>0</b>. When executed, this instruction has no effect on microprocessors that do not support compartment control. However, in a microprocessor modified according to the present invention, execution of OUT R<b>0</b>, 0 causes the microprocessor to output compartment control signals specifying compartment pattern 0 (CO<b>1</b>,CO<b>0</b>=0,0) and compartment select signals selectig compartment 0 (CS<b>1</b>,CS<b>0</b>=0,0). As indicated in the table of FIG. 8, when the OUT R<b>0</b> instruction is executed: </p><p id=\"P-0082\" num=\"0082\">[0082] operand 00 selects compartment pattern 0, compartment 0; </p><p id=\"P-0083\" num=\"0083\">[0083] operand 01 selects compartment pattern 0, compartment 1; </p><p id=\"P-0084\" num=\"0084\">[0084] operand 02 selects compartment pattern 0, compartment 2; </p><p id=\"P-0085\" num=\"0085\">[0085] operand 03 selects compartment pattern 0, compartment 3; </p><p id=\"P-0086\" num=\"0086\">[0086] operand 04 selects compartment pattern 1, compartment 0; </p><p id=\"P-0087\" num=\"0087\">[0087] operand 05 selects compartment pattern 1, compartment 1; </p><p id=\"P-0088\" num=\"0088\">[0088] operand 06 selects compartment pattern 1, compartment 2; </p><p id=\"P-0089\" num=\"0089\">[0089] operand 07 selects compartment pattern 2, compartment 0; </p><p id=\"P-0090\" num=\"0090\">[0090] operand 08 selects compartment pattern 2, compartment 1; </p><p id=\"P-0091\" num=\"0091\">[0091] operand 09 selects compartment pattern 3, compartment 0; and </p><p id=\"P-0092\" num=\"0092\">[0092] operand 0A (hex) selects compartment pattern 3, compartment 1. </p><p id=\"P-0093\" num=\"0093\">[0093] According to one embodiment of the present invention, cache compartmentalization is disabled when OUT R<b>0</b>, B(hex) is executed. One way to signal the cache memory that compartmentalization is disabled is to issue compartment select signals that select an invalid compartment. This is shown in the last line of the table where a compartment pattern having only two compartments is specified (compartment pattern 3) and yet compartment 3 is selected by the compartment select signals. </p><p id=\"P-0094\" num=\"0094\">[0094]FIG. 9 illustrates the flow and memory access of a computer program <b>41</b> in which cache compartments may be used to improve the cache hit-rate. The program <b>41</b> consists of an event loop <b>43</b> that is repeatedly executed to determine whether certain events have occurred. This construct is commonly used in application programs which must interact with a user. If an event is detected, program execution branches to perform processing required by the event. Because the events requiring processing are often user-initiated, it is undesirable for program execution to become hung up processing any one event for too long. Otherwise, there can be a noticeable delay before other user-initiated events are detected, causing the system to seem sluggish and unresponsive. Consequently, when an event requiring extensive code execution or time-consuming operations is detected, it is common to execute only a portion of the required processing for each pass through the event loop. The effect is a sort of task or context switching which tends to cause cache thrashing. </p><p id=\"P-0095\" num=\"0095\">[0095] As shown at step <b>47</b> of program <b>41</b>, when event 1 is detected, program execution branches to step <b>48</b> to execute program code stored in the region of memory labeled CODE<b>1</b>. Execution of CODE<b>1</b> results in operation on data stored in memory region DATA<b>1</b>. Access to CODE<b>1</b> and DATA<b>1</b> will cause data from those regions of memory to be cached in the computer system's cache memory. As an aside, it will be appreciated that both program code and program data is cached in the cache memory. From the standpoint of the cache memory however, the program code and the program data are both forms of data and are referred to collectively herein simply as \u201cdata\u201d. </p><p id=\"P-0096\" num=\"0096\">[0096] Suppose now that, after completing a portion of the processing required by event 1 (i.e., after completing step <b>48</b>), program execution returns to the event loop <b>43</b> and event 2 is detected at step <b>49</b>. Now the processing (step <b>50</b>) required by event 2 requires access to memory regions CODE<b>2</b> and DATA<b>2</b> so that a substantial number of cache miss/update operations are likely to occur. Similarly, if, after completing a portion of the processing required by event 2 at step <b>50</b>, event 3 is detected at step <b>51</b>, then values from memory regions CODE<b>2</b> and DATA<b>2</b> are likely to be replaced in the cache by values from memory regions CODE<b>3</b> and DATA<b>3</b> during processing step <b>52</b>. When the processing required by event 1 is resumed at step <b>48</b>, values from memory regions CODE<b>3</b> and DATA<b>3</b> will be replaced by values from memory regions CODE<b>1</b> and DATA<b>1</b>, and so forth. </p><p id=\"P-0097\" num=\"0097\">[0097]FIG. 10 is a flow diagram <b>60</b> illustrating one technique for using cache compartment control to reduce cache thrashing and to improve the overall cache hit-rate. The flow diagram <b>60</b> corresponds to a portion of the processing peformed, for example, at step <b>48</b> of FIG. 9. At step <b>61</b> a value indicating a present cache compartment mode (CCM) is read. The CCM value may be a globally accessible data value or may be obtained by a invoking a procedure or method. At step <b>63</b> the CCM value is stored for later recall. At step <b>65</b>, a new cache compartment mode is established. According to one embodiment of the present invention, this is accomplished by executing one or more instructions that cause the processor to issue compartment control signals to the cache memory and then by setting the CCM value to indicate that a new cache compartment mode has been set. If a cache miss occurs after step <b>65</b> is completed, updated data will be stored in a cache compartment according to the new cache compartment mode. </p><p id=\"P-0098\" num=\"0098\">[0098] After a cache compartment has been selected, the procedure body is executed at step <b>67</b>. After step <b>67</b> is completed, the cache compartment mode is restored at step <b>69</b>. According to one embodiment of the present invention, the cache compartment mode is restored by reading the original CCM value from its temporary storage location, executing instructions to cause the processor to issue the necessary compartment control signals, then writing the original CCM value back to the globally accessible location (again, either via global variable access or via a procedure or method call). </p><p id=\"P-0099\" num=\"0099\">[0099] By selecting a different cache compartment in response to each of the three events (<b>47</b>, <b>49</b>, <b>51</b>) described in reference to FIG. 9, cache thrashing can be reduced and a higher overall cache hit-rate achieved. </p><p id=\"P-0100\" num=\"0100\">[0100]FIG. 11 illustrates another embodiment of the present invention that provides software-controlled cache compartmentalization. In an operating system (OS) that implements task switching (the tasks being processes, threads or both), the individual tasks often access different regions of memory to obtain code and data. As shown in FIG. 11, for example, if tasks 1, 2, 3 . . . N are being concurrently executed, task 1 may access regions code<b>1</b> and data<b>1</b>, task <b>2</b> may access regions code<b>2</b> and data <b>2</b>, task 3 may access regions code <b>3</b> and data <b>3</b> and so forth. Consequently, when the operating system suspends one task and begins or resumes execution of a another task, a significant number of cache misses will occur and data cached during execution of the suspended task will be kicked out of the cache. Later when the suspended task is resumed, cache misses will occur again and data cached for previously executing tasks will be kicked out. In other words, task switching results in significant cache thrashing and lowers the cache hit-rate. </p><p id=\"P-0101\" num=\"0101\">[0101] According to one embodiment of the present invention, the task switching logic (code) within the operating system or an extension of the operating system is modified to provide cache compartment control. This is shown by the flow diagram <b>72</b> in FIG. 11. At step <b>73</b>, after a task switch event occurs (commonly a processor interrupt), the currently executing task is suspended. At step <b>75</b>, the next task to be executed is identified. At step <b>77</b>, the cache compartment mode is set based on a value stored in a cache compartment data base <b>80</b>. The cache compartment database <b>80</b> is indexed based on a task identifier and returns a previously stored CCM value for the task. According to an embodiment of the present invention discussed below, the cache compartment database <b>80</b> is populated with new CCM values by a task registration procedure that is invoked when a task is intially executed. If initial execution of a task has not yet begun, this fact may be indicated by the cache compartment database <b>80</b> so that when the task is first started by the task switching logic, either no change to the present cache compartment mode is made or a default cache compartment setting is issued. At step <b>79</b>, execution of the identified task is begun or resumed, as the case may be. </p><p id=\"P-0102\" num=\"0102\">[0102]FIG. 12 illustrates a task structure according to one embodiment of the present invention. The task includes three components: an initialization component <b>87</b>, a task body <b>89</b> and a termination component <b>91</b>. Typically, the initialization component <b>87</b> of a task is executed only upon initial invocation of the task, and the task body continues to execute (for example in an event loop) until a termination event is detected. The task terminates in response to the termination event. </p><p id=\"P-0103\" num=\"0103\">[0103] According to one embodiment of the present invention, each task is programmed to register a desired cache compartment mode (CCM) value in a database maintained by the operating system or an extension of the operating system. As discussed above, the stored CCM value is then used by the task switching logic of the OS to implement the desired compartment control whenever the task is selected for execution. As indicated in FIG. 12, the task registers the CCM value during initialization <b>87</b> by calling an operating system service called, for example, \u201cRegisterCCM\u201d, passing the desired CCM value and a task identifier as arguments. Other techniques may be used to register the CCM value without departing from the spirit and scope of the present invention. </p><p id=\"P-0104\" num=\"0104\">[0104]FIG. 13 is a flow diagram of the RegisterCCM service according to one embodiment of the present invention. A CCM value and task identifier are received as input parameters and, at step <b>95</b>, the CCM value is written into the cache compartment data base (e.g., element <b>80</b> of FIG. 11) at a location indicated by the task identifier. Then, at step <b>97</b>, one or more instructions are executed to cause the processor to output the compartment control signals indicated by the CCM value. </p><p id=\"P-0105\" num=\"0105\">[0105]FIG. 14 illustrates an alternate embodiment of the present invention in which a bank select signal <b>103</b> is included with the compartment control signals. Depending on the state of the bank select signal <b>103</b>, alternate banks of tag and data ways are used to implement the cache memory. For example, when the bank select signal <b>103</b> is in a first state, the output of data ways 0 through N (<b>105</b> and <b>107</b>) are routed by bank select multiplexers <b>115</b> to the input of a way select multiplexer <b>116</b>. When the bank select signal is in a second state, the output of data ways 0\u2032 through N\u2032 (<b>109</b> and <b>111</b>) are instead output by the bank select multiplexers <b>115</b> to the way select multiplexer <b>116</b>. Additional logic (not shown) is provided to select, based on the bank select signal, between tag ways 0 through N (<b>106</b> and <b>108</b>) and tag ways 0\u2032 through N\u2032 (<b>110</b> and <b>112</b>) to perform the tag compare function. </p><p id=\"P-0106\" num=\"0106\">[0106] One advantage to the selectable way bank design of FIG. 14 is that different sized data ways may be used to implement the various cache compartments. This approach allows programmers to select compartments in the cache memory based on cache requirements of the task being programmed. For tasks requiring extensive memory access a larger task compartment may be selected by including instructions which indicate the appropriate bank selection. Then, when a task that requires less memory access is executed, the bank selection could be dynamically switched (i.e., switched during run-time) to allow selection of a smaller cache compartment. </p><p id=\"P-0107\" num=\"0107\">[0107]FIG. 14 illustrates a configuration in which data ways 0 through N (<b>105</b> and <b>107</b>) are larger than data ways 0\u2032 through N\u2032 (<b>109</b> and <b>111</b>). The size of the corresponding tags ways is also different. This is because tag way 0 (<b>106</b>) is addressed by a larger index field than tag way 0\u2032 (<b>110</b>), so that the number of bits in the tags stored in tag way 0 (<b>106</b>) is correspondingly smaller than the number of bits in the tags stored in tag way 0\u2032 (<b>110</b>). </p><p id=\"P-0108\" num=\"0108\">[0108]FIG. 15 is a system-level diagram of an apparatus <b>112</b> according to one embodiment of the present invention. The apparatus <b>112</b> includes a processor <b>121</b>, cache memory <b>5</b>, system memory <b>131</b>, non-volatile memory <b>133</b> and one or more I/O devices <b>123</b>, all intercoupled by a system bus <b>125</b>. The processor <b>121</b> includes the above described logic to detect execution of cache compartment instructions and to issue compartment control signals to the cach memory <b>5</b>. According to one embodiment of the present invention, the cache control signals are supplied to the cache memory <b>5</b> via conductors included in the system bus <b>125</b>. </p><p id=\"P-0109\" num=\"0109\">[0109] Although the cache memory <b>5</b> is illustrated as being coupled to the system bus <b>125</b>, the cache memory <b>5</b> may also be connected to the processor <b>121</b> via a dedicated bus (e.g., a \u201cbackside bus\u201d). Further, the cache memory <b>5</b> may be included in the processor <b>121</b> as a read/write or read-only cache (e.g., an instruction cache). </p><p id=\"P-0110\" num=\"0110\">[0110] The apparatus <b>112</b> may be a general purpose computer, camera, data recording device, cellular telephone, electronic note-pad or any other device that processes data. In the case of a personal computer, the non-volatile memory <b>133</b> typically is used to store a boot program which is executed to load additional program code from one of the I/O devices <b>123</b> such as a magnetic or optical disk drive into system memory <b>131</b>. In another device, such as a cellular telephone, the non-volatile memory <b>133</b> may include the entire operating program for the device. </p><p id=\"P-0111\" num=\"0111\">[0111] The I/O devices <b>123</b> will vary depending on the functionality required by the apparatus <b>112</b>. In the case of a telephone, the processor <b>121</b> may be a microcontroller, and the I/O devices <b>123</b> may include signal generation and reception circuitry, a keypad, speaker and microphone. In a general purpose computer the I/O devices <b>123</b> would typically include user input devices such as a keyboard and mouse, a display device, one or more mass storage devices, a network connection device such as an area-network connection card or a modem, and any other device needed to support application programs executed by the computer. Application programs containing instructions to control cache compartmentalization in accordance with the present invention may be stored on a computer-readable medium that can be accessed by the processor via an appropriate one of the I/O devices <b>123</b>. Program code containing instructions to control cache compartmentalization in accordance with the present invention may also be received in a network connection device via a carrier wave having the program code embodied therein. In other implementations, apparatus <b>112</b> may include additional I/O devices <b>123</b> coupled to the bus to provide application-specific functionality. </p><p id=\"P-0112\" num=\"0112\">[0112] In the foregoing specification, the invention has been described with reference to specific exemplary embodiments thereof. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are, accordingly to be regarded in an illustrative rather than a restrictive sense. </p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Shine", "last_name": "Chung", "name": ""}], "assignees": [{"first_name": "", "last_name": "SONY CORPORATION OF AMERICA", "name": ""}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/08"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/12        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711128"}, {"primary": false, "label": "711E12077"}, {"primary": false, "label": "711136"}], "ecla_classes": [{"label": "G06F  12/12B8"}], "cpc_classes": [{"label": "G06F  12/128"}], "f_term_classes": [], "legal_status": "Granted", "priority_date": "1997-09-30", "application_date": "1997-09-30", "family_members": [{"ucid": "US-20010011328-A1", "titles": [{"lang": "EN", "text": "SOFTWARE-CONTROLLED CACHE MEMORY COMPARTMENTALIZATION"}]}, {"ucid": "US-6434671-B2", "titles": [{"lang": "EN", "text": "Software-controlled cache memory compartmentalization"}]}]}