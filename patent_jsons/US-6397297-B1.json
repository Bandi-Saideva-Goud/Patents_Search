{"patent_number": "US-6397297-B1", "publication_id": 73041919, "family_id": 23884910, "publication_date": "2002-05-28", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operation modes"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50326622\"><p>A computer system having cache modules interconnected in series includes a first and a second cache module directly coupled to an address generating line for parallel lookup of data and data conversion logic coupled between the first cache module and said second cache module.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00001\" num=\"1\"><claim-text>1. A computer system having cache modules interconnected in series comprising:</claim-text><claim-text>a first and a second cache module directly coupled to an address generating line for parallel lookup of data; and </claim-text><claim-text>data conversion logic coupled between said first cache module and said second cache module, said data conversion logic configured to convert the data from a first data type of the first cache module to a second data type of the second cache module. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00002\" num=\"2\"><claim-text>2. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein said first cache module is coupled to a data generating line and said second cache module is coupled to an output from said first cache module.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00003\" num=\"3\"><claim-text>3. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, further comprising a hit/miss generating line coupled between said first and second cache modules wherein said hit/miss generating line sends an indication whether data is found in said second cache module.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00004\" num=\"4\"><claim-text>4. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein said first cache module is a level <b>2</b> (L<b>2</b>) cache.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00005\" num=\"5\"><claim-text>5. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein said second cache module is a level <b>1</b> (L<b>1</b>) cache.</claim-text></claim>"}, {"num": 6, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00006\" num=\"6\"><claim-text>6. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00003\">claim 3</claim-ref>, wherein if a hit occurs in said second cache module, an indication is send to said first cache module via said hit/miss generating line.</claim-text></claim>"}, {"num": 7, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00007\" num=\"7\"><claim-text>7. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein if a miss occurs in said second cache module and said first cache module, the data is provided from a memory of the computer system to said first cache module.</claim-text></claim>"}, {"num": 8, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00008\" num=\"8\"><claim-text>8. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein after the data is provided from a memory of the computer system to said first cache module, said data is converted.</claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00009\" num=\"9\"><claim-text>9. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00008\">claim 8</claim-ref>, wherein after data is converted, said data is provided to said second cache module.</claim-text></claim>"}, {"num": 10, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00010\" num=\"10\"><claim-text>10. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein if a hit occurs in said first cache module, said data is converted.</claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00011\" num=\"11\"><claim-text>11. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00010\">claim 10</claim-ref>, wherein after data is converted, said data is provided to said second cache module.</claim-text></claim>"}, {"num": 12, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00012\" num=\"12\"><claim-text>12. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein said first cache module and said second cache module contain data that are transformed in character.</claim-text></claim>"}, {"num": 13, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00013\" num=\"13\"><claim-text>13. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00012\">claim 12</claim-ref>, wherein said first cache module contains floating point data.</claim-text></claim>"}, {"num": 14, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00014\" num=\"14\"><claim-text>14. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00012\">claim 12</claim-ref>, wherein said second cache module contains integer data.</claim-text></claim>"}, {"num": 15, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00015\" num=\"15\"><claim-text>15. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00001\">claim 1</claim-ref>, wherein said data conversion logic transforms floating point data into integer data.</claim-text></claim>"}, {"num": 16, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00016\" num=\"16\"><claim-text>16. A computer system having caches interconnected in parallel comprising:</claim-text><claim-text>a first and a second cache module directly coupled to an address generating line for parallel lookup of data and directly connected to a data generating line; </claim-text><claim-text>a hit/miss generating line directly coupled between the first cache module and the second cache module, the hit/miss generating line configured to send an indicator from any one of the first and second cache modules to the other of the first and second cache modules to indicate whether the data is found in the one of the first and second cache modules, </claim-text><claim-text>wherein if the indicator indicates a hit occurred in the one of the first and second cache modules, the other of the first and second cache modules cancels a search for the data, and </claim-text><claim-text>if the indicator indicates a miss occurred in the one and the other of the first and second cache modules, the one or the other of the first and second cache modules receives the data from a memory of the computer system; and </claim-text><claim-text>a select victim unit directly coupled between the first cache module and the second cache module, the select victim unit configured to select any one of the first and second cache modules to receive the data from a memory of the computer system when the data is not found in the first and second cache modules, </claim-text><claim-text>wherein when the one of the first and second cache modules is selected, the other of the first and second cache modules cancels the search for the data. </claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00017\" num=\"17\"><claim-text>17. The computer system according to <claim-ref idref=\"US-6397297-B1-CLM-00016\">claim 16</claim-ref>, wherein data stored in said first cache module and data stored in said second cache module is the same data type.</claim-text></claim>"}, {"num": 18, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6397297-B1-CLM-00018\" num=\"18\"><claim-text>18. A computer system having caches interconnected in series/parallel comprising:</claim-text><claim-text>a first and a second cache module directly coupled to an address generating line for parallel lookup of data; and </claim-text><claim-text>data conversion logic coupled between said first cache module and said second cache module, said data conversion logic configured to convert the data from a first data type of the first cache module to a second data type of the second cache module; </claim-text><claim-text>wherein said first cache module is coupled to a data generating line and said second cache module is coupled to a multiplexer providing the data from a memory of the computer system and from said first cache module.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53574080\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>FIELD OF THE INVENTION</h4><p>The present invention generally relates to computer systems. More particularly, the present invention relates to a method and apparatus of improving performance in computer systems by arranging cache modules in several interconnected operational modes.</p><h4>BACKGROUND OF THE INVENTION</h4><p>A cache or cache module as used interchangeably throughout this specification, is intended to enhance the speed at which information and data are retrieved. A main memory typically stores a large amount of data which is time consuming to retrieve. The cache module contains a copy of portions of the main memory. When a processor attempts to read a word of memory, a check is made to determine if the word is in the cache module. If so, the word is delivered to the processor. If not, a block of main memory, consisting of some fixed number of words, is read into the cache module and then the word is delivered to the processor.</p><p>The main memory consists of up to 2<sup>n </sup>addressable words, with each word having a unique n-bit address. For mapping purposes, this memory is considered to consist of a number of fixed-length blocks of K words each. That is, there are M=2<sup>n</sup>/K blocks. The cache module consists of C lines of K words each, and the number of lines is considerably less than the number of main memory blocks.</p><p>FIG. 1 is a block diagram illustrating a simplified picture of a network involving a processor <b>12</b> with cache module <b>40</b> connected via address, control and data lines <b>43</b>, <b>44</b>, and <b>45</b>, respectively. Address and data lines <b>43</b> and <b>45</b> also attached to address and data buffers <b>41</b> and <b>42</b>, respectively which attached to system bus <b>20</b> from which main memory (not shown) is reached.</p><p>Typically, processor <b>12</b> generates an address of a word to be read. If a \u201chit\u201d occurs, (the word is contained in cache module <b>40</b>), the word is delivered to processor <b>12</b>. When this cache hit occurs, the data and address buffers <b>42</b> and <b>41</b>, respectively, are disabled and communication is only between the processor <b>12</b> and the cache module <b>40</b>, with no system bus traffic. When a cache \u201cmiss\u201d occurs, (the word is not contained in cache module <b>40</b>), the desired address is loaded from main memory (not shown) onto system bus <b>20</b> and the data is returned through data buffer <b>42</b> to both the cache module <b>40</b> and the main memory. With a cache miss, a line in the cache may be overwritten or copied out of cache module <b>40</b> when new data is stored in the cache module. This overwritten line is referred to as a \u201cvictim block\u201d or a \u201cvictim line.\u201d</p><p>The basic structure of a conventional multi-processor computer system <b>10</b> employing several cache modules is shown in FIG. <b>2</b>. Computer system <b>10</b> includes processors <b>12</b>, <b>120</b> and <b>220</b> as shown which are connected to various peripheral devices including input/output (I/O) devices <b>14</b> (such as a display monitor, keyboard, graphical pointer (mouse) and a permanent storage device (hard disk)), memory <b>16</b> (such as random access memory or RAM) that is used by processors <b>12</b>, <b>120</b> and <b>220</b> to carry out program instructions, and firmware <b>18</b> whose primary purpose is to seek out and load an operating system from one of the peripherals (usually the permanent memory device) whenever computer system <b>10</b> is first turned on. Processors <b>12</b>, <b>120</b> and <b>220</b> communicate with the peripheral devices by various means, including a generalized interconnect or system bus <b>20</b>, or direct-memory-access channels (not shown).</p><p>Processor <b>12</b>, as well as each of the other processors <b>120</b> and <b>220</b>, includes a processor core <b>22</b> having a plurality of registers and execution units, which carry out program instructions <b>13</b> in order to operate the computer system <b>10</b>. As shown, processor <b>12</b> further includes one or more cache modules, such as an instruction cache <b>24</b> and a data cache <b>26</b>, which are implemented using high-speed memory devices. As described above, cache modules are commonly used to temporarily store values that might be repeatedly accessed by the processor, in order to speed up processing by avoiding the longer step of loading the values from memory <b>16</b>. These cache modules are referred to as \u201con-board\u201d when they are integrally packaged with the processor core on a single integrated chip <b>28</b>. Each cache module is associated with a cache controller (not shown) that manages the transfer of data and instructions between the processor core <b>22</b> and the cache.</p><p>Processor <b>12</b> can include additional cache modules, such as cache module <b>30</b>, which is referred to as a level <b>2</b> (L<b>2</b>) cache since it supports the on-board (level <b>1</b>) caches <b>24</b> and <b>26</b>. In other words, cache module <b>30</b> acts as an intermediary between memory <b>16</b> and the on-board caches, and can store a much larger amount of information (instructions and data) than the on-board caches can, but at a longer access penalty. Cache module <b>30</b> is connected to system bus <b>20</b>, and all loading of information from memory <b>16</b> into processor core <b>22</b> comes through cache module <b>30</b>.</p><p>One drawback to the conventional cache module arrangement as shown is that the cache modules do not benefit from being interconnected. Without the cache modules being interconnected, it is inefficient to retrieve data since each cache must be searched individually if data is not found in the first cache that is searched.</p><p>Accordingly, what is needed is an effective and efficient method for directly connecting cache modules for retrieval of information.</p><h4>SUMMARY OF THE INVENTION</h4><p>In accordance with an embodiment of the present invention, a computer system having cache modules interconnected in series includes a first and a second cache module directly coupled to an address generating line for parallel lookup of data and data conversion logic coupled between the first cache module and the second cache module.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1 is a block diagram illustrating a simplified picture of a network involving a processor with a cache module.</p><p>FIG. 2 is a block diagram illustrating a prior art computer system.</p><p>FIG. 3 is a block diagram illustrating the features of a typical cache module.</p><p>FIG. 4 is a block diagram illustrating a serial interconnection mode of two cache modules according to an embodiment of the present invention.</p><p>FIG. 5 is a block diagram illustrating a parallel interconnection mode of two cache modules according to an embodiment of the present invention.</p><p>FIG. 6 is a block diagram illustrating a serial and parallel interconnection mode of two cache modules according to an embodiment of the present invention.</p><p>FIG. 7 is a flow diagram illustrating a method for transferring data in a serial interconnection mode of two cache modules according to an embodiment of the present invention.</p><p>FIG. 8 is a flow diagram illustrating a method for transferring data in a parallel interconnection mode of two cache modules according to an embodiment of the present invention.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION</h4><p>Embodiments of the present invention relate to an apparatus of arranging cache modules in a serial, parallel and serial/parallel interconnection mode. According to an embodiment of the present invention, a computer system having cache modules interconnected in series includes a first and a second cache module directly coupled to an address generating line for parallel lookup of data and data conversion logic coupled between the first cache module and said second cache module.</p><p>According to an alternative embodiment of the present invention, a computer system having caches interconnected in parallel includes a first and a second cache module directly coupled to an address generating line for parallel lookup of data and directly connected to a data generating line.</p><p>According to another embodiment of the present invention, a computer system having cache modules interconnected in series/parallel includes a first and a second cache module directly coupled to an address generating line for parallel lookup of data and data conversion logic coupled between the first cache module and said second cache module, wherein the first cache module is coupled to a data generating line and the second cache module is coupled to a multiplexer providing converted data from memory and from the first cache module.</p><p>The following description is presented to enable one of ordinary skill in the art to make and use the invention. Various modifications to the embodiments will be readily apparent to those skilled in the art and the generic principles herein may be applied to other embodiments. Thus, the present invention is not intended to be limited to the embodiments shown but is to be accorded the widest scope consistent with the principles and features described herein.</p><p>FIG. 3 is a block diagram illustrating the features of a typical cache module <b>50</b>. Cache module <b>50</b> includes a Tag array <b>51</b>, Hit/Miss logic <b>52</b>, Replacement logic <b>53</b>, Data array <b>54</b> and Data output selection <b>55</b>. Tag array <b>51</b> is coupled to Hit/Miss logic <b>52</b>, Replacement logic <b>53</b> and Data array <b>54</b>. Hit/Miss logic is additionally coupled to Replacement logic <b>53</b> and Data output selection <b>55</b>. Data output selection is further coupled to Data array <b>54</b>.</p><p>Cache module <b>50</b> receives an address from processor <b>12</b> (not shown) over an address generating line (address) <b>56</b>. The address is sent to Tag array <b>51</b> and Hit/Miss logic <b>52</b>. Tag array <b>51</b> stores tags associated with each cache line of cache <b>50</b>. Hit/Miss logic <b>52</b> compares the address from processor <b>12</b> with a corresponding tag array value stored in Tag array <b>51</b>. Hit/Miss logic <b>52</b> also produces a hit/miss indication as to whether the tag array value is located in Tag array <b>51</b>. If a cache hit occurs, Hit/Miss logic forwards an indication that the tag array value is located in Tag array <b>51</b> to Data output selection <b>55</b>. Data output selection <b>55</b> selects data from Data array <b>54</b> based on a decision from Hit/Miss logic <b>52</b>.</p><p>Alternatively, if Hit/Miss logic <b>52</b> forwards an indication that the tag value is not located in Tag array <b>51</b>, this indication is sent to Replacement logic <b>53</b> which determines a \u201cvictim line\u201d when this cache miss occurs. Data is supplied by memory <b>16</b> via data generating line (data-in line) <b>57</b> to Data array <b>54</b> for output.</p><p>FIG. 4 illustrates a serial interconnection mode of two cache modules according to an embodiment of the present invention. In the serial interconnection mode, cache module <b>1</b> may be a level <b>2</b> (L<b>2</b>) cache and cache module <b>2</b> may be a level <b>1</b> (L<b>1</b>) cache for example. Each cache module includes the same circuitry of cache module <b>50</b> as shown in FIG. <b>3</b>. The serial interconnected mode may be used for data types that are transformed in character between a memory image and a usage with the processor. For example, the L<b>2</b> cache may cache a memory image, and the L<b>1</b> cache may contain a cache of processor data. An example of data that could utilize this behavior is single-precision floating point data (in the L<b>2</b> cache) transformed to <b>32</b> bit integer data (in the L<b>1</b> cache).</p><p>In the serial interconnection mode, cache module <b>1</b> and cache module <b>2</b> are each directly coupled to an address generating line (address line) <b>60</b>. Address line <b>60</b> may also be coupled to processor <b>12</b>. Cache module <b>1</b> is further coupled to a data generating line (Data-In) <b>61</b> and a hit/miss generating line (hit/miss) <b>65</b>. Cache module <b>1</b> outputs data on data output line (Data-Out) <b>62</b>. Data output line <b>62</b> is coupled to a data converter <b>70</b>. Data converter <b>70</b> converts the format of data from cache module <b>1</b> to a format used by cache module <b>2</b>. The output of data converter <b>70</b> is supplied to cache module <b>2</b> via data generating line (Data-In) <b>63</b>. Cache module <b>2</b> outputs data via data output line (Data-Out) <b>64</b>. Additionally, cache module <b>2</b> sends an indication to cache module <b>1</b> via hit/miss generating line (hit/miss) <b>65</b> whether data was located in cache module <b>2</b> or not.</p><p>FIG. 7 illustrates a method for transferring data in the serial interconnection mode of two cache modules according to an embodiment of the present invention. The method begins by receiving an address from processor <b>12</b> by cache module <b>1</b> and cache module <b>2</b> for parallel look up (Step <b>700</b>). A determination is made as to whether cache module <b>2</b> stores the requested data associated with the address from processor <b>12</b> (Step <b>710</b>). If cache module <b>2</b> stores that data, the data is output and the look up in cache module <b>1</b> stops (Step <b>730</b>). Alternatively, if cache module <b>2</b> does not have the stored data, a determination is made as to whether cache module <b>1</b> stores the data (Step <b>720</b>). If cache module <b>1</b> stores the data, the data is first converted from a format used by cache module <b>1</b> to a format used by cache module <b>2</b> (Step <b>750</b>) and then the converted data is moved from cache module <b>1</b> to cache module <b>2</b> for output (Step <b>760</b>). If, however, the data is not stored in cache module <b>1</b>, the data is loaded from memory into cache module <b>1</b> (Step <b>740</b>), converted (Step <b>750</b>) and moved to cache module <b>2</b> for output (Step <b>760</b>).</p><p>FIG. 5 illustrates a parallel interconnection mode of two caches according to an embodiment of the present invention. In the parallel interconnection mode, cache module <b>1</b> and cache module <b>2</b> may be the same type of cache module (e.g., L<b>1</b> or L<b>2</b> caches) and are interconnected in parallel as a single large cache module.</p><p>In the parallel interconnection mode, cache module <b>1</b> and cache module <b>2</b> are each directly coupled to an address generating line (address line) <b>60</b>. Address line <b>60</b> may also be coupled to processor <b>12</b>. Cache module <b>1</b> and cache module <b>2</b> are also each directly coupled to a data generating line (Data-In) <b>61</b>. Data generating line <b>61</b> may also be coupled to memory <b>16</b>. Hit/Miss generating line <b>65</b> is coupled between cache module <b>1</b> and cache module <b>2</b> for use with simultaneous look up of requested data in order to know the status of the other cache module. Cache module <b>1</b> and cache module <b>2</b> output data via data output lines (Data-Out) <b>62</b> and <b>64</b> respectively. A multiplexer <b>200</b> is used to output data from either cache module <b>1</b> or cache module <b>2</b>. Also includes is a select victim unit <b>72</b> which determine which cache module to use if to retrieve data from memory in the situation where neither cache module has the data. Select victim unit <b>72</b> can for example, alternate between the cache modules in assigning the cache module to retrieve data from memory or can use any other method of assigning a cache module to retrieve data known in the art.</p><p>FIG. 8 illustrates a method for transferring data in the parallel interconnection mode of two caches according to an embodiment of the present invention. The method begins by receiving an address from processor <b>12</b> by cache module <b>1</b> and cache module <b>2</b> for parallel look up (Step <b>800</b>). A determination is made as to whether the data is in either cache module (Step <b>810</b>). If the data is in at least one of the cache modules, the data is output by that cache module and the look up for the other cache is canceled (Step <b>830</b>). Alternatively, if neither cache module has the data, a selection is made using select victim unit <b>72</b> to load data from memory by one of the cache modules and cancel the lookup for the other cache module (Step <b>820</b>).</p><p>FIG. 6 illustrates a serial/parallel interconnection mode of two cache modules according to an embodiment of the present invention. In the serial/parallel interconnection mode, cache module <b>1</b> may be a level <b>2</b> (L<b>2</b>) cache, and cache module <b>2</b> may be a level <b>1</b> (L<b>1</b>) cache for example. Alternatively, cache module <b>1</b> and cache module <b>2</b> may be the same type of cache.</p><p>In the serial/parallel interconnection mode, cache module <b>1</b> and cache module <b>2</b> are each directly coupled to an address generating line (address line ) <b>60</b>. Address line <b>60</b> may also be coupled to processor <b>12</b>. Cache module <b>1</b> is further coupled to a data generating line (Data-<b>1</b>n) <b>61</b> and a hit/miss generating line (hit/miss) <b>65</b> is coupled between cache module <b>1</b> and cache module <b>2</b>. In addition, select victim unit <b>72</b> is also coupled between cache module <b>1</b> and cache module <b>2</b>. Cache module <b>1</b> outputs data on data output line (Data-Out) <b>62</b>. Data output line <b>62</b> is also coupled to a data converter <b>70</b>. Data converter converts the format of data from cache module <b>1</b> to a format used by cache module <b>2</b>. The output of data converter <b>70</b> is supplied to a multiplexer <b>75</b> via data generating line (Data-In) <b>63</b>. Data generating line <b>61</b> is also supplied to multiplexer <b>75</b>. Multiplexer <b>75</b> determines what type of data (e.g., data from memory or data from cache module <b>1</b>) to input and send to cache module <b>2</b>. Data from cache module <b>1</b> is sent via data output line <b>62</b> to multiplexer <b>200</b> and data from cache module <b>2</b> is output via data output line <b>64</b> to multiplexer <b>200</b>. Multiplexer <b>200</b> determines the correct data to output.</p><p>Several embodiments of the present invention are specifically illustrated and/or described herein. However, it will be appreciated that modifications and variations of the embodiments of the present invention are covered by the above teachings and within the purview of the appended claims without departing from the spirit and intended scope of the invention.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Zeev", "last_name": "Sperber", "name": ""}, {"first_name": "Jack", "last_name": "Doweck", "name": ""}, {"first_name": "Nicolas", "last_name": "Kacevas", "name": ""}, {"first_name": "Roy", "last_name": "Nesher", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTEL CORP."}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMUS"}], "national_classes": [{"primary": true, "label": "711122"}, {"primary": false, "label": "711E12043"}, {"primary": false, "label": "711118"}], "ecla_classes": [{"label": "G06F  12/08B22L"}], "cpc_classes": [{"label": "G06F  12/0897"}, {"label": "G06F  12/0897"}], "f_term_classes": [], "legal_status": "Expired - Fee Related", "priority_date": "1999-12-30", "application_date": "1999-12-30", "family_members": [{"ucid": "WO-2001050267-A3", "titles": [{"lang": "FR", "text": "ANTEMEMOIRE DOUBLE A FONCTIONNEMENT D'INTERCONNEXION MULTIPLE"}, {"lang": "EN", "text": "DUAL CACHE WITH MULTIPLE INTERCONNECTION OPERATION"}]}, {"ucid": "WO-2001050267-A2", "titles": [{"lang": "FR", "text": "ANTEMEMOIRE DOUBLE A FONCTIONNEMENT D'INTERCONNEXION MULTIPLE"}, {"lang": "EN", "text": "DUAL CACHE WITH MULTIPLE INTERCONNECTION OPERATION"}]}, {"ucid": "US-6397297-B1", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operation modes"}]}, {"ucid": "HK-1046576-B", "titles": [{"lang": "EN", "text": "DUAL CACHE WITH MULTIPLE INTERCONNECTION OPERATION MODES"}, {"lang": "ZH", "text": "\u5177\u6709\u591a\u4e92\u9023\u64cd\u4f5c\u6a21\u5f0f\u7684\u96d9\u9ad8\u901f\u7de9\u5b58"}]}, {"ucid": "HK-1046576-A1", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operationmodes."}]}, {"ucid": "GB-2372858-A", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operation"}]}, {"ucid": "GB-2372858-B", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operation modes"}]}, {"ucid": "TW-519589-B", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operation modes"}]}, {"ucid": "AU-1470301-A", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operation"}]}, {"ucid": "GB-0213515-D0", "titles": [{"lang": "EN", "text": "Dual cache with multiple interconnection operation"}]}]}