{"patent_number": "US-6446181-B1", "publication_id": 73133891, "family_id": 24158241, "publication_date": "2002-09-03", "titles": [{"lang": "EN", "text": "System having a configurable cache/SRAM memory"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11394121\" source=\"national office\"><p>An apparatus having a core processor and a memory system is disclosed. The core processor includes at least one data port. The memory system is connected in such a way as to provide substantially simultaneous data accesses through the data port. The memory system can be made user configurable to provide appropriate memory model.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50372946\"><p>An apparatus having a core processor and a memory system is disclosed. The core processor includes at least one data port. The memory system is connected in such a way as to provide substantially simultaneous data accesses through the data port. The memory system can be made user configurable to provide appropriate memory model.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00001\" num=\"1\"><claim-text>1. A system comprising:</claim-text><claim-text>a core processor having n number of ports; and </claim-text><claim-text>a plurality of memory banks coupled to at least one port, said plurality of memory banks being connected in such a way as to provide substantially simultaneous data accesses for said core processor, </claim-text><claim-text>wherein a number of said plurality of memory banks is greater than said n number of ports in the core processor, and </claim-text><claim-text>wherein each of a plurality of said memory banks is user-confiurable as an SRAM or a cache. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00002\" num=\"2\"><claim-text>2. The system of <claim-ref idref=\"US-6446181-B1-CLM-00001\">claim 1</claim-ref>, wherein said n number of ports is equal to 1.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00003\" num=\"3\"><claim-text>3. The system of <claim-ref idref=\"US-6446181-B1-CLM-00001\">claim 1</claim-ref>, wherein said core processor is a digital signal processor core.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00004\" num=\"4\"><claim-text>4. The system of <claim-ref idref=\"US-6446181-B1-CLM-00001\">claim 1</claim-ref>, wherein said core processor further includes:</claim-text><claim-text>a program sequencer; and </claim-text><claim-text>first and second data address generators coupled to said program sequencer, where said first and second data address generators provide addresses for said data accesses. </claim-text></claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00005\" num=\"5\"><claim-text>5. The system of <claim-ref idref=\"US-6446181-B1-CLM-00004\">claim 4</claim-ref>, further comprising:</claim-text><claim-text>a first memory bus coupled to said first data address generator and said plurality of memory banks; and </claim-text><claim-text>a second memory bus coupled to said second data address generator and said plurality of memory banks. </claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00006\" num=\"6\"><claim-text>6. The system of <claim-ref idref=\"US-6446181-B1-CLM-00005\">claim 5</claim-ref>, wherein said first memory bus is configured as a data memory bus, and said second memory bus is configured as a program memory bus.</claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00007\" num=\"7\"><claim-text>7. The system of <claim-ref idref=\"US-6446181-B1-CLM-00006\">claim 6</claim-ref>, wherein said core processor further includes:</claim-text><claim-text>a cache to hold instructions whose instruction fetches conflict with data accesses from said second memory bus. </claim-text></claim>"}, {"num": 8, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00008\" num=\"8\"><claim-text>8. The system of <claim-ref idref=\"US-6446181-B1-CLM-00005\">claim 5</claim-ref>, wherein said plurality of memory banks are connected in parallel to said first memory bus and said second memory bus.</claim-text></claim>"}, {"num": 9, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00009\" num=\"9\"><claim-text>9. The system of <claim-ref idref=\"US-6446181-B1-CLM-00005\">claim 5</claim-ref>, wherein said core processor further includes:</claim-text><claim-text>a store buffer to store result of a computation. </claim-text></claim>"}, {"num": 10, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00010\" num=\"10\"><claim-text>10. The system of <claim-ref idref=\"US-6446181-B1-CLM-00001\">claim 1</claim-ref>, wherein said core processor further includes:</claim-text><claim-text>a cache to hold instructions whose instruction fetches conflict with data accesses. </claim-text></claim>"}, {"num": 11, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00011\" num=\"11\"><claim-text>11. A system comprising:</claim-text><claim-text>a core processor including </claim-text><claim-text>n number of ports, </claim-text><claim-text>a program sequencer, </claim-text><claim-text>first and second data address generators coupled to said program sequencer, where said first and second data address generators provide addresses for said data accesses, and </claim-text><claim-text>a store buffer to store result of a computation; </claim-text><claim-text>a plurality of memory banks coupled to said at least one port, where said plurality of memory banks are connected in such a way as to provide substantially simultaneous data accesses for said core processor, and where a number of said plurality of memory banks is greater than said n number of ports in the core processor; </claim-text><claim-text>a first memory bus coupled to said first data address generator and said plurality of memory banks; </claim-text><claim-text>a second memory bus coupled to said second data address generator and said plurality of memory banks; and </claim-text><claim-text>a third memory bus coupled to said buffer and said plurality of memory banks. </claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00012\" num=\"12\"><claim-text>12. The system of <claim-ref idref=\"US-6446181-B1-CLM-00011\">claim 11</claim-ref>, further comprising:</claim-text><claim-text>a plurality of multiplexers to selectively connect said plurality of memory banks to said first, second, or third memory busses. </claim-text></claim>"}, {"num": 13, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00013\" num=\"13\"><claim-text>13. An apparatus comprising:</claim-text><claim-text>a digital signal processor core having a data port; and </claim-text><claim-text>a memory system having a plurality of blocks coupled to said data port, where said plurality of blocks are connected in such a way as to provide substantially simultaneous data accesses through said data port to said digital signal processor core, and where each of a plurality of said blocks is configurable as an SRAM or a cache. </claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00014\" num=\"14\"><claim-text>14. The apparatus of <claim-ref idref=\"US-6446181-B1-CLM-00013\">claim 13</claim-ref>, further comprising:</claim-text><claim-text>a plurality of memory busses to transport data to/from said data port from/to said plurality of blocks. </claim-text></claim>"}, {"num": 15, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00015\" num=\"15\"><claim-text>15. An apparatus comprising:</claim-text><claim-text>a digital signal processor core having a data port; </claim-text><claim-text>a memory system having a plurality of blocks coupled to said data port, where said plurality of blocks are connected in such a way as to provide substantially simultaneous data accesses through said data port to said digital signal processor core; </claim-text><claim-text>a plurality of memory busses to transport data to/from said data port from/to said plurality of blocks; and </claim-text><claim-text>a plurality of multiplexers to selectively connect said plurality of blocks to said plurality of memory busses. </claim-text></claim>"}, {"num": 16, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00016\" num=\"16\"><claim-text>16. An apparatus comprising:</claim-text><claim-text>a core processor having at least one data port; and </claim-text><claim-text>a memory system connected in such a way as to provide substantially simultaneous data accesses through said at least one data port, where said memory system includes a plurality of memory banks, each memory bank adapted to be user configurable as either an SRAM or a cache. </claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00017\" num=\"17\"><claim-text>17. The apparatus of <claim-ref idref=\"US-6446181-B1-CLM-00016\">claim 16</claim-ref>, wherein said memory system is user-configured to provide an all static random access memory (SRAM) design.</claim-text></claim>"}, {"num": 18, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00018\" num=\"18\"><claim-text>18. The apparatus of <claim-ref idref=\"US-6446181-B1-CLM-00016\">claim 16</claim-ref>, wherein said memory system is user-configured to provide an all cache design.</claim-text></claim>"}, {"num": 19, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6446181-B1-CLM-00019\" num=\"19\"><claim-text>19. The apparatus of <claim-ref idref=\"US-6446181-B1-CLM-00016\">claim 16</claim-ref>, wherein said memory system is user-configured to provide a mixture of SRAM and cache design.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53627614\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND</h4><p>This disclosure generally relates to digital signal processing and other processing applications, and specifically to a configurable, banked cache/SRAM memory architecture in such an application.</p><p>A digital signal processor (DSP) is a special purpose computer element that is designed to optimize performance for digital signal processing and other applications. The applications can include digital filters, image processing and speech recognition. The digital signal processing applications are often characterized by real-time operation, high interrupt rates and intensive numeric computations. In addition, the applications tend to be intensive in memory access operations, which may require the input and output of large quantities of data. Therefore, designs of digital signal processors may be quite different from those of general-purpose computers.</p><p>One approach that has been used in the architecture of digital signal processors to achieve high-speed numeric computation is the so-called \u201cHarvard\u201d architecture. This architecture utilizes separate, independent program and data memories so that the two memories may be accessed simultaneously. The digital signal processor architecture permits an instruction and an operand to be fetched from memory in a single clock cycle. A modified Harvard architecture utilizes the program memory for storing both instructions and operands to achieve full memory utilization. Thus, the program and data memories are often interconnected with the core processor by separate program and data buses.</p><p>When both instructions and operands (data) are stored in the program memory, conflicts may arise in the fetching of instructions. Certain instruction types may require data fetches from the program memory. In the pipelined architecture that may be used in a digital signal processor, the data fetch required by an instruction of this type may conflict with a subsequent instruction fetch. Such conflicts have been overcome in prior art digital signal processors by providing an instruction cache. Instructions that conflict with data fetches are stored in the instruction cache and are fetched from the instruction cache on subsequent occurrences of the instruction during program execution.</p><p>Although the modified Harvard architecture used in conjunction with an instruction cache provides excellent performance, the need exists for further enhancements to the performance of digital signal processors. In particular, increased computation rates and enhanced computation performance of the memory system provide advantages.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>Different aspects of the disclosure will be described in reference to the accompanying drawings wherein:</p><p>FIG. 1 is a block diagram of a digital signal processor (DSP) in accordance with one embodiment of the present invention;</p><p>FIG. 2 is a block diagram of a memory system containing two super-banks according to one embodiment of the present invention; and</p><p>FIG. <b>3</b>. is another embodiment of the memory system showing mini-banks.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION</h4><p>A processor's memory system architecture can have an impact on the processor performance. For example, fast execution of multiply-and-accumulate operations requires fetching an instruction word and two data words from memory in a single instruction cycle. Current digital signal processors (DSP) use a variety of techniques to achieve this, including multi-ported memories, separate instruction and data memories, and instruction caches. To support multiple simultaneous memory accesses, digital signal processors use multiple on-chip buses and multi-ported memories.</p><p>Enhanced performance of the memory system can be accomplished using single-ported memory array having \u201cmulti-ported\u201d behavior. Parallel accesses to multiple banks can be performed by providing configurable, fast static random access memory (SRAM) on chip. Alternatively, the memory system can be configured with caches, which provide a simple programming model.</p><p>A block diagram of a digital signal processor (DSP) in accordance with one embodiment of the present disclosure is shown in FIG. <b>1</b>. The DSP is configured in a modified Harvard architecture. Principal components of the DSP <b>100</b> include a core processor <b>102</b>, an I/O processor <b>104</b>, a memory system <b>106</b> and an external port <b>108</b>. The core processor <b>102</b> performs the main computation and data processing functions of the DSP <b>100</b>. The I/O processor <b>104</b> controls external communications via external port <b>108</b>, one or more serial ports and one or more link ports.</p><p>The DSP <b>100</b> is configured as a single monolithic integrated circuit. In one embodiment, the memory system <b>106</b> implementation supports the SRAM-based model with two super-banks of 16 kilobits each for a total of 32 kilobits. These two super-banks of memory are accessed simultaneously in each cycle to support the core processor requirements. Alternatively, each of these super-banks can be configured as cache memory.</p><p>A first memory bus <b>120</b> interconnects the core processor <b>102</b>, I/O processor <b>104</b>, and memory system <b>106</b>. A second memory bus <b>122</b> likewise interconnects core processor <b>102</b>, I/O processor <b>104</b>, and memory system <b>106</b>. In some embodiments, the first memory bus <b>120</b> and the second memory bus <b>122</b> are configured as a data memory bus and a program memory bus, respectively. An external port (EP) bus <b>124</b> interconnects I/O processor <b>104</b> and external port <b>108</b>. The external port <b>108</b> connects the EP bus <b>124</b> to an external bus <b>126</b>. Each of the buses <b>120</b>, <b>122</b> includes a data bus and an address bus. Each of the buses includes multiple lines for parallel transfer of binary information.</p><p>The core processor <b>102</b> includes a data register file <b>130</b> connected to the first memory bus <b>120</b> and the second memory bus <b>122</b>. The data register file <b>130</b> is connected in parallel to a multiplier <b>132</b> and an arithmetic logic unit (ALU) <b>134</b>. The multiplier <b>132</b> and the ALU <b>134</b> perform single cycle instructions. The parallel configuration maximizes computational throughput. Single, multi-function instructions execute parallel ALU and multiplier operations.</p><p>The core processor <b>12</b> further includes a first data address generator (DAGO) <b>136</b>, a second data address generator (DAG<b>1</b>) <b>138</b> and a program sequencer <b>140</b>. A bus connect multiplexer <b>142</b> receives inputs from the first memory bus <b>120</b> and the second memory bus <b>122</b>. The multiplexer <b>142</b> supplies bus data to data address generators <b>136</b>, <b>138</b> and to the program sequencer <b>140</b>. The first data address generator <b>136</b> supplies addresses to the first memory bus <b>120</b>. The second data address generator <b>138</b> supplies addresses to the second memory bus <b>122</b>.</p><p>The core processor <b>102</b> further includes an instruction cache <b>144</b> connected to the program sequencer <b>140</b>. The instruction cache <b>102</b> fetches an instruction and two data values. The instruction cache <b>102</b> is selective in that only the instructions whose instruction fetches conflict with data accesses are cached.</p><p>For some embodiments, the DSP <b>100</b> utilizes an enhanced Harvard architecture in which the first memory bus <b>32</b> transfers data, and the second memory bus <b>34</b> transfers both instructions and data. With separate program and data memory buses and the on-chip instruction cache <b>144</b>, the core processor <b>102</b> can simultaneously fetch two operands (from memory banks <b>110</b>, <b>112</b>) and an instruction (from cache <b>144</b>), all in a single cycle.</p><p>The memory system <b>106</b>, illustrated in detail in FIG. 2, preferably contains two super-banks of 16 kilobits each for a total of 32 kilobits. The super-banks A <b>200</b> and B <b>202</b> are accessed simultaneously in each cycle to support the core processor <b>102</b> requirements.</p><p>Each of these super-banks <b>200</b>, <b>202</b> can be configured as a SRAM and/or cache. By supporting both an SRAM and cache implementations together, the memory architecture provides flexibility for system designers. Configuring the memory as all cache allows for an easy programming model of the data cache for the rest of the code (e.g. operating system, micro-controller code, etc.). Configuring the super-banks as all SRAM provides predictability and performance for key digital signal processing applications. The hybrid version, e.g. half SRAM and half cache, allows mapping of critical data sets into the SRAM for predictability and performance, and mapping of the rest of the code into the cache to take advantage of the easy programming model with caches. Further, by providing SRAM behavior at the L1 memory, significant performance advantage can be achieved with low access latencies. In addition to the two super-banks, a 4-kilobit scratchpad SRAM <b>204</b> is provided as a user stack to speed up data switches.</p><p>In one embodiment, each of the data super-banks <b>200</b>, <b>202</b> is 16 kilobits in size and is further divided into four 4-kilobit mini-banks <b>300</b>, <b>302</b>, <b>304</b>, <b>306</b>. FIG. 3 shows a more detailed block diagram of the memory system <b>106</b>. In the illustrated embodiment, each mini-bank <b>300</b>, <b>302</b>, <b>304</b>, <b>306</b> is a two-way set associative cache and is configured as a single-ported memory array. By providing parallel accesses to eight different mini-banks <b>300</b>, <b>302</b>, <b>304</b>, <b>306</b> in the two super-banks A and B, a \u201cmulti-ported\u201d memory behavior can be achieved. Multiplexers <b>308</b>, <b>310</b>, <b>312</b>, <b>314</b> selectively provide accesses of the mini-banks <b>300</b>, <b>302</b>, <b>304</b>, <b>306</b>, respectively. The selective accesses are provided to the core processor <b>316</b> and the system interface <b>318</b>, such as an I/O processor. However, since the configuration is not a true multi-port system, simultaneous accesses to a same mini-bank are not allowed. Thus, if two accesses are addressed to the same mini-bank, a conflict results. One of the accesses is delayed by one clock cycle.</p><p>For one particular embodiment, the first data address generator <b>322</b>, the second data address generator <b>324</b>, and the store buffer <b>320</b> provide addresses for two operands and a result, respectively.</p><p>The core processor <b>316</b> controls the configuration of the super-banks A and B of the memory system <b>106</b>. The configuration can be defined as described below in Table 1.</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"3\" colsep=\"0\" rowsep=\"0\"><colspec align=\"center\" colname=\"1\" colwidth=\"91pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"42pt\"></colspec><colspec align=\"center\" colname=\"3\" colwidth=\"84pt\"></colspec><thead><row><entry nameend=\"3\" namest=\"1\" rowsep=\"1\">TABLE 1</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row><row><entry>    Memory</entry><entry>Super-bank</entry><entry>Super-bank</entry></row><row><entry>Configuration</entry><entry>A</entry><entry>B</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></thead><tbody valign=\"top\"><row><entry>      0</entry><entry>SRAM</entry><entry>SRAM</entry></row><row><entry>1</entry><entry>Reserved</entry><entry>Reserved</entry></row><row><entry>2</entry><entry>Cache</entry><entry>SRAM</entry></row><row><entry>3</entry><entry>Cache</entry><entry>Cache</entry></row><row><entry align=\"center\" nameend=\"3\" namest=\"1\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>The memory configurations 0 and 3 divide each super-bank into four mini-banks of all SRAM and all cache design, respectively. Each configuration provides either flexibility or ease of programming for the rest of the code. The memory configuration 2 supports hybrid design that allows mapping of critical data sets into the SRAM for predictability and performance, and mapping of the rest of the code into the cache to take advantage of the easy programming model with caches. When the SRAM mode is enabled, the logical address and physical address are the same. The memory configuration 1 is reserved for a future configuration.</p><p>A multi-ported memory array can provide bandwidth for two core processor <b>316</b> accesses and a direct memory access (DMA) through such interface as the system interface <b>328</b>. However, the area penalty can be large because multi-porting of a memory array can more than double the physical area of the array. Furthermore, the cost of building a multi-ported array often increases exponentially with the number of ports. The memory architecture with multiple memory banks, as described above, can support parallel accesses with minimal hardware overhead. The arrays are single-ported, yet they can provide multi-port behavior as long as the accesses are to different mini-banks.</p><p>The system environment can be optimized for maximum performance with minimal hardware. If DMA accesses are allowed into the cache, complex cache coherency issues are introduced that may result in control complexity and additional hardware. Thus, DMA accesses can be restricted only into the SRAM space. DMA accesses to the 4-kilobit scratchpad SRAM can also be restricted for simplicity.</p><p>Besides area advantage, multi-banking memory provides high access bandwidth, which is advantageous for digital signal processor performance. When in cache mode, a super-bank can support two core processor accesses in parallel with a fill or copyback transfer. When in SRAM mode, a super-bank can support dual core processor accesses in parallel with a DMA transfer. Further, power consumption can be reduced to a minimum by powering only the mini-banks that are needed by the accesses in a given cycle. At most, 3 out of 8 mini-banks are used per cycle.</p><p>Above described embodiments are for illustrative purposes only. Other embodiments and variations are possible. For example, even though the memory system has been described and illustrated in terms of a \u201cdual-port behavior\u201d configuration, the memory system can support a \u201cmulti-port\u201d behavior having more than two super-banks.</p><p>All these embodiments are intended to be encompassed by the following claims.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Hebbalalu S.", "last_name": "Ramagopal", "name": ""}, {"first_name": "David B.", "last_name": "Witt", "name": ""}, {"first_name": "Michael", "last_name": "Allen", "name": ""}, {"first_name": "Moinul", "last_name": "Syed", "name": ""}, {"first_name": "Ravi", "last_name": "Kolagotla", "name": ""}, {"first_name": "Lawrence A.", "last_name": "Booth, Jr.", "name": ""}, {"first_name": "William C.", "last_name": "Anderson", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTEL CORPORATION"}, {"first_name": "", "last_name": "", "name": "ANALOG DEVICES, INC."}, {"first_name": "", "last_name": "ANALOG DEVICES, INC.", "name": ""}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}, {"first_name": "", "last_name": "ANALOG DEVICES, INC.", "name": ""}, {"first_name": "", "last_name": "INTEL CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMEP"}, {"label": "G06F  13/16        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711168"}, {"primary": false, "label": "711170"}, {"primary": false, "label": "711E12041"}, {"primary": false, "label": "711149"}, {"primary": false, "label": "711150"}, {"primary": false, "label": "711131"}], "ecla_classes": [{"label": "G06F  12/08B6P"}, {"label": "G06F  13/16"}, {"label": "G06F  12/08B22"}], "cpc_classes": [{"label": "G06F  13/16"}, {"label": "G06F  12/0893"}, {"label": "G06F  12/0855"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "2000-03-31", "application_date": "2000-03-31", "family_members": [{"ucid": "WO-2001074134-A2", "titles": [{"lang": "FR", "text": "SYSTEME A MEMOIRE SRAM/CACHE CONFIGURABLE"}, {"lang": "EN", "text": "SYSTEM HAVING A CONFIGURABLE CACHE/SRAM MEMORY"}]}, {"ucid": "EP-1269328-B1", "titles": [{"lang": "DE", "text": "SYSTEM MIT EINEM KONFIGURIERBAREN CACHE/SRAM-SPEICHER"}, {"lang": "EN", "text": "SYSTEM HAVING A CONFIGURABLE CACHE/SRAM MEMORY"}, {"lang": "FR", "text": "SYSTEME A MEMOIRE SRAM/CACHE CONFIGURABLE"}]}, {"ucid": "AU-2001249665-A1", "titles": [{"lang": "EN", "text": "System having a configurable cache/sram memory"}]}, {"ucid": "EP-2312447-A1", "titles": [{"lang": "FR", "text": "Syt\u00e8me pourvu d'une m\u00e9moire Cache / SRAM configurable"}, {"lang": "EN", "text": "System having a configurable cache/SRAM memory"}, {"lang": "DE", "text": "System mit einem konfigurierbaren Cache/SRAM-Speicher"}]}, {"ucid": "CN-1429369-A", "titles": [{"lang": "EN", "text": "System having configurable cache/SRAM memory"}, {"lang": "ZH", "text": "\u5177\u6709\u53ef\u914d\u7f6e\u7684\u9ad8\u901f\u7f13\u5b58/\u9759\u6001\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668\u7684\u7cfb\u7edf"}]}, {"ucid": "TW-I243989-B", "titles": [{"lang": "EN", "text": "System having a configurable cache/SRAM memory"}]}, {"ucid": "EP-1269328-A2", "titles": [{"lang": "FR", "text": "SYSTEME A MEMOIRE SRAM/CACHE CONFIGURABLE"}, {"lang": "EN", "text": "SYSTEM HAVING A CONFIGURABLE CACHE/SRAM MEMORY"}, {"lang": "DE", "text": "SYSTEM MIT EINEM KONFIGURIERBAREN CACHE/SRAM-SPEICHER"}]}, {"ucid": "AU-4966501-A", "titles": []}, {"ucid": "US-6446181-B1", "titles": [{"lang": "EN", "text": "System having a configurable cache/SRAM memory"}]}, {"ucid": "CN-1220150-C", "titles": [{"lang": "EN", "text": "System having configurable cache/SRAM memory"}, {"lang": "ZH", "text": "\u5177\u6709\u53ef\u914d\u7f6e\u7684\u9ad8\u901f\u7f13\u5b58/\u9759\u6001\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668\u7684\u7cfb\u7edf"}]}, {"ucid": "WO-2001074134-A3", "titles": [{"lang": "EN", "text": "SYSTEM HAVING A CONFIGURABLE CACHE/SRAM MEMORY"}, {"lang": "FR", "text": "SYSTEME A MEMOIRE SRAM/CACHE CONFIGURABLE"}]}]}