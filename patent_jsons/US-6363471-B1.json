{"patent_number": "US-6363471-B1", "publication_id": 72934034, "family_id": 23891386, "publication_date": "2002-03-26", "titles": [{"lang": "EN", "text": "Mechanism for handling 16-bit addressing in a processor"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11301875\" source=\"national office\"><p>A processor includes an address generation unit (AGU) which adds address operands and the segment base. The AGU may add the segment base and the displacement while other address operands are being read from the register file. The sum of the segment base and the displacement may subsequently be added to the remaining address operands. The AGU receives the addressing mode of the instruction, and if the addressing mode is 16 bit, the AGU zeros the carry from the sixteenth bit to the seventeenth bit of the sums generated therein. Additionally, in parallel, the AGU determines if a carry from the sixteenth bit to the seventeenth bit would occur if the logical address were added to the segment base. In one embodiment, the sum of the address operands and the segment base, with carries from the sixteenth bit to the seventeenth bit zeroed, and the carry generated in parallel are provided to a translation lookaside buffer (TLB), which stores translations in the same format (sum and carry). In another embodiment, the AGU corrects the most significant bits of the generated sum based on the carry. The AGU and/or TLB may provide reduced address generation latency while handling the 16 bit addressing mode as defined in the instruction set architecture.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50289613\"><p>A processor includes an address generation unit (AGU) which adds address operands and the segment base. The AGU may add the segment base and the displacement while other address operands are being read from the register file. The sum of the segment base and the displacement may subsequently be added to the remaining address operands. The AGU receives the addressing mode of the instruction, and if the addressing mode is 16 bit, the AGU zeros the carry from the sixteenth bit to the seventeenth bit of the sums generated therein. Additionally, in parallel, the AGU determines if a carry from the sixteenth bit to the seventeenth bit would occur if the logical address were added to the segment base. In one embodiment, the sum of the address operands and the segment base, with carries from the sixteenth bit to the seventeenth bit zeroed, and the carry generated in parallel are provided to a translation lookaside buffer (TLB), which stores translations in the same format (sum and carry). In another embodiment, the AGU corrects the most significant bits of the generated sum based on the carry. The AGU and/or TLB may provide reduced address generation latency while handling the 16 bit addressing mode as defined in the instruction set architecture.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00001\" num=\"1\"><claim-text>1. A processor comprising:</claim-text><claim-text>an address generation unit (AGU) coupled to receive a segment base, one or more address operands of an instruction, and a mode signal identifying whether or not an addressing mode of said instruction is 16 bit, wherein said AGU includes adder circuitry configured to add said segment base and said one or more address operands to produce a value, and wherein said adder circuitry is further configured to zero a carry-in to a seventeenth bit of said value in response to said mode signal indicating that said addressing mode is 16 bit, and wherein said adder circuitry is configured to zero said carry-in independent of whether or not an addition of said segment base to a sum of said one or more address operands causes said carry-in to be a one, and wherein said AGU further includes a carry circuit configured to generate a first carry signal indicative of a carry-in to said seventeenth bit of a virtual address of a memory operand of said instruction according to an instruction set architecture defining said instruction, said carry circuit coupled to receive said mode signal and to generate said first carry signal in response to said mode signal, and wherein said first carry signal does not affect the generation of the value by the adder circuitry. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00002\" num=\"2\"><claim-text>2. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00001\">claim 1</claim-ref> wherein one of said one or more address operands is a displacement, and wherein said adder circuitry comprises a first adder coupled to receive said segment base, said displacement, and said mode signal, and wherein said first adder is configured to add said segment base and said displacement to produce a first sum, and wherein said first adder is configured to zero a carry-in to said seventeenth bit of said first sum in response to said mode signal indicating that said addressing mode is 16 bit.</claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00003\" num=\"3\"><claim-text>3. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00002\">claim 2</claim-ref> wherein said adder circuitry further includes a second adder coupled to receive said first sum, remaining ones of said one or more address operands, and said mode signal, and wherein said second adder is configured to add said first sum and said remaining ones of said one or more address operands to produce said value, and wherein said second adder is configured to zero a carry-in to said seventeenth bit of said value in response to said mode signal indicating that said addressing mode is 16 bit.</claim-text></claim>"}, {"num": 4, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00004\" num=\"4\"><claim-text>4. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00003\">claim 3</claim-ref> wherein said first adder and said second adder provide a carry-out of a sixteenth bit as said carry-in to said seventeenth bit in response to said mode signal indicating that said addressing mode is not 16 bit, and wherein said value comprises said virtual address of said memory operand if said mode signal indicates that said addressing mode is not 16 bit.</claim-text></claim>"}, {"num": 5, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00005\" num=\"5\"><claim-text>5. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00003\">claim 3</claim-ref> wherein a least significant 16 bits of said value comprise a least significant 16 bits of said virtual address of said memory operand if said mode signal indicates that said addressing mode is 16 bit, and wherein a remaining bits of said value comprise a most significant bits of said segment base if said mode signal indicates that said addressing mode is 16 bit.</claim-text></claim>"}, {"num": 6, "parent": 5, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00006\" num=\"6\"><claim-text>6. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00005\">claim 5</claim-ref> wherein said value comprises said virtual address of said memory operation if said first carry signal is zero.</claim-text></claim>"}, {"num": 7, "parent": 3, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00007\" num=\"7\"><claim-text>7. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00003\">claim 3</claim-ref> wherein said first adder is configured to generate a second carry signal indicative of a carry-out of a sixteenth bit of said first sum, and wherein said second adder is configured to generate a third carry signal indicative of a carry-out of a sixteenth bit of said value.</claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00008\" num=\"8\"><claim-text>8. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00007\">claim 7</claim-ref> wherein said carry circuit comprises a carry generation circuit coupled to receive said one or more address operands and configured to generate a fourth carry signal indicative of a carry-out of a sixteenth bit of a sum of said one or more address operands.</claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00009\" num=\"9\"><claim-text>9. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00008\">claim 8</claim-ref> wherein said carry circuit further comprises a circuit coupled to receive said second carry signal, said third carry signal, and said fourth carry signal, and wherein said circuit is configured to generate said first carry signal in response to said second carry signal, said third carry signal, and said fourth carry signal.</claim-text></claim>"}, {"num": 10, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00010\" num=\"10\"><claim-text>10. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00009\">claim 9</claim-ref> wherein said circuit is coupled to receive said mode signal, and wherein said circuit is configured to generate said first carry signal further in response to said mode signal.</claim-text></claim>"}, {"num": 11, "parent": 10, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00011\" num=\"11\"><claim-text>11. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00010\">claim 10</claim-ref> wherein said circuit is configured to exclusive-or said second carry signal, said third carry signal, and said fourth carry signal and to qualify an exclusive-or result with said mode signal.</claim-text></claim>"}, {"num": 12, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00012\" num=\"12\"><claim-text>12. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00001\">claim 1</claim-ref> further comprising a translation lookaside buffer (TLB) coupled to receive said value and said first carry signal from said address generation unit, wherein said TLB is configured to provide a physical address of said memory operand in response to said value and said first carry signal.</claim-text></claim>"}, {"num": 13, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00013\" num=\"13\"><claim-text>13. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00012\">claim 12</claim-ref> wherein said TLB comprises a tag array configured to store a plurality of tags for comparison to said value and said first carry signal.</claim-text></claim>"}, {"num": 14, "parent": 13, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00014\" num=\"14\"><claim-text>14. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00013\">claim 13</claim-ref> wherein one of said plurality of tags comprises a page portion of said value and a first carry corresponding to said first carry signal, and wherein said TLB provides a corresponding physical address.</claim-text></claim>"}, {"num": 15, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00015\" num=\"15\"><claim-text>15. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00014\">claim 14</claim-ref> wherein said one of said plurality of tags further includes a mode, and wherein said mode comprises an addressing mode corresponding to said one of said plurality of tags.</claim-text></claim>"}, {"num": 16, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00016\" num=\"16\"><claim-text>16. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00001\">claim 1</claim-ref> wherein said AGU further comprises an incrementor configured to increment a most significant portion of said segment base, and a multiplexor coupled to receive an output of said incrementor and a corresponding most significant portion of said value, and wherein said multiplexor is further coupled to receive said first carry signal as a selection control.</claim-text></claim>"}, {"num": 17, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00017\" num=\"17\"><claim-text>17. A computer system comprising:</claim-text><claim-text>a processor including an address generation unit (AGU) coupled to receive a segment base, one or more address operands of an instruction, and a mode signal identifying whether or not an addressing mode of said instruction is 16 bit, wherein said AGU includes adder circuitry configured to add said segment base and said one or more address operands to produce a value, and wherein said adder circuitry is further configured to zero a carry-in to a seventeenth bit of said value in response to said mode signal indicating that said addressing mode is 16 bit, and wherein said adder circuitry is configured to zero said carry-in independent of whether or not an addition of said segment base to a sum of said one or more address operands causes said carry-in to be a one, and wherein said AGU further includes a carry circuit configured to generate a first carry signal indicative of a carry-in to said seventeenth bit of a virtual address of a memory operand of said instruction according to an instruction set architecture employed by said processor, said carry circuit coupled to receive said mode signal and to generate said first carry signal in response to said mode signal, and </claim-text><claim-text>wherein said first carry signal does not affect the generation of said value by said adder circuitry; and </claim-text><claim-text>an input/output (I/O) device configured to communicate between said computer system and another computer system to which said I/O device is couplable. </claim-text></claim>"}, {"num": 18, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00018\" num=\"18\"><claim-text>18. The computer system as recited in <claim-ref idref=\"US-6363471-B1-CLM-00017\">claim 17</claim-ref> wherein said I/O device is a modem.</claim-text></claim>"}, {"num": 19, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00019\" num=\"19\"><claim-text>19. The computer system as recited in <claim-ref idref=\"US-6363471-B1-CLM-00017\">claim 17</claim-ref> further comprising a second processor identical to said processor.</claim-text></claim>"}, {"num": 20, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00020\" num=\"20\"><claim-text>20. A method comprising:</claim-text><claim-text>summing one or more address operands of an instruction and a segment base to produce a value, wherein said summing comprises zeroing a carry-in to a seventeenth bit of said value responsive to an addressing mode of said instruction being 16 bit, and wherein said zeroing is independent of whether or not an addition of said segment base to a sum of said one or more address operands causes said carry-in to be a one; and </claim-text><claim-text>generating a first carry-in to said seventeenth bit of a virtual address of a memory operand of said instruction according to an instruction set architecture defining said instruction and in response to said addressing mode, wherein said first carry-in does not affect said summing. </claim-text></claim>"}, {"num": 21, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00021\" num=\"21\"><claim-text>21. The method as recited in <claim-ref idref=\"US-6363471-B1-CLM-00020\">claim 20</claim-ref> further comprising:</claim-text><claim-text>incrementing a most significant bits of said segment base; and </claim-text><claim-text>selecting a result of said incrementing instead of said most significant bits of said value in response to said first carry-in being set. </claim-text></claim>"}, {"num": 22, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00022\" num=\"22\"><claim-text>22. The method as recited in <claim-ref idref=\"US-6363471-B1-CLM-00020\">claim 20</claim-ref> further comprising:</claim-text><claim-text>providing said value and said first carry-in to a translation lookaside buffer (TLB); and </claim-text><claim-text>providing a physical address corresponding to said memory operand from said </claim-text><claim-text>TLB in response to said value and said first carry-in. </claim-text></claim>"}, {"num": 23, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00023\" num=\"23\"><claim-text>23. The method as recited in <claim-ref idref=\"US-6363471-B1-CLM-00020\">claim 20</claim-ref> wherein said summing comprises:</claim-text><claim-text>summing said segment base and a displacement, which is one of said one or more address operands of said instruction, to produce a first sum, wherein said summing said segment base and said displacement comprises zeroing a carry-in to said seventeenth bit of said first sum in response to said addressing mode being 16 bit; and </claim-text><claim-text>summing said first sum and remaining ones of said one or more address operands of said instruction to produce said value, wherein said summing said first sum and remaining ones of said one or more address operands comprises zeroing a carry-in to said seventeenth bit of said value in response to said addressing mode being 16 bit. </claim-text></claim>"}, {"num": 24, "parent": 17, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00024\" num=\"24\"><claim-text>24. The computer system as recited in <claim-ref idref=\"US-6363471-B1-CLM-00017\">claim 17</claim-ref> further comprising a second processor including a second AGU coupled to receive a second segment base, a second one or more address operands of a second instruction, and a second mode signal identifying whether or not an addressing mode of said second instruction is 16 bit, wherein said second AGU includes second adder circuitry configured to add said second segment base and said second one or more address operands to produce a second value, and wherein said second adder circuitry is further configured to zero a carry-in to a seventeenth bit of said second value in response to said second mode signal indicating that said addressing mode is 16 bit, and wherein said second AGU further includes a second carry circuit configured to generate a second carry signal indicative of a carry-in to said seventeenth bit of a second virtual address of a second memory operand of said second instruction according to an instruction set architecture employed by said second processor, said second carry circuit coupled to receive said second mode signal and to generate said second carry signal in response to said second mode signal.</claim-text></claim>"}, {"num": 25, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00025\" num=\"25\"><claim-text>25. A processor comprising;</claim-text><claim-text>an address generation unit (AGU) coupled to receive a segment base, one or more address operands of an instruction, and a mode signal identifying an addressing mode of said instruction, wherein said AGU includes adder circuitry configured to add said segment base and said one or more address operands to produce a value, and wherein said adder circuitry is further configured to zero a carry-in to a first bit of said value in response to said mode signal indicating that said addressing mode is N bit, and wherein said adder circuitry is configured to zero said carry-in independent of whether or not an addition of said segment base to a sum of said one or more address operands causes said carry-in to be a one, wherein N is an integer greater than zero, and wherein the first bit is a next most significant bit to the Nth bit in the value, and wherein said AGU further includes a carry circuit configured to generate a first carry signal indicative of whether or not a carry-in to said first bit of a virtual address of a memory operand of said instruction is defined to occur according to an instruction set architecture defining said instruction, said carry circuit coupled to receive said mode signal and to generate said first carry signal in response to said mode signal, and wherein said first car signal does not affect the generation of said value by said adder circuitry. </claim-text></claim>"}, {"num": 26, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00026\" num=\"26\"><claim-text>26. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00025\">claim 25</claim-ref> wherein one of said one or more address operands is a displacement, and wherein said adder circuitry comprises a first adder coupled to receive said segment base, said displacement, and said mode signal, and wherein said first adder is configured to add said segment base and said displacement to produce a first sum, and wherein said first adder is configured to zero a carry-in to said first bit of said first sum in response to said mode signal indicating that said addressing mode is N bit.</claim-text></claim>"}, {"num": 27, "parent": 26, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00027\" num=\"27\"><claim-text>27. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00026\">claim 26</claim-ref> wherein said adder circuitry further includes a second adder coupled to receive said first sum, remaining ones of said one or more address operands, and said mode signal, and wherein said second adder is configured to add said first sum and said remaining ones of said one or more address operands to produce said value, and wherein said second adder is configured to zero a carry-in to said first bit of said value in response to said mode signal indicating that said addressing mode is N bit.</claim-text></claim>"}, {"num": 28, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00028\" num=\"28\"><claim-text>28. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00027\">claim 27</claim-ref> wherein said first adder and said second adder provide a carry-out of said Nth bit as said carry-in to said first bit in response to said mode signal indicating that said addressing mode is not N bit, and wherein said value comprises said virtual address of said memory operand if said mode signal indicates that said addressing mode is not N bit.</claim-text></claim>"}, {"num": 29, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00029\" num=\"29\"><claim-text>29. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00027\">claim 27</claim-ref> wherein said first adder is configured to generate a second carry signal indicative of a carry-out of said Nth bit of said first sum, and wherein said second adder is configured to generate a third carry signal indicative of a carry-out of said Nth bit of said value.</claim-text></claim>"}, {"num": 30, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00030\" num=\"30\"><claim-text>30. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00029\">claim 29</claim-ref> wherein said carry circuit comprises a carry generation circuit coupled to receive said one or more address operands and configured to generate a fourth carry signal indicative of a carry-out of said Nth bit of a sum of said one or more address operands.</claim-text></claim>"}, {"num": 31, "parent": 30, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00031\" num=\"31\"><claim-text>31. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00030\">claim 30</claim-ref> wherein said carry circuit further comprises a circuit coupled to receive said second carry signal, said third carry signal, and said fourth carry signal, and wherein said circuit is configured to generate said first carry signal in response to said second carry signal, said third carry signal, and said fourth carry signal.</claim-text></claim>"}, {"num": 32, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00032\" num=\"32\"><claim-text>32. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00031\">claim 31</claim-ref> wherein said circuit is coupled to receive said mode signal, and wherein said circuit is configured to generate said first carry signal further in response to said mode signal.</claim-text></claim>"}, {"num": 33, "parent": 32, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00033\" num=\"33\"><claim-text>33. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00032\">claim 32</claim-ref> wherein said circuit is configured to exclusive-or said second carry signal, said third carry signal, and said fourth carry signal and to qualify an exclusive-or result with said mode signal.</claim-text></claim>"}, {"num": 34, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00034\" num=\"34\"><claim-text>34. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00025\">claim 25</claim-ref> further comprising a translation lookaside buffer (TLB) coupled to receive said value and said first carry signal from said address generation unit, wherein said TLB is configured to provide a physical address of said memory operand in response to said value and said first carry signal.</claim-text></claim>"}, {"num": 35, "parent": 34, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00035\" num=\"35\"><claim-text>35. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00034\">claim 34</claim-ref> wherein said TLB comprises a tag array configured to store a plurality of tags for comparison to said value and said first carry signal.</claim-text></claim>"}, {"num": 36, "parent": 35, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00036\" num=\"36\"><claim-text>36. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00035\">claim 35</claim-ref> wherein one of said plurality of tags comprises a page portion of said value and a first carry corresponding to said first carry signal, and wherein said TLB provides a corresponding physical address.</claim-text></claim>"}, {"num": 37, "parent": 36, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00037\" num=\"37\"><claim-text>37. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00036\">claim 36</claim-ref> wherein said one of said plurality of tags further includes a mode, and wherein said mode comprises an addressing mode corresponding to said one of said plurality of tags.</claim-text></claim>"}, {"num": 38, "parent": 25, "type": "dependent", "paragraph_markup": "<claim id=\"US-6363471-B1-CLM-00038\" num=\"38\"><claim-text>38. The processor as recited in <claim-ref idref=\"US-6363471-B1-CLM-00025\">claim 25</claim-ref> wherein said AGU further comprises an incrementor configured to increment a most significant portion of said segment base, and a multiplexor coupled to receive an output of said incrementor and a corresponding most significant portion of said value, and wherein said multiplexor is further coupled to receive said first carry signal as a selection control.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53534063\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. Field of the Invention</p><p>This invention is related to the field of processors and, more particularly, to address generation mechanisms within processors.</p><p>2. Description of the Related Art</p><p>Processors are generally designed in accordance with an instruction set architecture, which specifies the instructions, the format of the instructions, and other resources used by the processor in executing instructions. Additionally, the instruction set architecture may specify the execution environment, including such features as the address translation mechanism, etc.</p><p>A popular instruction set architecture is the x86 instruction set architecture. Due to the wide acceptance of the x86 instruction set architecture in the computer industry, many processor designers select the x86 instruction set architecture when designing processors. The x86 instruction set architecture has been revised over time to expand the capabilities of the instruction set. For example, the x86 instruction set architecture was initially a sixteen bit instruction set architecture: the maximum size operands handled were 16 bit, and memory was addressed using a 16 bit address as well. Over time, the x86 instruction set architecture has been expanded to 32 bits. However, compatibility with the 16 bit mode was maintained to support software written for the earlier instruction set architecture. While compatibility is desirable, it creates complications in the design of processors implementing the instruction set architecture.</p><p>One such complication involves the generation of addresses of memory operands. Generally, an instruction may have one or more source operands upon which the instruction operates to produce a result (a destination operand). Operand are register operands if they are stored in a register defined by the instruction set architecture, or memory operands if they are stored in a memory location of a memory to which the processor may be coupled. If an instruction has a memory operand, it typically includes one or more address operands which are used to form the memory address at which the memory operand is stored. The address operands may include, for example, one or more of the following: a displacement (which is a value coded directly into the instruction), a base register operand, and an index register operand. The sum of the address operands forms a logical address. The logical address is translated through a segmentation mechanism to a linear address (also referred to herein as a virtual address). The segmentation mechanism comprises selecting a segment register according to the instruction, and adding a corresponding segment base address (or simply segment base) to the logical address to produce the virtual address. The virtual address may subsequently be translated through a paging mechanism to a physical address. The physical address is the address presented to the memory to identify the corresponding storage location.</p><p>It is desireable to generate the virtual addresses as quickly as possible in order to accelerate access to memory operands. However, the generation of virtual addresses is hindered by the existence of multiple addressing modes in the x86 instruction set architecture. The addressing modes are used to provide compatibility with the earlier 16 bit addressing while allowing 32 bit addressing as well. Generally, an addressing mode specifies the number of bits present in the address operands. More particularly, the code segment (which translates logical instruction fetch addresses to linear instruction fetch addresses in a manner similar to the generation of memory operand addresses) specifies a default addressing mode for each instruction. However, using an address override prefix byte, a particular instruction may reverse the default addressing mode. Thus, the addressing mode is determined on an instruction-by-instruction basis.</p><p>In the 16 bit addressing mode, the logical address is formed by adding the address operands of the instruction (as 16 bit quantities). Any carries from the sixteenth bit are discarded. The resulting 16 bit logical address is added to the segment base, which is a 32 bit quantity in the present x86 instruction set architecture, respecting any carry into the seventeenth bit of the virtual address sum. On the other hand, in 32 bit addressing mode, the address operands are 32 bit. Accordingly, the virtual address is a 32 bit sum of the segment base and the address operands. The differences in handling 16 bit and 32 bit addressing mode, particularly the discarding of carries when adding the address operands but the preservation of the carry when adding the segment base in 16 bit addressing mode, adds complication to the generation of memory operand addresses. This complication tends to slow the generation of addresses, thereby reducing the speed at which memory operands may be accessed.</p><h4>SUMMARY OF THE INVENTION</h4><p>The problems outlined above are in large part solved by a processor as described herein. The processor includes an address generation unit (AGU) which adds address operands and the segment base. The AGU may add the segment base and the displacement while other address operands are being read from the register file. The sum of the segment base and the displacement may subsequently be added to the remaining address operands. The AGU receives the addressing mode of the instruction, and if the addressing mode is 16 bit, the AGU zeros the carry from the sixteenth bit to the seventeenth bit of the sums generated therein. Additionally, in parallel, the AGU determines if a carry from the sixteenth bit to the seventeenth bit would occur if the logical address were added to the segment base. In one embodiment, the sum of the address operands and the segment base, with carries from the sixteenth bit to the seventeenth bit zeroed, and the carry generated in parallel are provided to a translation lookaside buffer (TLB), which stores translations in the same format (sum and carry). In another embodiment, the AGU corrects the most significant bits of the generated sum based on the carry. The AGU and/or TLB may provide reduced address generation latency while handling the 16 bit addressing mode as defined in the instruction set architecture.</p><p>Broadly speaking, a processor is contemplated, the processor comprising an AGU. The AGU is coupled to receive a segment base, one or more address operands of an instruction, and a mode signal identifying whether or not an addressing mode of the instruction is 16 bit. The AGU includes adder circuitry configured to add the segment base and the one or more address operands to produce a value, and further configured to zero a carry-in to a seventeenth bit of the value in response to the mode signal indicating that the addressing mode is 16 bit. The AGU further includes a carry circuit configured to generate a first carry signal indicative of a carry-in to the seventeenth bit of a virtual address of a memory operand of the instruction according to an instruction set architecture defining the instruction. The carry circuit is coupled to receive the mode signal and to generate the first carry signal in response to the mode signal. Additionally, a computer system is contemplated including the processor and an input/output (I/O) device configured to communicate between the computer system and another computer system to which the I/O device is couplable.</p><p>Moreover, a method is contemplated. One or more address operands of an instruction and a segment base are summed to produce a value, wherein the summing comprises zeroing a carry-in to a seventeenth bit of the value responsive to an addressing mode of the instruction being 16 bit. A first carry-in to the seventeenth bit of a virtual address of a memory operand of the instruction is generated according to an instruction set architecture defining the instruction and in response to the addressing mode.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>Other objects and advantages of the invention will become apparent upon reading the following detailed description and upon reference to the accompanying drawings in which:</p><p>FIG. 1 is a block diagram of one embodiment of a processor.</p><p>FIG. 2 is a timing diagram illustrating an exemplary pipeline which may be employed by one embodiment of the processor shown in FIG. <b>1</b>.</p><p>FIG. 3 is a block diagram of one embodiment of an address generation unit (AGU) which may be included in the processor of FIG. <b>1</b>.</p><p>FIG. 4 is a block diagram of one embodiment of a translation lookaside buffer (TLB) which may be employed with the AGU shown in FIG. <b>3</b>.</p><p>FIG. 5 is a flowchart illustrating an exemplary microcode routine which may be used to reload a TLB entry in response to a TLB miss.</p><p>FIG. 6 is a timing diagram illustrating operation of one embodiment of the AGU shown in FIG. <b>3</b> and the TLB shown in FIG. 4 in the pipeline shown in FIG. <b>2</b>.</p><p>FIG. 7 is a block diagram of another embodiment of the AGU shown in FIG. <b>3</b>.</p><p>FIG. 8 is a block diagram of one embodiment of a computer system including the processor shown in FIG. <b>1</b>.</p><p>FIG. 9 is a block diagram of a second embodiment of a computer system including the processor shown in FIG. <b>1</b>.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><p>While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.</p><h4>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</h4><p>Processor Overview</p><p>Turning now to FIG. 1, a block diagram of one embodiment of a processor <b>10</b> is shown. Other embodiments are possible and contemplated. In the embodiment of FIG. 1, processor <b>10</b> includes a line predictor <b>12</b>, an instruction cache (I-cache) <b>14</b>, an alignment unit <b>16</b>, a branch prediction/fetch PC generation unit <b>18</b>, a plurality of decode units <b>24</b>A-<b>24</b>D, a predictor miss decode unit <b>26</b>, a microcode unit <b>28</b>, a map unit <b>30</b>, a retire queue <b>32</b>, an architectural renames file <b>34</b>, a future file <b>20</b>, a scheduler <b>36</b>, an integer register file <b>38</b>A, a floating point register file <b>38</b>B, an integer execution core <b>40</b>A, a floating point execution core <b>40</b>B, a load/store unit <b>42</b>, a data cache (D-cache) <b>44</b>, an external interface unit <b>46</b>, and a PC silo <b>48</b>. Line predictor <b>12</b> is coupled to predictor miss decode unit <b>26</b>, branch prediction/fetch PC generation unit <b>18</b>, PC silo <b>48</b>, and alignment unit <b>16</b>. Line predictor <b>12</b> may also be coupled to I-cache <b>14</b>. I-cache <b>14</b> is coupled to alignment unit <b>16</b> and branch prediction/fetch PC generation unit <b>18</b>, which is further coupled to PC silo <b>48</b>. Alignment unit <b>16</b> is further coupled to predictor miss decode unit <b>26</b> and decode units <b>24</b>A-<b>24</b>D. Decode units <b>24</b>A-<b>24</b>D are further coupled to map unit <b>30</b>, and decode unit <b>24</b>D is coupled to microcode unit <b>28</b>. Map unit <b>30</b> is coupled to retire queue <b>32</b> (which is coupled to architectural renames file <b>34</b>), future file <b>20</b>, scheduler <b>36</b>, and PC silo <b>48</b>. Architectural renames file <b>34</b> is coupled to future file <b>20</b>. Scheduler <b>36</b> is coupled to register files <b>38</b>A-<b>38</b>B, which are further coupled to each other and respective execution cores <b>40</b>A-<b>40</b>B. Execution cores <b>40</b>A-<b>40</b>B are further coupled to load/store unit <b>42</b> and scheduler <b>36</b>. Execution core <b>40</b>A is further coupled to D-cache <b>44</b>. Load/store unit <b>42</b> is coupled to scheduler <b>36</b>, D-cache <b>44</b>, and external interface unit <b>46</b>. D-cache <b>44</b> is coupled to register files <b>38</b>. External interface unit <b>46</b> is coupled to an external interface <b>52</b> and to I-cache <b>14</b>. Elements referred to herein by a reference numeral followed by a letter will be collectively referred to by the reference numeral alone. For example, decode units <b>24</b>A-<b>24</b>D will be collectively referred to as decode units <b>24</b>.</p><p>In the embodiment of FIG. 1, processor <b>10</b> employs a variable byte length, complex instruction set computing (CISC) instruction set architecture. For example, processor <b>10</b> may employ the x86 instruction set architecture (also referred to as IA-32). Other embodiments may employ other instruction set architectures including fixed length instruction set architectures and reduced instruction set computing (RISC) instruction set architectures. Certain features shown in FIG. 1 may be omitted in such architectures.</p><p>Branch prediction/fetch PC generation unit <b>18</b> is configured to provide a fetch address (fetch PC) to I-cache <b>14</b>, line predictor <b>12</b>, and PC silo <b>48</b>. Branch prediction/fetch PC generation unit <b>18</b> may include a suitable branch prediction mechanism used to aid in the generation of fetch addresses. In response to the fetch address, line predictor <b>12</b> provides alignment information corresponding to a plurality of instructions to alignment unit <b>16</b>, and may provide a next fetch address for fetching instructions subsequent to the instructions identified by the provided instruction information. The next fetch address may be provided to branch prediction/fetch PC generation unit <b>18</b> or may be directly provided to I-cache <b>14</b>, as desired. Branch prediction/fetch PC generation unit <b>18</b> may receive a trap address from PC silo <b>48</b> (if a trap is detected) and the trap address may comprise the fetch PC generated by branch prediction/fetch PC generation unit <b>18</b>. Otherwise, the fetch PC may be generated using the branch prediction information and information from line predictor <b>12</b>. Generally, line predictor <b>12</b> stores information corresponding to instructions previously speculatively fetched by processor <b>10</b>. In one embodiment, line predictor <b>12</b> includes 2K entries, each entry locating a group of one or more instructions referred to herein as a \u201cline\u201d of instructions. The line of instructions may be concurrently processed by the instruction processing pipeline of processor <b>10</b> through being placed into scheduler <b>36</b>.</p><p>I-cache <b>14</b> is a high speed cache memory for storing instruction bytes. According to one embodiment I-cache <b>14</b> may comprise, for example, a 128 Kbyte, four way set associative organization employing 64 byte cache lines. However, any I-cache structure may be suitable (including direct-mapped structures).</p><p>Alignment unit <b>16</b> receives the instruction alignment information from line predictor <b>12</b> and instruction bytes corresponding to the fetch address from I-cache <b>14</b>. Alignment unit <b>16</b> selects instruction bytes into each of decode units <b>24</b>A-<b>24</b>D according to the provided instruction alignment information. More particularly, line predictor <b>12</b> provides an instruction pointer corresponding to each decode unit <b>24</b>A-<b>24</b>D. The instruction pointer locates an instruction within the fetched instruction bytes for conveyance to the corresponding decode unit <b>24</b>A-<b>24</b>D. In one embodiment, certain instructions may be conveyed to more than one decode unit <b>24</b>A-<b>24</b>D. Accordingly, in the embodiment shown, a line of instructions from line predictor <b>12</b> may include up to 4 instructions, although other embodiments may include more or fewer decode units <b>24</b> to provide for more or fewer instructions within a line.</p><p>Decode units <b>24</b>A-<b>24</b>B decode the instructions provided thereto, and each decode unit <b>24</b>A-<b>24</b>D generates information identifying one or more instruction operations (or ROPs) corresponding to the instructions. In one embodiment, each decode unit <b>24</b>A-<b>24</b>B may generate up to two instruction operations per instruction. As used herein, an instruction operation (or ROP) is an operation which an execution unit within execution cores <b>40</b>A-<b>40</b>B is configured to execute as a single entity. Simple instructions may correspond to a single instruction operation, while more complex instructions may correspond to multiple instruction operations. Certain of the more complex instructions may be implemented within microcode unit <b>28</b> as microcode routines (fetched from a read-only memory therein via decode unit <b>24</b>D in the present embodiment). Furthermore, other embodiments may employ a single instruction operation for each instruction (i.e. instruction and instruction operation may be synonymous in such embodiments).</p><p>PC silo <b>48</b> stores the fetch address and instruction information for each instruction fetch, and is responsible for redirecting instruction fetching upon exceptions (such as instruction traps defined by the instruction set architecture employed by processor <b>10</b>, branch mispredictions, and other microarchitecturally defined traps). PC silo <b>48</b> may include a circular buffer for storing fetch address and instruction information corresponding to multiple lines of instructions which may be outstanding within processor <b>10</b>. In response to retirement of a line of instructions, PC silo <b>48</b> may discard the corresponding entry. In response to an exception, PC silo <b>48</b> may provide a trap address to branch prediction/fetch PC generation unit <b>18</b>. Retirement and exception information may be provided by scheduler <b>36</b>. In one embodiment, PC silo <b>48</b> assigns a sequence number (R#) to each instruction to identify the order of instructions outstanding within processor <b>10</b>. Scheduler <b>36</b> may return R#s to PC silo <b>48</b> to identify instruction operations experiencing exceptions or retiring instruction operations.</p><p>Upon detecting a miss in line predictor <b>12</b>, alignment unit <b>16</b> routes the corresponding instruction bytes from I-cache <b>14</b> to predictor miss decode unit <b>26</b>. Predictor miss decode unit <b>26</b> decodes the instruction, enforcing any limits on a line of instructions as processor <b>10</b> is designed for (e.g. maximum number of instruction operations, maximum number of instructions, terminate on branch instructions, etc.). Upon terminating a line, predictor miss decode unit <b>26</b> provides the information to line predictor <b>12</b> for storage. It is noted that predictor miss decode unit <b>26</b> may be configured to dispatch instructions as they are decoded. Alternatively, predictor miss decode unit <b>26</b> may decode the line of instruction information and provide it to line predictor <b>12</b> for storage. Subsequently, the missing fetch address may be reattempted in line predictor <b>12</b> and a hit may be detected.</p><p>In addition to decoding instructions upon a miss in line predictor <b>12</b>, predictor miss decode unit <b>26</b> may be configured to decode instructions if the instruction information provided by line predictor <b>12</b> is invalid. In one embodiment, processor <b>10</b> does not attempt to keep information in line predictor <b>12</b> coherent with the instructions within I-cache <b>14</b> (e.g. when instructions are replaced or invalidate in I-cache <b>14</b>, the corresponding instruction information may not actively be invalidated). Decode units <b>24</b>A-<b>24</b>D may verify the instruction information provided, and may signal predictor miss decode unit <b>26</b> when invalid instruction information is detected. According to one particular embodiment, the following instruction operations are supported by processor <b>10</b>: integer (including arithmetic, logic, shift/rotate, and branch operations), floating point (including multimedia operations), and load/store.</p><p>The decoded instruction operations and source and destination register numbers are provided to map unit <b>30</b>. Map unit <b>30</b> is configured to perform register renaming by assigning physical register numbers (PR#s) to each destination register operand and source register operand of each instruction operation. The physical register numbers identify registers within register files <b>38</b>A-<b>38</b>B. Map unit <b>30</b> additionally provides an indication of the dependencies for each instruction operation by providing R#s of the instruction operations which update each physical register number assigned to a source operand of the instruction operation. Map unit <b>30</b> updates future file <b>20</b> with the physical register numbers assigned to each destination register (and the R# of the corresponding instruction operation) based on the corresponding logical register number. Additionally, map unit <b>30</b> stores the logical register numbers of the destination registers, assigned physical register numbers, and the previously assigned physical register numbers in retire queue <b>32</b>. As instructions are retired (indicated to map unit <b>30</b> by scheduler <b>36</b>), retire queue <b>32</b> updates architectural renames file <b>34</b> and frees any registers which are no longer in use. Accordingly, the physical register numbers in architectural register file <b>34</b> identify the physical registers storing the committed architectural state of processor <b>10</b>, while future file <b>20</b> represents the speculative state of processor <b>10</b>. In other words, architectural renames file <b>34</b> stores a physical register number corresponding to each logical register, representing the committed register state for each logical register. Future file <b>20</b> stores a physical register number corresponding to each logical register, representing the speculative register state for each logical register.</p><p>The line of instruction operations, source physical register numbers, and destination physical register numbers are stored into scheduler <b>36</b> according to the R#s assigned by PC silo <b>48</b>. Furthermore, dependencies for a particular instruction operation may be noted as dependencies on other instruction operations which are stored in the scheduler. In one embodiment, instruction operations remain in scheduler <b>36</b> until retired.</p><p>Scheduler <b>36</b> stores each instruction operation until the dependencies noted for that instruction operation have been satisfied. In response to scheduling a particular instruction operation for execution, scheduler <b>36</b> may determine at which clock cycle that particular instruction operation will update register files <b>38</b>A-<b>38</b>B. Different execution units within execution cores <b>40</b>A-<b>40</b>B may employ different numbers of pipeline stages (and hence different latencies). Furthermore, certain instructions may experience more latency within a pipeline than others. Accordingly, a countdown is generated which measures the latency for the particular instruction operation (in numbers of clock cycles). Scheduler <b>36</b> awaits the specified number of clock cycles (until the update will occur prior to or coincident with the dependent instruction operations reading the register file), and then indicates that instruction operations dependent upon that particular instruction operation may be scheduled. It is noted that scheduler <b>36</b> may schedule an instruction once its dependencies have been satisfied (i.e. out of order with respect to its order within the scheduler queue).</p><p>Integer and load/store instruction operations read source operands according to the source physical register numbers from register file <b>38</b>A and are conveyed to execution core <b>40</b>A for execution. Execution core <b>40</b>A executes the instruction operation and updates the physical register assigned to the destination within register file <b>38</b>A. Additionally, execution core <b>40</b>A reports the R# of the instruction operation and exception information regarding the instruction operation (if any) to scheduler <b>36</b>. Register file <b>38</b>B and execution core <b>40</b>B may operate in a similar fashion with respect to floating point instruction operations (and may provide store data for floating point stores to load/store unit <b>42</b>).</p><p>In one embodiment, execution core <b>40</b>A may include, for example, two integer units, a branch unit, and two address generation units (with corresponding translation lookaside buffers, or TLBs). Execution core <b>40</b>B may include a floating point/multimedia multiplier, a floating point/multimedia adder, and a store data unit for delivering store data to load/store unit <b>42</b>. Other configurations of execution units are possible.</p><p>Load/store unit <b>42</b> provides an interface to D-cache <b>44</b> for performing memory operations and for scheduling fill operations for memory operations which miss D-cache <b>44</b>. Load memory operations may be completed by execution core <b>40</b>A performing an address generation and forwarding data to register files <b>38</b>A-<b>38</b>B (from D-cache <b>44</b> or a store queue within load/store unit <b>42</b>). Store addresses may be presented to D-cache <b>44</b> upon generation thereof by execution core <b>40</b>A (directly via connections between execution core <b>40</b>A and D-Cache <b>44</b>). The store addresses are allocated a store queue entry. The store data may be provided concurrently, or may be provided subsequently, according to design choice. Upon retirement of the store instruction, the data is stored into D-cache <b>44</b> (although there may be some delay between retirement and update of D-cache <b>44</b>). Additionally, load/store unit <b>42</b> may include a load/store buffer for storing load/store addresses which miss D-cache <b>44</b> for subsequent cache fills (via external interface unit <b>46</b>) and re-attempting the missing load/store operations. Load/store unit <b>42</b> is further configured to handle load/store memory dependencies.</p><p>D-cache <b>44</b> is a high speed cache memory for storing data accessed by processor <b>10</b>. While D-cache <b>44</b> may comprise any suitable structure (including direct mapped and set-associative structures), one embodiment of D-cache <b>44</b> may comprise a 128 Kbyte, 2 way set associative cache having 64 byte lines.</p><p>External interface unit <b>46</b> is configured to communicate to other devices via external interface <b>52</b>. Any suitable external interface <b>52</b> may be used, including interfaces to L<b>2</b> caches and an external bus or buses for connecting processor <b>10</b> to other devices. External interface unit <b>46</b> fetches fills for I-cache <b>16</b> and D-cache <b>44</b>, as well as writing discarded updated cache lines from D-cache <b>44</b> to the external interface. Furthermore, external interface unit <b>46</b> may perform non-cacheable reads and writes generated by processor <b>10</b> as well.</p><p>Turning next to FIG. 2, an exemplary pipeline diagram illustrating an exemplary set of pipeline stages which may be employed by one embodiment of processor <b>10</b> is shown. Other embodiments may employ different pipelines, pipelines including more or fewer pipeline stages than the pipeline shown in FIG. <b>2</b>. The stages shown in FIG. 2 are delimited by vertical dashed lines. Each stage is one clock cycle of a clock signal used to clock storage elements (e.g. registers, latches, flops, and the like) within processor <b>10</b>.</p><p>As illustrated in FIG. 2, the exemplary pipeline includes a CAM<b>0</b> stage, a CAM<b>1</b> stage, a line predictor (LP) stage, an instruction cache (IC) stage, an alignment (AL) stage, a decode (DEC) stage, a map<b>1</b> (M<b>1</b>) stage, a map<b>2</b> (M<b>2</b>) stage, a write scheduler (WR SC) stage, a read scheduler (RD SC) stage, a register file read (RF RD) stage, an execute (EX) stage, a register file write (RF WR) stage, and a retire (RET) stage. Some instructions utilize multiple clock cycles in the execute state. For example, memory operations, floating point operations, and integer multiply operations are illustrated in exploded form in FIG. <b>2</b>. Memory operations include an address generation (AGU) stage, a translation (TLB) stage, a data cache <b>1</b> (DC<b>1</b>) stage, and a data cache <b>2</b> (DC<b>2</b>) stage. Similarly, floating point operations include up to four floating point execute (FEX<b>1</b>-FEX<b>4</b>) stages, and integer multiplies include up to four (IM<b>1</b>-IM<b>4</b>) stages.</p><p>During the CAM<b>0</b> and CAM<b>1</b> stages, line predictor <b>12</b> compares the fetch address provided by branch prediction/fetch PC generation unit <b>18</b> to the addresses of lines stored therein. Additionally, the fetch address is translated from a virtual address (e.g. a linear address in the x86 architecture) to a physical address during the CAM<b>0</b> and CAM<b>1</b> stages. In response to detecting a hit during the CAM<b>0</b> and CAM<b>1</b> stages, the corresponding line information is read from the line predictor during the line predictor stage. Also, I-cache <b>14</b> initiates a read (using the physical address) during the line predictor stage. The read completes during the instruction cache stage.</p><p>It is noted that, while the pipeline illustrated in FIG. 2 employs two clock cycles to detect a hit in line predictor <b>12</b> for a fetch address, other embodiments may employ a single clock cycle (and stage) to perform this operation. Moreover, in one embodiment line predictor <b>12</b> provides a next fetch address for I-cache <b>14</b> and a next entry in line predictor <b>12</b> for a hit, and therefore the CAM<b>0</b> and CAM<b>1</b> stages may be skipped for fetches resulting from a previous hit in line predictor <b>12</b>.</p><p>Instruction bytes provided by I-cache <b>14</b> are aligned to decode units <b>24</b>A-<b>24</b>D by alignment unit <b>16</b> during the alignment stage in response to the corresponding line information from line predictor <b>12</b>. Decode units <b>24</b>A-<b>24</b>D decode the provided instructions, identifying ROPs corresponding to the instructions as well as operand information during the decode stage. Map unit <b>30</b> generates ROPs from the provided information during the map<b>1</b> stage, and performs register renaming (updating future file <b>20</b>). During the map<b>2</b> stage, the ROPs and assigned renames are recorded in retire queue <b>32</b>. Furthermore, the ROPs upon which each ROP is dependent are determined. Each ROP may be register dependent upon earlier ROPs as recorded in the future file, and may also exhibit other types of dependencies (e.g. dependencies on a previous serializing instruction, etc.)</p><p>The generated ROPs are written into scheduler <b>36</b> during the write scheduler stage. Up until this stage, the ROPs located by a particular line of information flow through the pipeline as a unit. However, subsequent to be written into scheduler <b>36</b>, the ROPs may flow independently through the remaining stages, at different times Generally, a particular ROP remains at this stage until selected for execution by scheduler <b>36</b> (e.g. after the ROPs upon which the particular ROP is dependent have been selected for execution, as described above). Accordingly, a particular ROP may experience one or more clock cycles of delay between the write scheduler write stage and the read scheduler stage. During the read scheduler stage, the particular ROP participates in the selection logic within scheduler <b>36</b>, is selected for execution, and is read from scheduler <b>36</b>. The particular ROP then proceeds to read register file operations from one of register files <b>38</b>A-<b>38</b>B (depending upon the type of ROP) in the register file read stage.</p><p>The particular ROP and operands are provided to the corresponding execution core <b>40</b>A or <b>40</b>B, and the instruction operation is performed on the operands during the execution stage. As mentioned above, some ROPs have several pipeline stages of execution. For example, memory instruction operations (e.g. loads and stores) are executed through an address generation stage (in which the data address of the memory location accessed by the memory instruction operation is generated), a translation stage (in which the virtual data address provided by the address generation stage is translated) and a pair of data cache stages in which D-cache <b>44</b> is accessed. Floating point operations may employ up to 4 clock cycles of execution, and integer multiplies may similarly employ up to 4 clock cycles of execution.</p><p>Upon completing the execution stage or stages, the particular ROP updates its assigned physical register during the register file write stage. Finally, the particular ROP is retired after each previous ROP is retired (in the retire stage). Again, one or more clock cycles may elapse for a particular ROP between the register file write stage and the retire stage. Furthermore, a particular ROP may be stalled at any stage due to pipeline stall conditions, as is well known in the art.</p><p>Address Generation</p><p>Turning next to FIG. 3, a block diagram of one embodiment of an address generation unit (AGU) <b>60</b> is shown. Other embodiments are possible and contemplated. In the embodiment of FIG. 3, AGU <b>60</b> includes a first adder <b>62</b>, a second adder <b>64</b>, a carry generator <b>66</b>, a shift unit <b>68</b>, and carry logic <b>70</b>. Additionally shown in FIG. 3 is integer register file <b>38</b>A and segment registers <b>72</b>. Integer register file <b>38</b>A is coupled to receive base and index PR#s from scheduler <b>36</b> and to provide corresponding base and index operands to AGU <b>60</b>. Segment registers <b>72</b> are coupled to receive a segment register selection (SegReg Select in FIG. 3) from scheduler <b>36</b> and to provide a corresponding segment base (SegBase in FIG. 3) to AGU <b>60</b>. AGU <b>60</b> is further coupled to receive a scale, a mode signal, and a displacement operand from scheduler <b>36</b>. More particularly, first adder <b>62</b> is coupled to receive the segment base, displacement, and mode signal and is coupled to provide a first sum to second adder <b>64</b> and a carry signal C<sub>16SD </sub>to carry logic <b>70</b>. Shift unit <b>68</b> is coupled to receive the index operand and scale, and is coupled to provide the shifted index operand to carry generator <b>66</b> and second adder <b>64</b>. Carry generator <b>66</b> and second adder <b>64</b> are coupled to receive the base operand, and carry generator <b>66</b> is further coupled to receive the displacement operand and to provide a carry signal C<sub>16DIB </sub>to carry logic <b>70</b>. Second adder <b>64</b> is coupled to provide an output value (labeled pseudo-address in FIG. 3) to D-cache <b>44</b> and a data translation lookaside buffer (DTLB) <b>80</b> (shown in FIG. <b>4</b>). Carry logic <b>70</b> is coupled to provide a carry signal C<sub>16 </sub>to DTLB <b>80</b>.</p><p>Generally, scheduler <b>36</b> selects load/store memory operations for execution once dependencies of those load/store memory operations are satisfied. A memory operation is an instruction operation which causes the transfer of data between a memory location (which may be in cache) and the processor. A load memory operation causes the transfer of data from memory to the processor, and a store memory operation causes the transfer of data from the processor to memory. The memory operation may be derived from an instruction which has a memory operand, or may be a pure load or store instruction specifying a memory operand. Scheduler <b>36</b> conveys the base and index PR#s to integer register file <b>38</b>A, which provides the corresponding base and index operands to AGU <b>60</b>. The index operand may optionally be scaled by 2, 4, or 8 (which results in a shift of the index operand by one, two, or three bits), and hence the scale is provided to shift unit <b>68</b> which appropriately shifts the index operand. Scheduler <b>36</b> provides the segment register selection to segment registers <b>72</b>, which provide the corresponding segment base to AGU <b>60</b>. Scheduler <b>36</b> also provides a mode signal indicating whether or not the addressing mode is 16 bit for the memory operation. AGU <b>60</b> adds the operands to produce a pseudo-address and carry signal C<sub>16</sub>. The pseudo-address is provided to D-cache <b>44</b> and DTLB <b>80</b>, and the C<sub>16 </sub>signal is provided to DTLB <b>80</b>. As will be described in greater detail below, in some cases the pseudo-address is the virtual address of the memory operand, and in some cases is a value which may not be the virtual address but which may be used, in conjunction with the C<sub>16 </sub>signal, to determine the virtual address. More particularly, AGU <b>60</b> zeros the carries from the sixteenth to the seventeenth bit in 16 bit addressing mode when adding the address operands and segment base to produce the pseudo-address. In parallel, AGU <b>60</b> determines if a carry from the sixteenth bit to the seventeenth bit is generated when adding the logical address and the segment base (the carry signal C<sub>16</sub>).</p><p>AGU <b>60</b> provides for rapid address generation in both 32 bit and 16 bit addressing modes, while handling the carry between the sixteenth bit and the seventeenth bit (bits <b>15</b> and <b>16</b> as numbered in FIG. 3) in the manner defined for 16 bit addressing mode. The displacement and segment base may both be available earlier in time than the base and index operands for a given address generation. The displacement is a constant in the instruction, and thus is available directly from scheduler <b>36</b>. The segment registers <b>72</b> are relatively few in number, and therefore may be accessed more rapidly than the larger integer register file <b>38</b>A. For example, segment registers <b>72</b> may be implemented as discrete registers rather than a random access memory (RAM). Accordingly, first adder <b>62</b> adds the segment base and displacement operands to produce a first sum while the index and base operands are read from integer register file <b>38</b>A. First adder <b>62</b> receives the mode signal and, if the mode signal indicates 16 bit addressing mode, first adder <b>62</b> zeros the carry-in to bit <b>16</b> of the first sum (illustrated by the AND gate in adder <b>62</b> between the adder producing the least significant 16 bits (<b>15</b>:<b>0</b>) and the most significant 16 bits (<b>31</b>:<b>16</b>)). In the illustration, the mode signal being a binary zero indicates 16 bit addressing mode, and causes the carry-in to the most significant bits adder to be zero. In 32 bit addressing mode, the carry-out of the least significant bits adder is provided to the most significant bits adder. Additionally, the carry-out from bit <b>15</b> (the C<sub>16SD </sub>signal) is provided to carry logic <b>70</b>.</p><p>Second adder <b>64</b> receives the first sum from first adder <b>62</b> and the base and index operands, and adds the values to produce the pseudo-address. By adding the segment base and displacement while the base and index operands are being read, a three input adder may be used to generate the pseudo-address and thus the overall delay in producing the address may be reduced as compared to performing a four input add, or as compared to adding the base, index and displacement first and then adding the segment base. Similar to first adder <b>62</b>, second adder <b>64</b> zeros the carry-in to bit <b>16</b> if the mode signal indicates 16 bit addressing mode and provides the carry-out of bit <b>15</b> as the carry-in to bit <b>16</b> in 32 bit addressing mode. It is noted that, since second adder <b>64</b> is a three input adder, the carry is a two bit quantity. Similar to the discussion above for first adder <b>62</b>, the pseudo-address produced by second adder <b>64</b> is the virtual address of the memory operand in 32 bit addressing mode. On the other hand, since the carry-in to bit <b>16</b> is always zero in 16 bit addressing mode, the pseudo-address may or may not be the virtual address of the memory operand in 16 bit address mode (since a carry-in to bit 16 bit is defined to be preserved when adding the segment base to the logical address). Additionally, the least significant bit of the carry-out from bit <b>15</b> (the C<sub>16SDIB</sub>[<b>0</b>] signal) is provided to carry logic <b>70</b>.</p><p>In 16 bit addressing mode, the most significant bits of the virtual address are either the segment base[<b>1</b>:<b>16</b>] or the segment base[<b>31</b>:<b>16</b>]+1. This is true because the other operands are defined to be added (as sixteen bit quantities) with all carries discarded, creating a sixteen bit logical address which is then added to the 32 bit segment base (and thus at most a carry of one will be generated). For AGU <b>60</b>, the operands provided in 16 bit addressing mode may be sixteen bit quantities zero-extended to 32 bits. Thus, pseudo-address[<b>31</b>:<b>16</b>] is equal to segment base[<b>31</b>:<b>16</b>] in 16 bit addressing mode. Accordingly, the pseudo-address is the virtual address if a carry is not generated from the sixteenth bit to the seventeenth bit of the sum of the segment base and the logical address. If a carry is generated, the least significant 16 bits of the pseudo-address equal the least significant 16 bits of the virtual address, and the remaining bits are the most significant bits of the segment base (which, as a quantity, is one less than the most significant bits of the virtual address).</p><p>Carry generator <b>66</b> and carry logic <b>70</b> are used to determine if a carry occurs between the sixteenth bit and the seventeenth bit of the sum of the logical address and the segment base. The indication of the carry is transmitted by carry logic <b>70</b> as the carry signal C<sub>16</sub>. The carry out of the sixteenth bit (bit <b>15</b>) of the sum of base, index, and displacement (generated by carry generator <b>66</b>) and the sum of the segment base, base, index, and displacement will differ by at most one. If the carry-outs differ, the difference is the carry generated by adding the segment base to the logical address. Accordingly, a comparison of the carry out of the two sums can be used to determine the carry signal C<sub>16</sub>. More particularly, the least significant bit of the carry-outs may be compared since a difference of zero or one are the only mathematical possibilities. However, the carry-out for the sum of the segment base, base, index, and displacement is not directly generated in AGU <b>60</b>. Instead, the carry-outs from adders <b>62</b> and <b>64</b> together represents the carry. The equations below illustrate how the carries are combined to determine the C<sub>16 </sub>signal, where only the 16 bit portion of the addition is considered and the function TR in equation 1 represents truncation of carries. Equation 1 illustrates the desired carry (C<sub>16</sub>) to be determined:</p><p><maths><formula-text>2<sup>16</sup>*C<sub>16</sub>+S<sub>1</sub>[<b>15</b>:<b>0</b>]=Segbase[<b>15</b>:<b>0</b>]+TR(Base[<b>15</b>:<b>0</b>]+Index[<b>15</b>:<b>0</b>]+Disp[<b>15</b>:<b>0</b>])\u2003\u2003(1)</formula-text></maths></p><p>Equations 2-4 illustrate the carries generated by first adder <b>62</b>, second adder <b>64</b>, and carry generator <b>66</b>, respectively.</p><p><maths><formula-text>2<sup>16</sup>*C<sub>16SD</sub>+S<sub>2</sub>[<b>15</b>:<b>0</b>]=Segbase[<b>15</b>:<b>0</b>]+Disp[<b>15</b>:<b>0</b>]\u2003\u2003(2)</formula-text></maths></p><p><maths><formula-text>2<sup>16</sup>*C<sub>16SDIB</sub>[<b>1</b>:<b>0</b>]+S<sub>1</sub>[<b>15</b>:<b>0</b>]=S<sub>2</sub>[<b>15</b>:<b>0</b>]+Base[<b>15</b>:<b>0</b>]+Index[<b>15</b>:<b>0</b>]\u2003\u2003(3)</formula-text></maths></p><p><maths><formula-text>2<sup>16</sup>*C<sub>16DIB</sub>[<b>1</b>:<b>0</b>]+S<sub>3</sub>[<b>15</b>:<b>0</b>]=Base[<b>15</b>:<b>0</b>]+Index[<b>15</b>:<b>0</b>]+Disp[<b>15</b>:<b>0</b>]\u2003\u2003(4)</formula-text></maths></p><p>Substituting S<sub>2 </sub>as defined in equation 2 into equation 3 yields equation 5:</p><p><maths><formula-text>2<sup>16</sup>*(C<sub>16SDIB</sub>[<b>1</b>:<b>0</b>]+C<sub>16SD</sub>)+S<sub>1</sub>[<b>15</b>:<b>0</b>]=Segbase[<b>15</b>:<b>0</b>]+Disp[<b>15</b>:<b>0</b>]+Base[<b>15</b>:<b>0</b>]+Index[<b>15</b>:<b>0</b>]\u2003\u2003(5)</formula-text></maths></p><p>In equation 4, note that S<sub>3 </sub>is the same as TR(Base[<b>15</b>:<b>0</b>]+Index[<b>15</b>:<b>0</b>]+Disp[<b>15</b>:<b>0</b>]) in equation 1, and substitute to form equation 6:</p><p><maths><formula-text>2<sup>16</sup>*(C<sub>16</sub>+C<sub>16DIB</sub>[<b>1</b>:<b>0</b>])+S<sub>1</sub>[<b>15</b>:<b>0</b>]=Segbase[<b>15</b>:<b>0</b>]+Base[<b>15</b>:<b>0</b>]+Index[<b>15</b>:<b>0</b>]+Disp[<b>15</b>:<b>0</b>]\u2003\u2003(6)</formula-text></maths></p><p>Comparing equations 5 and 6, equation 7 can be derived:</p><p>\u2003C<sub>16</sub>=C<sub>16SDIB</sub>[<b>1</b>:<b>0</b>]+C<sub>16SD</sub>\u2212C<sub>16DIB</sub>[<b>1</b>:<b>0</b>]\u2003\u2003(7)</p><p>As mentioned above and as equation 7 shows, the difference between C<sub>16DIB</sub>[<b>1</b>:<b>0</b>]+C<sub>16SD </sub>and C<sub>16DIB</sub>[<b>1</b>:<b>0</b>] is either one or zero, and represents the desired carry C<sub>16</sub>. Accordingly, C<sub>16SD </sub>can be used to invert the binary sense of C<sub>16SDIB</sub>[<b>0</b>] (if C<sub>16SD </sub>and C<sub>16SDIB</sub>[<b>0</b>] differ) and the corresponding value can be compared to C<sub>16DIB</sub>[<b>0</b>] to determine C<sub>16 </sub>(where C<sub>16 </sub>is set if C<sub>16DIB</sub>[<b>0</b>] and the inverted binary sense of C<sub>16SDIB</sub>[<b>0</b>] differ). This is an exclusive OR of the three values, as shown in equation 8:</p><p><maths><formula-text>C<sub>16</sub>=C<sub>16SDIB</sub>[<b>0</b>]XOR C<sub>16SD </sub>XOR C<sub>16DIB</sub>[<b>0</b>]\u2003\u2003(8)</formula-text></maths></p><p>Accordingly, carry logic <b>70</b> exclusive ORs the provided carry signals. Additionally, carry logic <b>70</b> qualifies the resulting C<sub>16 </sub>signal with the mode signal, so that the C<sub>16 </sub>signal is zero in 32 bit addressing mode and is generated according to the various carries in 16 bit addressing mode. In 16 bit addressing mode, if the C<sub>16 </sub>signal is asserted, the pseudo-address is not the virtual address of the memory operand. Instead, the most significant 16 bits of the pseudo-address need to be incremented to form the virtual address. However, rather than actually perform the increment of the segment base and select the incremented or non-incremented segment base, AGU <b>60</b> as illustrated in FIG. 3 provides the pseudo-address and the C<sub>16 </sub>signal to DTLB <b>80</b>. DTLB <b>80</b> stores addresses in the same form as provided by AGU <b>60</b>, allowing for additional savings in the address generation latency. DTLB <b>80</b> provides physical addresses to D-cache <b>44</b> for tag comparison to determine a hit.</p><p>It is noted that one or more of the displacement, base, or index operands may not be used in a given instruction. The corresponding operands provided to AGU <b>60</b> for those instructions may be zero.</p><p>It is noted that, while adders <b>62</b> and <b>64</b> are illustrated herein as having a least significant portion and a most significant portion with logic in between to zero the carry or pass the carry based on the mode, the illustrations are meant to be illustrative only. Depending upon the actual adder implementation, the carry may be zeroed in any suitable fashion. For example, in a carry lookahead adder or a carry save adder, the carry-in to the seventeenth bit may be zeroed. On the other hand, a carry select adder may be implemented by selecting the non-carry sum for the most significant bits. Any suitable adder circuitry may be employed.</p><p>It is noted that AGU <b>60</b> and DTLB <b>80</b> may be part of integer execution core <b>40</b>A. Furthermore, while AGU <b>60</b> is shown as a dedicated address generation unit, other embodiments may implement the address generation unit as part of a general arithmetic/logic unit (ALU). In other words, the adders used for address generation may also be used to perform ALU operations, if desired. Additionally, multiple AGUs may be implemented, if desired, to concurrently execute multiple memory operations. The multiple AGUs may access one or more DTLBs, as desired.</p><p>Turning next to FIG. 4, a block diagram of one embodiment of DTLB <b>80</b> is shown. Other embodiments are possible and contemplated. In the embodiment of FIG. 4, DTLB <b>80</b> includes a tag array <b>82</b>, a data array <b>84</b>, an update control circuit <b>86</b>, a miss save register <b>88</b>, and a protection check circuit <b>90</b>. Tag array <b>82</b> and miss save register <b>88</b> are coupled to receive the pseudo-address, carry signal C<sub>16</sub>, and mode signal from AGU <b>60</b>. Additionally, tag array <b>82</b> is coupled to data array <b>84</b> and update control circuit <b>86</b>, and is further coupled to provide a hit signal to scheduler <b>36</b>. Miss save register <b>88</b> is coupled to update control circuit <b>86</b>, which is farther coupled to integer execution core <b>40</b>A. Data array <b>84</b> is coupled to receive update data from integer execution core <b>40</b>A, to provide a physical address (PA) to D-cache <b>44</b>, and to provide PTE/PDE information to protection check circuit <b>90</b>, which is coupled to provide an exception signal to scheduler <b>36</b>.</p><p>Generally, DTLB <b>80</b> is configured to search the address translations cached therein for virtual addresses provided by AGU <b>60</b>. If a hit is detected for a virtual address, the corresponding physical address is provided from data array <b>84</b> and tag array <b>82</b> asserts the hit signal. Additionally, certain information from the translation table entry used to translate the address (e.g. the PTE/PDE information) is cached in data array <b>84</b> and is provided to protection check circuit <b>90</b>. Protection check circuit <b>90</b> detects any protection violations using the translation information and the type of access, and signals an exception if a violation is detected.</p><p>More particularly, tag array <b>82</b> comprises a plurality of entries, each entry storing a mode field (M) an address field (A[<b>31</b>:<b>12</b>]), a carry field (C<sub>16</sub>), and a valid bit (V). Data array <b>84</b> comprises a plurality of entries, each of which is assigned to a corresponding entry in tag array <b>82</b>. The entries in data array <b>84</b> store the physical address corresponding to the virtual address identified by the corresponding tag entry and the PTE/PDE information from the corresponding page table entries used to translate the virtual address. Tag array <b>82</b> may comprise a content addressable memory (CAM), with the match line for each tag array entry selecting the corresponding entry in data array <b>84</b>. In one embodiment, DTLB <b>80</b> may comprise 128 entries, although any number of entries may be employed.</p><p>For addresses generated in 16 bit addressing mode, the address field of the corresponding tag entry stores a value matching the pseudo-address which is generated for that address. In other words, the most significant bits of the address field are the segment base corresponding to the address, and the least significant bits match the virtual address of the memory operand. A box <b>92</b> in FIG. 4 illustrates the pseudo-address bits provided to and stored by DTLB <b>80</b> for both 32 bit addressing mode and 16 bit addressing mode. The address field in each tag entry is defined in the same fashion. The carry field stores the value of the carry signal (C<sub>16</sub>) which corresponds to that address as well. For 32 bit addressing mode addresses, the carry field is clear. Both the address field and the carry field are matched against the corresponding values from AGU <b>60</b>, and a hit is not detected unless both fields match and the corresponding valid bit is set. If aliasing between 16 bit addressing mode translation entries and 32 bit translation mode entries is not desired, the mode signal and mode field may be compared as well. The mode field identifies which entries are 16 bit addressing mode entries and which are not.</p><p>If a miss is detected for a particular memory operation, miss save register <b>88</b> stores the pseudo-address, C<sub>16</sub>, and mode signals. The lack of a hit signal assertion for the memory operation may inform scheduler <b>36</b> that a DTLB miss has been detected and that the translation tables (e.g. page directory tables and page tables, as defined in the x86 instruction set architecture) are to be searched to find a corresponding translation. In one embodiment, if a memory operation is speculative and misses DTLB <b>80</b>, scheduler <b>36</b> re-executes the memory operation non-speculatively and miss save register <b>88</b> captures the corresponding information during the non-speculative operation. In the present embodiment, translation table searches may be performed via a microcode routine in MROM unit <b>28</b>. Thus, update control circuit <b>86</b> may communicate with integer execution core <b>40</b>A to receive the newly fetched address translation into tag array <b>82</b> and data array <b>84</b>. Generally, update control circuit <b>86</b> allocates an entry in tag array <b>82</b> and data array <b>84</b> for the newly fetched address translation. Any suitable replacement policy may be used. For example, a not most recently used (NMRU) policy may be used. In an NMRU policy, a replacement pointer may be implemented. When a TLB fill is performed, the entry indicated by the replacement pointer is replaced with the new information. The replacement pointer is incremented after each access, unless the increment causes the pointer to indicate the entry which hits during that access. Thus, the pointer indicates an entry which is not the most recently used entry. The information from miss save register <b>88</b> is stored into that allocated tag entry, and integer execution core <b>40</b>A provides the translation table information including the physical address and the PTE/PDE information to data array <b>84</b> for storage.</p><p>Another instruction which affects DTLB <b>80</b> is the invalidate page instruction. This instruction is defined to invalidate one page of translation information from the DTLB. However, since the page address of 16 bit addressing mode pages may not be accurately reflected in DTLB <b>80</b> (i.e. the C<sub>16 </sub>bit may be set), certain 16 bit addressing mode pages might not be invalidated when the invalidate page instruction is executed. Since each entry stores the mode bit (M) indicating whether or not the corresponding address translation is a 16 bit addressing mode translation, DTLB <b>80</b> may invalidate all of the 16 bit addressing mode translations in response to the invalidate page instruction. Additionally, any matching 32 bit address mode pages may be invalidated.</p><p>In one embodiment, a page may be defined to be 4 kilobytes, 2 Megabytes, or 4 Megabytes in size. Tag array <b>82</b> may store additional information identifying which size page is mapped by a given entry, and corresponding portions of the address field are don't cared for such entries. However, a 16 bit addressing mode mapping relies on some of these don't care bits to accurately map a page. In one particular embodiment, if a 16 bit addressing mode translation is found to be a 2 Megabyte or 4 Megabyte translation, DTLB <b>80</b> stores the page mapping as if it were a 4 kilobyte page. Thus, the 16 bit addressing mode operates correctly. Alternatively, DTLB <b>80</b> and AGU <b>60</b> may be designed to use more significant bits and a corresponding carry signal to correctly translate 16 bit addressing mode pages which are defined to be 2 or 4 Megabytes.</p><p>It is noted that, although the above discussion refers to 16 bit and 32 bit addressing modes, embodiments are contemplated in which a 64 bit addressing mode is also provided. An AGU <b>60</b> supporting 64 bit addressing modes would include an adder large enough to support the number of bits of virtual address in 64 bit mode, which may be less than 64 bits (e.g. 40-48 bits, or any number of bits up to and including 64 bits, depending upon the definition of the 64 bit addressing mode). The adders would still provide for zeroing the carry between the sixteenth and seventeenth bit, as described above. Furthermore, DTLB <b>80</b> would provide additional bits in the address field (and physical address field) to accommodate the larger number of address bits. The number of physical address bits may be 64 bits or less than 64 bits as well, and the number of physical address bits may differ from the number of virtual address bits.</p><p>Turning now to FIG. 5, a flowchart is shown illustrating an exemplary microcode routine which may be used in response to a DTLB miss for a 16 bit addressing mode virtual address. Other embodiments are possible and contemplated. Although the steps shown in the flowchart of FIG. 5 are shown in a particular order for ease of understanding, any suitable order may be used. Additionally, the exemplary microcode routine may include other steps for translating a non-16 bit addressing mode address, or a separate microcode routine may be used for such addresses. Alternatively, the 16 bit addressing mode TLB miss, the non-16 bit address mode TLB miss, or both may be handled in dedicated hardware instead of microcode.</p><p>The microcode routine begins by reading the information stored in miss save register <b>88</b> (step <b>100</b>). The information may be read by dispatching an instruction to integer execution core <b>40</b>A, which communicates with update control circuit <b>86</b> to receive the contents of the miss save register and stores the information into a microcode temporary register (as mapped into integer register file <b>38</b>A). Using the miss save information, the virtual address of the miss is calculated (step <b>102</b>). More particularly, if the C<sub>16 </sub>bit is set, the pseudo-address (exclusive of the least significant 16 bits) may be incremented and the corresponding value concatenated with the least significant bits of the pseudo-address to provide the virtual address. The virtual address (along with certain other processor resources, such as the CR<b>3</b> register) is then used to search the translation tables as defined in the instruction set architecture employed by the processor (step <b>104</b>). For example, the translation tables may include the page directory and page tables defined by the x86 instruction set architecture. If the search is successful (decision block <b>106</b>), the microcode routine communicates the translation information to DTLB <b>80</b> for storage, including causing the storage of the C<sub>16 </sub>bit from miss save register <b>88</b> and setting the mode field of the entry to indicate 16 bit addressing mode (step <b>108</b>). On the other hand, if the search is unsuccessful (decision block <b>106</b>), a page fault is signalled (step <b>110</b>). The page fault may involve, for example, branching to another microcode routine which handles page faults.</p><p>Turning next to FIG. 6, an exemplary timing diagram for load memory operations is illustrated, highlighting the operation of one embodiment of AGU <b>60</b> and one embodiment of DTLB <b>80</b> according to the pipeline shown in FIG. <b>2</b>. Other embodiments are possible and contemplated. More particularly, the register file read, AGU, and TLB stages are shown, delimited by vertical solid lines. Each stage is divided into phase zero and phase one (separated by a dashed vertical line). The phases are defined by the high and low periods of the clock signal clocking the pipeline.</p><p>During phase zero of the register file read stage, the segment base is read from the segment register file <b>72</b> (reference numeral <b>123</b>). During phase one of the register file read stage, first adder <b>62</b> adds the segment base and displacement, producing the first sum and the C<sub>16SD </sub>signal (reference numeral <b>120</b>). Additionally, the base and index operands are read from integer register file <b>38</b>A during the register file read stage (reference numeral <b>121</b>). During phase zero of the AGU stage, second adder <b>64</b> adds the first sum and the index and base operands, producing the pseudo-address and the C <sub>16SDIB </sub>signal (reference numeral <b>122</b>). In parallel, carry generator <b>86</b> generates the carry from the index, base, and displacement and carry logic <b>70</b> generates the C<sub>16 </sub>signal (reference numeral <b>124</b>). The pseudo-address and C<sub>16 </sub>signal are provided to DTLB <b>80</b>, which CAMs the values against tag array <b>82</b> during phase one of the AGU stage (reference numeral <b>126</b>). The selected data array entry is read (reference numeral <b>128</b>) and the physical address is provided to D-cache <b>44</b> for tag comparison (reference numeral <b>130</b>).</p><p>For the embodiment illustrated via FIG. 6, flops, latches, registers, or other clocked storage devices may be inserted into the embodiment of FIG. 3 to store intermediate values for pipelining to the next stage. For example, flops may capture the first sum, C<sub>16SD </sub>signal, and base and index values for use in the AGU stage. Other embodiments may insert the pipeline storage devices at different points. For example, a second AGU is contemplated for executing store memory operations. The second AGU may operate one phase delayed from that shown in FIG. 6 (e.g. SegBase and Displacement may be added in phase zero of the AGU stage, the first sum and index and base operands may be added in phase one of the AGU stage, etc.). The pipeline storage devices may be added at different points for such an embodiment.</p><p>Turning now to FIG. 7, a block diagram of a second embodiment of AGU <b>60</b> (AGU <b>60</b><i>a</i>) is shown. AGU <b>60</b><i>a </i>includes first adder <b>62</b>, second adder <b>64</b>, carry generator <b>66</b>, shift unit <b>68</b>, and carry logic <b>70</b> similar to AGU <b>60</b>. However, the C<sub>16 </sub>signal generated by carry logic <b>70</b> is coupled to a multiplexor (mux) <b>140</b>. Mux <b>140</b> is coupled to provide the portion of the virtual address exclusive of the least significant sixteen bits, which are provided by second adder <b>64</b>. Mux <b>140</b> receives the pseudo-address generated by second adder <b>64</b> (exclusive of the least significant sixteen bits) as an input, and the segment base most significant bits incremented by an incrementor <b>142</b> as another input. If the C<sub>16 </sub>signal is asserted, mux <b>140</b> selects the incremented segment base. If the C<sub>16 </sub>signal is deasserted, mux <b>140</b> selects the output of second adder <b>64</b>. In this manner, the address provided by AGU <b>60</b><i>a </i>is the virtual address in both 16 bit and non-16 bit addressing modes. Thus, AGU <b>60</b><i>a </i>may be used with a conventional DTLB.</p><p>Computer Systems</p><p>Turning now to FIG. 8, a block diagram of one embodiment of a computer system <b>200</b> including processor <b>10</b> coupled to a variety of system components through a bus bridge <b>202</b> is shown. Other embodiments are possible and contemplated. In the depicted system, a main memory <b>204</b> is coupled to bus bridge <b>202</b> through a memory bus <b>206</b>, and a graphics controller <b>208</b> is coupled to bus bridge <b>202</b> through an AGP bus <b>210</b>. Finally, a plurality of PCI devices <b>212</b>A-<b>212</b>B are coupled to bus bridge <b>202</b> through a PCI bus <b>214</b>. A secondary bus bridge <b>216</b> may further be provided to accommodate an electrical interface to one or more EISA or ISA devices <b>218</b> through an EISA/ISA bus <b>220</b>. Processor <b>10</b> is coupled to bus bridge <b>202</b> through a CPU bus <b>224</b> and to an optional L<b>2</b> cache <b>228</b>. Together, CPU bus <b>224</b> and the interface to L<b>2</b> cache <b>228</b> may comprise external interface <b>52</b>.</p><p>Bus bridge <b>202</b> provides an interface between processor <b>10</b>, main memory <b>204</b>, graphics controller <b>208</b>, and devices attached to PCI bus <b>214</b>. When an operation is received from one of the devices connected to bus bridge <b>202</b>, bus bridge <b>202</b> identifies the target of the operation (e.g. a particular device or, in the case of PCI bus <b>214</b>, that the target is on PCI bus <b>214</b>). Bus bridge <b>202</b> routes the operation to the targeted device. Bus bridge <b>202</b> generally translates an operation from the protocol used by the source device or bus to the protocol used by the target device or bus.</p><p>In addition to providing an interface to an ISA/EISA bus for PCI bus <b>214</b>, secondary bus bridge <b>216</b> may further incorporate additional functionality, as desired. An input/output controller (not shown), either external from or integrated with secondary bus bridge <b>216</b>, may also be included within computer system <b>200</b> to provide operational support for a keyboard and mouse <b>222</b> and for various serial and parallel ports, as desired. An external cache unit (not shown) may further be coupled to CPU bus <b>224</b> between processor <b>10</b> and bus bridge <b>202</b> in other embodiments. Alternatively, the external cache may be coupled to bus bridge <b>202</b> and cache control logic for the external cache may be integrated into bus bridge <b>202</b>. L<b>2</b> cache <b>228</b> is further shown in a backside configuration to processor <b>10</b>. It is noted that L<b>2</b> cache <b>228</b> may be separate from processor <b>10</b>, integrated into a cartridge (e.g. slot <b>1</b> or slot A) with processor <b>10</b>, or even integrated onto a semiconductor substrate with processor <b>10</b>.</p><p>Main memory <b>204</b> is a memory in which application programs are stored and from which processor <b>10</b> primarily executes. A suitable main memory <b>204</b> comprises DRAM (Dynamic Random Access Memory). For example, a plurality of banks of SDRAM (Synchronous DRAM) or Rambus DRAM (RDRAM) may be suitable.</p><p>PCI devices <b>212</b>A-<b>212</b>B are illustrative of a variety of peripheral devices such as, for example, network interface cards, video accelerators, audio cards, hard or floppy disk drives or drive controllers, SCSI (Small Computer Systems Interface) adapters and telephony cards. Similarly, ISA device <b>218</b> is illustrative of various types of peripheral devices, such as a modem, a sound card, and a variety of data acquisition cards such as GPIB or field bus interface cards.</p><p>Graphics controller <b>208</b> is provided to control the rendering of text and images on a display <b>226</b>. Graphics controller <b>208</b> may embody a typical graphics accelerator generally known in the art to render three-dimensional data structures which can be effectively shifted into and from main memory <b>204</b>. Graphics controller <b>208</b> may therefore be a master of AGP bus <b>210</b> in that it can request and receive access to a target interface within bus bridge <b>202</b> to thereby obtain access to main memory <b>204</b>. A dedicated graphics bus accommodates rapid retrieval of data from main memory <b>204</b>. For certain operations, graphics controller <b>208</b> may flier be configured to generate PCI protocol transactions on AGP bus <b>210</b>. The AGP interface of bus bridge <b>202</b> may thus include functionality to support both AGP protocol transactions as well as PCI protocol target and initiator transactions. Display <b>226</b> is any electronic display upon which an image or text can be presented. A suitable display <b>226</b> includes a cathode ray tube (\u201cCRT\u201d), a liquid crystal display (\u201cLCD\u201d), etc.</p><p>It is noted that, while the AGP, PCI, and ISA or EISA buses have been used as examples in the above description, any bus architectures may be substituted as desired. It is further noted that computer system <b>200</b> may be a multiprocessing computer system including additional processors (e.g. processor <b>10</b><i>a </i>shown as an optional component of computer system <b>200</b>). Processor <b>10</b><i>a </i>may be similar to processor <b>10</b>. More particularly, processor <b>10</b><i>a </i>may be an identical copy of processor <b>10</b>. Processor <b>10</b><i>a </i>may be connected to bus bridge <b>202</b> via an independent bus (as shown in FIG. 8) or may share CPU bus <b>224</b> with processor <b>10</b>. Furthermore, processor <b>10</b><i>a </i>may be coupled to an optional L<b>2</b> cache <b>228</b><i>a </i>similar to L<b>2</b> cache <b>228</b>.</p><p>Turning now to FIG. 9, another embodiment of a computer system <b>300</b> is shown. Other embodiments are possible and contemplated. In the embodiment of FIG. 9, computer system <b>300</b> includes several processing nodes <b>312</b>A, <b>312</b>B, <b>312</b>C, and <b>312</b>D. Each processing node is coupled to a respective memory <b>314</b>A-<b>314</b>D via a memory controller <b>316</b>A-<b>316</b>D included within each respective processing node <b>312</b>A-<b>312</b>D. Additionally, processing nodes <b>312</b>A-<b>312</b>D include interface logic used to communicate between the processing nodes <b>312</b>A-<b>312</b>D. For example, processing node <b>312</b>A includes interface logic <b>318</b>A for communicating with processing node <b>312</b>B, interface logic <b>318</b>B for communicating with processing node <b>312</b>C, and a third interface logic <b>318</b>C for communicating with yet another processing node (not shown). Similarly, processing node <b>312</b>B includes interface logic <b>318</b>D, <b>318</b>E, and <b>318</b>F; processing node <b>312</b>C includes interface logic <b>318</b>G, <b>318</b>H, and <b>318</b>I; and processing node <b>312</b>D includes interface logic <b>318</b>J, <b>318</b>K, and <b>318</b>L. Processing node <b>312</b>D is coupled to communicate with a plurality of input/output devices (e.g. devices <b>320</b>A-<b>320</b>B in a daisy chain configuration) via interface logic <b>318</b>L. Other processing nodes may communicate with other I/O devices in a similar fashion.</p><p>Processing nodes <b>312</b>A-<b>312</b>D implement a packet-based link for inter-processing node communication. In the present embodiment, the link is implemented as sets of unidirectional lines (e.g. lines <b>324</b>A are used to transmit packets from processing node <b>312</b>A to processing node <b>312</b>B and lines <b>324</b>B are used to transmit packets from processing node <b>312</b>B to processing node <b>312</b>A). Other sets of lines <b>324</b>C-<b>324</b>H are used to transmit packets between other processing nodes as illustrated in FIG. <b>9</b>. Generally, each set of lines <b>324</b> may include one or more data lines, one or more clock lines corresponding to the data lines, and one or more control lines indicating the type of packet being conveyed. The link may be operated in a cache coherent fashion for communication between processing nodes or in a noncoherent fashion for communication between a processing node and an I/O device (or a bus bridge to an I/O bus of conventional construction such as the PCI bus or ISA bus). Furthermore, the link may be operated in a non-coherent fashion using a daisy-chain structure between I/O devices as shown. It is noted that a packet to be transmitted from one processing node to another may pass through one or more intermediate nodes. For example, a packet transmitted by processing node <b>312</b>A to processing node <b>312</b>D may pass through either processing node <b>312</b>B or processing node <b>312</b>C as shown in FIG. <b>9</b>. Any suitable routing algorithm may be used. Other embodiments of computer system <b>300</b> may include more or fewer processing nodes then the embodiment shown in FIG. <b>9</b>.</p><p>Generally, the packets may be transmitted as one or more bit times on the lines <b>324</b> between nodes. A bit time may be the rising or falling edge of the clock signal on the corresponding clock lines. The packets may include command packets for initiating transactions, probe packets for maintaining cache coherency, and response packets from responding to probes and commands.</p><p>Processing nodes <b>312</b>A-<b>312</b>D, in addition to a memory controller and interface logic, may include one or more processors. Broadly speaking, a processing node comprises at least one processor and may optionally include a memory controller for communicating with a memory and other logic as desired. More particularly, a processing node <b>312</b>A-<b>312</b>D may comprise processor <b>10</b>. External interface unit <b>46</b> may includes the interface logic <b>318</b> within the node, as well as the memory controller <b>316</b>.</p><p>Memories <b>314</b>A-<b>314</b>D may comprise any suitable memory devices. For example, a memory <b>314</b>A-<b>314</b>D may comprise one or more RAMBUS DRAMs (RDRAMs), synchronous DRAMs (SDRAMs), static RAM, etc. The address space of computer system <b>300</b> is divided among memories <b>314</b>A-<b>314</b>D. Each processing node <b>312</b>A-<b>312</b>D may include a memory map used to determine which addresses are mapped to which memories <b>314</b>A-<b>314</b>D, and hence to which processing node <b>312</b>A-<b>312</b>D a memory request for a particular address should be routed. In one embodiment, the coherency point for an address within computer system <b>300</b> is the memory controller <b>316</b>A-<b>316</b>D coupled to the memory storing bytes corresponding to the address. In other words, the memory controller <b>316</b>A-<b>316</b>D is responsible for ensuring that each memory access to the corresponding memory <b>314</b>A-<b>314</b>D occurs in a cache coherent fashion. Memory controllers <b>316</b>A-<b>316</b>D may comprise control circuitry for interfacing to memories <b>314</b>A-<b>314</b>D. Additionally, memory controllers <b>316</b>A-<b>316</b>D may include request queues for queuing memory requests.</p><p>Generally, interface logic <b>318</b>A-<b>318</b>L may comprise a variety of buffers for receiving packets from the link and for buffering packets to be transmitted upon the link. Computer system <b>300</b> may employ any suitable flow control mechanism for transmitting packets. For example, in one embodiment, each interface logic <b>318</b> stores a count of the number of each type of buffer within the receiver at the other end of the link to which that interface logic is connected. The interface logic does not transmit a packet unless the receiving interface logic has a free buffer to store the packet. As a receiving buffer is freed by routing a packet onward, the receiving interface logic transmits a message to the sending interface logic to indicate that the buffer has been freed. Such a mechanism may be referred to as a \u201ccoupon-based\u201d system.</p><p>I/O devices <b>320</b>A-<b>320</b>B may be any suitable I/O devices. For example, I/O devices <b>320</b>A-<b>320</b>B may include network interface cards, video accelerators, audio cards, hard or floppy disk drives or drive controllers, SCSI (Small Computer Systems Interface) adapters and telephony cards, modems, sound cards, and a variety of data acquisition cards such as GPIB or field bus interface cards.</p><p>Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Stephan G.", "last_name": "Meier", "name": ""}, {"first_name": "Bruce A.", "last_name": "Gieseke", "name": ""}, {"first_name": "William A.", "last_name": "McGee", "name": ""}, {"first_name": "Ramsey W.", "last_name": "Haddad", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "ADVANCED MICRO DEVICES, INC."}, {"first_name": "", "last_name": "ADVANCED MICRO DEVICES, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F   9/38        20060101A I20051008RMEP"}, {"label": "G06F  12/10        20060101A I20051008RMEP"}, {"label": "G06F   9/355       20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711220"}, {"primary": false, "label": "708491"}, {"primary": false, "label": "712E09041"}, {"primary": false, "label": "712E09049"}, {"primary": false, "label": "711E12065"}, {"primary": false, "label": "712E09055"}, {"primary": false, "label": "712E09072"}], "ecla_classes": [{"label": "G06F   9/38E8"}, {"label": "G06F   9/38C4"}, {"label": "G06F   9/38B"}, {"label": "G06F   9/38B8"}, {"label": "G06F   9/30A1P"}, {"label": "G06F  12/10L2"}, {"label": "G06F   9/355"}, {"label": "G06F   9/38E"}], "cpc_classes": [{"label": "G06F   9/3814"}, {"label": "G06F   9/30036"}, {"label": "G06F   9/3822"}, {"label": "G06F   9/3859"}, {"label": "G06F   9/355"}, {"label": "G06F  12/1036"}, {"label": "G06F   9/3838"}, {"label": "G06F   9/3855"}, {"label": "G06F   9/3836"}, {"label": "G06F   9/3802"}, {"label": "G06F   9/384"}, {"label": "G06F   9/3857"}, {"label": "G06F   9/355"}, {"label": "G06F   9/3855"}, {"label": "G06F   9/30036"}, {"label": "G06F   9/384"}, {"label": "G06F   9/3814"}, {"label": "G06F   9/3836"}, {"label": "G06F   9/3822"}, {"label": "G06F  12/1036"}, {"label": "G06F   9/3859"}, {"label": "G06F   9/3802"}, {"label": "G06F   9/3838"}, {"label": "G06F   9/3857"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "2000-01-03", "application_date": "2000-01-03", "family_members": [{"ucid": "US-6363471-B1", "titles": [{"lang": "EN", "text": "Mechanism for handling 16-bit addressing in a processor"}]}]}