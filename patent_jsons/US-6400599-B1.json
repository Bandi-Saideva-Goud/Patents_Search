{"patent_number": "US-6400599-B1", "publication_id": 73038871, "family_id": 25529539, "publication_date": "2002-06-04", "titles": [{"lang": "EN", "text": "Cache memory cell with a pre-programmed state"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50327586\"><p>A memory device including a first set of memory cells, a second set of memory cells having preprogrammed states, and a circuit configured to access data included in a first segment of memory cells. When data is read from the second set of memory cells the circuit includes an enable signal to determine whether the data outputted by the second set of memory cells is preprogrammed data or data stored during normal operation. For one embodiment, data read into or retrieved from the memory cells is performed in a consistent fashion between the first set of memory cells and the second set of memory cells.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6400599-B1-CLM-00001\" num=\"1\"><claim-text>1. A memory cell comprising:</claim-text><claim-text>a first CMOS inverter having an NMOS transistor and a PMOS transistor; </claim-text><claim-text>a second CMOS inverter cross-coupled to the first CMOS inverter; </claim-text><claim-text>a first transistor having a gate, a source, and a drain, wherein the source is coupled to output of said first CMOS inverter, the gate is coupled to a first signal, and the drain is coupled to a first out; </claim-text><claim-text>a second transistor having a gate, a source, and a drain, wherein the source is coupled to output of second CMOS inverter, the gate is coupled to the first signal, and the drain is coupled to a second out; and </claim-text><claim-text>a circuit coupled to the output of the first CMOS inverter, wherein the circuit stores a first preprogrammed value in the memory cell. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6400599-B1-CLM-00002\" num=\"2\"><claim-text>2. The memory cell of <claim-ref idref=\"US-6400599-B1-CLM-00001\">claim 1</claim-ref>, wherein the circuit is coupled to the output of the second CMOS inverter and stores a second preprogrammed value in the memory cell.</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6400599-B1-CLM-00003\" num=\"3\"><claim-text>3. The memory cell of <claim-ref idref=\"US-6400599-B1-CLM-00001\">claim 1</claim-ref>, wherein the circuit comprises a NMOS transistor having a gate coupled to a second signal, a drain coupled to ground, and a source coupled to the output of the first CMOS.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53575467\"><?RELAPP description=\"Other Patent Relations\" end=\"lead\"?><p>This application is a divisional application of U.S. patent application Ser. No. 08/982,822, filed Dec. 2, 1997, now issued as U.S. Pat. No. 6,070,229.</p><?RELAPP description=\"Other Patent Relations\" end=\"tail\"?><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>BACKGROUND OF THE INVENTION</h4><p>1. Field of the Invention</p><p>The present invention relates to memory circuits. More particularly, the present invention relates to a cache within a microprocessor configured to include memory cells with preprogrammed data.</p><p>2. Background</p><p>Improvements in microprocessor designs has lead to microprocessors with a high operating frequency. Current microprocessor designs exceed operating frequencies of 100 megahertz (\u201cMHz\u201d). However, the increase in operating frequency has not lead to excepted performance gains. One of the main components affecting performance gains is created by the microprocessor execution units idling during delays in external memory access. The delays in external memory access are caused by the inductive losses associated with off chip transmissions. The delays in external memory access are also caused by the conventional design characteristics of static random access memory (\u201cSRAM\u201d) cells and dynamic random access memory (\u201cDRAM\u201d) cells.</p><p>To counteract the performance losses associated with external memory access conventional microprocessor designs developed cache systems. The cache systems store copies of external data internal to the microprocessor, thus avoiding the performance loss created by accessing external memory. One disadvantage of the conventional cache system is that the cache systems requires consistent updating to ensure data coherency. Because the updating process requires access to external memory intermittent delay cycles still exists within the microprocessor.</p><p>FIG. 1 illustrates a prior art cache system. Processor <b>100</b> is coupled to external memory <b>120</b> via XBUS <b>130</b>. Using XBUS <b>130</b>, processor <b>100</b> is able to store and retrieve data from external memory <b>120</b>. Processor <b>100</b> also includes cache <b>110</b>. Cache <b>110</b> is used to store copies of data included in external memory <b>120</b>, thus reducing processor <b>100</b> access to external memory <b>120</b>. By reducing the frequency of access to external memory <b>120</b>, processor <b>100</b> reduces idle cycles, thus increasing the throughput of executions within processor <b>100</b>.</p><p>External memory <b>120</b> includes data <b>140</b> and data <b>150</b> located in non-adjacent address of external memory <b>120</b>. For one embodiment data <b>140</b> and data <b>150</b> include fixed data that is used in many iterations of a sequence of instructions. That is, this fixed data is repeatedly used. The fixed data may include an instruction or executable data. During execution of the sequence of instructions, processor <b>100</b> must consistently update cache <b>110</b> with new data to ensure cache <b>100</b> and external memory <b>120</b> coherency. During this updating process a current copy of data <b>140</b> or data <b>150</b> within cache <b>110</b> may be flushed. However, because data <b>140</b> and data <b>150</b> are frequently used during execution of instructions, cache <b>110</b> must repeatedly access external memory <b>120</b> and re-copy data <b>140</b> or data <b>105</b> as required by the sequence of instruction. Accordingly, frequent access to external memory <b>120</b> to update cache <b>110</b> reduces the performance gains of including a cache within a processor <b>100</b>.</p><p>Some processors use a write back cache to counteract the performance loss of consistent cache updating. A write back cache delays time intensive memory updates by storing new data within the cache for a given time period prior to external memory updates. However, write back caches require a complicated controller to track data between the cache and main memory. Further, write back caches are unable to store repetitive data or instruction sequences permanently. Accordingly, write back caches do not provide any performance gains for processors that execute a particular code consistently. Therefore, what is needed is a cache wherein a segment of memory cells are configurable to store pre-programmed data. Also, what is needed is to have the segment of memory cells operate as typical memory cells when the pre-programmed data is not required. While some prior systems have allowed a segment of memory cells to operate as read-only memory or as random access memory, these prior systems typically require careful control of transistor sizes in designing a memory cell.</p><h4>SUMMARY OF THE INVENTION</h4><p>In one embodiment, the present invention concerns a cache including a plurality of first and second memory cells, an addressing circuit, an enable circuit, and an output circuit.</p><p>The second memory cells are configured to store data in a first mode and a second mode. The first mode involves a normal operation wherein the first and second memory cells store and retrieve data similarly. The second mode involves the retrieval of preprogrammed data within the second memory cells. When cache data is accessed, the addressing circuit selects a segment of the cache based on address inputs. Using the output circuit the cache stores or retrieves data from the selected segment of the cache. Dependent on the distribution of memory cells, a given selected segment includes first memory cells and/or second memory cells.</p><p>For one embodiment, the enable circuit uses predetermined addresses to determine whether second memory cells within a selected segment of the cache are in first mode or second mode. For alternative embodiments, the enable circuit uses a separate enable signal to determine whether second memory cells within a selected segment of the cache are in first mode or said mode.</p><p>Other features and advantages of the present invention will be apparent from the accompanying drawings and from the detailed description that follows.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>The features and advantages of the present invention are illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements and in which:</p><p>FIG. 1 shows one embodiment of a prior art cache system within a processor;</p><p>FIG. 2 shows one embodiment of a cache with a fixed data segment;</p><p>FIG. 3 shows one embodiment of cache cells with different memory cell structures;</p><p>FIG. 4 shows one embodiment of a preprogrammed memory cell;</p><p>FIG. 5 shows one embodiment of a preprogrammed memory cell.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION</h4><p>A cache system with a segment of the cache including preprogrammed memory cells is disclosed. The preprogrammed memory cells store and retrieve data using the storage and retrieval methods of other cells within the cache. Typically these methods allow data to be changed within each cell. However, the preprogrammed memory cells also include preprogrammed data. Accordingly, the preprogrammed memory cells can retrieve a stored value (which may be changed) or retrieve the preprogrammed data. For an alternative embodiment, an enable signal is used in conjunction with a word line, to retrieve preprogrammed data from the cache system. Accessing, a segment of data within the cache is determined via memory addresses selected by execution units within the processor in one embodiment where the cache is included within a processor. Accordingly, for an alternative embodiment, a predetermined matched address is used to trigger retrieval of preprogrammed data within the cache by providing the enable signal for a selected cell or cells.</p><p>The preprogrammed memory cell follow the design of other memory cells within the cache system. Accordingly, the area of the cache is not significantly increased. Further, circuits typically used with non-preprogrammed memory cells, such as sense amplifier and column decoders, can be used with the preprogrammed memory cells.</p><p>An intended advantage of an embodiment of the present invention is to provide a storage device for storing recurrently accessed external memory data. The storage device includes preprogrammed memory cells within a cache system. Placing the preprogrammed memory cells in a cache system provides the microprocessor's execution units with immediate access to the recurrent data. For one embodiment, the preprogrammed memory cells are designed to operate concurrently with other memory cells in the cache.</p><p>Another intended advantage of an embodiment of the present invention is to reduce access to external memory. Because accessing external memory dramatically effects the microprocessor's performance, the present invention places recurrently accessed data in a cache system. The localized data storage reduces the microprocessor's access to external memory.</p><p>Another intended advantage of an embodiment of the present invention is to provide for a permanent cache storage without affecting the performance of the cache. For one embodiment, the preprogrammed memory cells store and retrieve data which may be modified while maintaining their preprogrammed states. Accordingly, the storage ability of the cache is unaffected even though segments of the cache are used to store fixed data. The fixed data is retrieved when predetermined addresses are selected by an agent's request for information.</p><p>FIG. 2 shows a block diagram of one embodiment of cache <b>200</b> configured in accordance with the present invention. Cache <b>200</b> includes a plurality of memory block <b>270</b>s, a column decoder <b>230</b>, a row decoder <b>240</b>, logic <b>250</b>, and circuit <b>220</b>. Each memory block <b>270</b> includes a plurality of memory cells. For one embodiment, a memory block <b>270</b> may be selected or addressed by supplying an address along address <b>210</b> to row decoder <b>240</b> and column decoder <b>230</b>. In particular, for a given address, row decoder <b>240</b> selects a word line within cache <b>200</b>. For the same word line column decoder <b>230</b> may select bit lines for addressed memory cells within the word line. Data from bus data <b>280</b> may then be read from or written to the selected bit lines via circuit <b>220</b>.</p><p>Cache <b>200</b> also includes fixed data <b>260</b>. For one embodiment, fixed data <b>260</b> includes a memory block comprising preprogrammed memory cells (not shown). Each preprogrammed memory cell includes a predetermined state or operates as a non-preprogrammed memory cell dependent on a signal, data enable <b>245</b>. Data enable <b>245</b> is coupled to logic <b>250</b>. For one embodiment a predetermined address along address <b>210</b> causes logic block <b>250</b> to set data enable <b>245</b> to an active high. Accordingly, all addressed preprogrammed memory cells coupled to data enable <b>245</b> output their preprogrammed state values along bus <b>235</b> in response to an active high signal on data enable <b>245</b>. This results in sense amp <b>220</b> outputting the preprogrammed states along data <b>280</b>. For an alternative embodiment, a different enabling signal coupled to an external pin is inputted to logic <b>250</b> to set data enable <b>245</b> to an active high. In yet another embodiment, an enable signal is generated internally by a microprocessor including cache <b>200</b>; the microprocessor may be programmed or hardwired to cause the enable signal to be generated whenever predetermined addresses are requested by a requester, such as a program or an external device.</p><p>FIG. 3 shows a memory cell organization within cache <b>300</b> for one embodiment of the present invention. Cache <b>300</b> includes <b>256</b> rows of memory cells. For one embodiment, cache <b>300</b> includes two types of memory cells, cell <b>310</b> and cell <b>320</b>. Both cell <b>310</b> and cell <b>320</b> may operate as volatile memory cells which may be written to or read from, however cell <b>320</b> includes a preprogrammed memory state. Because cell <b>320</b> operates as both a volatile memory cell and a preprogrammed memory cell, the memory space available within cache <b>300</b> is not affected by the placement of cell <b>320</b>. Additionally, the same detection circuit (not shown) is used to determine the stored value in cells <b>310</b> and <b>320</b>. Accordingly, the. intermixing of cells <b>310</b> and cells <b>320</b> within cache <b>300</b> does not significantly affect the design of a processor including cache <b>300</b> or the design of a separate cache (e.g. level 2 cache).</p><p>As illustrated in FIG. 3, row <b>60</b> and row <b>20</b> include cell <b>320</b>. For one embodiment, during the operation of cache <b>300</b> when row <b>60</b> is accessed a row of preprogrammed data is available; Similarly, when row <b>20</b> is accessed one half of the outputted data may include preprogrammed values. For an alternative embodiment, a group of four cells comprise a memory block. Accordingly, row <b>20</b> includes alternating memory blocks, wherein ever other memory block includes preprogrammed data values. In yet another embodiment, a plurality of adjacent rows all include cell <b>320</b>. Thus, providing a contiguous segment of a cache with preprogrammed data values.</p><p>FIG. 4 illustrates cell <b>320</b> for one embodiment of the present invention. Memory cell <b>400</b> includes PMOS transistor <b>480</b> coupled to NMOS transistors <b>470</b> and <b>490</b>. The source of PMOS transistor <b>480</b> is coupled to a power supply while the drain of PMOS transistor <b>480</b> is coupled to the source of NMOS transistor <b>490</b>. The source of NMOS transistor <b>470</b> is coupled to ground while the drain of NMOS transistor <b>490</b> is coupled to out <b>416</b>.</p><p>Memory cell <b>400</b> also includes PMOS transistor <b>460</b> coupled to NMOS transistors <b>430</b>, <b>440</b>, and <b>450</b>. The source of PMOS transistor <b>460</b> is coupled to a power supply while the drain of PMOS transistor <b>460</b> is coupled to the source of NMOS transistor <b>450</b>. The source of NMOS transistors <b>430</b> and <b>490</b> are coupled to ground while the drain of NMOS transistor <b>450</b> is coupled to out <b>415</b>. The gates of NMOS transistor <b>440</b>, NMOS transistor <b>470</b>, PMOS transistor <b>460</b>, and PMOS transistor <b>480</b> are cross-coupled. In particular, the gates of NMOS transistor <b>470</b> and PMOS transistor <b>480</b> are coupled to the drain of PMOS transistor <b>460</b>, which is the output of the inverter formed by transistors <b>460</b> and <b>440</b>. Similarly, the gates of NMOS transistor <b>440</b> and PMOS transistor <b>460</b> are coupled to the drain of PMOS transistor <b>480</b>, which is the output of the inverter formed by transistors <b>470</b> and <b>480</b>. The cross-coupling structure creates complimentary logic states and allows memory cell <b>400</b> to act as a bi-stable static storage device with two storage nodes. For an alternative embodiment, memory cell <b>400</b> comprises a dynamic storage device wherein the values included in storage nodes are refreshed for a given clock cycle. In another alternative embodiment, the memory cell <b>400</b> comprises a readable and writeable storage cell which is non-volatile, such as a flash memory cell which also includes a circuit which provides a preprogrammed state.</p><p>The storage nodes of memory cell <b>400</b> are denoted as nodes A and B. Using word enable <b>420</b>, which is coupled to the gate of NMOS transistors <b>450</b> and <b>490</b>, a bit value may be stored or retrieved from nodes A and B via out <b>415</b> and out <b>416</b>. It will be appreciated that out <b>415</b> and out <b>416</b> may be complimentary bit lines which form a column in the memory array and are coupled to memory cells in the same column but other rows. These outputs are coupled to a conventional sensor amplifier to read the data in a memory cell (when reading) and to drivers to write data to the memory cell (when writing). Additionally, the memory cell <b>400</b> may be operated in a read-only mode where the preprogrammed data is read. This is done by activating the data enable line (driving it high) to turn on transistor <b>430</b>. Toggling data enable <b>410</b>, which is coupled to the gate of NMOS transistor <b>430</b>, provides for a preprogrammed logic value of \u201c0\u201d at node A and a preprogrammed logic value of \u201c1\u201d at node B. Accordingly, data enable <b>410</b> and NMOS transistor <b>430</b> provide for an enable circuit, wherein memory cell <b>400</b> may be used to store preprogrammed values and output the preprogrammed values along out <b>415</b> and out <b>416</b>. Data enable <b>410</b> and NMOS transistor <b>430</b> provide for an enable circuit that does not vary the storage and retrieval capacity of memory cell <b>400</b>. For one embodiment, the channel length and width of NMOS transistor <b>430</b> is minimized so that a cache including an array of a plurality of memory cell <b>400</b>s does not significantly increase in area.</p><p>FIG. 5 illustrates cell <b>320</b> for an alternative embodiment of the present invention wherein the preprogrammed values of nodes A and B are the compliments of memory cell <b>400</b>. Memory cell <b>500</b> includes PMOS transistor <b>560</b> coupled to NMOS transistors <b>540</b> and <b>550</b>. The source of PMOS transistor <b>560</b> is coupled to a power supply while the drain of PMOS transistor <b>560</b> is coupled to the source of NMOS transistor <b>550</b>. The source of NMOS transistor <b>540</b> is coupled to ground while the drain of NMOS transistor <b>550</b> is coupled to out <b>515</b>.</p><p>Memory cell <b>500</b> also includes PMOS transistor <b>580</b> coupled to NMOS transistors <b>530</b>, <b>570</b>, and <b>590</b>. The source of PMOS transistor <b>580</b> is coupled to a power supply while the drain of PMOS transistor <b>580</b> is coupled to the source of NMOS transistor <b>590</b>. The source of NMOS transistors <b>530</b> and <b>570</b> are coupled to ground while the drain of NMOS transistor <b>590</b> is coupled to out <b>516</b>. The gates of NMOS transistor <b>540</b>, NMOS transistor <b>570</b>, PMOS transistor <b>560</b>, and PMOS transistor <b>580</b> are cross-coupled. In particular, the gates of NMOS transistor <b>570</b> and PMOS transistor <b>580</b> are coupled to the drain of PMOS transistor <b>560</b>. Similarly, the gates of NMOS transistor <b>540</b> and PMOS transistor <b>560</b> are coupled to the drain of PMOS transistor <b>580</b>. The cross-coupling structure creates complimentary logic states and allows memory cell <b>500</b> to act as a bi-stable static storage device with two storage nodes. For an alternative embodiment, memory cell <b>500</b> comprises a dynamic storage device wherein the values included in storage nodes are refreshed for a given clock cycle. In another alternative embodiment, the memory cell <b>500</b> comprises a readable and writeable storage cell which is non-volatile, such as a flash memory cell which also includes a circuit which provides a preprogrammed state.</p><p>The storage nodes of memory cell <b>500</b> are denoted as nodes A and B. Using word enable <b>520</b>, which is coupled to the gate of NMOS transistors <b>550</b> and <b>590</b>, a bit value may be stored or retrieved from nodes A and B via out <b>515</b> and out <b>516</b>. Additionally, toggling data enable <b>510</b> (by driving it high in this embodiment), which is coupled to the gate of NMOS transistor <b>530</b>, provides for a preprogrammed logic value of \u201c0\u201d at node B and a preprogrammed logic value of \u201c1\u201d at node A. Accordingly, data enable <b>510</b> and NMOS transistor <b>530</b> provide for an enable circuit, wherein memory cell <b>500</b> may be used to store preprogrammed values and output the preprogrammed values along out <b>515</b> and out <b>516</b>. Data enable <b>510</b> and NMOS transistor <b>430</b> provide for an enable circuit that does not vary the storage and retrieval capacity of memory cell <b>500</b>. For one embodiment, the channel length and width of NMOS transistor <b>530</b> is minimized so that a cache including a plurality of memory cell <b>500</b>s does not significantly increase in area.</p><p>While memory cell <b>400</b> and memory cell <b>500</b> have been illustrated as seven transistor cells, other cell configurations may also be used and modified to be preprogrammed into a preferred state. For one embodiment, memory cells wherein resistive loads are used to preprogram storage nodes may be used.</p><p>Embodiments of the present invention have been described according to cache <b>300</b>. However, the present invention may be practiced in multi-port random access memory (\u201cRAM\u201d) devices or level two (\u201cL2\u201d) caches which are typically coupled directly to the external bus of a host processor. The present memory cells may also be used in RAM memories that are stand alone chips or are incorporated into other integrated circuits such as embedded controllers.</p><p>In the foregoing specification, the invention has been described with reference to specific exemplary embodiments thereof. It will, however, be evident that various modifications and changes may be made thereof without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "Peter H.", "last_name": "Voss", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "SANDCRAFT, INC."}, {"first_name": "", "last_name": "AVAGO TECHNOLOGIES INTERNATIONAL SALES PTE. LIMITED", "name": ""}, {"first_name": "", "last_name": "AVAGO TECHNOLOGIES INTERNATIONAL SALES PTE. LIMITED", "name": ""}, {"first_name": "", "last_name": "BROADCOM CORPORATION", "name": ""}, {"first_name": "", "last_name": "AVAGO TECHNOLOGIES GENERAL IP (SINGAPORE) PTE. LTD.", "name": ""}, {"first_name": "", "last_name": "BANK OF AMERICA, N.A., AS COLLATERAL AGENT", "name": ""}, {"first_name": "", "last_name": "BROADCOM CORPORATION", "name": ""}, {"first_name": "", "last_name": "NETLOGIC I LLC", "name": ""}, {"first_name": "", "last_name": "NETLOGIC MICROSYSTEMS, INC.", "name": ""}, {"first_name": "", "last_name": "NETLOGIC MICROSYSTEMS, INC.", "name": ""}, {"first_name": "", "last_name": "RMI CORPORATION", "name": ""}, {"first_name": "", "last_name": "VENTURE LENDING & LEASING IV, INC.", "name": ""}, {"first_name": "", "last_name": "VENTURE LENDING & LEASING IV, INC., AS AGENT FOR ITSELF AND SILICON VALLEY BANK AND GOLD HILL VENTURE LENDING 03, L.P.", "name": ""}, {"first_name": "", "last_name": "RAZA MICROELECTRONICS, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G11C  11/00"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMUS"}], "national_classes": [{"primary": true, "label": "365154"}, {"primary": false, "label": "711E12017"}, {"primary": false, "label": "365104"}, {"primary": false, "label": "365156"}], "ecla_classes": [{"label": "S06F212:2515"}, {"label": "G06F  12/08B"}], "cpc_classes": [{"label": "G06F  12/0802"}, {"label": "G06F2212/2515"}, {"label": "G06F  12/0802"}, {"label": "G06F2212/2515"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "1997-12-02", "application_date": "2000-05-12", "family_members": [{"ucid": "US-6070229-A", "titles": [{"lang": "EN", "text": "Cache memory cell with a pre-programmed state"}]}, {"ucid": "US-6400599-B1", "titles": [{"lang": "EN", "text": "Cache memory cell with a pre-programmed state"}]}]}