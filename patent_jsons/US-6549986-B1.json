{"patent_number": "US-6549986-B1", "publication_id": 73379951, "family_id": 24394074, "publication_date": "2003-04-15", "titles": [{"lang": "EN", "text": "Low power instruction cache"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"docdb\" mxw-id=\"PA11503515\" source=\"national office\"><p>A low power instruction cache is disclosed. There are a number of tag memory banks. Each tag memory bank is associated with a unique instruction cache. Each tag memory bank has a number of tag memory rows and each tag memory row has a number of tag memory cells. Certain upper bits of a program counter are compared to a tag stored in one row of a tag memory bank. If there is a match between the certain upper bits of the program counter and the tag, a hit signal is generated. The hit signal indicates that the tag memory bank containing the matched row (i.e. the matched tag) is associated with the instruction cache having a desired instruction. The desired instruction is then read from the instruction cache associated with the tag memory bank corresponding to the generated hit signal. Thus, instead of reading one instruction from each of the instruction caches and then eliminating all but one of the read instructions, only the desired instruction from a single instruction cache is read. As such, a large amount of power is saved.</p></abstract>"}, {"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA50478085\"><p>A low power instruction cache is disclosed. There are a number of tag memory banks. Each tag memory bank is associated with a unique instruction cache. Each tag memory bank has a number of tag memory rows and each tag memory row has a number of tag memory cells. Certain upper bits of a program counter are compared to a tag stored in one row of a tag memory bank. If there is a match between the certain upper bits of the program counter and the tag, a hit signal is generated. The hit signal indicates that the tag memory bank containing the matched row (i.e. the matched tag) is associated with the instruction cache having a desired instruction. The desired instruction is then read from the instruction cache associated with the tag memory bank corresponding to the generated hit signal. Thus, instead of reading one instruction from each of the instruction caches and then eliminating all but one of the read instructions, only the desired instruction from a single instruction cache is read. As such, a large amount of power is saved.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00001\" num=\"1\"><claim-text>1. A method comprising steps of:</claim-text><claim-text>comparing in a first tag memory cell each of a first plurality of program counter bits with a respective tag bit in a first tag in a first tag memory bank and comparing in a second tag memory cell said each of said first plurality of program counter bits with a respective tag bit in a second tag in a second tag memory bank; </claim-text><claim-text>enabling a first instruction cache associated with said first tag memory bank when said first plurality of program counter bits match said first tag; </claim-text><claim-text>reading a desired instruction from said first instruction cache, said desired instruction being at an address pointed to by a second plurality of program counter bits. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00002\" num=\"2\"><claim-text>2. The method of <claim-ref idref=\"US-6549986-B1-CLM-00001\">claim 1</claim-ref> wherein said comparing of each of said first plurality of program counter bits with said respective tag bit in said first tag is performed by a first XOR gate inside said first tag memory cell and wherein said comparing of each of said first plurality of program counter bits with said respective tag bit in said second tag is performed by a second XOR gate inside said second tag memory cell.</claim-text></claim>"}, {"num": 3, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00003\" num=\"3\"><claim-text>3. The method of <claim-ref idref=\"US-6549986-B1-CLM-00002\">claim 2</claim-ref> wherein said enabling step comprises logically combining an output of said first XOR gate and an output of said second XOR gate.</claim-text></claim>"}, {"num": 4, "parent": 2, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00004\" num=\"4\"><claim-text>4. The method of <claim-ref idref=\"US-6549986-B1-CLM-00002\">claim 2</claim-ref> wherein said enabling step comprises NOR'ing an output of said first XOR gate and an output of said second XOR gate.</claim-text></claim>"}, {"num": 5, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00005\" num=\"5\"><claim-text>5. The method of <claim-ref idref=\"US-6549986-B1-CLM-00001\">claim 1</claim-ref> wherein said reading step comprises a step of loading said desired instruction into an instruction register coupled to said instruction cache.</claim-text></claim>"}, {"num": 6, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00006\" num=\"6\"><claim-text>6. A circuit comprising:</claim-text><claim-text>a plurality of tag memory banks; </claim-text><claim-text>a purality of tag memory rows in each of said plurality of tag memory banks; </claim-text><claim-text>a plurality of tag memory cells in each of said plurality of tag memory rows; </claim-text><claim-text>at least one of said plurality of tag memory cells comprising a comparator for comparing one of a plurality of program counter bits with one of a plurality of tag bits in said at least one of said plurality of tag memory cells; </claim-text><claim-text>an output of said comparator being used to enable one of a plurality of instruction caches. </claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00007\" num=\"7\"><claim-text>7. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00006\">claim 6</claim-ref> wherein each of said plurality of tag memory banks corresponds to a unique one of said plurality of instruction caches.</claim-text></claim>"}, {"num": 8, "parent": 7, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00008\" num=\"8\"><claim-text>8. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00007\">claim 7</claim-ref> wherein said one of said plurality of instruction caches is enabled when respective comparators in each of said plurality of tag memory cells of one of said plurality of tag memory rows indicate a match between each of said plurality of program counter bits and each of said plurality of tag bits.</claim-text></claim>"}, {"num": 9, "parent": 8, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00009\" num=\"9\"><claim-text>9. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00008\">claim 8</claim-ref> wherein said one of said plurality of instruction caches corresponds with one of said plurality of tag memory banks and wherein said one of said plurality of tag memory banks contains said one of said plurality of tag memory rows.</claim-text></claim>"}, {"num": 10, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00010\" num=\"10\"><claim-text>10. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00006\">claim 6</claim-ref> wherein said comparator comprises an XOR gate.</claim-text></claim>"}, {"num": 11, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00011\" num=\"11\"><claim-text>11. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00006\">claim 6</claim-ref> wherein each of said plurality of tag memory cells comprises one of a plurality of comparators for comparing a respective one of said plurality of program counter bits with a respective one said plurality of tag bits.</claim-text></claim>"}, {"num": 12, "parent": 11, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00012\" num=\"12\"><claim-text>12. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00011\">claim 11</claim-ref> wherein respective outputs of said plurality of comparators are logically combined to generate a hit signal for one of said plurality of tag memory banks, said hit signal indicating a match between each of said plurality of program counter bits and each of said plurality of tag bits in one of said plurality of tag memory rows in said one of said plurality of tag memory banks.</claim-text></claim>"}, {"num": 13, "parent": 12, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00013\" num=\"13\"><claim-text>13. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00012\">claim 12</claim-ref> wherein respective outputs of said plurality of comparators are NOR'ed to generate said hit signal.</claim-text></claim>"}, {"num": 14, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00014\" num=\"14\"><claim-text>14. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00006\">claim 6</claim-ref> wherein said plurality of tag memory banks comprises four tag memory banks.</claim-text></claim>"}, {"num": 15, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00015\" num=\"15\"><claim-text>15. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00006\">claim 6</claim-ref> wherein said plurality of instruction caches comprises four instruction caches.</claim-text></claim>"}, {"num": 16, "parent": 14, "type": "dependent", "paragraph_markup": "<claim id=\"US-6549986-B1-CLM-00016\" num=\"16\"><claim-text>16. The circuit of <claim-ref idref=\"US-6549986-B1-CLM-00014\">claim 14</claim-ref> wherein said plurality of instruction caches comprises four instruction caches, each of said four instruction caches corresponding to one of said four tag memory banks.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES53907972\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>FIELD OF THE INVENTION</h4><p>The present invention is generally in the field of processors. More specifically, the invention is in the field of cache memories.</p><h4>BACKGROUND ART</h4><p>As is generally known, computer programs continue to increase in size. As computer programs grow in size, the memory requirements of the computer and various memory devices also increase. However, as the size of a program currently residing in the computer's main memory gets larger, the speed at which the processor executes tasks begins to decrease. This results from the constant fetching of instructions from the main memory of the computer into the processor (also referred to as a \u201cCentral Processing Unit\u201d or \u201cCPU\u201d). The larger the program currently being used, the more often instructions must be fetched. This fetching process requires a certain number of clock phases. Therefore, the more often instructions have to be fetched from the main memory, the less time the processor has available to decode and execute those instructions and the slower the speed at which the processor can finish tasks.</p><p>Thus, it is desirable to set aside in a local memory, i.e. a memory requiring less access time than the main memory, a limited number of program instructions that the processor may want to fetch. An instruction cache is such a local memory. An instruction cache is a relatively small memory module where a limited number of program instructions may be stored.</p><p>The processor performs constant checks to determine whether instructions stored in the main memory required by the processor are already resident in the instruction cache. If they are already resident in the instruction cache, the instruction fetch step is performed by referring to the instruction cache, since there is no need to go to the main memory to find what is already in the instruction cache.</p><p>Thus, the processor must be able to determine if an instruction to be fetched from the main memory is already resident in the instruction cache. The processor's program counter contains the address of an instruction needed by the processor. One way to determine if an instruction is already resident in the instruction cache is to keep track of the addresses of the instructions when they are first brought into the instruction cache from the main memory. To do this, copies of certain upper bits of the main memory addresses are stored in a tag memory bank where each entry in the tag memory bank is referred to as a \u201ctag.\u201d As an example, the upper 23 bits of a 32-bit main memory address comprise the tag. These upper 23 bits of the 32-bit main memory address are referred to as the \u201ctag.\u201d</p><p>When the processor wishes to determine whether a particular instruction is resident in the instruction cache, the address of the instruction is sent from the program counter across the address bus to the instruction cache and the tag memory bank. In the present example, the 23-bit tags within the tag memory bank and the 32-bit wide instructions in the instruction cache are read. The upper 23 bits of address of the instruction contained in the program counter is then compared with a tag in the tag memory. If there is a match, also referred to as a \u201chit,\u201d the instruction is already resident in the instruction cache, and it is not necessary to fetch the instruction from the main memory. If there is no match, also referred to as a \u201cmiss,\u201d the instruction must be fetched from the main memory at the address contained in the program counter.</p><p>A \u201cset-associative\u201d cache consists of multiple sets, each set consisting of an instruction cache and a tag memory bank. A set-associative cache decreases the number of instances where the program is required to return to the main memory. This is because a number of instruction caches hold instructions corresponding to a number of different segments of a computer program. Thus, the speed at which the processor executes a program increases since there is a greater chance that the processor can find a desired instruction in the set-associative cache as opposed to the main memory.</p><p>A set-associative cache also has disadvantages. Because there are multiple tag memory banks, each tag memory bank must be accessed to determine if a tag which is resident in that bank matches the corresponding upper bits contained in the program counter. In the present example, each tag memory bank must be accessed to determine whether it has a tag which matches the upper 23 bits in the program counter. Power is consumed each time a tag and an instruction are read from a tag memory bank and an instruction cache, respectively. For example, if the set-associative cache has four memory banks and four instruction caches, each time the processor accesses the set-associative cache, four instructions and four tags are read. Thereafter, at most a single tag is matched and an instruction corresponding to the matched tag is identified as the desired instruction.</p><p>In a set-associative cache discussed above, power consumed is proportional to the number of tags read, multiplied by the width of a tag in bits, plus the number of instructions read, multiplied by the width of an instruction in bits. The number of instructions and tags are, in turn, equal to the number of sets of instruction caches and tag memory banks. In the above example, the width of a tag is 23 bits, the width of an instruction is 32 bits, and there are 4 sets of instruction caches and tag memory banks. As such, the power consumption for each set-associative cache read operation is proportional to:</p><p><maths><formula-text>(4 instructions\u00d732 bits)+(4 tags\u00d723 bits).</formula-text></maths></p><p>Thus, although a set-associative cache increases the speed with which the processor executes tasks, there is a corresponding increase in power consumption resulting from the reading of the additional tags and instructions from the additional sets of instruction caches and tag memory banks. Using the example above, it can be seen that in addition to the power consumed from reading and comparing the four tags, power is consumed reading four instructions, although at most only one of the instructions will be the desired instruction.</p><p>Thus, it can be seen that there is a need in the art for a method to implement a set-associative cache which maintains the advantages discussed above, such as increased operating speed, while at the same time reducing the additional power consumption inherent in a set-associative cache.</p><h4>SUMMARY OF THE INVENTION</h4><p>The present invention is a low power instruction cache. According to the invention, there are a number of tag memory banks. Each tag memory bank is associated with a unique instruction cache. Each tag memory bank has a number of tag memory rows and each tag memory row has a number of tag memory cells. The invention compares certain upper bits of a program counter to a tag stored in one row of a tag memory bank. If there is a match between the certain upper bits of the program counter and the tag, a hit signal is generated. The hit signal indicates that the tag memory bank containing the matched row (i.e. the matched tag) is associated with the instruction cache having a desired instruction. The desired instruction is then read from the instruction cache associated with the tag memory bank corresponding to the generated hit signal.</p><p>Utilizing the present invention, instead of reading one instruction from each of the instruction caches and then eliminating all but one of the read instructions, only the desired instruction from a single instruction cache is read. As such, a large amount of power is saved. In one embodiment of the invention, there are four tag memory banks, each having 32 tag memory rows, and each row having 23 tag memory cells. There are also four instruction caches, each associated with one of the four tag memory banks. The upper 23 bits in the program counter is compared with each of the 23 bits in a particular tag memory row in each of the four tag memory banks. When there is a match between the upper 23 bits in the program counter and the 23 bits in a particular tag memory row, a hit signal is generated corresponding to the particular tag memory bank containing the matched tag memory row. Thereafter, a desired instruction is read only from the particular instruction cache associated with the tag memory bank corresponding to the generated hit signal.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1A illustrates an instruction cache and a tag memory bank.</p><p>FIG. 1B illustrates an instruction memory address.</p><p>FIG. 1C illustrates a block diagram of a set-associative cache.</p><p>FIG. 2 illustrates a timing diagram of cache operations which occur during two clock phases.</p><p>FIG. 3 illustrates a tag memory cell.</p><p>FIG. 4 illustrates two tag memory cells within a tag memory row of a tag memory bank.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION OF THE INVENTION</h4><p>The present invention is a low power instruction cache. The following description contains specific information pertaining to different types of configurations, components and implementations of the invention. One skilled in the art will recognize that the present invention may be practiced with configurations, components and implementations different from those specifically discussed in the present application. Moreover, some of the specific details of the invention are not discussed in order to not obscure the invention. The specific details not discussed in the present application are within the knowledge of a person of ordinary skills in the art.</p><p>The drawings in the present application and their accompanying detailed description are directed to merely example embodiments of the invention. To maintain brevity, other embodiments of the invention which use the principles of the present invention are not specifically described in the present application and are not specifically illustrated by the present drawings.</p><p>FIG. 1A is used to explain some of the terminology used in the present invention. FIG. 1A shows instruction cache <b>130</b> which has 128 locations available to store 32-bit wide instructions. The 128 locations in instruction cache <b>130</b> can be addressed using the seven bits in bit locations 0 through 6 of instruction memory address <b>100</b> shown in FIG. <b>1</b>B. These seven bits are referred to as instruction address <b>138</b>. The upper 23 bits of instruction memory address <b>100</b> occupying bit positions 7 through 29 comprise a \u201ctag\u201d which is referred to by numeral <b>134</b> in FIG. <b>1</b>B. Each tag is stored in an assigned location in tag memory <b>132</b> in FIG. <b>1</b>A. In the present example, tag memory <b>132</b> has 32 locations. Each one of the 32 tags can be addressed using the five bits in bit locations 2 through 6 of instruction memory address <b>100</b>. These five bits are referred to as tag address <b>136</b>. Each of the 32 locations of tag memory <b>132</b> can store one tag. Instruction cache <b>130</b> and tag memory <b>132</b> together make up one set within a set-associative cache.</p><p>FIG. 1C shows a block diagram of one example of a set-associative cache. In this example, set-associative cache <b>140</b> is comprised of four instruction caches. Each instruction cache is identical to instruction cache <b>130</b> shown in FIG. <b>1</b>A. These four instruction caches are instruction cache <b>112</b>, instruction cache <b>116</b>, instruction cache <b>120</b> and instruction cache <b>124</b>.</p><p>FIG. 1C also shows four tag memory banks. Each tag memory bank is identical to tag memory <b>132</b> shown in FIG. <b>1</b>A. These four tag memory banks are tag memory bank <b>114</b>, tag memory bank <b>118</b>, tag memory bank <b>122</b> and tag memory bank <b>126</b>.</p><p>Although not shown in any of the Figures, an address bus allows a program counter to communicate with instruction caches <b>112</b>, <b>116</b>, <b>120</b> and <b>124</b> and tag memory banks <b>114</b>, <b>118</b>, <b>122</b> and <b>126</b>. Instruction caches <b>112</b>, <b>116</b>, <b>120</b> and <b>124</b> also communicate with an instruction register which is not shown in any of the Figures. Also not shown in any of the Figures is a cache controller which controls the cache operations.</p><p>By way of background, instruction caches <b>112</b>, <b>116</b>, <b>120</b> and <b>124</b>, and tag memory banks <b>114</b>, <b>118</b>, <b>122</b>, and <b>126</b> are initially \u201cbuilt up\u201d as follows. The program counter contains the address of the instruction needed by the processor. This address shall be referred to as the \u201cmain memory instruction address.\u201d The main memory instruction address contained in the program counter is bussed into the cache. A copy of the upper 23 bits of the main memory instruction address is stored in a tag memory location in one of tag memory banks <b>114</b>, <b>118</b>, <b>122</b> or <b>126</b>.</p><p>As discussed above, the tag memory location where the copy of the upper 23 bits is stored corresponds to a unique five-bit pattern in tag address <b>136</b> in FIG. <b>1</b>B. These 5 bits can be decoded to access any one of the 32 tag memory locations in tag memory banks <b>114</b>, <b>118</b>, <b>122</b> or <b>126</b> (2<sup>5</sup>=32). The arrows at the top of the tag memory banks in FIG. 1C referred to by numeral <b>136</b> represent the five bits of tag address <b>136</b> in FIG. 1B being used to select one out of the 32 tag locations within each tag memory bank. The tag memory bank decoder is not shown in any of the Figures.</p><p>Continuing with the above discussion regarding how the instruction caches and the tag memory banks are built up, each instruction for which a tag is stored in a tag memory bank is stored in one of the locations in instruction caches <b>112</b>, <b>116</b>, <b>120</b> or <b>124</b>. As discussed above, the instruction cache location where the instruction is stored is determined by the 7 bits of instruction memory address <b>100</b> referred to by numeral <b>138</b> in FIG. <b>1</b>B. These 7 bits can be decoded to address any one of the <b>128</b> instruction cache locations in each of instruction caches <b>112</b>, <b>116</b>, <b>120</b> and <b>124</b> (2<sup>7</sup>=128). The arrows at the top of the instruction caches in FIG. 1C referred to by numeral <b>138</b> represent the seven bits of instruction address <b>138</b> in FIG. 1B being used to select one out of <b>128</b> instruction locations within the instruction cache. The instruction cache decoder is not shown in any of the Figures. Thus, instruction caches <b>112</b>, <b>116</b>, <b>120</b> and <b>124</b>, and tag memory banks <b>114</b>, <b>118</b>, <b>122</b> and <b>126</b> are initially built up as explained above.</p><p>As discussed above, in the present example, set-associative cache <b>140</b> has four instruction caches, each instruction cache capable of storing <b>128</b> instructions, each instruction being 32-bit wide. In the present example, set-associative cache <b>140</b> also has four tag memory banks, each tag memory bank capable of storing 32 tags, where each tag has 23 bits. The 23 bits comprising a tag are also called the \u201ctag bits\u201d in the present application.</p><p>In the exemplary set-associative cache <b>140</b> shown in FIG. 1C, the operations discussed below take place during two clock phases. Referring to the timing diagram in FIG. 2, these two clock phases are clock phase <b>1</b>, also referred to as C<b>1</b>, and clock phase <b>2</b>, also referred to as C<b>2</b>. During a first C<b>1</b> referred to by numeral <b>202</b> in FIG. 2, the main memory instruction address is sent across the address bus from the program counter to the set-associative cache and the five bits of tag address <b>136</b> are decoded to determine the location in each of tag memory banks <b>114</b>, <b>118</b>, <b>122</b> and <b>126</b> that corresponds to the unique 5-bit pattern of tag address <b>136</b>.</p><p>During a first C<b>2</b> referred to by numeral <b>204</b> in FIG. 2, the seven bits corresponding to the cache instruction address, referred to by numeral <b>138</b> in FIG. 1B, are decoded to determine a respective location in each instruction cache <b>112</b>, <b>116</b>, <b>120</b>, and <b>124</b> that corresponds to the unique 7-bit pattern. Also during this first C<b>2</b>, a respective tag from each of the four tag memory banks is read and each tag is compared to the upper 23 bits of the main memory instruction address. The respective tag read from each of the four tag memory banks corresponds to the decoded five-bit tag address <b>136</b>. If the upper 23 bits of the main memory instruction address is identical to the tag read from one of the four tag memory banks, then the instruction cache corresponding to that tag memory bank contains the desired instruction. As such, the instruction cache containing the desired instruction is enabled to send the desired instruction to the instruction register.</p><p>During a second C<b>1</b> referred to by numeral <b>206</b> in FIG. 2, the desired instruction is read from the enabled instruction cache. During a second C<b>2</b> referred to by numeral <b>208</b> in FIG. 2, the desired instruction is sent to the instruction register.</p><p>It can be seen from the timing diagram of FIG. 2 that, unlike the set-associate instruction cache discussed in the background art section of the present application, the invention's low power set-associative instruction cache does not read all the four instructions in instruction caches <b>112</b>, <b>116</b>, <b>120</b> and <b>124</b>. Only if one of the tags read from tag memory banks <b>114</b>, <b>118</b>, <b>122</b> and <b>126</b> is identical to the upper 23 bits of the main memory instruction address contained in the program counter a corresponding instruction cache will be enabled and the desired instruction will be read from the enabled instruction cache. Thus, only one instruction cache is enabled and only one instruction is read. Therefore, there is significantly less power consumption. In other words, instead of the power consumed being proportional to (4 instructions\u00d732 bits)+(4 tags\u00d723 bits), the consumed power is proportional to (1 instruction\u00d732 bits)+(4 tags\u00d723 bits).</p><p>Turning to the invention's logic and circuit diagram, reference is made to FIG. <b>3</b>. FIG. 3 shows a schematic diagram of memory cell <b>300</b>. Memory cell <b>300</b> represents just one of many such memory cells that are located inside each tag memory bank, such as tag memory banks <b>114</b>, <b>118</b>, <b>122</b>, and <b>126</b>. In the present example, in each tag memory bank there is an array of memory cells similar to memory cell <b>300</b>. The array consists of 32 tag memory rows with 23 memory cells in each tag memory row. In other words, there are 32 tag memory locations within a tag memory bank, each containing a 23-bit wide tag.</p><p>Line <b>377</b> and line <b>379</b> are connected to memory cell <b>300</b> at node <b>373</b> and node <b>375</b>, respectively. Lines <b>381</b> and <b>383</b> are connected to memory cell <b>300</b> at node <b>365</b> and node <b>367</b>, respectively. The wordline, referred to in FIG. 3 by numeral <b>368</b>, is connected to the gates of NFET <b>370</b> and NFET <b>372</b>. The drain of NFET <b>370</b> is connected to node <b>387</b> and the source of NFET <b>370</b> is connected to node <b>375</b>. The drain of NFET <b>372</b> is connected to node <b>385</b> and the source of NFET <b>370</b> is connected to node <b>373</b>. Inverter <b>360</b> has an input connected to node <b>389</b> and an output connected to node <b>391</b>. Inverter <b>362</b> has an input connected to node <b>387</b> and an output connected to node <b>385</b>.</p><p>The gate of NFET <b>354</b> is connected to node <b>393</b>. The source of NFET <b>354</b> at node <b>319</b> is connected to node <b>365</b> through line <b>305</b> and the drain of NFET <b>354</b> at node <b>323</b> is connected to node <b>301</b> through line <b>397</b>. The gate of NFET <b>358</b> is connected to node <b>395</b>. The source of NFET <b>358</b> at node <b>325</b> is connected to node <b>301</b> through line <b>399</b> and the drain of NFET <b>358</b> at node <b>321</b> is connected to node <b>367</b> through line <b>307</b></p><p>The gate of PFET <b>352</b> is connected to node <b>395</b> through line <b>317</b>. The source of PFET <b>352</b> at node <b>323</b> is connected to node <b>301</b> through line <b>397</b> and the drain of PFET <b>352</b> at node <b>319</b> is connected to node <b>365</b> through line <b>305</b>. The gate of PFET <b>356</b> is connected to node <b>393</b> through line <b>315</b>. The source of PFET <b>356</b> at node <b>321</b> is connected to node <b>367</b> through line <b>307</b> and the drain of PFET <b>356</b> at node <b>325</b> is connected to node <b>301</b> through line <b>399</b>. The gate of NFET <b>314</b> is connected to node <b>301</b> through line <b>303</b>. The drain of NFET <b>314</b> is connected to node <b>311</b> and the source of NFET <b>314</b> is connected to node <b>309</b>.</p><p>The 23 upper bits of the of the main memory instruction address are sent from the program counter across the address bus. There are two address lines for memory cell <b>300</b>. One address line, referred to by numeral <b>383</b>, carries an address bit referred to as bit A to node <b>367</b> and through line <b>307</b> to the drain of NFET <b>358</b> and the source of PFET <b>356</b>, which are connected together at node <b>321</b>. The other address line, referred to by numeral <b>381</b>, carries an address bit referred to as bit A\u2032, i.e. an inverted bit A, to node <b>365</b> and through line <b>305</b> to the source of NFET <b>354</b> and the drain of PFET <b>352</b>, which are connected together at node <b>319</b>.</p><p>The tag bits are sent across bus lines to memory cell <b>300</b>. There are two bus lines for memory cell <b>300</b>. The first bus line, referred to by numeral <b>377</b>, carries a tag bit, referred to as bit T, to node <b>373</b>. The second bus line, referred to by numeral <b>379</b>, carries a tag bit, referred to as bit T\u2032, to node <b>375</b>.</p><p>Wordline <b>368</b> enables a particular tag memory row of <b>23</b> memory cells to receive a 23 bit tag. One tag memory row out of 32 tag memory rows is enabled by the wordline to receive a 23 bit tag. When the wordline for the tag memory row containing memory cell <b>300</b> is high, NFET <b>370</b> and NFET <b>372</b> turn on, allowing the tag bits to enter memory cell <b>300</b> through bus lines <b>377</b> and <b>379</b>.</p><p>The tag bit T is input to inverter <b>360</b> at node <b>389</b>. As such, the output of inverter <b>360</b> at node <b>391</b> is an inverted bit T, i.e., bit T\u2032. Bit T\u2032 is input to inverter <b>362</b> at node <b>387</b>. Thus, at the output of inverter <b>362</b> at node <b>385</b> is an inverted bit T\u2032, i.e., bit T.</p><p>NFET <b>354</b>, NFET <b>358</b>, PFET <b>352</b> and PFET <b>356</b> are connected in a manner to provide an \u201cExclusive OR\u201d (or \u201cXOR\u201d) output at node <b>301</b> of input bits A and T. Bit T is input to the gate of NFET <b>354</b> at node <b>393</b>. At the same time bit T is input to the gate of PFET <b>356</b> through line <b>315</b>. Bit T\u2032 is input to the gate of NFET <b>358</b> at node <b>395</b>. At the same time bit T\u2032 is input to the gate of PFET <b>352</b> through line <b>317</b>.</p><p>If bit T is a logical \u201c1\u201d, bit T\u2032 will be a logical \u201c0\u201d. Thus, NFET <b>354</b> turns on as a result of bit T being a \u201c1\u201d and NFET <b>358</b> is off as a result of bit T\u2032 being a \u201c0\u201d. PFET <b>356</b> is off as a result of bit T being a \u201c1\u201d and PFET <b>352</b> turns on as a result of bit T\u2032 being a \u201c0\u201d. Thus, since both NFET <b>354</b> and PFET <b>352</b> are on, bit A\u2032 at node <b>319</b> is allowed to pass through NFET <b>354</b> and PFET <b>352</b> to node <b>301</b> through line <b>397</b>. Thus, if bit T is a logical \u201c1\u201d, the output of the XOR at node <b>301</b> is the same as bit A\u2032.</p><p>If bit T is a \u201c0\u201d, bit T\u2032 will be a \u201c1\u201d. Thus, NFET <b>354</b> is off as a result of bit T being a \u201c0\u201d and NFET <b>358</b> turns on as a result of bit T\u2032 being a \u201c1\u201d. PFET <b>356</b> turns on as a result of bit T being a \u201c0\u201d and PFET <b>352</b> is off as a result of bit T\u2032 being a \u201c1\u201d.</p><p>Thus, since both NFET <b>358</b> and PFET <b>356</b> are on, bit A at node <b>321</b> is allowed to pass through NFET <b>358</b> and PFET <b>356</b> to node <b>301</b> through line <b>399</b>. Thus, if bit T is a logical \u201c0\u201d, the output of the XOR at node <b>301</b> is the same as bit A.</p><p>Thus, it is seen that PFET <b>352</b>, NFET <b>354</b>, PFET <b>356</b> and NFET <b>358</b> operate as an XOR gate as shown in the following table:</p><p><tables id=\"TABLE-US-00001\"><table colsep=\"0\" frame=\"none\" rowsep=\"0\"><tgroup align=\"left\" cols=\"4\" colsep=\"0\" rowsep=\"0\"><colspec align=\"left\" colname=\"offset\" colwidth=\"42pt\"></colspec><colspec align=\"center\" colname=\"1\" colwidth=\"14pt\"></colspec><colspec align=\"center\" colname=\"2\" colwidth=\"91pt\"></colspec><colspec align=\"left\" colname=\"3\" colwidth=\"70pt\"></colspec><thead><row><entry></entry><entry align=\"center\" nameend=\"3\" namest=\"OFFSET\" rowsep=\"1\"></entry></row><row><entry></entry><entry>A</entry><entry>T</entry><entry>Output</entry></row><row><entry></entry><entry align=\"center\" nameend=\"3\" namest=\"OFFSET\" rowsep=\"1\"></entry></row></thead><tbody valign=\"top\"><row><entry></entry><entry>0</entry><entry>0</entry><entry>0 (A)</entry></row><row><entry></entry><entry>0</entry><entry>1</entry><entry>1 (A\u2032)</entry></row><row><entry></entry><entry>1</entry><entry>0</entry><entry>1 (A)</entry></row><row><entry></entry><entry>1</entry><entry>1</entry><entry>0 (A\u2032)</entry></row><row><entry></entry><entry align=\"center\" nameend=\"3\" namest=\"OFFSET\" rowsep=\"1\"></entry></row></tbody></tgroup></table></tables></p><p>Thus, it is seen that when the address bit in memory cell <b>300</b> is the same as the tag memory cell <b>300</b>, i.e., both are a \u201c0\u201d or both are a \u201c1\u201d, the output of the XOR at node <b>301</b> will be a \u201c0\u201d. An Exclusive OR (\u201cXOR\u201d) gate is an example of a comparator since the output of the XOR gate indicates whether its two inputs are equal. An XOR gate is also referred to as a comparator in the present application.</p><p>The output of the XOR at node <b>301</b> is connected to the gate of NFET <b>314</b> through line <b>303</b>. If the output at node <b>301</b> is a \u201c1\u201d, NFET <b>314</b> turns on. When the output at node <b>301</b> is a \u201c0\u201d, NFET <b>314</b> is off.</p><p>FIG. 4 shows a schematic diagram of two memory cells, memory cell<sub>0 </sub>and memory cell<sub>1</sub>, which are connected to bus lines and address lines, along with additional circuits which will be described below. Both memory cell<sub>0 </sub>and memory cell<sub>1 </sub>are located in tag memory row<sub>0 </sub>which is the first tag memory row out of the total of 32 tag memory rows in the tag memory bank.</p><p>Memory cell<sub>0 </sub>and memory cell<sub>1 </sub>represent two memory cells that are part of an array of memory cells located inside the tag memory banks. Memory cell<sub>0 </sub>and memory cell<sub>1 </sub>are identical in form and function to memory cell <b>300</b> in FIG. <b>3</b>. As discussed above, in the present example the array would consist of 32 tag memory rows of memory cells with 23 memory cells in each row. This corresponds to the 32 tag memory locations within a tag memory, each containing 23 tag bits which make up an individual tag.</p><p>Node <b>461</b> is the output of the XOR within memory cell<sub>0</sub>. Node <b>461</b> is connected to the gate of NFET <b>412</b> through line <b>417</b>. The drain of NFET <b>412</b> is connected to precharge line <b>439</b> at node <b>415</b> and the source of NFET <b>412</b> is connected to line <b>437</b> at node <b>413</b>.</p><p>Node <b>463</b> is the output of the XOR within memory cell<sub>1</sub>. Node <b>463</b> is connected to the gate of NFET <b>414</b> through line <b>423</b>. The drain of NFET <b>414</b> is connected to precharge line <b>439</b> at node <b>421</b> and the source of NFET <b>414</b> is connected to line <b>437</b> at node <b>419</b>.</p><p>The source of NFET <b>420</b> is connected to ground and the drain of NFET <b>420</b> is connected through line <b>437</b> to the source of NFET <b>412</b> at node <b>413</b> and also to the source of NFET <b>414</b> at node <b>419</b>. The gate of NFET <b>420</b> is connected to and driven by enable line <b>435</b>.</p><p>The source of PFET <b>422</b> is connected to V<sub>DD </sub>and the drain of PFET <b>422</b> is connected through line <b>439</b> to the drain of NFET <b>412</b> at node <b>415</b> and to the drain of NFET <b>414</b> at node <b>421</b> and also to a first input of NAND gate <b>424</b>. The gate of PFET <b>422</b> is connected to line <b>433</b>.</p><p>A first input of NAND gate <b>424</b> is connected through precharge line <b>439</b> to the drain of NFET <b>414</b> at node <b>421</b> and to the drain of NFET <b>412</b> at node <b>415</b> and also to the drain of PFET <b>422</b>. A second input of NAND gate <b>424</b> is connected to enable line <b>435</b>. The output of NAND gate <b>424</b> is connected to the input of inverter <b>426</b> through line <b>441</b>. The output of inverter <b>426</b> is connected to the gate of NFET <b>428</b> through line <b>443</b>.</p><p>The drain of NFET <b>428</b> is connected through line <b>451</b> to the drain of PFET <b>430</b> at node <b>449</b>. The drain of NFET <b>428</b> is also connected through line <b>451</b> to the input of inverter <b>432</b> at node <b>449</b>. The source of NFET <b>428</b> is connected through line <b>445</b> to the drain of NFET <b>446</b>. The gate of PFET <b>430</b> is connected to line <b>447</b>. The source of PFET <b>430</b> is connected to V<sub>DD</sub>. The gate of NFET <b>446</b> is connected to line <b>459</b> and the source of NFET <b>446</b> is connected to ground.</p><p>The output of inverter <b>432</b> is connected to the gate of NFET <b>442</b> at node <b>453</b> and to the source of NFET <b>434</b> at node <b>453</b>. The drain of NFET <b>442</b> is connected to the source of NFET <b>436</b> while the source of NFET <b>442</b> is connected to ground. The drain of NFET <b>436</b> is connected to the output of inverter <b>440</b> and the input of inverter <b>438</b> at node <b>455</b>. The gate of NFET <b>436</b> is connected to line <b>469</b>.</p><p>The drain of NFET <b>434</b> is connected to the input of inverter <b>440</b> and also to the output of inverter <b>438</b> at node <b>467</b>. The gate of NFET <b>434</b> is connected to line <b>469</b>. The output of inverter <b>440</b> is connected to the input of inverter <b>438</b> at node <b>455</b>.</p><p>During every C<b>2</b> phase, i.e. when C<b>2</b> is high and C<b>1</b> is low, PFET <b>422</b> turns on and line <b>439</b> will be pre-charged, i.e. line <b>439</b> will be high. Thus there will be a logical \u201c1\u201d at the first input of NAND gate <b>424</b> through precharge line <b>439</b> when C<b>2</b> is high. When C<b>1</b> is high, NFET <b>420</b> turns on only if the five bit pattern in tag address <b>136</b> identifies tag memory row<sub>0 </sub>as the selected tag memory row. If tag memory row<sub>0 </sub>is selected by the five bit pattern in tag address <b>136</b>, enable line <b>435</b> is high when C<b>1</b> is high and there is a \u201c1\u201d on the second input of NAND gate <b>424</b>. Thus, NAND gate <b>424</b> is enabled to pass to the output of inverter <b>426</b> whatever state exists on precharge line <b>439</b> when C<b>1</b> is high. The output of NAND gate <b>424</b> is inverted at inverter <b>426</b>. Thus, when C<b>1</b> is high, if precharge line <b>439</b> is low, the output of inverter <b>426</b> will be a \u201c0\u201d. If precharge line <b>439</b> is high, the output of inverter <b>426</b> will be a \u201c1\u201d.</p><p>Output of the XOR within memory cell<sub>0 </sub>at node <b>461</b> is connected to the gate of NFET <b>412</b> and the output of the XOR within memory cell<sub>1 </sub>at node <b>463</b> is connected to the gate of NFET <b>414</b>. NFET <b>412</b> and NFET <b>414</b> are connected in a manner to provide a \u201cdynamic NOR gate\u201d. There would be one respective NFET in the dynamic NOR gate for each of the remaining 21 memory cells of tag memory row<sub>0</sub>. The remaining 21 memory cells in tag memory row<sub>0 </sub>are not shown in FIG. <b>4</b>. The dynamic NOR gate operates as described below.</p><p>Each memory cell compares one tag bit and one address bit. If the tag bit and the address bit are the same, i.e., either both a \u201c0\u201d or both a \u201c1\u201d, the output of the XOR within the memory cell will be a \u201c0\u201d. If the tag bit and the address bit are different, the output of the XOR within the memory cell will be a \u201c1\u201d.</p><p>It is recalled that NFET <b>420</b> is turned on when C<b>1</b> is high and when tag memory row<sub>0 </sub>is selected. As such, line <b>437</b> will be shorted to ground and a \u201c0\u201d will be present on line <b>437</b> when C<b>1</b> is high and tag memory row<sub>0 </sub>is selected. If either the output of the XOR in memory cell<sub>0 </sub>at node <b>461</b> or the output of the XOR in memory cell<sub>1 </sub>at node <b>463</b> is a \u201c1\u201d, then their respective NFET in the dynamic NOR gate turns on. When tag memory row<sub>0 </sub>is selected and if either NFET <b>412</b> or NFET <b>414</b> is turned on, precharge line <b>439</b> will short to line <b>437</b> and precharge line <b>439</b> will discharge. Accordingly, there will also be a \u201c0\u201d at the first input to NAND gate <b>424</b> and a \u201c1\u201d at the output of NAND gate <b>424</b>.</p><p>Thus, there will be a \u201c1\u201d on the output of NAND gate <b>424</b> when at least one bit in the 23 upper bits of the main memory instruction address is different from the corresponding bit in the 23-bit tag. This \u201c1\u201d is then at the input of inverter <b>426</b> resulting in a \u201c0\u201d at the output of inverter <b>426</b>. This \u201c0\u201d at the output of inverter <b>426</b> corresponds to the condition when the upper 23 bits of the main memory instruction address are not identical to the 23 bits of the tag. This condition is referred to as a \u201cmiss\u201d.</p><p>If both the output of the XOR in memory cell<sub>0 </sub>at node <b>461</b> and the output of the XOR in memory cell<sub>1 </sub>at node <b>463</b> are a \u201c0\u201d, then their respective NFET in the dynamic NOR gate is off. Thus, precharge line <b>439</b> would not be shorted to line <b>437</b> and therefore when tag memory row<sub>0 </sub>is selected and C<b>1</b> transitions from low to high, precharge line <b>439</b> and the first input of NAND gate <b>424</b> will still be a \u201c1\u201d and the output of NAND <b>424</b> will be a \u201c0\u201d. This \u201c0\u201d which is at the input of inverter <b>426</b> results in a \u201c1\u201d at the output of inverter <b>426</b>. This \u201c1\u201d at the output of inverter <b>426</b> corresponds to the condition when the upper 23 bits of the main memory instruction address match the 23 bits of the tag. This condition is referred to as a \u201chit\u201d.</p><p>It can be seen that NAND gate <b>424</b> and inverter <b>426</b> function together as an AND gate. The output of inverter <b>426</b> is where the result of the compare operation is seen. There would be one respective NAND gate and one respective inverter for each of the remaining 31 tag memory rows in the tag memory bank. The remaining 31 tag memory rows in the tag memory bank are not shown in FIG. <b>4</b>.</p><p>NFET <b>428</b> is part of another dynamic NOR gate. There would be one respective NFET such as NFET <b>428</b> for each of the remaining 31 tag memory rows in the tag memory bank. The remaining 31 tag memory rows in the tag memory bank are not shown in FIG. <b>4</b>. This dynamic NOR gate operates as described below.</p><p>When C<b>1</b> is low, PFET <b>430</b> turns on and line <b>451</b> will be pre-charged. As discussed above, when tag memory row<sub>0 </sub>is selected and C<b>1</b> transitions from low to high, the result of the compare operation will be present on the output of inverter <b>426</b>. If a \u201c0\u201d is present on the output of inverter <b>426</b>, corresponding to a miss, NFET <b>428</b> is off. Thus, there will be a \u201c1\u201d at the input of inverter <b>432</b> and a \u201c0\u201d at the output of inverter <b>432</b>.</p><p>If a \u201c1\u201d is present on the output of inverter <b>426</b>, corresponding to a hit, NFET <b>428</b> turns on. Moreover, NFET <b>446</b> turns on when C<b>1</b> transitions from low to high and line <b>445</b> will be shorted to ground when C<b>1</b> is high. Thus, when NFET <b>428</b> turns on and when C<b>1</b> transitions from low to high, line <b>451</b> will be shorted to line <b>445</b> and will be pulled low. Thus, there will be a \u201c0\u201d at the input of inverter <b>432</b> and a \u201c1\u201d at the output of inverter <b>432</b>. It is noted that the C<b>1</b> input to the gate of NFET <b>446</b> must be delayed for a short time so that the output of inverter <b>426</b> has time to settle before NFET <b>446</b> turns on. As such, the \u201cdelayed C<b>1</b>\u201d at the input to the gate of NFET <b>446</b> avoids a \u201crace\u201d condition.</p><p>NFET <b>434</b>, NFET <b>436</b>, NFET <b>442</b>, inverter <b>438</b> and inverter <b>440</b> are connected in a manner to \u201clatch\u201d the hit or miss. When tag memory row<sub>0 </sub>is selected and C<b>1</b> transitions from low to high, line <b>457</b> will be high if there is a \u201c1\u201d at the output of inverter <b>426</b>, corresponding to a hit condition on tag memory row<sub>0 </sub>of the tag memory bank. There would be one respective line identical to line <b>457</b> for each of the remaining 31 tag memory rows in the tag memory bank. The remaining 31 tag memory rows in the tag memory bank are not shown in FIG. <b>4</b>. Thus, whenever there is a hit in a selected tag memory row within the tag memory bank, the corresponding line for that tag memory row, such as line <b>457</b> for tag memory row<sub>0</sub>, will be high. The 32 lines, which include line <b>457</b>, are OR'ed together in a manner known in the art. When any one of the 32 inputs to the OR is a \u201c1\u201d, the output of the OR will be a \u201c1\u201d (the OR gate is not shown in any of the Figures). Thus, the output of the OR will be a \u201c1\u201d whenever there is a hit on any one of the 32 tag memory rows of the tag memory bank. The output of this OR is referred to as \u201cany tag hit\u201d.</p><p>When the output of the OR is a \u201c1\u201d, there is a hit in the tag memory bank corresponding to that OR gate. In the present example, at most one of the four tag memory banks will result in a \u201c1\u201d in its corresponding \u201cany tag hit\u201d OR gate. The desired instruction is thus in the instruction cache corresponding to the tag memory bank which has a \u201c1\u201d at the output of its \u201cany tag hit\u201d OR gate.</p><p>The instruction cache containing the desired instruction is enabled to send the desired instruction to the instruction register. The desired instruction is at an address decoded from the seven bits contained in the cache instruction address <b>138</b>. Thus, when there is a hit, the seven-bit address decoder for the instruction cache containing the desired instruction will be enabled. If there is a miss, the decoder for the instruction cache will be disabled.</p><p>Thus, it is seen that the invention completes the tag comparison during the first C<b>2</b>, referred to by numeral <b>204</b> in FIG. 2, by means of an XOR gate within the tag memory cell itself. In other words, during the first C<b>2</b> the invention determines if there is a \u201chit\u201d, i.e. if there is a match between the upper 23 bits in the program counter and any of the 23-bit tags in one of the four memory banks. The desired instruction is located in the instruction cache associated with the particular tag memory bank containing the tag that resulted in a hit.</p><p>Unlike other set-associative caches, the invention does not read four instructions from each of the four instruction caches. Instead, only the desired instruction is read from a single instruction cache. If there is a \u201chit,\u201d the desired instruction is located in one of the four instruction caches. The decoder for the instruction cache corresponding to the tag memory bank where a hit has occurred is enabled. During the second C<b>2</b>, referred to by numeral <b>208</b> in FIG. 2, the desired instruction is sent from the enabled instruction cache to the instruction register.</p><p>As discussed above, in techniques other than the invention's technique, a total of four instructions are read during the second C<b>1</b>, one from each of the four instruction caches in the set-associative cache. As a result, the power consumed is expressed as:</p><p><maths><formula-text>Power \u221d(4 instructions\u00d732 bits)+(4 tags\u00d723 bits).</formula-text></maths></p><p>In contrast, the invention reads only one instruction during the second C<b>1</b>. As a result, the power consumed is expressed as:</p><p><maths><formula-text>Power \u221d(1 instruction\u00d732 bits)+(4 tags\u00d723 bits).</formula-text></maths></p><p>Accordingly, the invention results in a significant saving in the power consumption of the set-associative cache.</p><p>Thus, a low power instruction cache has been described.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "John R.", "last_name": "Spence", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "CONEXANT SYSTEMS, INC."}, {"first_name": "", "last_name": "INTELLECTUAL VENTURES ASSETS 191 LLC", "name": ""}, {"first_name": "", "last_name": "INTELLECTUAL VENTURES ASSETS 186 LLC", "name": ""}, {"first_name": "", "last_name": "INTELLECTUAL VENTURES ASSETS 191 LLC", "name": ""}, {"first_name": "", "last_name": "RATEZE REMOTE MGMT. L.L.C.", "name": ""}, {"first_name": "", "last_name": "LEEDMIN DEVELOPMENT AG, LLC", "name": ""}, {"first_name": "", "last_name": "MINDSPEED TECHNOLOGIES, INC.", "name": ""}, {"first_name": "", "last_name": "MINDSPEED TECHNOLOGIES, INC.", "name": ""}, {"first_name": "", "last_name": "CONEXANT SYSTEMS, INC.", "name": ""}, {"first_name": "", "last_name": "MINDSPEED TECHNOLOGIES", "name": ""}, {"first_name": "", "last_name": "CONEXANT SYSTEMS, INC.", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F  12/02"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F  12/08        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "711125"}, {"primary": false, "label": "711E12018"}], "ecla_classes": [{"label": "S06F212:1028"}, {"label": "Y02B60:12F"}, {"label": "G06F  12/08B10"}, {"label": "S06F12:08B14"}], "cpc_classes": [{"label": "Y02D  10/00"}, {"label": "G06F   9/3802"}, {"label": "G06F  12/0875"}, {"label": "Y02D  10/00"}, {"label": "G06F2212/1028"}, {"label": "G06F  12/0864"}, {"label": "G06F  12/0875"}, {"label": "G06F   9/3802"}, {"label": "G06F  12/0864"}, {"label": "G06F2212/1028"}], "f_term_classes": [], "legal_status": "Expired - Lifetime", "priority_date": "2000-06-20", "application_date": "2000-06-20", "family_members": [{"ucid": "US-6549986-B1", "titles": [{"lang": "EN", "text": "Low power instruction cache"}]}]}