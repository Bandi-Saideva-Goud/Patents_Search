{"patent_number": "US-6230260-B1", "publication_id": 72649023, "family_id": 22509580, "publication_date": "2001-05-08", "titles": [{"lang": "EN", "text": "Circuit arrangement and method of speculative instruction execution utilizing instruction history caching"}], "abstracts": [{"lang": "EN", "paragraph_markup": "<abstract lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PA72551916\"><p>A data processing system, circuit arrangement, integrated circuit device, program product, and method utilize a unique prefetch circuit arrangement that speculatively fetches instructions for execution by a processor based upon history data associated with such instructions. In particular, the history data for a given instruction identifies the next instruction that was executed immediately subsequent to the given instruction. An instruction history cache is utilized in some implementations to store history data representing predicted next instructions for a plurality of instructions stored in a memory, and the instruction history cache is operated concurrently with a secondary instruction cache so that predicted and actual next instructions may be retrieved in parallel. Predicted next instructions are speculatively executed when retrieved from the instruction history cache; however, execution of such instructions is terminated if the predicted and actual next instructions do not match. Also, in some implementations, the history data in the instruction history cache that is associated with a particular instruction may represent a predicted instruction to execute at least two cycles subsequent to execution of that particular instruction. In other implementations, history data for use in predicting next instructions may be embedded within instructions themselves, often eliminating the need for a separate instruction history cache.</p></abstract>"}], "claims": [{"lang": "EN", "claims": [{"num": 1, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00001\" num=\"1\"><claim-text>1. A circuit arrangement, comprising:</claim-text><claim-text>(a) a memory having stored therein a plurality of instructions, the memory including primary and secondary instruction caches, wherein the secondary instruction cache has an access time that is greater than that of the primary instruction cache; </claim-text><claim-text>(b) an instruction history cache having stored therein a plurality of predicted next instructions, each representing a predicted instruction to execute subsequent to an instruction stored in the memory; </claim-text><claim-text>(c) at least one execution unit configured to execute a first instruction from the plurality of instructions in the memory; </claim-text><claim-text>(d) a prefetch circuit arrangement configured to initiate retrieval, from the instruction history cache and the secondary instruction cache respectively, of predicted and actual next instructions to execute subsequent to the first instruction, the prefetch circuit arrangement further configured to supply the predicted next instruction to the execution unit for execution thereby subsequent to execution of the first instruction; and </claim-text><claim-text>(e) a prediction verification circuit arrangement configured to receive the predicted and actual next instructions respectively from the instruction history cache and the secondary instruction cache and terminate execution of the predicted next instruction by the execution unit if the predicted and actual next instructions do not match. </claim-text></claim>"}, {"num": 2, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00002\" num=\"2\"><claim-text>2. The circuit arrangement of claim <b>1</b>, wherein the plurality of instructions are Very Long Instruction Words (VLIW's).</claim-text></claim>"}, {"num": 3, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00003\" num=\"3\"><claim-text>3. The circuit arrangement of claim <b>1</b>, wherein the primary cache includes a level one instruction cache, and wherein the secondary cache includes a level two cache.</claim-text></claim>"}, {"num": 4, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00004\" num=\"4\"><claim-text>4. The circuit arrangement of claim <b>1</b>, further comprising a history update circuit arrangement configured to store the actual next instruction as the predicted next instruction for the first instruction.</claim-text></claim>"}, {"num": 5, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00005\" num=\"5\"><claim-text>5. The circuit arrangement of claim <b>4</b>, wherein the history update circuit arrangement is configured to store the actual next instruction as the predicted next instruction only if the actual next instruction differs from the predicted next instruction.</claim-text></claim>"}, {"num": 6, "parent": 4, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00006\" num=\"6\"><claim-text>6. The circuit arrangement of claim <b>4</b>, wherein the instruction history cache has an access time of N cycles, and wherein the history update circuit arrangement is configured to offset the predicted next instruction for the first instruction by N\u22121 instructions in the instruction history cache such that the predicted next instruction for the first instruction is accessed in the instruction history cache via an address of a second instruction executed N\u22121 cycles prior to the first instruction.</claim-text></claim>"}, {"num": 7, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00007\" num=\"7\"><claim-text>7. The circuit arrangement of claim <b>6</b>, wherein the execution unit comprises an execution pipe comprising a plurality of stages, wherein the instruction history cache includes a write access port configured to store an instruction supplied at a data input at an address supplied at an address input, and wherein the history update circuit arrangement comprises a set of data lines electrically coupling an instruction register in one of the plurality of stages of the execution pipe to the data input of the write access port, and a set of address lines electrically coupling an address register in another of the plurality of stages of the execution pipe to the address input of the write access port, wherein the stage to which the set of data lines is coupled is offset by N\u22121 cycles from the stage to which the set of address lines is coupled.</claim-text></claim>"}, {"num": 8, "parent": 6, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00008\" num=\"8\"><claim-text>8. The circuit arrangement of claim <b>6</b>, wherein the execution unit comprises an execution pipe comprising a plurality of stages, wherein the instruction history cache includes a write access port configured to store an instruction supplied at a data input at an address supplied at an address input, and wherein the history update circuit arrangement further comprises a selector circuit arrangement interposed between the execution pipe and the instruction history cache, the selector circuit configured to selectively couple at least one of the data input and the address input of the write access port to different stages of the execution pipe to controllably offset the predicted next instruction for the first instruction by one or more instructions in the instruction history cache in response to a selector input.</claim-text></claim>"}, {"num": 9, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00009\" num=\"9\"><claim-text>9. The circuit arrangement of claim <b>1</b>, wherein the prediction verification circuit includes a compare block configured to receive the predicted and actual next instructions respectively from the instruction history cache and the secondary instruction cache and output in response to a mismatch therebetween an inhibit signal to the execution unit to terminate execution of the predicted next instruction.</claim-text></claim>"}, {"num": 10, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00010\" num=\"10\"><claim-text>10. The circuit arrangement of claim <b>9</b>, wherein the execution unit includes an execution pipe having a register write stage that stores a result of execution of the predicted next instruction, and wherein the execution unit is configured to inhibit the register write stage for the predicted next instruction in response to the inhibit signal from the compare block.</claim-text></claim>"}, {"num": 11, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00011\" num=\"11\"><claim-text>11. The circuit arrangement of claim <b>9</b>, wherein the compare block is configured to be enabled by a miss signal from the primary cache and a hit signal from the secondary cache.</claim-text></claim>"}, {"num": 12, "parent": 9, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00012\" num=\"12\"><claim-text>12. The circuit arrangement of claim <b>9</b>, wherein the secondary cache has an access time that is M cycles greater than the instruction history cache, and wherein the prediction verification circuit arrangement further comprises an M-stage buffer interposed between the instruction history cache and the compare block.</claim-text></claim>"}, {"num": 13, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00013\" num=\"13\"><claim-text>13. The circuit arrangement of claim <b>1</b>, wherein the execution unit is configured to output an address to the primary, secondary and instruction history caches to concurrently initiate concurrent access operations the primary, secondary and instruction history caches.</claim-text></claim>"}, {"num": 14, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00014\" num=\"14\"><claim-text>14. The circuit arrangement of claim <b>1</b>, wherein the execution unit is disposed in a first integrated circuit device, the circuit arrangement further comprising a plurality of memory devices coupled to the first integrated circuit device, wherein each of the plurality of memory devices includes a portion of an address space for each of the secondary and instruction history caches, with each memory device storing a portion of each of the predicted and actual next instructions, and wherein the prediction verification circuit comprises:</claim-text><claim-text>(a) a plurality of partial compare blocks respectively disposed in the plurality of memory devices, each partial compare block configured to receive the portions of the predicted and actual next instructions stored in the associated memory device and output in response to a mismatch therebetween a partial compare signal to the first integrated circuit device; and </claim-text><claim-text>(b) a master compare block, disposed in the first integrated circuit device and configured to combine the partial compare signals from the plurality of partial compare blocks to generate an inhibit signal for selectively terminating execution of the predicted next instruction if any of the partial compare signals indicate a mismatch between any portions of the predicted and actual next instructions. </claim-text></claim>"}, {"num": 15, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00015\" num=\"15\"><claim-text>15. A data processing system comprising the circuit arrangement of claim <b>1</b>.</claim-text></claim>"}, {"num": 16, "parent": 1, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00016\" num=\"16\"><claim-text>16. A program product, comprising a hardware definition program that defines the circuit arrangement of claim <b>1</b>; and a signal bearing media bearing the hardware definition program.</claim-text></claim>"}, {"num": 17, "parent": 16, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00017\" num=\"17\"><claim-text>17. The program product of claim <b>16</b>, wherein the signal bearing media includes at least one of a transmission type media and a recordable media.</claim-text></claim>"}, {"num": 18, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00018\" num=\"18\"><claim-text>18. A data processing system, comprising:</claim-text><claim-text>(a) a mainstore having stored therein a plurality of instructions; </claim-text><claim-text>(b) a secondary cache coupled to the mainstore and storing at least a first portion of the plurality of instructions; </claim-text><claim-text>(c) an instruction history cache having stored therein a plurality of predicted next instructions, each representing a predicted instruction to execute subsequent to one of the plurality of instructions; and </claim-text><claim-text>(c) a processor coupled to the secondary cache and the instruction history cache, the processor including: </claim-text><claim-text>(1) a primary instruction cache coupled to the secondary cache and storing at least a second portion of the plurality of instructions, wherein the secondary instruction cache has an access time that is greater than that of the primary instruction cache; </claim-text><claim-text>(2) at least one execution unit configured to execute a first instruction from the plurality of instructions; </claim-text><claim-text>(3) a prefetch circuit arrangement configured to initiate retrieval, from the instruction history cache and the secondary instruction cache respectively, of predicted and actual next instructions to execute subsequent to the first instruction, the prefetch circuit arrangement further configured to supply the predicted next instruction to the execution unit for execution thereby subsequent to execution of the first instruction; and </claim-text><claim-text>(4) a prediction verification circuit arrangement configured to receive the predicted and actual next instructions respectively from the instruction history cache and the secondary instruction cache and terminate execution of the predicted next instruction by the execution unit if the predicted and actual next instructions do not match. </claim-text></claim>"}, {"num": 19, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00019\" num=\"19\"><claim-text>19. A method of speculatively fetching instructions for execution by an execution unit coupled to a memory including primary and secondary instruction caches, with the secondary instruction cache having an access time that is greater than that of the primary instruction cache, the method comprising:</claim-text><claim-text>(a) concurrently initiating retrieval, from an instruction history cache and the secondary instruction cache, of predicted and actual next instructions to execute subsequent to execution of a first instruction by the execution unit; </claim-text><claim-text>(b) receiving the predicted next instruction from the instruction history cache and supplying the predicted next instruction to the execution unit for execution thereby; and </claim-text><claim-text>(c) comparing the predicted next instruction received from the instruction history cache with the actual next instruction received from the secondary cache, and terminating execution of the predicted next instruction by the execution unit if the predicted and actual next instructions do not match. </claim-text></claim>"}, {"num": 20, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00020\" num=\"20\"><claim-text>20. A circuit arrangement, comprising:</claim-text><claim-text>(a) a memory having stored therein a plurality of instructions, the memory including primary and secondary instruction caches, with the secondary instruction cache having an access time that is greater than that of the primary instruction cache; </claim-text><claim-text>(b) an instruction history cache having stored therein a plurality of predicted next instructions, each representing a predicted instruction to execute at least two cycles subsequent to execution of an instruction in the memory; </claim-text><claim-text>(c) at least one execution unit configured to begin execution of a first instruction from the memory, and thereafter to begin execution of a second instruction from the memory; </claim-text><claim-text>(d) a prefetch circuit arrangement configured to prefetch a predicted next instruction for the second instruction from the instruction history cache concurrently with execution of the first instruction by the execution unit, wherein the prefetch circuit arrangement is further configured to initiate retrieval, from the instruction history cache and the secondary instruction cache respectively, of predicted and actual next instructions for the second instruction from the secondary instruction cache concurrently with prefetching the predicted next instruction, and to supply the predicted next instruction to the execution unit for execution thereby subsequent to execution of the first instruction; and </claim-text><claim-text>(e) a prediction verification circuit arrangement configured to receive the predicted and actual next instructions respectively from the instruction history cache and the secondary instruction cache and terminate execution of the predicted next instruction by the execution unit if the predicted and actual next instructions do not match. </claim-text></claim>"}, {"num": 21, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00021\" num=\"21\"><claim-text>21. The circuit arrangement of claim <b>20</b>, further comprising a history update circuit arrangement configured to store as the predicted next instruction for the second instruction an instruction actually executed the at least two cycles subsequent to the second instruction.</claim-text></claim>"}, {"num": 22, "parent": 21, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00022\" num=\"22\"><claim-text>22. The circuit arrangement of claim <b>21</b>, wherein the instruction history cache has an access time of N cycles, and wherein the history update circuit arrangement is configured to offset the predicted next instruction for the second instruction by N\u22121 instructions in the instruction history cache such that the predicted next instruction for the second instruction is accessed in the instruction history cache via an address of a third instruction executed N\u22121 cycles prior to the second instruction.</claim-text></claim>"}, {"num": 23, "parent": 22, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00023\" num=\"23\"><claim-text>23. The circuit arrangement of claim <b>22</b>, wherein the execution unit comprises an execution pipe comprising a plurality of stages, wherein the instruction history cache includes a write access port configured to store an instruction supplied at a data input at an address supplied at an address input, and wherein the history update circuit arrangement comprises a set of data lines electrically coupling an instruction register in one of the plurality of stages of the execution pipe to the data input of the write access port, and a set of address lines electrically coupling an address register in another of the plurality of stages of the execution pipe to the address input of the write access port, wherein the stage to which the set of data lines is coupled is offset by N\u22121 cycles from the stage to which the set of address lines is coupled.</claim-text></claim>"}, {"num": 24, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00024\" num=\"24\"><claim-text>24. A data processing system comprising the circuit arrangement of claim <b>20</b>.</claim-text></claim>"}, {"num": 25, "parent": 20, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00025\" num=\"25\"><claim-text>25. A program product, comprising a hardware definition program that defines the circuit arrangement of claim <b>20</b>; and a signal bearing media bearing the hardware definition program.</claim-text></claim>"}, {"num": 26, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00026\" num=\"26\"><claim-text>26. A method of speculatively fetching instructions for execution by an execution unit coupled to a memory including primary and secondary instruction caches, with the secondary instruction cache having an access time that is greater than that of the primary instruction cache, the method comprising:</claim-text><claim-text>(a) initiating execution of a first instruction from the memory by the execution unit; </claim-text><claim-text>(b) after initiating execution of the first instruction, initiating execution of a second instruction from the memory by the execution unit; </claim-text><claim-text>(c) concurrently initiating retrieval from an instruction history cache and the secondary instruction cache, of a predicted next instruction and an actual next instruction for the second instruction, respectively, and concurrently with execution of the first instruction by the execution unit, the instruction history cache having stored therein a plurality of predicted next instructions, each representing a predicted instruction to execute at least two cycles subsequent to execution of an instruction in the memory; </claim-text><claim-text>(d) receiving the predicted next instruction from the instruction history cache and supplying the predicted next instruction to the execution unit for execution thereby; and </claim-text><claim-text>(e) comparing the predicted next instruction received from the instruction history cache with the actual next instruction received from the secondary cache, and terminating execution of the predicted next instruction by the execution unit if the predicted and actual next instructions do not match. </claim-text></claim>"}, {"num": 27, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00027\" num=\"27\"><claim-text>27. A circuit arrangement, comprising:</claim-text><claim-text>(a) a memory storing a plurality of instructions, wherein each instruction includes history data embedded therein that identifies a predicted next instruction to execute subsequent to execution of one of the plurality of instructions, wherein each of the plurality of instructions is a Very Long Instruction Word (VLIW) instruction including a plurality of parcels, with the history data therefor stored in at least one of the parcels; </claim-text><claim-text>(b) at least one execution unit coupled to the memory, the execution unit configured to execute a first instruction stored in the memory; and </claim-text><claim-text>(c) a prefetch circuit arrangement configured to initiate retrieval from the memory of the predicted next instruction identified by the history data of the first instruction concurrently with execution of the first instruction by the execution unit. </claim-text></claim>"}, {"num": 28, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00028\" num=\"28\"><claim-text>28. The circuit arrangement of claim <b>27</b>, wherein the history address index for each instruction is stored in the last parcel of the instruction.</claim-text></claim>"}, {"num": 29, "parent": 28, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00029\" num=\"29\"><claim-text>29. The circuit arrangement of claim <b>28</b>, wherein each instruction in the plurality of instructions includes as the last parcel thereof one of a NOOP parcel and a branch parcel.</claim-text></claim>"}, {"num": 30, "parent": 29, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00030\" num=\"30\"><claim-text>30. The circuit arrangement of claim <b>29</b>, wherein any instruction having a branch parcel as the last parcel thereof includes a second branch parcel, wherein the branch parcels in any given instruction include branch to addresses that branch to the same cache line in the memory; whereby the branch to address for the branch parcel in the last parcel is replaced with the history address index therefor.</claim-text></claim>"}, {"num": 31, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00031\" num=\"31\"><claim-text>31. The circuit arrangement of claim <b>27</b>, wherein the memory includes primary and secondary instruction caches, wherein the prefetch circuit arrangement is configured to initiate retrieval of the predicted next instruction identified by the history data of the first instruction by addressing the secondary cache using the history address index in the first instruction, wherein the secondary instruction cache has an access time in response to receiving the history address index of N cycles greater than an access time of the primary instruction cache.</claim-text></claim>"}, {"num": 32, "parent": 31, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00032\" num=\"32\"><claim-text>32. The circuit arrangement of claim <b>31</b>, wherein the history data for the first instruction identifies a predicted next instruction for a second instruction to be executed N cycles after the first instruction.</claim-text></claim>"}, {"num": 33, "parent": 32, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00033\" num=\"33\"><claim-text>33. The circuit arrangement of claim <b>32</b>, wherein the prefetch circuit arrangement is further configured to initiate execution of the predicted next instruction by the execution unit, the circuit arrangement further comprising:</claim-text><claim-text>(a) a prediction verification circuit configured to compare the addresses of the predicted next instruction and the actual next instruction executed subsequent to the second instruction and terminate execution of the predicted next instruction by the execution unit if the addresses of the predicted and actual next instructions do not match; and </claim-text><claim-text>(b) a history update circuit arrangement configured to store as the history data for the first instruction an address index associated with the address of the actual next instruction executed subsequent to the second instruction. </claim-text></claim>"}, {"num": 34, "parent": 33, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00034\" num=\"34\"><claim-text>34. The circuit arrangement of claim <b>33</b>, wherein the execution unit comprises an execution pipe comprising a plurality of stages, wherein the primary instruction cache includes a write access port configured to store an address index supplied at a data input at an address supplied at an address input, and wherein the history update circuit arrangement comprises a set of data lines electrically coupling an instruction register in one of the plurality of stages of the execution pipe to the data input of the write access port, and a set of address lines electrically coupling an address register in another of the plurality of stages of the execution pipe to the address input of the write access port, wherein the stage to which the set of data lines is coupled is offset by N cycles from the stage to which the set of address lines is coupled.</claim-text></claim>"}, {"num": 35, "parent": 33, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00035\" num=\"35\"><claim-text>35. The circuit arrangement of claim <b>33</b>, wherein the execution unit comprises an execution pipe comprising a plurality of stages, wherein the primary instruction cache includes a write access port configured to store an address index supplied at a data input at an address supplied at an address input, and wherein the history update circuit arrangement further comprises a selector circuit arrangement interposed between the execution pipe and the primary instruction cache, the selector circuit configured to selectively couple at least one of the data input and the address input of the write access port to different stages of the execution pipe to controllably offset the predicted next instruction for the second instruction by one or more instructions in the instruction history cache in response to a selector input.</claim-text></claim>"}, {"num": 36, "parent": 33, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00036\" num=\"36\"><claim-text>36. The circuit arrangement of claim <b>33</b>, wherein each instruction in the primary cache has associated therewith a change indicator that indicates if the history data associated with the instruction has changed, the circuit arrangement further comprising an address compare block configured to set the change indicator for the first instruction if the addresses of the predicted and actual next instructions do not match.</claim-text></claim>"}, {"num": 37, "parent": 36, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00037\" num=\"37\"><claim-text>37. The circuit arrangement of claim <b>36</b>, further comprising a castout controller, coupled to the primary and secondary instruction caches, the castout controller configured to update the history data for a copy of the first instruction in the secondary instruction cache in response to replacement of a copy of the first instruction in the primary instruction cache when the change indicator for the first instruction is set.</claim-text></claim>"}, {"num": 38, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00038\" num=\"38\"><claim-text>38. A data processing system comprising the circuit arrangement of claim <b>27</b>.</claim-text></claim>"}, {"num": 39, "parent": 27, "type": "dependent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00039\" num=\"39\"><claim-text>39. A program product, comprising a hardware definition program that defines the circuit arrangement of claim <b>27</b>; and a signal bearing media bearing the hardware definition program.</claim-text></claim>"}, {"num": 40, "parent": -1, "type": "independent", "paragraph_markup": "<claim id=\"US-6230260-B1-CLM-00040\" num=\"40\"><claim-text>40. A method of speculatively fetching instructions, the method comprising:</claim-text><claim-text>(a) executing a first instruction among a plurality of instructions stored in a memory, wherein the first instruction includes history data embedded therein that identifies a predicted next instruction to execute subsequent to execution of one of the plurality of instructions, and wherein each of the plurality of instructions is a Very Long Instruction Word (VLIW) instruction including a plurality of parcels, with the history data therefor stored in at least one of the parcels; and </claim-text><claim-text>(b) concurrently with executing the first instruction, initiating retrieval from the memory of the predicted next instruction identified by the history data of the first instruction.</claim-text></claim>"}]}], "descriptions": [{"lang": "EN", "paragraph_markup": "<description lang=\"EN\" load-source=\"patent-office\" mxw-id=\"PDES54540446\"><?BRFSUM description=\"Brief Summary\" end=\"lead\"?><h4>FIELD OF THE INVENTION</h4><p>The invention is generally related to integrated circuit device architecture and design, and in particular to branch prediction in a processor integrated circuit device.</p><h4>BACKGROUND OF THE INVENTION</h4><p>Users of data processing systems such as computers and the like continue to demand greater and greater performance from such systems for handling increasingly complex and difficult tasks. Greater performance from the processors that operate such systems may be obtained through faster clock speeds, so that individual instructions are processed more quickly. However, relatively greater performance gains have been achieved through performing multiple operations in parallel with one another.</p><p>One manner of parallelization is known as \u201cpipelining\u201d , where instructions are fed into a pipeline for an execution unit in a processor that performs different operations necessary to process the instructions in parallel. For example, to process a typical instruction, a pipeline may include separate stages for fetching the instruction from memory, executing the instruction, and writing the results of the instruction back into memory. Thus, for a sequence of instructions fed in sequence into the pipeline, as the results of the first instruction are being written back into memory by the third stage of the pipeline, a next instruction is being executed by the second stage, and still a next instruction is being fetched by the first stage. While each individual instruction may take several clock cycles to be processed, since other instructions are also being processed at the same time, the overall throughput of the processor is much greater.</p><p>Greater parallelization can also be performed by attempting to execute multiple instructions in parallel using multiple execution units in a processor. Processors that include multiple execution units are often referred to as \u201csuperscalar\u201d processors, and such processors include scheduling circuitry that attempts to efficiently dispatch instructions to different execution units so that as many instructions are processed at the same time as possible. Relatively complex decision-making circuitry is often required, however, because oftentimes one instruction cannot be processed until after another instruction is completed. For example, if a first instruction loads a register with a value from memory, and a second instruction adds a fixed number to the contents of the register, the second instruction typically cannot be executed until execution of the first instruction is complete.</p><p>The use of relatively complex scheduling circuitry can occupy a significant amount of circuitry on an integrated circuit device, and can slow the overall execution speed of a processor. For these reasons, significant development work has been devoted to Very Long Instruction Word (VLIW) processors, where the decision as to which instructions can be executed in parallel is made when a program is created, rather than during execution. A VLIW processor typically includes multiple execution units, and each VLIW instruction includes multiple primitive instructions known as parcels that are known to be executable at the same time as one another. Each primitive instruction in a VLIW may therefore be directly dispatched to one of the execution units without the extra overhead associated with scheduling. VLIW processors rely on sophisticated computer programs known as compilers to generate suitable VLIW instructions for a computer program written by a computer user. VLIW processors are typically less complex and more efficient than superscalar processors given the elimination of the overhead associated with scheduling the execution of instructions.</p><p>Despite the type of processor, another bottleneck on computer performance is that of transferring information between a processor and memory. In particular, processing speed has increased much more quickly than that of main memory. As a result, cache memories, or caches, are often used in many such systems to increase performance in a relatively cost-effective manner.</p><p>A cache is typically a relatively faster memory that is coupled intermediate one or more processors and a relatively slower memory such as implemented in volatile or non-volatile memory devices, mass storage devices, and/or external network storage devices, among others. A cache speeds access by maintaining a copy of the information stored at selected memory addresses so that access requests to the selected memory addresses by a processor are handled by the cache. Whenever an access request is received for a memory address not stored in the cache, the cache typically retrieves the information from the memory and forwards the information to the processor. Moreover, if the cache is full, typically the information related to the least recently used memory address is discarded or returned to the memory to make room for information related to more recently accessed memory addresses.</p><p>The benefits of a cache are maximized whenever the number of access requests to cached memory addresses, known as \u201ccache hits\u201d, are maximized relative to the number of access requests to non-cached memory addresses, known as \u201ccache misses\u201d. Despite the added overhead that typically occurs as a result of a cache miss, as long as the percentage of cache hits is high, the overall access rate for the system is increased.</p><p>However, it has been found that with much commercial program code such as operating system code and the like, the miss rate for instructions in a cache is often relatively high due to the lack of code reuse and the presence of a large number of branch instructions, which are used to cause a processor to take different instruction paths based upon the result of conditions, or tests, specified in the instructions. Also, a great deal of operating system code is devoted to error and exception handling, and is thus rarely executed, often resulting in a cache temporarily storing a significant number of instructions that are never executed.</p><p>It has further been found that for VLIW processors, the miss rate is often even higher because compiling a computer program into a VLIW-compatible format typically expands the program code 2-4 times. Also, the relative frequency of branch instructions in VLIW program code is much higher\u2014typically two branches out of every three instructions verses one branch every 5-6 instructions with a superscalar processor.</p><p>One manner of increasing the hit rate for a cache is to increase the size of the cache. However, cache memory is often relatively expensive, and oftentimes is limited by design constraints\u2014particularly if the cache is integrated with a processor on the same integrated circuit device. Internal caches integrated with a processor are typically faster than external caches implemented in separate circuitry. On the other hand, due to design and cost restraints, internal caches are typically much smaller in size than their external counterparts.</p><p>One cost-effective alternative is to chain together multiple caches of varying speeds, with a relatively smaller, but faster primary cache chained to a relatively larger, but slower secondary cache. In addition, instructions and data may be separated into separate data and instruction caches. For example, for instructions, some processors implement a relatively small internal level one (L1) instruction cache with an additional external level two (L2) instruction cache coupled intermediate the L1 instruction cache and main memory storage. Typically, an L1 instruction cache has an access time of one clock cycle, and thus, data may be fed to the processor at approximately the same rate as instructions can be processed by the processor. On the other hand, an external L2instruction cache oftentimes has an access time of at least 5 clock cycles, so if a processor is required to rely extensively on memory accesses to an L2 instruction cache, the processor may often stall waiting for data to be retrieved by the cache, thereby significantly degrading processor performance.</p><p>As an attempt to minimize the delays associated with retrieving instructions from memory, many processors include prefetch circuitry that attempts to \u201cpredict\u201d what instructions will need to be executed in the immediate future, and then to speculatively retrieve those instructions from memory before they are needed by the processor. Branch instructions present the greatest impediments to prefetching instructions, and as a result, prefetch circuitry typically performs an operation known as \u201cbranch prediction\u201d to attempt to speculatively determine whether or not a particular instruction path will be taken after a branch instruction.</p><p>One manner of branch prediction relies on a branch history table or cache that maintains a history of whether or not previously-executed branch instructions resulted in branches being taken. In particular, it has been found that more often than not branch instruction will take the same instruction path each time it is executed. By predicting that the same path will be taken the next time a particular branch instruction is executed, the prediction is usually successful.</p><p>Conventional branch history tables typically store an indication of whether the condition for a particular branch instruction was met the last time the instruction was executed. However, with a conventional branch history table, often the table must be accessed to determine whether a branch was taken, followed by generating the address for the next instruction, and then fetching the instruction stored at the generated address. If the instruction at the generated address is not in the primary cache, the processor will stall waiting for the secondary cache to handle the fetch request.</p><p>Consequently, while conventional branch history tables do reduce the overhead associated with branch instructions, some degree of overhead still exists in many circumstances. As a result, processor performance is adversely affected. Furthermore, with VLIW program code, where branch instructions are encountered more frequently, the adverse impact of branch instructions on processor performance is even greater.</p><p>Therefore, a substantial need exists for an improved manner of branch prediction that minimizes the overhead associated with branch instructions and maximizes processor performance, particularly for VLIW and superscalar processors and the like.</p><h4>SUMMARY OF THE INVENTION</h4><p>The invention addresses these and other problems associated with the prior art by providing a data processing system, circuit arrangement, integrated circuit device, program product, and method that utilize a unique prefetch circuit arrangement that speculatively fetches instructions for execution by a processor based upon history data associated with such instructions. In particular, the history data for a given instruction identifies another instruction that was executed one or more cycles after the given instruction. Based upon the recognition that instruction streams tend to follow like paths the majority of the time, historical information about past next instructions has been found to be a reliable predictor for speculative instruction fetching.</p><p>Consistent with one aspect of the invention, an instruction history cache is utilized to store history data representing predicted next instructions for a plurality of instructions stored in a memory that includes primary and secondary instruction caches. The instruction history cache is operated concurrently with the secondary instruction cache in the memory so that predicted and actual next instructions may be retrieved in parallel by a prefetch circuit arrangement. The prefetch circuit arrangement is further configured to supply the predicted next instruction from the instruction history cache to an execution unit for execution thereby subsequent to execution of a first instruction by the execution unit. Also, a prediction verification circuit arrangement coupled to the execution unit is configured to terminate execution of the predicted next instruction by the execution unit if the predicted and actual next instructions do not match.</p><p>Unlike conventional branch prediction caches that indicate whether or not a particular branch was taken, an instruction history cache consistent with invention stores the history of the actual instructions that were executed subsequent to branch and other instructions. As a result, the latency associated with calculating an address and initiating an instruction fetch based upon an indication of whether a branch was taken is avoided, often significantly improving instruction throughput.</p><p>Moreover, with the above-described configuration, predicted next instructions may be speculatively fetched and executed prior to verification that such instructions are actually the correct instructions to execute. Thus, for any instruction fetch that cannot be satisfied by the primary instruction cache, the time required to retrieve instructions may be shortened relative to if the instruction fetch was simply satisfied by the secondary instruction cache.</p><p>Consistent with another aspect of the invention, an instruction history cache is also utilized to store history data representing predicted next instructions. Each predicted next instruction, however, represents a predicted instruction to execute at least two cycles subsequent to execution of a particular instruction in a memory. At least one execution unit is configured to begin execution of a first instruction from the memory, and thereafter to begin execution of second instruction from the memory. Furthermore, a prefetch circuit arrangement is configured to prefetch a predicted next instruction for the second instruction from the instruction history cache concurrently with execution of the first instruction by the execution unit.</p><p>Put another way, the history data associated with a given instruction does not predict the next instruction to executed subsequent to that instruction. Rather, it predicts the next instruction to execute subsequent to execution of a future instruction relative to the given instruction. Put yet another way, the history data associated with a given instruction predicts an instruction to execute two or more cycles after the given instruction. It has been found that, in many implementations, speculatively retrieving instructions from an instruction history cache may still result in delays due to the access time of the instruction history cache. Thus, by speculatively retrieving a predicted next\u2014next instruction, or another predicted instruction farther in the future, the latency associated with retrieving such an instruction may be further reduced.</p><p>Consistent with an additional aspect of the invention, history data for use in predicting next instructions may be embedded within instructions stored in a memory. An execution unit and a prefetch circuit arrangement may then operate concurrently with one another, with the execution unit executing instructions stored in the memory concurrently with the prefetch circuit arrangement initiating retrieval from the memory of the predicted next instructions identified by the history data of such instructions.</p><p>By embedding history data within instructions, the need for a separate instruction history cache may often be avoided, thereby reducing the complexity and number of components in a circuit arrangement. Moreover, in many implementations, e.g., very long instruction word (VLIW) processors and the like, history data may often be embedded in unused portions of VLIW instructions such that the addition of history data requires no additional memory storage above and beyond that required for the instructions themselves.</p><p>These and other advantages and features, which characterize the invention, are set forth in the claims annexed hereto and forming a further part hereof. However, for a better understanding of the invention, and of the advantages and objectives attained through its use, reference should be made to the Drawings, and to the accompanying descriptive matter, in which there is described exemplary embodiments of the invention.</p><?BRFSUM description=\"Brief Summary\" end=\"tail\"?><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"lead\"?><h4>BRIEF DESCRIPTION OF THE DRAWINGS</h4><p>FIG. 1 is a block diagram of a VLIW data processing system utilizing an instruction history cache consistent with the invention.</p><p>FIG. 2 is a block diagram illustrating the interconnections between the processor, instruction history cache and L2 cache of FIG. <b>1</b>.</p><p>FIG. 3 is a block diagram of the instruction caching hierarchy for another VLIW data processing system utilizing an instruction history cache consistent with the invention, illustrating the components utilized in speculatively retrieving VLIW instructions.</p><p>FIG. 4 is a timing diagram illustrating the timing of the sequence of operations performed in during retrieval of VLIW instructions and updating of history data in the VLIW data processing system of FIGS. 3 and 5.</p><p>FIG. 5 is a block diagram of the instruction caching hierarchy of FIG. 3, illustrating the components utilized in updating the history data in the instruction history cache.</p><p>FIG. 6 is a flowchart illustrating the operations performed during an instruction fetch with the data processing system of FIGS. 3 and 5.</p><p>FIG. 7 is a block diagram of another VLIW data processing system consistent with the invention, implementing an integrated external L2/instruction history cache.</p><p>FIG. 8 is a block diagram of a bit mapping for a VLIW instruction suitable for embedding history data within the instruction in a manner consistent with the invention.</p><p>FIG. 9 is a block diagram of another VLIW data processing system consistent with the invention, illustrating the components utilized in speculatively retrieving VLIW instructions and updating history data embedded within the VLIW instructions.</p><p>FIG. 10 is a block diagram of another VLIW data processing system consistent with the invention, illustrating a multi-level cache hierarchy suitable for maintaining embedded history data in VLIW instructions when the instructions are cached in and out of various levels in the cache hierarchy.</p><p>FIG. 11 is a flowchart of the cast-out algorithm used by the L1/L2 castout controller of FIG. <b>10</b>.</p><p>FIG. 12 is a block diagram of another VLIW data processing system consistent with the invention, illustrating a history data updating mechanism with controllable offset.</p><?brief-description-of-drawings description=\"Brief Description of Drawings\" end=\"tail\"?><?DETDESC description=\"Detailed Description\" end=\"lead\"?><h4>DETAILED DESCRIPTION</h4><p>The various embodiments of the invention described herein generally operate by caching instruction history data used to speculatively fetch and execute instructions. A prefetch circuit arrangement is typically used to speculatively fetch instructions and forward such instructions to one or more execution units in a processor for execution thereby. Moreover, a prediction verification circuit arrangement is typically used to verify the predictions made based on history data, and if necessary, to terminate the execution of mis-predicted instructions.</p><p>In some implementations, the history data is cached in a separate instruction history cache. The instruction history cache may be internal or external, and the cache is used to store predicted next instructions, rather than the addresses thereof, to reduce the latency associated with retrieving such instructions.</p><p>In other implementations, history data is embedded within instructions themselves, typically in the form of an address that identifies a next instruction, or address index from which the address of the next instruction may be generated. For VLIW processors and the like, this feature often enables history data to be stored in unused portions of instructions with no additional memory storage requirements. Given that cache space is often at a premium, there is thus no adverse storage impact associated with such an implementation.</p><p>Moreover, as will become more apparent below, while the history data associated with a given instruction may be used to represent the next instruction to execute immediately subsequent to execution of that instruction, in many implementations it is beneficial to associate history data for another instruction with a given instruction, so that the history data for that instruction represents the next instruction to execute immediately subsequent to execution of the other instruction. Put another way, the history data pertaining to the next instruction to execute immediately subsequent to an instruction may be offset in memory from that instruction.</p><p>The invention is suitable for use with a wide variety of processor architectures, including very long instruction word (VLIW) processors and superscalar processors such as reduced instruction set computer (RISC) processors and complex instruction set computer (CISC) processors, etc. The discussion hereinafter will focus on the use of the invention in connection with a VLIW-based architecture; however, implementation of the various aspects and features of the invention in a non-VLIW environment will be apparent to one of ordinary skill in the art upon a reading of the material herein</p><p>In the context of the invention, a circuit arrangement is an arrangement of analog and/or digital electronic components electrically coupled with one another via conductive traces and/or wires, whether implemented wholly in one integrated circuit device or implemented in a plurality of integrated circuit devices electrically coupled with one another via one or more circuit boards. Moreover, it should be recognized that integrated circuit devices are typically designed and fabricated using one or more computer data files, referred to herein as hardware definition programs, that define the layout of the circuit arrangements on the devices. The programs are typically generated in a known manner by a design tool and are subsequently used during manufacturing to create the layout masks that define the circuit arrangements applied to a semiconductor wafer. Typically, the programs are provided in a predefined format using a hardware definition language (HDL) such as VHDL, verilog, EDIF, etc. Thus, while the invention has and hereinafter will be described in the context of circuit arrangements implemented in fully functioning integrated circuit devices, those skilled in the art will appreciate that circuit arrangements consistent with the invention are capable of being distributed as program products in a variety of forms, and that the invention applies equally regardless of the particular type of signal bearing media used to actually carry out the distribution. Examples of signal bearing media include but are not limited to recordable type media such as volatile and non-volatile memory devices, floppy disks, hard disk drives, CD-ROM's, and DVD's, among others, and transmission type media such as digital and analog communications links.</p><h4>Exemplary Data Processing System Environment</h4><p>Turning now to the Drawings, wherein like numbers denote like parts throughout the several views, FIG. 1 illustrates an exemplary data processing system <b>10</b> consistent with the invention. In general, data processing system <b>10</b> includes one or more processors <b>12</b> coupled to a memory <b>14</b> that provides instructions and data for processing by the processor. Memory <b>14</b> is typically partitioned into a number of levels to form a memory hierarchy. For example, the greatest volume of memory is typically represented by a mass storage subsystem, such as a direct access storage device (DASD) <b>16</b>, coupled to a main memory, or mainstore <b>18</b> via an input/output (I/O) subsystem <b>20</b>. Mainstore <b>18</b> is typically a relatively large bank of volatile memory, such as dynamic random access memory (DRAM). Other forms of external storage may be accessed via I/O subsystem <b>20</b>, e.g., various local and wide area networks and other communications facilities, to provide a relatively larger address space for the memory. Additional external information may be interfaced with data processing system <b>10</b> via a system to system interconnect <b>22</b>, e.g., via fiber optic or serial communication links.</p><p>Between processor <b>12</b> and mainstore <b>18</b> is provided one or more levels of cache memories, e.g., level three (L3) caches <b>24</b>, level two (L2) caches <b>26</b>, and level one (L1) caches (here partitioned into separate data and instruction caches <b>28</b>, <b>30</b>). As represented in FIG. 1, any level in a cache hierarchy may be implemented internal to processor <b>12</b> on the same integrated circuit device, as with caches <b>28</b>, <b>30</b>. In the alternative, any level in a cache hierarchy may be implemented external to processor <b>12</b> and disposed on separate integrated circuit devices, as with L2 and L3 caches <b>26</b>, <b>24</b>. Moreover, any given cache may service more than one processor, e.g., as represented by L3 caches <b>24</b>. In general, it should also be appreciated that, starting with the processor, each level in the memory hierarchy typically has a smaller storage capacity but a faster access time than the next level removed from the processor. Consequently, it is desirable to maintain frequently used data as close as possible to the processor to maximize the efficiency of the memory system.</p><p>Processor <b>12</b> in FIG. 1 represents a generic processor architecture that includes a number of components common to various types of processors. Data is principally handled via a number of register files <b>32</b>, with arithmetic operations performed thereon by one or more arithmetic logic units (ALU's) <b>34</b>. Floating point operations may also be handled by one or more floating point units (FPU's) <b>36</b>. In general, each of ALU's and FPUs <b>36</b> may be considered an execution unit, as is well known in the art.</p><p>To manipulate the data in the register files, processor <b>12</b> processes various instructions stored in L1 instruction cache (ICache) <b>30</b>, utilizing decode logic <b>38</b> and a branch unit <b>40</b>, each of which is generally understood in the art, and which will vary depending upon the particular architecture used. In the illustrated embodiment, for example, processor <b>12</b> is a very long instruction word (VLIW) processor in which each instruction includes a plurality of parcels to be executed in parallel by multiple execution units in the processor. It should be appreciated that other architectures may be supported, e.g., superscalar RISC or CISC architectures, among others. With these latter architectures, it should be appreciated that additional logic may be required between L1 ICache <b>30</b> and decode logic <b>38</b> to route appropriate instructions to the various execution units for optimum performance. Other modifications and variations will be apparent to one of ordinary skill in the art.</p><h4>Instruction History Cache Implementations</h4><p>As shown in FIG. 1, processor <b>12</b> may also be interfaced with an internal or external instruction history cache (IHC) <b>42</b> that is utilized to store history data for use in a manner consistent with the invention. IHC <b>42</b> in particular stores a plurality of VLIW instructions to be executed after other VLIW instructions. IHC <b>42</b> stores copies of VLIW instructions themselves rather than the addresses of those instructions so that additional accesses to the various levels of caches are not required to speculatively retrieve such VLIW instructions.</p><p>In the illustrated embodiment, VLIW instructions are 64-bytes in length, including sixteen 32-bit parcels. The cache line length for IHC <b>42</b> is one VLIW instruction, or 64-bytes. Typically, IHC <b>42</b> is direct-mapped, thereby eliminating the need for a directory. The IHC may be implemented internal to processor <b>12</b>, or in the alternative, may be an external cache, as best shown in FIG. <b>1</b>.</p><p>FIG. 2 illustrates in greater detail the instruction and data flow between processor <b>12</b>, L2 cache <b>26</b> and instruction history cache <b>42</b>. In this embodiment, L2 cache <b>26</b> is implemented as an external 32-MB four-way associative cache with a 1 KB, or 16 VLIW, cache line size. As such, L2 cache <b>26</b> also includes a directory identified at <b>44</b>. Instructions and data are passed between processor <b>12</b>, L2 cache <b>26</b> and instruction history cache <b>42</b> via a 64-byte wide bus <b>46</b>. L2 cache <b>26</b> and L2 directory <b>44</b> are supplied with a 44-bit real address via address lines <b>47</b>. In this implementation, the L2 cache is addressed via a real address, requiring an virtual/effective address to real address translation in processor <b>12</b>, as will become more apparent below. Due to the external nature of the L2 cache, the address translation required to access the cache, and the multi-way set associativity of the cache, the L2 cache in this implementation is assumed to have a five cycle access time. It should be appreciated that other L2 caches may have shorter or longer access times consistent with the invention.</p><p>The address supplied to L2 cache <b>26</b> is also referred to as a \u201cbranch to\u201d address, representing the actual next instruction information determined from a currently-executed VLIW instruction. It is this address, or more specifically the instruction stored at this address, that the instruction speculatively retrieved from the instruction history cache must match to verify a correct next instruction prediction. Moreover, L2 directory <b>44</b> outputs, in response to the real address supplied by lines <b>47</b>, a 24-bit directory entry indicating, among other things, whether a cache hit has occurred, and if so, which of the four sets houses the requested cache line.</p><p>Instruction history cache <b>42</b> is driven by IHC address lines <b>48</b>, provided with an 17-bit instruction address register (IAR) index that is used to address the cache. Instruction history cache <b>42</b> in this implementation is implemented as an 8-MB direct-mapped cache. Consequently, no separate directory is required, which typically reduces the access time for the instruction history cache relative to the directory-based L2 cache. It is assumed for this implementation that the access time of IHC <b>42</b> is three cycles, versus the five cycle access time for L2 cache <b>26</b>.</p><p>The IHC address provided to instruction history cache <b>42</b> represents a \u201cbranch from\u201d address, as it is the address of a current instruction being executed that is used to retrieve a predicted next instruction.</p><p>The L1 ICache <b>30</b> in processor <b>12</b> is implemented as a 64-KB direct-mapped cache. In the illustrated implementation, L1 ICache <b>30</b> has a 1-KB (or 16 VLIW) cache line size, and an access time of one cycle.</p><p>It should be appreciated that alternate overall and/or cache line sizes may be utilized for each of caches <b>26</b>, <b>30</b> and <b>42</b>, and that other associativities may be used for each of these caches. Therefore, the invention should not be limited to the particular implementation disclosed herein.</p><p>FIG. 3 illustrates another data processing system <b>50</b>, utilizing a processor <b>52</b>, L2 cache <b>54</b>, instruction history cache <b>56</b> and L1 ICache <b>58</b> that are configured in substantially the same manner as data processor system <b>10</b> of FIGS. 1 and 2. As noted in FIG. 3, L2 cache <b>54</b> has a 5 cycle access time, and instruction history cache <b>56</b> has a 3 cycle access time.</p><p>To ensure that the predicted next instruction for a given instruction will be available from the IHC without stalling the processor, data processing system <b>50</b> is configured to offset the history data for a given instruction by two instructions to account for the three cycle access time of the IHC. That is, assuming VLIW instructions N\u22122, N\u22121, N, N+1, N+2 and N+3 were previously executed in sequence and the history data therefor stored in IHC <b>56</b>, the history data for VLIW instruction N is associated with VLIW instruction N\u22122, the history data for VLIW instruction N+1 is associated with VLIW instruction N\u22121, etc. In short, the history data associated with a given VLIW instruction is the predicted next-next-next instruction to execute after that given instruction.</p><p>This association is handled in the illustrated implementation by storing the history data for a given instruction\u2014that is, the predicted next instruction to execute after that given instruction\u2014using the address of the instruction executed two cycles earlier as an index into the instruction history cache. Then, when the address of the instruction last executed two cycles earlier is used to retrieve that earlier instruction from either the L1 ICache or L2 cache, that address is simultaneously provided to the IHC to initiate the retrieval of the predicted next instruction for the latter instruction. With the additional two cycles required to fetch from the IHC, therefore, the predicted next instruction will be returned from the IHC at the appropriate time.</p><p>Put another way, for a given VLIW instruction N, the predicted next instruction therefor, VLIW N+1, is stored in the IHC using the address of VLIW N\u22122. Then, when an attempt is made to retrieve VLIW N\u22122 from either the L1 ICache or the L2 cache, the address of VLIW N\u22122 is provided simultaneously to the IHC to begin retrieval of VLIW N+1 therefrom. Assuming in the next two cycles VLIW N\u22121 and VLIW N are fetched in sequence, on the next cycle the IHC makes VLIW N+1 available just in time to be executed immediately after VLIW N. Consequently, even if the L1 ICache misses on VLIW N+1, the instruction is still available from the IHC, without the delay that would otherwise be required to fetch the instruction from the L2 cache. Moreover, given the offset in which the history data is stored in the IHC, the extra two cycles that would otherwise be required to retrieve the predicted next instruction from the IHC are avoided by in effect starting the IHC access two cycles early.</p><p>To generalize this relationship, in the illustrated embodiment it is typically desirable to offset the history data for a given instruction by x\u22121 additional cycles, where x is the access time of the IHC. Put another way, it is desirable to store as the history data for a given instruction the predicted instruction to execute x cycles in the future.</p><p>Thus, in this implementation, instruction history cache <b>56</b> is indexed by the address of the instruction currently being fetched as the next instruction to execute, represented by instruction address register (IAR) <b>59</b>. The address specified in IAR <b>59</b> is also simultaneously supplied to L1 ICache <b>58</b>, as well as to L2 cache <b>54</b> via a translation lookaside buffer (TLB) <b>90</b> that converts the virtual address stored in IAR <b>59</b> into a real address for use in accessing the L2 cache. It should be appreciated that, should virtual addressing not be used, a TLB or other translation mechanism may not be required between processor <b>52</b> and L2 cache <b>54</b>.</p><p>Typically, an index, rather than the entire instruction address register, is provided to IHC <b>56</b> given that only a subset of the addressable memory space is stored in the caches. For an 8-MB instruction history cache, a 17-bit index may be used from the current address, e.g. bits 41-57 of a 64-bit address. No directory is required, however, for instruction history cache <b>56</b> since verification of a correct instruction prediction is made via the prediction verification circuit arrangement described hereinafter.</p><p>Similarly, for L1 ICache <b>58</b>, a 10-bit address index may be provided from IAR <b>59</b> to index the cache. It should be appreciated that L1 cache <b>58</b> also includes a directory (not shown) to verify whether or not an L1 cache hit has occurred. The use and configuration of such a directory is well known in the art, and thus, need not be described further herein.</p><p>IAR <b>59</b> forms the first stage of an execution pipe <b>60</b> that represents one or more execution units in processor <b>52</b>. For a VLIW processor, for example, multiple execution units typically operate in parallel to separately handle the various parcels in each VLIW instruction. Each execution unit typically has one or more separate pipes; however, from a functional standpoint, the pipes for such multiple execution units may be considered to be a single pipe as represented in FIG. <b>3</b>. Consequently, it should be appreciated that any number of execution pipes and/or units may be utilized in a data processing system consistent with the invention, and an implementation of such other pipes and units would be within ability of one of ordinary skill in the art having the benefit of the material disclosed herein.</p><p>Each stage of pipe <b>60</b> includes storage for an instruction address, as well as a VLIW instruction specified by that address. Pipe <b>60</b> is a six-stage pipeline, with the instruction addresses for stages two to six of the pipe stored respectively in instruction address registers <b>62</b>, <b>64</b>, <b>66</b>, <b>68</b> and <b>70</b>, and with the instructions specified by such addresses stored respectively in instruction registers (IREG's) <b>74</b>, <b>76</b>, <b>78</b>, <b>80</b> and <b>82</b>. No separate IREG is utilized for the first stage of the pipe, since the first stage is an instruction fetch into the second stage IREG. An alternate suitable description of pipe <b>60</b> is that the pipe is a five-stage pipe, with IAR <b>62</b> and IREG <b>74</b> forming the first stage of the pipe, and with IAR <b>59</b> being excluded from the pipe.</p><p>The various stages of the pipe are also identified as being relative to a current instruction N, with an instruction N\u2212x representing an instruction being processed x cycles in advance of the current instruction, and with an instruction N+y representing an instruction being processed y cycles after the current instruction.</p><p>Stage one of the pipe is an instruction fetch stage (IFETCH) during which an instruction is fetched from memory (typically the L1 ICache or L2 cache). Stage two of the pipe is a general purpose register file read access stage (GPR). Stage three of the pipe is an effective address generation stage (AGEN). Stage four of the pipe is an L1 data cache (DCache) access stage (DCACHE), and stage five is a data format of data bus stage (DATABUS). Stage six in the pipe is the general purpose register file write access stage (GPR WRT), in which the results of the instruction execution are written back to the general purpose register file, or in general to any other architected register bits. The operations performed during these stages are well known processor operations and are not relevant to an understanding of the invention. Thus, no further discussion of these stages is provided herein.</p><p>Furthermore, additional stages, numbers of stages and arrangements of stages may be utilized in other implementations consistent with the invention. For example, for a superscalar processor, the execution pipe may also include a branch address generation stage prior to IFETCH. A VLIW-based architecture, on the other hand, typically does not require a branch address generation stage since the instructions are aligned within the instruction caches and no ordering of instructions need be performed prior to executing the instruction.</p><p>A prefetch circuit arrangement <b>85</b> is used to initiate retrieval of predicted and actual next instructions respectively from instruction history cache <b>56</b> and L2 cache <b>54</b>. Retrieval of an instruction to execute three cycles in the future, also referred to as the predicted next-next-next instruction, is performed via line <b>85</b><i>a</i>, based upon the address index from IAR <b>59</b>. Retrieval of the actual next instruction from the L2 cache is performed via a line <b>85</b><i>b</i>, based upon the \u201cbranch to\u201d address specified in the instruction stored in IREG <b>74</b> in stage two of the pipe. The branch to address on line <b>85</b><i>b </i>is converted into a real address by TLB <b>90</b> to access the L2 cache. For example, as represented by an instruction <b>86</b> stored in register <b>74</b>, the branch to address is typically specified in a branch conditional (BC) parcel <b>88</b> in the instruction.</p><p>Once an instruction fetch is issued to the L2 cache and instruction history cache, each cache will, in time, output the instruction stored at the address provided thereto. For L2 cache <b>54</b>, the output instruction is the actual next instruction, represented as \u201cVLIW\u201d. For instruction history cache <b>56</b>, the instruction output is a predicted next instruction, represented at \u201cVLIW'\u201d. A prediction verification circuit arrangement <b>91</b> recieves VLIW and VLIW'. Moreover, VLIW\u2032 is provided directly to second stage IREG <b>74</b> to begin execution of the predicted next instruction.</p><p>Prediction verification circuit arrangement <b>91</b> includes a compare block <b>92</b> that determines whether VLIW output from L2 cache <b>54</b> matches VLIW\u2032 output from instruction history cache <b>56</b>. Since instruction history cache <b>56</b> has a 3-cycle access time and L2 cache <b>54</b> has a 5-cycle access time, VLIW\u2032 will be output to circuit arrangement <b>91</b> two cycles prior to VLIW. Thus, to align VLIW\u2032 with VLIW, a 2-stage buffer, including instruction buffer registers <b>94</b>, <b>96</b>, is interposed between instruction history cache <b>56</b> and compare block <b>92</b>. It should be appreciated that any number of stages may need to be inserted between instruction history cache <b>56</b> and compare block <b>92</b> depending upon difference in access times between caches <b>54</b>, <b>56</b>.</p><p>Compare block <b>92</b> is enabled by an AND gate <b>93</b> that receives an L1 miss signal and an L2 hit signal respectively from the directories for L1 ICache <b>58</b> and L2 cache <b>54</b>. When enabled, compare block <b>92</b> outputs an inhibit signal IHC/L2 COMP that is asserted whenever VLIW\u2032 does not match VLIW. As a result of this inhibit signal, VLIW', which at this point is stored in stage six IREG <b>82</b> of execution pipe <b>60</b>, is \u201ckilled\u201d so that the results of the execution of this instruction are effectively discarded.</p><p>In the illustrated implementation, discarding of the results of VLIW\u2032 is performed by marking the instruction invalid to inhibit performance of the GPR WRT operation at stage six of the execution pipe, since a write back to the general purpose register file or any other architected register bits is typically the last operation performed as a result of execution of an instruction. This technique is typically used by conventional processors in other circumstances to effectively kill or stall instructions in a pipe, and as such is well known in the art. In other implementations, it may be desirable to terminate execution of VLIW\u2032 in other manners. For example, rather than simply invalidating the instruction, it may be desirable to allow the instruction to proceed through completion, and then \u201cundo\u201d the result by restoring the general purpose register file with a backup copy representing the states of the registers prior to execution of the instruction.</p><p>It may also be desirable to couple the output of L2 cache <b>54</b> to the state machine for the execution pipe and the instruction buffers (not shown) such that the pipe will stall until VLIW is retuned from L2 cache <b>54</b>. The purpose of this pipe stall is to account for an instruction fetch that also misses on the L2 cache, since such a miss would require an access to the L3 cache and/or mainstore, necessitating an access time greater than five cycles.</p><p>FIG. 4 illustrates the relative timing of operations illustrated in FIG. <b>3</b>. First, the execution pipe, including the IFETCH, GPR, AGEN, DCACHE, DATABUS and GPR WRT status is shown. The instruction history cache access for the next instruction for the instruction to be executed two cycles in the future, is illustrated as occurring in parallel with the execution pipe, occupying three access cycles, followed by the two buffer stages in the prediction verification circuit <b>91</b>. Also concurrently shown is an L2 cache access, including 2 cycles required to access the cache, followed by the 3 array cycles within which the cache processes and outputs the result. An access to the L2 directory is also shown occurring in parallel with the L2 cache access. It is to be noted that the L2 directory indicates an L2 hit or miss prior to next instruction by the L2 cache. The compare enable signal, generated from an L2 hit is used to selectively stall the pipes until the L2 fetch is complete upon occurrence of an L1 miss. The compare block is illustrated as operating on half cycles therefrom, with the inhibit signal, denoted IHC/L2 COMP, output one-half cycle after the compare enable signal is asserted. Accordingly, upon reaching the GPR WRT stage of the execution pipe, an inhibit signal is available to either permit or inhibit the write back of results to the GPR file. If an inhibit is indicated, the GPR WRT operation is bypassed, and the result of the instruction is effectively discarded.</p><p>FIG. 5 illustrates the components involved in the write back of history data into instruction history cache <b>56</b> for the purpose of dynamically updating the history data therein. L2 cache <b>54</b>, which is not relevant to this updating operation, has been omitted from the figure for simplicity.</p><p>To store information back into instruction history cache <b>56</b>, a separate write access port is provided in the instruction history cache. The use and configuration of separate read and write access ports into a cache are well known in the art. The desired offset for storing the actual next instruction data for a given instruction is provided by taking the instruction to write into the instruction history cache, and the address or index at which to write that instruction, from separate stages of the execution pipe. For the illustrated implementation, a two stage differential is used, with the instruction stored in second stage IREG <b>74</b> of the execution pipe stored in the IHC at the location specified by the fourth stage IAR <b>66</b>. The first stage differential accounts for the desire to store the actual next instruction for a given instruction, and the second stage differential accounts for the desired 1-cycle offset of history data in the IHC from that given instruction. In other words, the two stage differential effectively stores the actual next-next-next instruction in the location in the IHC associated with a given instruction.</p><p>It should be appreciated that the desired offset may also be achieved by taking the address and instruction from different stages in execution pipe <b>60</b>, e.g., stages three and five, or stages four and six, etc. Moreover, for different offsets, it should be appreciated that the outputs of different registers may be used in the alternative.</p><p>Returning to FIG. 4, the relative timing of the writeback operation is illustrated in greater detail. Specifically, at the fourth (DCACHE), the value of IAR register <b>66</b>, representing the address of VLIW N+1, is provided as the write address to the L1 ICache and IHC, while the value of IREG <b>74</b> at the second stage, representing VLIW N+3, is provided as the data to write into the L1 ICache and IHC. Then, in the next cycle, if the L2 directory hits, the L1 ICache and IHC are written to using the aforementioned address and data, thereby updating the history data to reflect the actual next instruction executed.</p><p>FIG. 6 illustrates an instruction fetch operation <b>120</b> performed by data processing system <b>50</b>, illustrating the different program flows that occur based upon whether an instruction fetch hits in the L1 ICache, the L2 cache or the IHC. First, in block <b>122</b>, the contents of VLIW N+4 stored in IAR <b>59</b> (FIG. 3) are forwarded simultaneously to the L1 ICache, the L2 cache and the IHC. Next, in block <b>124</b> (and typically in less than one cycle), the L1 ICache directory returns a hit/miss indication. If a hit has occurred, normal execution occurs as shown in block <b>126</b>, with the instruction fetch satisfied by the L1 ICache in the next cycle. Also, at this time, it may be desirable to update the IHC at this time, or in the alternative, it may be desirable to check the history data in the IHC for a change, and update the IHC only if a change has occurred, to minimize traffic to the IHC.</p><p>If a cache miss occurs in the L1 ICache, flow progresses to block <b>128</b>, where the predicted VLIW output from the IHC the next cycle is fed into the pipe for execution. It should be noted that the access to the IHC to retrieve the predicted VLIW would have been instituted two cycles earlier, i.e., during the dispatch of the address for VLIW N+2 at block <b>122</b>.</p><p>Execution of the predicted VLIW then progresses through the pipe one or more cycles until an indication of an L2 hit/miss is returned from the directory of the L2 cache, represented at block <b>130</b>. If a miss has occurred, the operations performed in block <b>132</b> are performed, given that the predicted VLIW is not correct since the actual requested instruction was not found in the L2 cache. In particular, the pipes are stalled, and the VLIW in stage two of the pipe (shown as VLIW N+3 stored in IREG <b>74</b> of FIG. 3) is killed, in any number of manners known in the art. A mainstore access is also initiated to retrieve the requested instruction from a higher level in the memory hierarchy, and once the requested instruction is returned, the L2 cache is updated, the correct VLIW is dispatched to the pipe, the IHC is updated, the L1 ICache is updated, and the pipes are restored. Restoration of the pipes may require only that clocking of the pipes be reinitiated, or in some circumstances, the pipes may need to be restored to a prior state should the pipes have progressed beyond a desirable point.</p><p>Returning to block <b>130</b>, if the L2 hit on the instruction fetch, it is next determined in block <b>134</b> whether the L2 MRU prediction was correct. Block <b>134</b>, which is only performed for associative caches, may be omitted for direct-mapped L2 caches. If the MRU prediction is not correct, the operations performed in block <b>136</b> are performed. In particular, the pipes are stalled, and the VLIW in stage two of the pipe (shown as VLIW N+3 stored in IREG <b>74</b> of FIG. 3) is killed, in any number of manners known in the art. The correct VLIW is fetched from the L2 cache based upon the directory lookup, the correct VLIW is sent to the pipes, and the IHC is updated. The L1 ICache and L2 MRU array are also updated, and the pipes are restored in any of the manners discussed above.</p><p>Returning to block <b>134</b>, if the MRU prediction was correct, block <b>138</b> next determines whether the IHC prediction was correct (i.e., via compare block <b>92</b> of FIG. <b>3</b>). If so, execution can continue without any stalls, with the L1 ICache updated in time by the L2 cache, as shown in block <b>140</b>. If, however, the prediction is not correct, the mispredicted VLIW in stage two of the pipe is killed in block <b>142</b> in the manner discussed above. Next, in block <b>144</b>, the VLIW fetched from the L2 cache is dispatched to the pipe, with the IHC and L1 updated in the manner discussed above.</p><p>FIG. 7 illustrates another data processing system <b>150</b> showing a multi-chip integrated L2/instruction history cache implementation. Data processing system <b>150</b> includes a processor <b>152</b> within which is disposed an L1 ICache <b>154</b> and at least one execution pipe <b>156</b>. An integrated L2/instruction history cache <b>158</b> is coupled to processor <b>152</b> via a instruction/data bus <b>160</b>. Cache <b>158</b> is implemented using a plurality of memory chips, e.g., chips <b>162</b>, <b>164</b>, <b>166</b>, <b>168</b>, <b>170</b>, <b>172</b>, <b>174</b> and <b>176</b>. Each memory chip is logically partitioned into an L2 cache partition and an instruction history cache partition, e.g., partitions <b>178</b>, <b>180</b> for chip <b>176</b>. Separate access ports are provided for each of the partitions, with an access port for the L2 cache coupled to address lines <b>182</b> from processor <b>152</b>, which provide a real address for accessing the L2 cache. Lines <b>182</b> are also provided to an L2 directory chip <b>184</b> that returns a directory entry providing an L2 hit signal to indicate whether or not the access request from the processor hit in the L2 cache.</p><p>A separate port controls the instruction history cache, and is controlled via address lines <b>186</b> from processor <b>152</b>. Instruction history cache, as with data processing system <b>10</b> above, receives an instruction address register index value to access the cache.</p><p>Cache <b>58</b> may be implemented, for example, using eight 1-MB SRAM or DRAM memory devices, with each providing eight bytes, or one-eighth, of a 64-byte VLIW over bus <b>160</b>. Assuming a four-way associative implementation, each set is partitioned \u00bc-MB, with the most recently used partition also functioning as the instruction history cache. The IHC partition may also be exclusive of the L2 cache, although by allowing one partition to function as both the IHC and the L2 cache, no additional memory is required to implement the IHC. Various alternative cache sizes, partition sizes and/or numbers of chips may be utilized in the alternative.</p><p>By implementing an L2 cache and an instruction history cache using a common set of integrated circuit devices, or chips, one advantage that may be obtained thereby is that much of the processing circuitry required to perform the prediction verification function may be shifted from the processor to the chips that implement the cache. For example, a prediction verification circuit arrangement may include a plurality of partial compare blocks, with each disposed in one of the chips, e.g., block <b>188</b> for chip <b>176</b>. Within each compare block, an 8-byte portion of a predicted next instruction output from the instruction history partition is compared with an 8-byte portion of the actual next instruction output from the L2 partition, with an 8-byte compare block <b>190</b> used to compare each of the bits in the 8-byte portions output by the L2 and instruction history partitions. Assuming the same difference in access times as discussed above, a pair of instruction buffers <b>192</b>, <b>194</b> may be required to align the predicted and actual next instruction portions. Compare block <b>190</b> then outputs a partial IHC/L2 COMP signal that indicates whether the 8-byte portions of the predicted and actual next instructions match. Each partial compare block then outputs a partial compare signal, which is logically AND'ed with the other partial compare signals in an AND block <b>196</b> in processor <b>152</b> that operates as a master compare block. The output of block <b>196</b> forms the overall IHC/L2 COMP inhibit signal used to selectively inhibit or terminate a mis-predicted instruction.</p><p>It should be appreciated that in other implementations, various functions in the prefetch and prediction verification circuit arrangements may be allocated to different integrated circuit devices within the system. Therefore, the invention should not be limited to the specific implementations discussed herein.</p><h4>Embedded Instruction History Implementations</h4><p>In certain embodiments of the invention, it may be desirable to eliminate the use of a separate instruction history cache altogether, thereby simplifying the design of the instruction fetching mechanism of a processor. In particular, it has been found that in many implementations it is possible to embed history data within instructions themselves, typically within unused bits within the instructions to minimize any expansion of program code due to the addition of history data. This has the effect of the L2 cache incorporating the functionality of an instruction history cache.</p><p>VLIW-based architectures are particularly well suited for embedding history data within VLIW instructions given that a large majority of VLIW instructions incorporate some unused space. So long as certain rules are adhered to by a VLIW compiler, it has been found that it is possible to embed history data with little or no effect on the storage requirements for a VLIW program.</p><p>Typically, the history data representing a next instruction to execute subsequent to one of the VLIW instructions stored in a memory is represented by an identifier from which the address of such an instruction may be obtained. The full address of a next instruction is typically not required; however, given that only the amount of bits necessary to address the L2 cache are typically necessary to obtain the history data since if a miss on the L2 cache occurs, the next instruction will need to be retrieved from main storage, and the invalidity of any predicted instruction address will be moot.</p><p>For example, for a 4-MB L2 cache implemented in system having a 64-bit addressing scheme, no more than a 22-bit address index is typically required to address any given byte within the cache. Furthermore, with a 64-byte cache line and instruction size, and with cache lines and instructions properly aligned, the 6 least significant bits (LSB's) of the 22-bit address index are known to be 0, and thus only 16 bits are required to access any given cache line in a 4-MB L2 cache.</p><p>One manner in which the address index may be stored within an instruction is to leave a certain number of bits unused and reserved for history data. For example, for a VLIW instruction, such an instruction typically includes a plurality of parcels that are intended to be executed in parallel with one another by various execution units. VLIW compilers typically assemble VLIW instructions by placing as many parcels as possible in the available slots of an instruction. To ensure adequate free space is allocated for history data in an instruction, therefore, a compiler could be directed to reserve one slot of an instruction for history data.</p><p>Despite the fact that a majority of VLIW instructions are never completely filled, leaving one slot of a VLIW instruction always blank will have an adverse impact on processor performance for those instructions that could have been filled with additional parcels but for the addition of the history data to the instruction. However, by implementing an additional compiler rule, a certain amount of free space may be left in a VLIW instruction with relatively less impact on processor performance.</p><p>Specifically, it may be desirable to direct a VLIW compiler to assemble into any given VLIW instruction only branch instructions having a branch to address in the same cache line. Then, for any such VLIW instruction having more than branch parcel, the branch to address fields of multiple branch instructions become redundant, and one of such fields may be utilized to store history data with little or no impact on the overall density of parcels within instructions. It is believed that this rule would have little impact on compiler performance since a large majority of VLIW instructions tend to have multiple branch parcels anyway.</p><p>For example, an instruction format for a VLIW processor architecture may incorporate 32-bit parcels implementing 32-bit PowerPC-compatible instructions. Consistent with the PowerPC architecture, 16-bits of any branch instructions are assigned to a branch address field from which the address to branch to in response to meeting a predetermined condition is generated. Assuming 64-bit addressing, all branch instructions may be required to branch within a 1-MB address space, with the 64-bit branch to address generated using the 42 most significant bits (MSB's) of the instruction address register concatenated with the 16-bit branch address field, and followed by six zeros (given a 64-byte instruction size).</p><p>Assuming the addressing scheme defined above, a VLIW compiler may be created that allocates a fixed number of bits in any instruction to history data with minimal program code expansion. For example, a compiler may be configured to allocate the 16 LSB's of any instruction to history data by adhering to the following rules when assembling parcels into a VLIW instruction:</p><p>I. If the VLIW instruction is not full, insert a NOOP operation in the last slot of the instruction.</p><p>II. If the VLIW instruction is full, and at least one parcel is a NOOP operation, place the NOOP operation in the last slot of the instruction.</p><p>III. If the VLIW instruction is full with non-NOOP operations, and two or more branch parcels exist in the instruction, place one of the branch parcels in the last slot of the instruction (and optionally place all other branch parcels near the end of the instruction but before the last slot so the common branch address for all branch parcels is always located in the same slot).</p><p>IV. If the VLIW instruction is full with non-NOOP operations, but fewer than two branch parcels exist in the instruction, attempt to trade parcels with nearby instructions to add additional branch or NOOP parcels to the instruction.</p><p>V. If the VLIW instruction is full with non-NOOP operations and fewer than two branch parcels, but no parcels could be swapped into the instruction, insert a NOOP parcel in the last slot of the instruction and move one parcel to a next instruction.</p><p>Based upon the fact that over 75% of most VLIW instructions are not completely full, and of the remaining instructions, all but about 10% include more than one branch parcel, it is anticipated that the above rules will tend to expand most VLIW program code less than about 1%.</p><p>In other implementations, other manners of locating unused space in a VLIW instruction may be used. For example, in some implementations, some pre-decoding is done on VLIW instructions to expand parcels into relatively larger codes. In some implementations, for a 64-byte VLIW instruction with sixteen 32-bit parcels, the parcels may be expanded into 64-bit codes containing additional bits needed by the execution units. Furthermore, it has been found that in many circumstances, branch instructions, among others, always expand to less than 48 bits. Thus, even if a VLIW instruction is full of parcels and does not meet any of Rules I-IV above, in many circumstances history data may be embedded into unused portions thereof after the parcels are expanded into codes. Thus, history data may be maintained within any level of the memory hierarchy that stores expanded code, e.g., an L2 cache if the predecoder is disposed between the L2 cache and mainstore. In such an instance, typically the L2 cache lines and VLIW instructions are expanded into 128-bytes, such that at least in the L2 cache suitable unused space exists for storing history data. Other manners of locating unused space may be used in the alternative, e.g. utilizing unused bits in operand instructions or mask fields, etc.</p><p>FIG. 8 illustrates a 64-byte VLIW instruction <b>200</b> including sixteen 32-bit parcels. Instruction <b>200</b> is shown having multiple branch parcels, and consistent with the above Rules, the last two slots (for parcels <b>14</b> and <b>15</b>) are filled with such branch parcels. Parcels <b>14</b> and <b>15</b> are illustrated in greater detail at <b>202</b> and <b>204</b>, with each parcel shown following the general PowerPC instruction format with the first 6 bits of each parcel assigned to an operation field (e.g., field <b>206</b> for parcel <b>202</b>) and the next two sets of 5 bits assigned to bit in (BI) and bit out (BO) fields (e.g., fields <b>208</b>, <b>210</b> for parcel <b>202</b>). As parcels <b>14</b> and <b>15</b> are branch parcels, the remaining <b>16</b> bits of each parcel are assigned to the branch address field (e.g., field <b>212</b> for parcel <b>202</b>). Given, however, that the branch address field is redundant within a given VLIW instruction that requires all branch instructions to branch to the same cache line, the branch to address field <b>214</b> of parcel <b>204</b> is available for storing history data therein.</p><p>In the alternative, parcel <b>15</b> may be a NOOP parcel <b>216</b>, having a NOOP operation field <b>218</b>, and an unused field <b>219</b> within which the same history data may be stored for the VLIW instruction. It should be appreciated that a wide variety of alternate bit-mappings may be utilized in the alternative.</p><p>FIG. 9 illustrates another data processing system <b>220</b> configured to store and maintain history data within given VLIW instructions formatted in the manner described above. It should be appreciated that the remainder of the components in system <b>220</b> may be configured and arranged similar to data processing system <b>10</b> of FIG. 1, with the exception of a separate instruction history cache <b>42</b>. Returning to FIG. 9, system <b>220</b> includes a processor <b>221</b> having an execution pipe <b>222</b> comprising six stages. Instruction address information is maintained in a sequence of address registers (IAR's) <b>250</b>, <b>224</b>, <b>226</b>, <b>228</b>, <b>230</b> and <b>232</b> respectively disposed in the six stages of the pipe. In addition, VLIW instructions for stages two to six of the pipe are stored in instruction registers (IREG's) <b>236</b>, <b>238</b>, <b>240</b>, <b>242</b> and <b>244</b>. An L1 ICache <b>248</b> is illustrated with a 64-byte cache line size, which is accessed via an instruction address stored in IAR <b>250</b>. Shown within L1 ICache <b>248</b> is a VLIW instruction <b>252</b> which meets the compiler rules defined above, specifically with a next-to-last slot filled with a branch parcel <b>254</b> having a branch to address field <b>256</b> defined therein, and a last slot filled with a branch or NOOP parcel <b>258</b> having a history address index (HAX) field <b>260</b> within which is stored the history data to associate with the instruction.</p><p>In this implementation, a compare block <b>262</b> is utilized to compare the actual next instruction, represented by the branch to address field of the instruction stored in IREG <b>236</b>, with the predicted next instruction offset by two cycles, represented by the output of IAR <b>228</b> (specifically, bits 42-57 thereof, corresponding to the same 16 bits in the branch to address field).</p><p>Also, as illustrated by IREG <b>236</b>, the history address index field thereof is used to access L2 cache <b>264</b> each cycle to retrieve the predicted next instruction for the instruction to be executed two cycles in the future. To this extent, L2 cache <b>264</b> is configured to have a three cycle access time for history-based accesses. This may be implemented, for example, by utilizing a separate history read access port in the L2 cache that bypasses any virtual to real address translation and any directory access, thereby essentially configuring the L2 cache through this port as a direct-mapped cache that operates in substantially the same manner as an instruction history cache. By storing all VLIW instructions for a given program within a contiguous block in memory, for example, translation may often be avoided to a history access since the bits within a given block will not change due to translation (e.g., if a program was maintained within a contiguous and aligned 16-MB block, the 24 LSB's would typically not change as a result of translation). Also, the MRU prediction for the L2 cache would be used to select the correct set to retrieve in response to the history access without having to access the directory. The use and configuration of a multiple address input L2 cache to implement the functionality described above is within the ability of one of ordinary skill in the art, and thus need not be discussed in greater detail herein.</p><p>To update new history address information into the VLIW instructions, the branch to address field of the instruction stored in IREG <b>236</b> and the address stored in IAR <b>228</b> for the VLIW instruction two cycles previous are respectively provided as the data and address for writing into L1 ICache <b>248</b>. By storing the actual branch instruction with the VLIW instruction address two cycles previous, the history data is updated with the actual next instruction for the VLIW stored in instruction register <b>236</b>. Consequently, in this implementation, the embedding of history data within VLIW instructions significantly simplifies the processor architecture, performing the same function as a separate instruction history cache while eliminating the need for such a cache altogether.</p><p>It will be appreciated that the implementation of the compiler rules discussed above in a VLIW compiler is well within the abilities of one of ordinary skill in the compiler art based upon a reading of the material herein. It should further be appreciated that other sets of compiler rules, as well as other arrangements and mappings of VLIW instructions may be used to embed history data within instructions consistent with the invention. Moreover, it will be appreciated that the implementation of such variations consistent the other embodiments described herein, will also be apparent to one of ordinary skill in the art.</p><p>For the implementation of FIG. 9, it is believed that in many instances it would be desirable to maintain the history data stored in L1 ICache <b>248</b> in other levels of the memory hierarchy, given that in many instances the instructions stored in an L1 ICache are often cached out relatively quickly, thus limiting the temporal persistence of the history data stored therein. Thus, it may be desirable to maintain the history data associated with a VLIW instruction by copying the instruction with its associated history data into other levels of the memory hierarchy. Typically, the instruction caching hierarchy in many processor implementations merely discards instructions being cached out of a given level of cache, since the instructions typically not modified in lower level caches, and thus coherency between caches is not a concern. Thus, to permit history data to be maintained in multiple levels of cache, it is only necessary to modify an instruction caching mechanism to copy instructions back into higher level caches as they are cached out of a given cache, similar in many respects to the handling of data in a multi-level data caching hierarchy.</p><p>One drawback to this approach, however, is that the number of accesses to the higher level caches increases as instructions are written back into such caches, thereby decreasing the overall performance of the caches. To alleviate this concern, it may be desirable to only copy information back to a higher level cache whenever the history data for an instruction has changed.</p><p>For example, FIG. 10 illustrates a data processing system <b>270</b> which implements a change bit associated with each instruction stored in a cache to reduce frequency at which VLIW instructions being cast out by a given cache are written back into a higher level of the memory. The change bit is used to determine whether, when a given instruction is being cast out of a given cache, that instruction should be written back into the higher level cache to maintain the history data associated therewith. This scheme is in many respects similar to the use of \u201cdirty\u201d bits on data caches and the like.</p><p>Data processing system <b>270</b> includes a processor <b>272</b> coupled to an L2 cache <b>274</b> (here implemented as an instruction cache) and L3 cache <b>276</b>. Processor <b>272</b> includes an execution pipe <b>278</b>, of which only the first four stages are shown. It is assumed that the remaining two stages are similarly configured to the pipes in the other embodiments disclosed herein. Pipeline <b>278</b> therefore includes at least four instruction address registers <b>294</b>, <b>280</b>, <b>282</b> and <b>284</b> corresponding to the first four stages of the pipe, and instruction registers <b>286</b>, <b>288</b> and <b>290</b> corresponding to stages two to four of the pipe.</p><p>A level one ICache <b>292</b> is illustrated, with instructions fetched therefrom based upon an address provided by instruction address register <b>294</b>. Within ICache <b>292</b> are disposed a plurality of instructions, e.g., instruction <b>296</b>, including two branch parcels <b>298</b>, <b>302</b>, with branch parcel <b>298</b> including a branch to address field <b>300</b>, and parcel <b>302</b> including a history address index field <b>304</b>. Also shown in processor <b>272</b> is the directory <b>306</b> for L1 ICache <b>292</b>, including a plurality of directory entries, e.g., entry <b>308</b> corresponding to instruction <b>296</b>. L1 instruction directory <b>306</b> is configured in the same manner as a conventional instruction cache directory, with the exception that the directory also includes an additional field <b>310</b> of change bits, e.g. change bit <b>312</b> for directory entry <b>308</b>.</p><p>The prefetching and prediction verification operations performed in data processing system <b>270</b> are identical to system <b>220</b> of FIG. <b>9</b>. The history data is also updated in the same manner as discussed above with respect to FIG. 9, namely, the address stored in the previous previous instruction <b>284</b> is used to index the L1 ICache, with the address of the actual next instruction to store in the L1 ICache retrieved from the branch to address field of the instruction in IREG <b>286</b>.</p><p>Additionally, a compare is performed in block <b>313</b> between the actual next instruction and the predicted next instruction stored in the instruction in IREG <b>290</b> to determine whether the history information has changed. If so, the change bit for the corresponding directory entry for the VLIW instruction is set to indicate that the history data has been updated since the instruction was cached into the L1 ICache.</p><p>To maintain coherency between the various levels of caches, e.g., between the L1 and L2 caches, a castout controller <b>314</b> is utilized in processor <b>272</b>. The basic operation of controller <b>314</b> is illustrated at <b>320</b> in FIG. <b>11</b>. Controller <b>314</b> generally operates in the same manner as a castout controller for a data cache to determine whether or not information from a particular cache must be stored in a higher level cache when it is being removed from a lower level cache.</p><p>Controller <b>314</b> principally operates by snooping all L1 instruction accesses in block <b>322</b> and determining whether any such accesses result in an L1 miss (block <b>324</b>). Whenever an L1 miss occurs, it is determined in block <b>326</b> whether the change bit of the least recently used (LRU) cache line is set. If the change bit is set, control passes to block <b>328</b> to update the history data for the copy of the LRU VLIW instruction in the L2 cache, and the change bit in the directory entry for directory <b>316</b> of L2 cache <b>274</b> (FIG. 2) is updated as well to indicate that the L2 cache now includes an updated copy of the VLIW instruction. These operations are represented in FIG. 10 by the arrows labeled <b>1</b>A and <b>1</b>B, respectively.</p><p>Once the VLIW instruction and directory information in the L2 cache have been updated, control passes to block <b>330</b> to reload the least recently used cache line in the L1 ICache with the new VLIW information and directory entry therefor from the L2 cache (including the change bit). These operations are represented in FIG. 10 by the arrows <b>2</b>A and <b>2</b>B.</p><p>Returning to block <b>326</b>, if the change bit of the least recently used cache line in the L1 cache is not set, block <b>328</b> is by-passed, and the information therein discarded as a result of the reload operation performed in block <b>330</b>.</p><p>Returning to FIG. 10, it should be appreciated that, so long as the history data has not been updated, the write back operation of a cast out cache line to the L2 cache is avoided, thereby decreasing the number of accesses to the L2 cache and improving the performance thereof. In particular, given that history data tends to stabilize after a period of time based upon the likelihood of a given branch always following the same path in future executions, history data will not tend to change very frequently, and thus the number of L2 accesses will be minimized.</p><p>It should be appreciated that a similar operation may be performed to maintain coherence between the L2 and L3 caches if desired, using the same algorithm described above to update directories <b>316</b> and <b>318</b> for L2 cache <b>274</b> and L3 cache <b>276</b>. Moreover, it may be required to implement an additional castout controller in processor <b>272</b> to handle such operations. In the alternative, the cast out operation may be offloaded to a separate component to perform the same functionality.</p><p>Now turning to FIG. 12, a data processing system <b>340</b> is presented to illustrate an additional feature whereby a variable offset in the history data may be provided to enable a processor <b>341</b> to operate with different types of L2 caches. For example, a given processor core design may be used in multiple implementations with L2 caches having different access times relative to the availability of history data. Thus, rather than maintaining a fixed 2-cycle offset as with the embodiments described above in connection with FIGS. 9 and 10, it may be desirable to permit any number of offsets, e.g., 2, 3, 4 or 5 offsets, as necessary. For processor <b>341</b>, this is implemented by utilizing a multiplexing scheme that provides the writeback address for the L1 ICache to be taken from various stages of an execution pipe <b>342</b>.</p><p>Pipe <b>342</b> is illustrated as including six stages, utilizing IAR's <b>370</b>, <b>344</b>, <b>346</b>, <b>348</b>, <b>350</b> and <b>352</b>, and IREG's <b>356</b>, <b>358</b>, <b>360</b>, <b>362</b> and <b>264</b>. A level 1 ICache <b>368</b> is accessed by IAR <b>370</b>, and a compare block <b>372</b> is utilized to verify the prediction made based upon the history data. As with the implementation described in connection with FIG. 9, the branch to address of the instruction stored in the IREG <b>356</b> is utilized as the new history information and the actual (correct) address with which to compare the predicted address. However, instead of taking the output of the instruction address register from only one stage of pipe <b>342</b>, separate address lines output from IREG's <b>344</b>, <b>346</b>, <b>348</b> and <b>350</b> are provided to a select block <b>374</b>, the output of which is fed to compare block <b>372</b> and the write address for L1 ICache <b>368</b>.</p><p>Select block <b>374</b> is controlled via a decoder <b>376</b>, having a state selected by an N-bit register <b>378</b>. In this implementation, with four possible addresses to be output by block <b>374</b>, a 2-bit register may be utilized. It is typically desirable for register <b>378</b> to be loaded at start-up to maintain a fixed number of cycles during the operation of the device. With the configuration shown in FIG. 12, an N value of 0 would represent a 1-cycle offset, with N values of 1, 2 and 3, respectively representing 2-, 3- and 4-cycle offsets. As such, processor <b>341</b> of data processing system <b>340</b> may be utilized in a wider variety of applications.</p><p>Various additional modifications may be made to the illustrated embodiments without departing from the spirit and scope of the invention. For example, it may be desirable, when storing a history address index as history data in an instruction, to inhibit an access to the L2 cache whenever it is detected that a sequential operation will occur\u2014i.e., when it is detected that no branch will occur subsequent to execution of a given instruction. This would further reduce the number of accesses to the L2 cache and thereby increase the relative performance thereof.</p><p>Also, in other implementations, should the history change relatively frequently, it may be desirable to include an additional confirmation bit that indicates that the last change to the history data was useful. Thus, whenever a compare was done, a confirmation bit may be used to indicate that the last change was positive.</p><p>Various additional modifications may be made to the illustrated embodiments without departing from the spirit and scope of the invention. Therefore, the invention lies in the claims hereinafter appended.</p><?DETDESC description=\"Detailed Description\" end=\"tail\"?></description>"}], "inventors": [{"first_name": "David Arnold", "last_name": "Luick", "name": ""}], "assignees": [{"first_name": "", "last_name": "", "name": "INTERNATIONAL BUSINESS MACHINES CORPORATION"}, {"first_name": "", "last_name": "INTERNATIONAL BUSINESS MACHINES CORPORATION", "name": ""}], "ipc_classes": [{"primary": true, "label": "G06F   9/38"}], "locarno_classes": [], "ipcr_classes": [{"label": "G06F   9/30        20060101ALI20051220RMJP"}, {"label": "G06F  12/08        20060101AFI20051220RMJP"}, {"label": "G06F   9/38        20060101A I20051008RMEP"}], "national_classes": [{"primary": true, "label": "712239"}, {"primary": false, "label": "712E09056"}, {"primary": false, "label": "712E09051"}, {"primary": false, "label": "712E09071"}, {"primary": false, "label": "712024"}], "ecla_classes": [{"label": "G06F   9/38B2"}, {"label": "G06F   9/38T"}, {"label": "G06F   9/38E2D"}], "cpc_classes": [{"label": "G06F   9/3804"}, {"label": "G06F   9/3885"}, {"label": "G06F   9/3844"}], "f_term_classes": [], "legal_status": "Expired - Fee Related", "priority_date": "1998-09-01", "application_date": "1998-09-01", "family_members": [{"ucid": "JP-3659340-B2", "titles": [{"lang": "JA", "text": "\u547d\u4ee4\u5c65\u6b74\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3092\u4f7f\u7528\u3057\u3066\u63a8\u6e2c\u7684\u306b\u547d\u4ee4\u3092\u5b9f\u884c\u3059\u308b\u56de\u8def\u3001\u88fd\u54c1\u3001\u304a\u3088\u3073\u305d\u306e\u305f\u3081\u306e\u65b9\u6cd5"}, {"lang": "EN", "text": "Circuit, product, and method for speculatively executing instructions using instruction history caching"}]}, {"ucid": "JP-2000089953-A", "titles": [{"lang": "JA", "text": "\u547d\u4ee4\u5c65\u6b74\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3092\u4f7f\u7528\u3057\u3066\u63a8\u6e2c\u7684\u306b\u547d\u4ee4\u3092\u5b9f\u884c\u3059\u308b\u56de\u8def\u304a\u3088\u3073\u65b9\u6cd5"}, {"lang": "EN", "text": "CIRCUIT AND METHOD INFERENTIALLY EXECUTING INSTRUCTION BY USING INSTRUCTION HISTORY CACHING"}]}, {"ucid": "JP-3412575-B2", "titles": [{"lang": "JA", "text": "\u547d\u4ee4\u5c65\u6b74\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3092\u4f7f\u7528\u3057\u3066\u63a8\u6e2c\u7684\u306b\u547d\u4ee4\u3092\u5b9f\u884c\u3059\u308b\u56de\u8def\u3001\u30c7\u30fc\u30bf\u51e6\u7406\u30b7\u30b9\u30c6\u30e0\u3001\u304a\u3088\u3073\u305d\u306e\u305f\u3081\u306e\u65b9\u6cd5"}, {"lang": "EN", "text": "Circuit for executing instructions speculatively using instruction history caching, data processing system, and method therefor"}]}, {"ucid": "US-6230260-B1", "titles": [{"lang": "EN", "text": "Circuit arrangement and method of speculative instruction execution utilizing instruction history caching"}]}, {"ucid": "JP-2002091761-A", "titles": [{"lang": "JA", "text": "\u547d\u4ee4\u5c65\u6b74\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3092\u4f7f\u7528\u3057\u3066\u63a8\u6e2c\u7684\u306b\u547d\u4ee4\u3092\u5b9f\u884c\u3059\u308b\u56de\u8def\u3001\u88fd\u54c1\u3001\u304a\u3088\u3073\u305d\u306e\u305f\u3081\u306e\u65b9\u6cd5"}, {"lang": "EN", "text": "CIRCUIT, PRODUCT AND METHOD FOR SPECULATIVE INSTRUCTION EXECUTION USING INSTRUCTION HISTORY CACHING"}]}]}